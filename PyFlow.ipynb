{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOaJa7RoeJXSlnFXVvMjRqC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📊 PyFlow: Deep PYUSD Analysis with Google Cloud's Premium RPC Methods\n",
        "\n",
        "**Hackathon Context:** This notebook is developed for the **PayPal x Google Cloud Web3 Bounty**, demonstrating how **Google Cloud Platform's Blockchain Node Engine** unlocks powerful, cost-effective analysis of the **PayPal USD (PYUSD)** stablecoin on Ethereum.\n",
        "\n",
        "---\n",
        "\n",
        "## The Challenge: Unlocking Deep Blockchain Insights\n",
        "\n",
        "Understanding the intricate movements, internal logic, and real-world interactions of stablecoins like **PYUSD** often requires deep, computationally intensive blockchain analysis. Standard block explorers and basic RPC calls provide only surface-level data, while accessing advanced tracing and state inspection methods on most platforms is prohibitively expensive or heavily rate-limited due to their high computational demands.\n",
        "\n",
        "## The Solution: PyFlow leveraging GCP's Advantage\n",
        "\n",
        "This notebook, **PyFlow**, provides a comprehensive toolkit for advanced PYUSD analysis by specifically utilizing **Google Cloud Platform's premium RPC debug and trace methods**.\n",
        "\n",
        "> **🚀 GCP's Unique Offering: Cost-Effective Access to High-Multiplier Methods**\n",
        ">\n",
        "> Many advanced RPC methods carry significant **request multipliers** due to their computational intensity. For example, a method with a `50x` multiplier consumes the equivalent quota/cost of 50 basic calls (like `eth_call`). Methods like `trace_replayTransaction` have an even higher `100x` multiplier.\n",
        ">\n",
        "> **GCP's Blockchain Node Engine stands out by offering generous free quotas even for these high-multiplier methods**, effectively democratizing access to capabilities previously reserved for specialized infrastructure or high budgets.\n",
        "\n",
        "This allows PyFlow to perform analysis typically infeasible elsewhere, such as:\n",
        "\n",
        "*   **Forensic Accounting:** Tracing PYUSD flow through complex multi-contract DeFi interactions using methods like `debug_traceTransaction` (`50x`).\n",
        "*   **Gas Optimization Analysis:** Pinpointing exact gas costs within internal PYUSD functions or integrations.\n",
        "*   **Security Investigations:** Replaying failed transactions (`trace_replayTransaction`, `100x`) or examining state changes (`stateDiff` via replay).\n",
        "*   **Smart Contract Auditing:** Verifying internal logic, storage layout (`debug_storageRangeAt`, `50x`), and event emission (`eth_getLogs`, `50x`).\n",
        "*   **Network Health Insights:** Analyzing pending transaction queues (`txpool_status`, `50x`) and estimating confirmation times.\n",
        "\n",
        "## 🛠️ Methods Explored (with GCP Request Multipliers):\n",
        "\n",
        "This notebook provides practical implementations and analysis using the following GCP-powered methods for PYUSD on Ethereum. Multipliers indicate the relative request cost compared to a standard call:\n",
        "\n",
        "*   **Detailed Tracing:**\n",
        "    *   `debug_traceTransaction` (`50x`): In-depth EVM execution trace (using `callTracer` & `structLog`).\n",
        "    *   `trace_transaction` (`50x`): Alternative transaction tracing method.\n",
        "*   **Block-Level Analysis:**\n",
        "    *   `trace_block` (`50x`, Mainnet only): Trace all transactions within a specified block.\n",
        "    *   `debug_traceBlockByNumber` / `debug_traceBlockByHash` (`50x`): Alternative block tracing.\n",
        "*   **State Replay & Simulation:**\n",
        "    *   `trace_replayTransaction` (`100x`, Mainnet only): Re-execute a past transaction with tracers.\n",
        "    *   `trace_replayBlockTransactions` (`100x`, Mainnet only): Re-execute all transactions in a block with tracers.\n",
        "    *   `trace_call` (`50x`, Mainnet only): Simulate transaction calls without sending to the network.\n",
        "*   **State & Data Retrieval:**\n",
        "    *   `eth_getLogs` (`50x`): Efficiently fetch specific PYUSD events (e.g., Transfers, Approvals).\n",
        "    *   `eth_getCode` (`10x`): Retrieve deployed contract bytecode.\n",
        "    *   `debug_storageRangeAt` (`50x`): Inspect raw contract storage slots.\n",
        "    *   `eth_getProof` (`50x`): Fetch Merkle proofs for state verification.\n",
        "*   **Network Monitoring:**\n",
        "    *   `txpool_status` (`50x`): Analyze pending/queued transaction counts.\n",
        "\n",
        "*(Note: Multipliers are based on GCP documentation and highlight the computational intensity absorbed by the service.)*\n",
        "\n",
        "---\n",
        "\n",
        "**💡 Goal:** By the end of this notebook, you will understand how to leverage GCP's unique RPC capabilities, including high-multiplier methods offered with generous quotas, to perform advanced, cost-effective blockchain intelligence specifically tailored for the PYUSD stablecoin.\n"
      ],
      "metadata": {
        "id": "F-UdW5sIniuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🛠️ Environment Setup: Installing Dependencies for PyFlow\n",
        "---\n",
        "\n",
        "This cell installs the necessary Python packages to run the PyFlow analysis notebook. It sets up a complete environment for interacting with the Ethereum blockchain (via GCP), analyzing PYUSD data, generating visualizations, and connecting to Google Cloud services.\n",
        "\n",
        "### 📊 Key Dependencies & Purpose:\n",
        "\n",
        "| Category                 | Packages                                                       | Purpose                                                             |\n",
        "| :----------------------- | :------------------------------------------------------------- | :------------------------------------------------------------------ |\n",
        "| **Core Blockchain/Data** | `web3`, `pandas`, `numpy`                                    | Ethereum RPC interaction, data manipulation                         |\n",
        "| **Visualization**        | `matplotlib`, `plotly`, `seaborn`, `networkx`, `graphviz`    | Charts, transaction graphs, visual analysis                         |\n",
        "| **Google Cloud**         |  `gspread`, `oauth2client` | Accessing Google Sheets export, Authentication |\n",
        "| **Ethereum Utilities**   | `eth-utils`, `rlp`, `tqdm`                                   | Cryptographic functions, RLP encoding, progress bars                |\n",
        "| **Notebook Enhancement** | `ipywidgets`, `rich`                                         | Interactive controls, improved console output                     |\n",
        "\n",
        "### ⚙️ Runtime Notes:\n",
        "\n",
        "*   **Environment:** Designed primarily for Google Colab.\n",
        "*   **Resources:** A standard Colab runtime is usually sufficient, but a High-RAM runtime is recommended for analyzing very large blocks or complex transaction traces. GPU is generally not required.\n",
        "*   **Colab Features:** The setup automatically installs system-level `graphviz` and enables interactive data tables within Colab.\n",
        "\n",
        "> **⏳ Installation Time:** The process uses `pip` and typically completes in **1-2 minutes**. Please ensure this cell executes successfully before proceeding."
      ],
      "metadata": {
        "id": "Zn0aZAlQop7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# 🛠️ Environment Setup and Package Installation\n",
        "# =============================================================================================\n",
        "# This cell installs and configures all necessary packages for blockchain data analysis.\n",
        "# The setup process may take 1-2 minutes to complete.\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",          # Informational messages\n",
        "    \"success\": \"spring_green3\", # Success indicators\n",
        "    \"warning\": \"gold3\",       # Warning messages\n",
        "    \"error\": \"red3\",          # Error messages\n",
        "    \"highlight\": \"royal_blue1\"  # Highlighted information\n",
        "})\n",
        "\n",
        "# Create console with auto color system detection for better visual feedback\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "console.print(\"\\n✨ Environment Setup and Package Installation ✨\", style=\"bold cyan3\")\n",
        "console.print(\"─────────────────────────────────────────────────\", style=\"cyan3\")\n",
        "\n",
        "console.print(\"🔄 Starting package installation process...\", style=\"info\")\n",
        "\n",
        "# Function to install packages and handle errors with better formatting\n",
        "# This provides visual feedback during the installation process\n",
        "def install_packages(packages, description):\n",
        "    \"\"\"Install specified packages with progress indicator and error handling\"\"\"\n",
        "    with Progress(\n",
        "        SpinnerColumn(),\n",
        "        TextColumn(f\"[info]Installing {description}...\"),\n",
        "        transient=True,\n",
        "    ) as progress:\n",
        "        task = progress.add_task(\"\", total=None)\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages.split())\n",
        "            console.print(f\"✓ {description} installed\", style=\"success\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError:\n",
        "            console.print(f\"❌ Error installing {description}\", style=\"error\")\n",
        "            return False\n",
        "\n",
        "# =============================================================================================\n",
        "# Core Libraries Installation\n",
        "# =============================================================================================\n",
        "\n",
        "# Install core data processing libraries\n",
        "# - web3: For blockchain interaction and smart contract calls\n",
        "# - pandas: For data manipulation and analysis\n",
        "# - numpy: For numerical operations\n",
        "# - matplotlib: For basic visualization\n",
        "success = install_packages(\"web3==6.11.1 pandas numpy matplotlib\",\n",
        "                         \"Core data libraries (web3, pandas, numpy, matplotlib)\")\n",
        "\n",
        "# Install advanced visualization and analysis libraries\n",
        "# - plotly: For interactive charts\n",
        "# - seaborn: For statistical visualizations\n",
        "# - networkx: For blockchain transaction network analysis\n",
        "if success:\n",
        "    success = install_packages(\"plotly seaborn networkx\",\n",
        "                             \"Visualization and analysis libraries (plotly, seaborn, networkx)\")\n",
        "\n",
        "# Install visualization export libraries\n",
        "# - kaleido: For high-quality Plotly chart exports to PNG/PDF/SVG\n",
        "if success:\n",
        "    success = install_packages(\"kaleido\",\n",
        "                             \"Visualization export library (required for exporting charts to images)\")\n",
        "\n",
        "# Install Google API libraries for data access and storage\n",
        "# - gspread: For Google Sheets integration\n",
        "# - oauth2client: For authentication with Google services\n",
        "if success:\n",
        "    success = install_packages(\"gspread oauth2client\",\n",
        "                             \"Google API libraries (gspread, oauth2client)\")\n",
        "\n",
        "# Install interactive widgets for Jupyter/Colab notebooks\n",
        "# - ipywidgets: For creating interactive controls and dashboards\n",
        "if success:\n",
        "    success = install_packages(\"ipywidgets\",\n",
        "                             \"Interactive widgets for Jupyter notebooks\")\n",
        "\n",
        "# Install Ethereum proof verification and analysis libraries\n",
        "# - eth-utils: For cryptographic functions and general Ethereum utilities\n",
        "# - rlp: For Recursive Length Prefix encoding used in Ethereum\n",
        "# - tqdm: For progress visualization in notebook environments\n",
        "# - graphviz: For visualizing Merkle proofs and contract structures\n",
        "if success:\n",
        "    success = install_packages(\"eth-utils rlp tqdm graphviz\",\n",
        "                             \"Ethereum proof verification libraries\")\n",
        "\n",
        "# For Colab environments, install system-level graphviz for visualization\n",
        "\n",
        "try:\n",
        "    # Check if running in Google Colab\n",
        "    import google.colab\n",
        "    console.print(\"\\n\\n🔄 Installing system dependencies for visualization...\", style=\"info\")\n",
        "    # Install graphviz system package (used for rendering graphs)\n",
        "    subprocess.check_call(['apt-get', '-qq', 'install', 'graphviz'])\n",
        "    console.print(\"✓ System-level graphviz installed for advanced visualizations\", style=\"success\")\n",
        "\n",
        "    # Enable enhanced data visualization and export capabilities\n",
        "    console.print(\"\\n\\n🔄 Enabling enhanced data visualization and export...\", style=\"info\")\n",
        "\n",
        "    # Enable interactive data tables from Google Colab\n",
        "    try:\n",
        "        from google.colab import data_table\n",
        "        data_table.enable_dataframe_formatter()\n",
        "        console.print(\"✓ Interactive data tables enabled\", style=\"success\")\n",
        "    except ImportError:\n",
        "        console.print(\"⚠️ Could not enable interactive data tables\", style=\"warning\")\n",
        "\n",
        "    # Import additional components for file exports and Google Sheets integration\n",
        "    try:\n",
        "        # For direct CSV/JSON downloads\n",
        "        import base64\n",
        "        import io\n",
        "\n",
        "        # For Google Sheets export\n",
        "        from google.colab import output\n",
        "        from googleapiclient.discovery import build\n",
        "        from googleapiclient.http import MediaInMemoryUpload\n",
        "\n",
        "        console.print(\"✓ Export functionality enabled\", style=\"success\")\n",
        "    except ImportError:\n",
        "        console.print(\"⚠️ Some export functions may be limited\", style=\"warning\")\n",
        "\n",
        "    # Verify data table display\n",
        "    try:\n",
        "        from IPython.display import display, HTML\n",
        "        console.print(\"✓ Data table display verified\", style=\"success\")\n",
        "    except:\n",
        "        console.print(\"⚠️ Data table display verification failed\", style=\"warning\")\n",
        "\n",
        "except ImportError:\n",
        "    console.print(\"ℹ️ Not running in Colab, skipping system-level installations\", style=\"info\")\n",
        "except Exception as e:\n",
        "    console.print(f\"⚠️ Note: Could not install graphviz system package: {e}. Some visualizations may be limited.\", style=\"warning\")\n",
        "\n",
        "# Final status message with extra spacing\n",
        "if success:\n",
        "    console.print(\"\\n\\n📦 ✓ All required packages installed successfully!\", style=\"success\")\n",
        "else:\n",
        "    console.print(\"\\n\\n⚠️ [bold]Some packages failed to install. Please check the errors above.[/bold]\", style=\"warning\")\n",
        "\n",
        "# =============================================================================================\n",
        "# Environment Verification\n",
        "# =============================================================================================\n",
        "# Verify all packages imported correctly and set up the analytics environment\n",
        "\n",
        "try:\n",
        "    # Core data and utility libraries\n",
        "    import os\n",
        "    import json\n",
        "    import time\n",
        "    import warnings\n",
        "    import hashlib\n",
        "\n",
        "    # Data analysis stack\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    # Network and graph analysis\n",
        "    import networkx as nx\n",
        "\n",
        "    # Visualization libraries\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "\n",
        "    # Date handling\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    # Collections and data structures\n",
        "    from collections import defaultdict, Counter\n",
        "\n",
        "    # Blockchain interaction libraries\n",
        "    from web3 import Web3\n",
        "    from web3.exceptions import TransactionNotFound\n",
        "    from web3.middleware import geth_poa_middleware\n",
        "    from hexbytes import HexBytes\n",
        "\n",
        "    # Google Cloud and authentication (for gspread)\n",
        "    from google.colab import auth # Kept for potential gspread auth if needed in Colab\n",
        "    from google.oauth2 import service_account\n",
        "    import gspread\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "    # Import ipywidgets components for interactive dashboards\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "    # Rich components for improved CLI-style output\n",
        "    from rich.panel import Panel\n",
        "    from rich.syntax import Syntax\n",
        "    from rich.table import Table\n",
        "\n",
        "    # Ethereum specific utilities for cryptography and data structures\n",
        "    from eth_utils import keccak, to_bytes, to_hex\n",
        "    import rlp\n",
        "    from tqdm.notebook import tqdm\n",
        "    from graphviz import Digraph\n",
        "\n",
        "    # Suppress warnings for cleaner output\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # Configure pandas display settings for better readability\n",
        "    pd.set_option('display.max_columns', None)  # Show all columns\n",
        "    pd.set_option('display.max_rows', 100)      # Reasonable number of rows\n",
        "    pd.set_option('display.float_format', '{:.6f}'.format)  # Format for amounts\n",
        "\n",
        "    # Setup Plotly for better Jupyter/Colab integration\n",
        "    import plotly.io as pio\n",
        "    pio.templates.default = \"plotly_white\"\n",
        "\n",
        "    console.print(\"\\n\\n🚀 ✓ Setup complete! Analytics platform initialized.\", style=\"success\")\n",
        "except ImportError as e:\n",
        "    console.print(f\"\\n\\n❌ Error importing libraries: {e}\", style=\"error\")\n",
        "    console.print(\"⚠️ Some required packages may not have been installed correctly.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "jDFZ9R4Iotee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔑 Configuration & Authentication: Connecting to GCP and Ethereum RPC\n",
        "---\n",
        "\n",
        "This crucial cell configures PyFlow to connect to Google Cloud Platform services (for authentication and Google Sheets) and the necessary Ethereum networks via GCP's Blockchain Node Engine. **You MUST edit this cell with your specific credentials before running it.**\n",
        "\n",
        "### 📋 Step 1: Provide Your GCP Credentials\n",
        "\n",
        "To use GCP's Blockchain RPC and potentially Google Sheets, you need:\n",
        "\n",
        "1.  **Your GCP Project ID:**\n",
        "    *   **Purpose:** Identifies your Google Cloud project, primarily used here to scope authentication requests for Google Drive/Sheets access.\n",
        "    *   **How to Obtain:** If you don't have one, create it at [GCP Console](https://console.cloud.google.com/projectcreate).\n",
        "    *   **➡️ ACTION REQUIRED:** Find the `GCP_PROJECT_ID` variable in the code below and replace `\"YOUR_PROJECT_ID\"` with your actual Project ID string.\n",
        "2.  **Your GCP Blockchain RPC Endpoints (with API Key):**\n",
        "    *   **Purpose:** Secure URLs to connect to Ethereum Mainnet and testnets via GCP. This is key to interacting with the blockchain using `web3.py`.\n",
        "    *   **How to Obtain:**\n",
        "        1.  Go to the [GCP Blockchain Node Engine Console](https://console.cloud.google.com/blockchain/node-engine) in your project.\n",
        "        2.  Enable the API if you haven't already.\n",
        "        3.  Copy the **full HTTPS RPC endpoint URL** (including `?key=...`) for **Ethereum Mainnet**. Optionally, copy URLs for testnets (Holesky, Sepolia) if needed.\n",
        "    *   **➡️ ACTION REQUIRED:** Find the `BLOCKCHAIN_RPC` dictionary in the code below. Replace the placeholder URLs (e.g., `\"https://blockchain.googleapis.com/...\"`) with your *complete* copied endpoint URLs for `'mainnet'`, `'holesky'`, and `'sepolia'`.\n",
        "\n",
        "    *Example Format (Use your actual URLs):*\n",
        "    ```python\n",
        "    BLOCKCHAIN_RPC = {\n",
        "        'ethereum': {\n",
        "            'mainnet': 'https://YOUR_MAINNET_ENDPOINT_URL?key=YOUR_API_KEY',\n",
        "            # Optional testnets:\n",
        "            'holesky': 'https://YOUR_HOLESKY_ENDPOINT_URL?key=YOUR_API_KEY',\n",
        "            'sepolia': 'https://YOUR_SEPOLIA_ENDPOINT_URL?key=YOUR_API_KEY'\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "\n",
        "### 🌐 Step 2: Enable Required GCP APIs\n",
        "\n",
        "Ensure the following APIs are **enabled** in your GCP Project *before* running this cell for authentication and Google Sheets integration to work correctly:\n",
        "\n",
        "*   **Blockchain Node Engine API:** ([Enable Link](Coming Soon))\n",
        "*   **Google Drive API:** Required for Google Sheets export/import functionality via `gspread`. ([Enable Link](https://console.cloud.google.com/apis/library/drive.googleapis.com))\n",
        "*   **Google Sheets API:** Required for Google Sheets export/import functionality via `gspread`. ([Enable Link](https://console.cloud.google.com/apis/library/sheets.googleapis.com))\n",
        "\n",
        "> #### **💡Tip: Follow README for Video Instructions.**\n",
        "\n",
        "### 🔐 Step 3: Run the Cell & Authenticate\n",
        "\n",
        "When you execute the code cell below:\n",
        "\n",
        "1.  It will define constants (like PYUSD contract addresses) and configurations (trace settings).\n",
        "2.  It will attempt to **authenticate** your Google account (via a pop-up in Colab) to grant access to the enabled GCP services needed for Google Sheets (Drive, Sheets). Follow the prompts.\n",
        "3.  It will initialize `web3.py` clients using your provided RPC endpoints.\n",
        "4.  It will initialize a client for Google Sheets (`gspread`).\n",
        "5.  It will perform **connection tests** (check RPC node block height) and display a status summary.\n",
        "\n",
        "> **⚠️ IMPORTANT:** Double-check that you have replaced the placeholder `GCP_PROJECT_ID` and the **full** `BLOCKCHAIN_RPC` URLs before running. The notebook relies heavily on a successful connection to the **Ethereum Mainnet** endpoint via GCP for most subsequent analysis."
      ],
      "metadata": {
        "id": "caZ8zeBkpW9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# 📋 Configuration and Authentication for Blockchain Analytics\n",
        "# =============================================================================================\n",
        "# This cell configures & Authenticates for blockchain data analysis.\n",
        "\n",
        "# Import necessary libraries\n",
        "import google.auth\n",
        "\n",
        "try:\n",
        "    from google.colab import auth\n",
        "except ImportError:\n",
        "    auth = None\n",
        "    print(\"Note: Not running in Google Colab, standard gcloud auth will be used if available.\")\n",
        "\n",
        "import gspread\n",
        "from web3 import Web3\n",
        "from web3.middleware import geth_poa_middleware\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn, TimeElapsedColumn\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",\n",
        "    \"success\": \"spring_green3\",\n",
        "    \"warning\": \"gold3\",\n",
        "    \"error\": \"red3\",\n",
        "    \"highlight\": \"royal_blue1\"\n",
        "})\n",
        "\n",
        "# Ensure console is created with the theme\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# =============================================================================================\n",
        "# Contract Configuration: PYUSD Stablecoin Addresses\n",
        "# =============================================================================================\n",
        "\n",
        "# Main PYUSD Contract addresses (used for querying transactions and events)\n",
        "PYUSD_PROXY = Web3.to_checksum_address('0x6c3ea9036406852006290770bedfcaba0e23a0e8')\n",
        "PYUSD_IMPLEMENTATION = Web3.to_checksum_address('0x8EcaE0B0402E29694B3Af35d5943D4631Ee568dC')\n",
        "SUPPLY_CONTROL_PROXY = Web3.to_checksum_address('0x31d9bDEa6F104606C954f8FE6ba614F1BD347Ec3')\n",
        "SUPPLY_CONTROL_IMPLEMENTATION = Web3.to_checksum_address('0xFaB5891ED867a1195303251912013b92c4fc3a1D')\n",
        "\n",
        "# PYUSD Contract Registry with implementation contracts\n",
        "PYUSD_CONTRACTS = {\n",
        "    PYUSD_PROXY.lower(): \"PYUSD Token\",\n",
        "    PYUSD_IMPLEMENTATION.lower(): \"PYUSD Implementation\",\n",
        "    SUPPLY_CONTROL_PROXY.lower(): \"Supply Control\",\n",
        "    SUPPLY_CONTROL_IMPLEMENTATION.lower(): \"Supply Control Impl\"\n",
        "}\n",
        "\n",
        "# Define event topics first\n",
        "TRANSFER_EVENT_TOPIC = Web3.keccak(text=\"Transfer(address,address,uint256)\").hex()\n",
        "APPROVAL_EVENT_TOPIC = Web3.keccak(text=\"Approval(address,address,uint256)\").hex()\n",
        "PAUSED_EVENT_TOPIC = Web3.keccak(text=\"Paused(address)\").hex()\n",
        "UNPAUSED_EVENT_TOPIC = Web3.keccak(text=\"Unpaused(address)\").hex()\n",
        "\n",
        "# Comprehensive PYUSD configuration\n",
        "PYUSD_CONFIG = {\n",
        "    'ethereum': {\n",
        "        'address': PYUSD_PROXY,\n",
        "        'implementation': PYUSD_IMPLEMENTATION,\n",
        "        'decimals': 6,\n",
        "        'symbol': 'PYUSD',\n",
        "        'deployment_block': 15921958,\n",
        "        'transfer_event_topic': TRANSFER_EVENT_TOPIC,\n",
        "        'approval_event_topic': APPROVAL_EVENT_TOPIC,\n",
        "        'pause_event_topic': PAUSED_EVENT_TOPIC,\n",
        "        'unpause_event_topic': UNPAUSED_EVENT_TOPIC\n",
        "    }\n",
        "}\n",
        "\n",
        "PYUSD_ADDRESS_LOWER_ETH = PYUSD_CONFIG['ethereum']['address'].lower()\n",
        "\n",
        "# PYUSD Function Signature Registry\n",
        "PYUSD_SIGNATURES = {\n",
        "    '0xa9059cbb': {\"name\": \"transfer(address,uint256)\", \"type\": \"function\", \"category\": \"token_movement\"},\n",
        "    '0x095ea7b3': {\"name\": \"approve(address,uint256)\", \"type\": \"function\", \"category\": \"allowance\"},\n",
        "    '0x23b872dd': {\"name\": \"transferFrom(address,address,uint256)\", \"type\": \"function\", \"category\": \"token_movement\"},\n",
        "    '0x40c10f19': {\"name\": \"mint(address,uint256)\", \"type\": \"function\", \"category\": \"supply_change\"},\n",
        "    '0x42966c68': {\"name\": \"burn(uint256)\", \"type\": \"function\", \"category\": \"supply_change\"},\n",
        "    '0x18160ddd': {\"name\": \"totalSupply()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x70a08231': {\"name\": \"balanceOf(address)\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0xdd62ed3e': {\"name\": \"allowance(address,address)\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x313ce567': {\"name\": \"decimals()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x06fdde03': {\"name\": \"name()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x95d89b41': {\"name\": \"symbol()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x8456cb59': {\"name\": \"pause()\", \"type\": \"function\", \"category\": \"control\"},\n",
        "    '0x3f4ba83a': {\"name\": \"unpause()\", \"type\": \"function\", \"category\": \"control\"},\n",
        "    '0x5c975abb': {\"name\": \"paused()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0xf2fde38b': {\"name\": \"transferOwnership(address)\", \"type\": \"function\", \"category\": \"admin\"},\n",
        "    '0x8da5cb5b': {\"name\": \"owner()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x715018a6': {\"name\": \"renounceOwnership()\", \"type\": \"function\", \"category\": \"admin\"}\n",
        "}\n",
        "\n",
        "# PYUSD Event Signature Registry with decoders - using the defined event topics\n",
        "PYUSD_EVENTS = {\n",
        "    TRANSFER_EVENT_TOPIC: {\n",
        "        \"name\": \"Transfer(address,address,uint256)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"from\": Web3.to_checksum_address('0x' + topics[1][-40:]),\n",
        "            \"to\": Web3.to_checksum_address('0x' + topics[2][-40:]),\n",
        "            \"value\": int(data, 16)\n",
        "        }\n",
        "    },\n",
        "    APPROVAL_EVENT_TOPIC: {\n",
        "        \"name\": \"Approval(address,address,uint256)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"owner\": Web3.to_checksum_address('0x' + topics[1][-40:]),\n",
        "            \"spender\": Web3.to_checksum_address('0x' + topics[2][-40:]),\n",
        "            \"value\": int(data, 16)\n",
        "        }\n",
        "    },\n",
        "    PAUSED_EVENT_TOPIC: {\n",
        "        \"name\": \"Paused(address)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"account\": Web3.to_checksum_address('0x' + topics[1][-40:]) if len(topics) > 1 else None\n",
        "        }\n",
        "    },\n",
        "    UNPAUSED_EVENT_TOPIC: {\n",
        "        \"name\": \"Unpaused(address)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"account\": Web3.to_checksum_address('0x' + topics[1][-40:]) if len(topics) > 1 else None\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Tracing configurations\n",
        "TRACE_CONFIGS = {\n",
        "    \"callTracer\": {\n",
        "        \"withLog\": True,\n",
        "        \"enableReturnData\": True,\n",
        "        \"enableMemory\": True,\n",
        "        \"enableStack\": True\n",
        "    },\n",
        "    \"structLog\": {\n",
        "        \"disableStorage\": False,\n",
        "        \"disableMemory\": False,\n",
        "        \"disableStack\": False,\n",
        "        \"fullStorage\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "# Gas analysis categories\n",
        "GAS_CATEGORIES = {\n",
        "    \"token_movement\": [\"transfer\", \"transferFrom\"],\n",
        "    \"supply_change\": [\"mint\", \"burn\"],\n",
        "    \"allowance\": [\"approve\", \"increaseAllowance\", \"decreaseAllowance\"],\n",
        "    \"control\": [\"pause\", \"unpause\"],\n",
        "    \"admin\": [\"transferOwnership\", \"renounceOwnership\", \"addMinter\", \"removeMinter\"],\n",
        "    \"view\": [\"balanceOf\", \"allowance\", \"totalSupply\", \"decimals\", \"name\", \"symbol\", \"paused\", \"owner\"],\n",
        "    \"other\": []\n",
        "}\n",
        "\n",
        "\n",
        "# =============================================================================================\n",
        "# Data Source Configuration: Google Cloud & Blockchain RPC\n",
        "# =============================================================================================\n",
        "\n",
        "# Replace \"YOUR_PROJECT_ID\" with your actual GCP Project ID (needed for GSheets auth scope)\n",
        "GCP_PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
        "if \"YOUR_PROJECT_ID\" in GCP_PROJECT_ID or not GCP_PROJECT_ID:\n",
        "    console.print(\"[error]🚨 CRITICAL: Please replace placeholder or provide your actual GCP Project ID in GCP_PROJECT_ID.\", style=\"bold red\")\n",
        "\n",
        "# Replace \"YOUR_MAINNET_BLOCKCHAIN_RPC_URL\", \"YOUR_HOLESKY_BLOCKCHAIN_RPC_URL\", \"YOUR_SEPOLIA_BLOCKCHAIN_RPC_URL\" with your FULL RPC endpoint URLs including your API key.\n",
        "# e.g., 'mainnet': 'https://blockchain.googleapis.com/v1/projects/...........'\n",
        "BLOCKCHAIN_RPC = {\n",
        "    'ethereum': {\n",
        "        'holesky': 'YOUR_HOLESKY_BLOCKCHAIN_RPC_URL',\n",
        "        'mainnet': 'YOUR_MAINNET_BLOCKCHAIN_RPC_URL',\n",
        "        'sepolia': 'YOUR_SEPOLIA_BLOCKCHAIN_RPC_URL'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Basic Validation checks for placeholders in URLs\n",
        "rpc_urls_valid = True\n",
        "if 'ethereum' not in BLOCKCHAIN_RPC or not BLOCKCHAIN_RPC['ethereum']: # Check if ethereum key exists and has entries\n",
        "    console.print(\"[error]🚨 CRITICAL: BLOCKCHAIN_RPC['ethereum'] is missing or empty.\", style=\"bold red\")\n",
        "    rpc_urls_valid = False\n",
        "else:\n",
        "    for network, url in BLOCKCHAIN_RPC.get('ethereum', {}).items():\n",
        "        # More robust check for placeholders or incomplete URLs\n",
        "        if not url or \"xxx\" in url.lower() or \"/v1/\" not in url or \"key=\" not in url or url.endswith(\"key=\"):\n",
        "            console.print(f\"[error]🚨 CRITICAL: RPC URL for '{network}' seems invalid or uses placeholder ('{url}'). Use full URL with API key.\", style=\"bold red\")\n",
        "            rpc_urls_valid = False\n",
        "\n",
        "# Transaction tracing configuration (for detailed transaction analysis)\n",
        "# Increased timeout for complex traces\n",
        "DEFAULT_TRACE_CONFIG = {\n",
        "    'tracer': 'callTracer',\n",
        "    'timeout': '120s',\n",
        "    'tracerConfig': {\n",
        "        'onlyTopCall': False,\n",
        "        'withLog': True,\n",
        "    }\n",
        "}\n",
        "\n",
        "STRUCTLOG_TRACE_CONFIG = {\n",
        "    'tracer': 'structLog',\n",
        "    # 'timeout': '120s',\n",
        "}\n",
        "\n",
        "# =============================================================================================\n",
        "# Global Client Variables\n",
        "# =============================================================================================\n",
        "gc_sheets = None\n",
        "w3_clients = {}\n",
        "\n",
        "# =============================================================================================\n",
        "# Utility Functions: Testing & System Verification\n",
        "# =============================================================================================\n",
        "\n",
        "def authenticate_gcp(progress, task_id):\n",
        "    \"\"\"Authenticate to GCP, initialize Google Sheets client (updates progress descriptively).\"\"\"\n",
        "    global gc_sheets\n",
        "    progress.update(task_id, description=\"[info]Initiating GCP Authentication...\")\n",
        "    if not GCP_PROJECT_ID or \"project_id\" in GCP_PROJECT_ID:\n",
        "         progress.update(task_id, description=\"[error]GCP Auth Failed (No Project ID)\")\n",
        "         return False\n",
        "    auth_success = False\n",
        "    gs_init_success = False\n",
        "    effective_project_id = GCP_PROJECT_ID\n",
        "\n",
        "    try:\n",
        "        # Step 1: Authentication (Colab vs. Default)\n",
        "        creds = None\n",
        "        if auth: # If google.colab.auth was imported successfully\n",
        "            progress.update(task_id, description=\"[info]Waiting for Colab user authentication...\")\n",
        "            auth.authenticate_user(project_id=effective_project_id) # Use project ID here if needed by Colab auth context\n",
        "            auth_success = True\n",
        "            progress.update(task_id, description=\"[info]Colab user authenticated. Getting credentials...\")\n",
        "            creds, _ = google.auth.default() # Get default credentials after Colab auth\n",
        "        else:\n",
        "            # Attempt standard ADC (Application Default Credentials) - works in VM, Cloud Shell, local gcloud auth login\n",
        "            progress.update(task_id, description=\"[info]Attempting default GCP authentication...\")\n",
        "            try:\n",
        "                creds, inferred_project_id = google.auth.default()\n",
        "                if not creds:\n",
        "                     raise Exception(\"Could not get default credentials.\")\n",
        "                auth_success = True\n",
        "                progress.update(task_id, description=\"[info]Default GCP credentials obtained.\")\n",
        "            except Exception as adc_error:\n",
        "                progress.update(task_id, description=\"[error]Default GCP Authentication Failed!\")\n",
        "                console.print(f\"❌ Default GCP Auth error: {adc_error}\", style=\"error\")\n",
        "                return False # Hard stop if auth fails\n",
        "\n",
        "        # Ensure we have credentials before proceeding\n",
        "        if not creds:\n",
        "             progress.update(task_id, description=\"[error]Credentials not obtained after auth attempt.\")\n",
        "             return False\n",
        "\n",
        "        # Step 2: Initialize Google Sheets Client\n",
        "        progress.update(task_id, description=\"[info]Initializing Google Sheets client...\")\n",
        "        gc_sheets = gspread.authorize(creds)\n",
        "        # Perform a minimal check (e.g., list spreadsheets) if needed, but authorize usually suffices\n",
        "        # gc_sheets.list_spreadsheet_files(max_results=1)\n",
        "        gs_init_success = True\n",
        "\n",
        "        progress.update(task_id, description=\"[success]GCP Authentication & GSheets Client Initialized\")\n",
        "        return True # Overall success\n",
        "\n",
        "    except Exception as e:\n",
        "        error_stage = \"GCP Setup Error!\"\n",
        "        if not auth_success:\n",
        "            error_stage = \"GCP Authentication Failed!\"\n",
        "        elif not gs_init_success:\n",
        "            error_stage = \"Google Sheets Client Init Failed!\"\n",
        "        progress.update(task_id, description=f\"[error]{error_stage}\")\n",
        "        console.print(f\"❌ {error_stage}: {str(e)}\", style=\"error\")\n",
        "        if not gs_init_success: gc_sheets = None\n",
        "        return False\n",
        "\n",
        "\n",
        "def initialize_all_web3_clients(progress, task_id):\n",
        "    \"\"\"Initializes Web3 clients for all networks (updates progress descriptively).\"\"\"\n",
        "    global w3_clients\n",
        "    progress.update(task_id, description=\"[info]Initializing Web3 Clients...\")\n",
        "    w3_clients = {}\n",
        "    success_count = 0\n",
        "    total_networks = 0\n",
        "    if 'ethereum' not in BLOCKCHAIN_RPC or not BLOCKCHAIN_RPC['ethereum']:\n",
        "        progress.update(task_id, description=\"[error]No valid RPC Config found!\")\n",
        "        return False\n",
        "    total_networks = len(BLOCKCHAIN_RPC['ethereum'])\n",
        "    network_statuses = []\n",
        "\n",
        "    for network, rpc_url in BLOCKCHAIN_RPC['ethereum'].items():\n",
        "        progress.update(task_id, description=f\"[info]Connecting to {network.capitalize()}...\")\n",
        "        time.sleep(0.1) # Small delay for visual update\n",
        "        # Find the original url value before the loop modified it\n",
        "        original_url = BLOCKCHAIN_RPC.get('ethereum', {}).get(network, \"\")\n",
        "        is_invalid_url = not original_url or \"xxx\" in original_url.lower() or \"/v1/\" not in original_url or \"key=\" not in original_url or original_url.endswith(\"key=\")\n",
        "        if is_invalid_url:\n",
        "            w3_clients[network] = None\n",
        "            network_statuses.append(f\"{network.capitalize()}:[error]Skipped (Invalid URL)[/error]\")\n",
        "            progress.update(task_id, description=f\"[warning]Skipping {network.capitalize()} (Invalid URL)...\")\n",
        "            continue\n",
        "        try:\n",
        "            # Increased timeout slightly for potentially slower network conditions\n",
        "            provider = Web3.HTTPProvider(rpc_url, request_kwargs={'timeout': 120})\n",
        "            w3_client = Web3(provider)\n",
        "            # Inject middleware only if needed (e.g., for PoA testnets like Goerli, Rinkeby - less relevant for Mainnet/Sepolia/Holesky now)\n",
        "            # Check chain ID if necessary to decide on middleware, but generally safe to add\n",
        "            w3_client.middleware_onion.inject(geth_poa_middleware, layer=0)\n",
        "\n",
        "            # Test connection with get_block_number\n",
        "            block_num = w3_client.eth.get_block_number()\n",
        "            w3_clients[network] = w3_client\n",
        "            success_count += 1\n",
        "            network_statuses.append(f\"{network.capitalize()}:[success]OK (Block: {block_num:,})[/success]\")\n",
        "            progress.update(task_id, description=f\"[info]Connecting... ({success_count}/{total_networks} OK)\")\n",
        "        except Exception as e:\n",
        "            error_short = type(e).__name__\n",
        "            # Add more detail for common errors\n",
        "            if \"Max retries exceeded\" in str(e): error_short = \"ConnectionTimeout\"\n",
        "            elif \"Failed to establish a new connection\" in str(e): error_short = \"ConnectionRefused\"\n",
        "            network_statuses.append(f\"{network.capitalize()}:[error]{error_short}[/error]\")\n",
        "            w3_clients[network] = None\n",
        "            progress.update(task_id, description=f\"[warning]Failed {network.capitalize()} ({error_short})...\")\n",
        "            console.print(f\"[warning]Web3 connection error for {network.capitalize()}: {e}\", style=\"warning\")\n",
        "\n",
        "\n",
        "    final_web3_status = f\"[success]Web3 Clients Initialized ({success_count}/{total_networks} OK)\"\n",
        "    if success_count == 0:\n",
        "        final_web3_status = \"[error]Web3 Client Init Failed (All Networks)\"\n",
        "    elif success_count < total_networks:\n",
        "         final_web3_status = f\"[warning]Web3 Clients Initialized ({success_count}/{total_networks} OK)\"\n",
        "    progress.update(task_id, description=final_web3_status)\n",
        "\n",
        "    # Return True if mainnet client initialized successfully\n",
        "    return w3_clients.get('mainnet') is not None\n",
        "\n",
        "# =============================================================================================\n",
        "# Main Execution: System Initialization and Status Check (with Progress)\n",
        "# =============================================================================================\n",
        "\n",
        "# --- Title Display ---\n",
        "console.print(\"\\n✨ Configuration and Authentication ✨\", style=\"bold cyan3\")\n",
        "console.print(\"───────────────────────────────────────\", style=\"cyan3\")\n",
        "\n",
        "# Initialize status variables\n",
        "gcp_auth_success = False\n",
        "any_web3_success = False\n",
        "mainnet_ready = False\n",
        "\n",
        "# Use Rich Progress for initialization steps\n",
        "# Set transient=True to make the progress bar disappear on completion\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    TimeElapsedColumn(),\n",
        "    console=console, # Ensure progress uses the themed console\n",
        "    transient=True # Make spinner disappear when done\n",
        ") as progress:\n",
        "    # Add tasks for each step (total=1 means they complete in one update)\n",
        "    auth_task = progress.add_task(\"GCP Authentication...\", total=1)\n",
        "    web3_task = progress.add_task(\"Initializing Web3 Clients...\", total=1)\n",
        "\n",
        "    # --- Run Initialization Steps (functions update progress description) ---\n",
        "    gcp_auth_success = authenticate_gcp(progress, auth_task)\n",
        "    progress.update(auth_task, completed=1) # Mark as done\n",
        "\n",
        "    if rpc_urls_valid:\n",
        "        any_web3_success = initialize_all_web3_clients(progress, web3_task)\n",
        "    else:\n",
        "        progress.update(web3_task, description=\"[error]Skipped Web3 Init (Invalid URLs)\")\n",
        "    progress.update(web3_task, completed=1)\n",
        "\n",
        "\n",
        "# --- Get Final Status ---\n",
        "mainnet_ready = any_web3_success # mainnet_ready directly reflects if mainnet client succeeded\n",
        "overall_success = gcp_auth_success and mainnet_ready\n",
        "\n",
        "# --- Display Intermediate Success Messages (Now that progress is done) ---\n",
        "if gcp_auth_success:\n",
        "    console.print(f\"✓ User authentication successful!\", style=\"success\")\n",
        "    if gc_sheets: console.print(f\"✓ Google Sheets client initialized\", style=\"success\")\n",
        "else:\n",
        "    console.print(f\"❌ GCP authentication failed.\", style=\"error\")\n",
        "\n",
        "# Updated Web3 success message based on w3_clients dictionary\n",
        "if w3_clients:\n",
        "    connected_nets = [net.capitalize() for net, client in w3_clients.items() if client]\n",
        "    if connected_nets:\n",
        "        console.print(f\"✓ Web3 clients connected: {', '.join(connected_nets)}\", style=\"success\")\n",
        "    elif rpc_urls_valid: # Only show warning if init was attempted but failed all\n",
        "         console.print(\"[warning]Web3 clients initialized, but none connected successfully.\", style=\"warning\")\n",
        "else:\n",
        "     # This case occurs if rpc_urls_valid was False\n",
        "     console.print(\"[error]Web3 client initialization skipped due to invalid RPC URLs.\", style=\"error\")\n",
        "\n",
        "\n",
        "# --- Display Final System Status Summary ---\n",
        "console.print(\"\\n\\n📊 System Status Summary\", style=\"highlight\")\n",
        "# RPC Status\n",
        "if w3_clients:\n",
        "    for network, client in w3_clients.items():\n",
        "        connected = client is not None\n",
        "        status_msg = \"[red]Failed/Skipped[/red]\" # Default if not connected\n",
        "        if connected:\n",
        "             try:\n",
        "                 block_num = client.eth.block_number # Get block number again for final status\n",
        "                 block_num_str = f\"(Block #{block_num:,})\"\n",
        "                 status_msg = f\"[green]Connected[/green] {block_num_str}\"\n",
        "             except Exception as e:\n",
        "                  # If client exists but fails here, mark as unresponsive\n",
        "                  status_msg = f\"[orange3]Unresponsive ({type(e).__name__})[/orange3]\"\n",
        "                  w3_clients[network] = None # Clear bad client for consistency\n",
        "                  console.print(f\"[warning]RPC ({network.capitalize()}) became unresponsive: {e}\", style=\"warning\")\n",
        "        else:\n",
        "            # Add reason if skipped due to invalid URL during init\n",
        "            original_url = BLOCKCHAIN_RPC.get('ethereum', {}).get(network, \"\")\n",
        "            if not original_url or \"xxx\" in original_url.lower():\n",
        "                 status_msg = \"[red]Skipped (Invalid URL)[/red]\"\n",
        "\n",
        "        console.print(f\"  • Ethereum RPC ({network.capitalize()}): {status_msg}\")\n",
        "elif not rpc_urls_valid:\n",
        "    console.print(\"  • Ethereum RPC: [red]Skipped (Invalid URLs)[/red]\")\n",
        "else:\n",
        "    console.print(\"  • Ethereum RPC: [red]Initialization Failed[/red]\")\n",
        "\n",
        "# GCP Status\n",
        "status_auth = \"[green]Successful[/green]\" if gcp_auth_success else \"[red]Failed[/red]\"\n",
        "console.print(f\"  • GCP Authentication: {status_auth}\")\n",
        "\n",
        "# Google Sheets Status\n",
        "status_gs = \"[green]Initialized[/green]\" if gc_sheets else \"[red]Not Initialized[/red]\"\n",
        "if not gcp_auth_success: # Also mark skipped if auth failed\n",
        "    status_gs = \"[yellow]Skipped[/yellow]\"\n",
        "console.print(f\"  • Google Sheets Client: {status_gs}\")\n",
        "\n",
        "# --- Final Ready/Failure Message with Checkmark ---\n",
        "if overall_success:\n",
        "    console.print(\"\\n\\n[bold green]✓ Configuration Complete:[/bold green] System Ready for Ethereum Blockchain Analytics (via RPC) and Google Sheets\")\n",
        "    # Optional warnings for testnets can still be useful\n",
        "    if 'holesky' in w3_clients and w3_clients.get('holesky') is None: console.print(\"  [warning](Note: Holesky testnet connection failed/skipped/unresponsive)\", style=\"warning\")\n",
        "    if 'sepolia' in w3_clients and w3_clients.get('sepolia') is None: console.print(\"  [warning](Note: Sepolia testnet connection failed/skipped/unresponsive)\", style=\"warning\")\n",
        "else:\n",
        "     failure_reasons = []\n",
        "     if not gcp_auth_success: failure_reasons.append(\"GCP Auth Failed\")\n",
        "     if not w3_clients.get('mainnet'): failure_reasons.append(\"Mainnet RPC Connection Failed/Skipped\")\n",
        "     if gcp_auth_success and not gc_sheets: failure_reasons.append(\"Google Sheets Client Failed\") # Check if GSheets failed despite auth success\n",
        "     if not rpc_urls_valid: failure_reasons.append(\"Invalid RPC URL Placeholders\")\n",
        "\n",
        "\n",
        "     reason_str = ', '.join(failure_reasons) if failure_reasons else \"Unknown Issues\"\n",
        "     console.print(f\"\\n\\n[bold red]❌ Configuration Failed:[/bold red] System setup encountered issues ({reason_str}). Review status messages above.\")"
      ],
      "metadata": {
        "id": "PLaPz_r4paFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 🎯 Analysis Targets & Utility Functions\n",
        "---\n",
        "\n",
        "This cell handles target validation and prepares the essential utilities needed for transaction/block analysis:\n",
        "\n",
        "1.  **🌐 Network Verification:**\n",
        "    *   Verifies connectivity to Ethereum Mainnet and available testnets\n",
        "    *   Displays current block heights and chain IDs\n",
        "    *   Attempts reconnection if mainnet client is unavailable\n",
        "\n",
        "2.  **🎯 Define Analysis Targets:**\n",
        "    *   Set the specific Ethereum Mainnet **transaction hash** (`TARGET_TX_HASH`) or **block identifier** (`TARGET_BLOCK_IDENTIFIER`) you wish to analyze\n",
        "    *   **ACTION:** Modify these values to analyze different transactions or blocks relevant to PYUSD\n",
        "    *   Targets are automatically validated for proper format and existence on-chain\n",
        "\n",
        "3.  **🔧 Helper Function Library:**\n",
        "    *   Initializes essential functions used throughout the notebook for:\n",
        "        *   Making raw RPC requests (`make_rpc_request`) to Ethereum nodes\n",
        "        *   Decoding PYUSD-specific function calls and events\n",
        "        *   Formatting blockchain values (ETH/PYUSD amounts, gas)\n",
        "        *   Handling addresses and transaction data\n",
        "        *   Creating visualizations for transaction analysis\n",
        "\n",
        "> **Note:** If a target validation fails, specific diagnostic information will be displayed to help troubleshoot the issue."
      ],
      "metadata": {
        "id": "5vZzVowv-D0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# 🎯 Target Selection & Helper Functions for Tracing\n",
        "# =============================================================================================\n",
        "# This cell validates targets, initializes tracing configurations, and sets up helper functions.\n",
        "\n",
        "# Ensure web3 clients dictionary is loaded from the previous cell\n",
        "if 'w3_clients' not in locals() or not isinstance(w3_clients, dict):\n",
        "     raise NameError(\"Web3 clients dictionary 'w3_clients' not initialized. Please run '🔑 Configuration & Authentication: Connecting to GCP and Ethereum RPC' Cell\")\n",
        "\n",
        "# --- Network Status Verification ---\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    console=console,\n",
        "    transient=True\n",
        ") as progress:\n",
        "    verification_task = progress.add_task(\"[info]Verifying network connections...\", total=1)\n",
        "\n",
        "    w3_mainnet = w3_clients.get('mainnet')\n",
        "    if not w3_mainnet or not w3_mainnet.is_connected():\n",
        "         # Attempt re-initialization with visual feedback\n",
        "         progress.update(verification_task, description=\"[warning]⚠️ Mainnet client not found. Attempting re-initialization...\")\n",
        "         web3_task = progress.add_task(\"[info]Reinitializing Web3 clients...\", total=1)\n",
        "         initialize_all_web3_clients(progress, web3_task)\n",
        "         progress.update(web3_task, completed=1)\n",
        "\n",
        "         # Check if reconnection succeeded\n",
        "         w3_mainnet = w3_clients.get('mainnet')\n",
        "         if not w3_mainnet or not w3_mainnet.is_connected():\n",
        "              raise ConnectionError(\"Cannot proceed without a connected Mainnet Web3 client. Check your RPC endpoints.\")\n",
        "\n",
        "    # Get testnet client if available (for testing function implementations)\n",
        "    progress.update(verification_task, description=\"[info]Checking for testnet availability...\")\n",
        "    w3_testnet = w3_clients.get('sepolia') or w3_clients.get('holesky') # Prefer Sepolia if available\n",
        "    if w3_testnet and w3_testnet.is_connected():\n",
        "        # Find the network name ('holesky' or 'sepolia')\n",
        "        testnet_name = next((name for name in ['sepolia', 'holesky'] if w3_clients.get(name) == w3_testnet), None)\n",
        "    else:\n",
        "        testnet_name = None # No connections with testnet\n",
        "\n",
        "    progress.update(verification_task, completed=1)\n",
        "\n",
        "# --- Network Status Table ---\n",
        "console.print(\"[bold cyan3 size=20]🌐 Network Connections[/]\", justify=\"left\")\n",
        "console.print(\"────────────────────────\", style=\"cyan3\")\n",
        "\n",
        "network_table = Table(show_header=True, header_style=\"bold cyan3\")\n",
        "network_table.add_column(\"Network\", style=\"dim\")\n",
        "network_table.add_column(\"Status\", justify=\"center\")\n",
        "network_table.add_column(\"Block Height\", justify=\"right\")\n",
        "network_table.add_column(\"Chain ID\", justify=\"right\")\n",
        "\n",
        "# Add Mainnet info\n",
        "latest_block_mainnet = w3_mainnet.eth.block_number if w3_mainnet else \"N/A\"\n",
        "chain_id_mainnet = w3_mainnet.eth.chain_id if w3_mainnet else \"N/A\"\n",
        "network_table.add_row(\n",
        "    \"Ethereum Mainnet\",\n",
        "    \"[spring_green3]Connected[/spring_green3]\" if w3_mainnet and w3_mainnet.is_connected() else \"[red3]Disconnected[/red3]\",\n",
        "    f\"{latest_block_mainnet:,}\" if isinstance(latest_block_mainnet, int) else str(latest_block_mainnet),\n",
        "    str(chain_id_mainnet)\n",
        ")\n",
        "\n",
        "# Add Testnet info if available\n",
        "if testnet_name:\n",
        "    latest_block_testnet = w3_testnet.eth.block_number if w3_testnet else \"N/A\"\n",
        "    chain_id_testnet = w3_testnet.eth.chain_id if w3_testnet else \"N/A\"\n",
        "    network_table.add_row(\n",
        "        f\"{testnet_name.capitalize()} Testnet\",\n",
        "        \"[spring_green3]Connected[/spring_green3]\" if w3_testnet and w3_testnet.is_connected() else \"[red3]Disconnected[/red3]\",\n",
        "        f\"{latest_block_testnet:,}\" if isinstance(latest_block_testnet, int) else str(latest_block_testnet),\n",
        "        str(chain_id_testnet)\n",
        "    )\n",
        "else:\n",
        "    network_table.add_row(\"Testnet\", \"[gold3]Not Available[/gold3]\", \"N/A\", \"N/A\")\n",
        "\n",
        "# Display the network connection table\n",
        "console.print(network_table)\n",
        "console.print(\"\\n\\n\")  # Empty lines for better spacing\n",
        "\n",
        "############################################################\n",
        "# 🎯 DEFINE YOUR ETHEREUM ANALYSIS TARGET\n",
        "# Set BOTH values below for optimal analysis capabilities.\n",
        "############################################################\n",
        "\n",
        "# Transaction Hash for analysis\n",
        "# Required by certain analysis functions.\n",
        "TARGET_TX_HASH = \"YOUR_TARGET_TX_HASH\"\n",
        "\n",
        "# Block Number/Identifier for analysis\n",
        "# Required by other analysis functions (often related to block context).\n",
        "# Use the block containing the target transaction, or the specific block you want to analyze.\n",
        "TARGET_BLOCK_IDENTIFIER = YOUR_TARGET_BLOCK_NUMBER # Or block hash, \"latest\", etc.\n",
        "\n",
        "# Important Notes:\n",
        "# - Full analysis experience requires both TARGET_TX_HASH and TARGET_BLOCK_IDENTIFIER.\n",
        "# - Some functions specifically need the block context, others the transaction details.\n",
        "# - If both values are set, TARGET_TX_HASH takes precedence in situations where\n",
        "#   only one identifier can be used as the primary target.\n",
        "############################################################\n",
        "\n",
        "# Import necessary packages for helper functions\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from graphviz import Digraph\n",
        "from IPython.display import display, Javascript\n",
        "from hexbytes import HexBytes\n",
        "from rich.panel import Panel\n",
        "from rich.syntax import Syntax\n",
        "from rich.table import Table\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Plotly configuration for Colab\n",
        "try:\n",
        "    display(Javascript('''\n",
        "        require.config({\n",
        "            paths: {\n",
        "                plotly: 'https://cdn.plot.ly/plotly-latest.min.js'\n",
        "            }\n",
        "        });\n",
        "    '''))\n",
        "except Exception as e:\n",
        "    console.print(f\"[warning]Could not re-configure Plotly: {e}\", style=\"warning\")\n",
        "\n",
        "# --- Target Validation Functions ---\n",
        "def validate_tx_hash(tx_hash):\n",
        "    \"\"\"Validates a transaction hash with detailed diagnostics\"\"\"\n",
        "    if not tx_hash:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Missing\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Transaction hash not provided\"\n",
        "        }\n",
        "\n",
        "    if not isinstance(tx_hash, str):\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Type\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Expected string, got {type(tx_hash).__name__}\"\n",
        "        }\n",
        "\n",
        "    if not tx_hash.startswith('0x'):\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Format\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Transaction hash must start with '0x'\"\n",
        "        }\n",
        "\n",
        "    if len(tx_hash) < 66:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Too Short\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Length is {len(tx_hash)}, should be 66 characters\"\n",
        "        }\n",
        "\n",
        "    if len(tx_hash) > 66:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Too Long\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Length is {len(tx_hash)}, should be 66 characters (including '0x')\"\n",
        "        }\n",
        "\n",
        "    # Check if characters are valid hex\n",
        "    try:\n",
        "        int(tx_hash[2:], 16)\n",
        "    except ValueError:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Hex\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Contains non-hexadecimal characters\"\n",
        "        }\n",
        "\n",
        "    # At this point, the format is valid, try to retrieve it\n",
        "    try:\n",
        "        tx_receipt = w3_mainnet.eth.get_transaction_receipt(tx_hash[:66])  # Truncate to valid length for retrieval\n",
        "        tx_details = w3_mainnet.eth.get_transaction(tx_hash[:66])\n",
        "\n",
        "        # Format gas info\n",
        "        gas_used = tx_receipt.get('gasUsed', 0)\n",
        "        gas_limit = tx_details.get('gas', 0)\n",
        "        gas_percentage = (gas_used / gas_limit * 100) if gas_limit else 0\n",
        "\n",
        "        # Check if transaction was successful\n",
        "        is_success = tx_receipt.get('status') == 1\n",
        "\n",
        "        return {\n",
        "            'valid': True,\n",
        "            'status': \"Found\" if is_success else \"Failed Transaction\",\n",
        "            'status_color': \"spring_green3\" if is_success else \"gold3\",\n",
        "            'details': f\"Block: {tx_receipt.get('blockNumber')}, Gas: {gas_used:,}/{gas_limit:,} ({gas_percentage:.1f}%)\",\n",
        "            'data': {\n",
        "                'receipt': tx_receipt,\n",
        "                'transaction': tx_details,\n",
        "                'success': is_success\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'valid': True,  # Format is valid but transaction not found\n",
        "            'status': \"Valid Format, Not Found\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': f\"Error: {str(e)}\"  # No truncation\n",
        "        }\n",
        "\n",
        "def validate_block_identifier(block_id):\n",
        "    \"\"\"Validates a block identifier with detailed diagnostics\"\"\"\n",
        "    if block_id is None:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Missing\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Block identifier not provided\"\n",
        "        }\n",
        "\n",
        "    # For integer block numbers\n",
        "    if isinstance(block_id, int):\n",
        "        if block_id < 0:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Negative Number\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Block number cannot be negative\"\n",
        "            }\n",
        "\n",
        "        # Check if block is within realistic range\n",
        "        latest_block = w3_mainnet.eth.block_number if w3_mainnet else None\n",
        "        if latest_block and block_id > latest_block:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Future Block\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': f\"Block {block_id:,} exceeds current mainnet height ({latest_block:,})\"\n",
        "            }\n",
        "\n",
        "        # Block is valid by format, try to retrieve it\n",
        "        try:\n",
        "            block_details = w3_mainnet.eth.get_block(block_id)\n",
        "\n",
        "            # Format timestamp from Unix timestamp\n",
        "            block_time = datetime.fromtimestamp(block_details.timestamp)\n",
        "\n",
        "            return {\n",
        "                'valid': True,\n",
        "                'status': \"Found\",\n",
        "                'status_color': \"spring_green3\",\n",
        "                'details': f\"Time: {block_time.strftime('%Y-%m-%d %H:%M:%S')}, TX Count: {len(block_details['transactions'])}\",\n",
        "                'data': block_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'valid': True,  # Format is valid but block not found\n",
        "                'status': \"Valid Format, Not Found\",\n",
        "                'status_color': \"gold3\",\n",
        "                'details': f\"Error: {str(e)}\"  # No truncation\n",
        "            }\n",
        "\n",
        "    # For hex string or hash\n",
        "    if isinstance(block_id, str):\n",
        "        if not block_id.startswith('0x'):\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Invalid Format\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Block hash must start with '0x'\"\n",
        "            }\n",
        "\n",
        "        # Check if characters are valid hex\n",
        "        try:\n",
        "            int(block_id[2:], 16)\n",
        "        except ValueError:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Invalid Hex\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Contains non-hexadecimal characters\"\n",
        "            }\n",
        "\n",
        "        # Block hash is valid by format, try to retrieve it\n",
        "        try:\n",
        "            block_details = w3_mainnet.eth.get_block(block_id)\n",
        "\n",
        "            # Format timestamp from Unix timestamp\n",
        "            block_time = datetime.fromtimestamp(block_details.timestamp)\n",
        "\n",
        "            return {\n",
        "                'valid': True,\n",
        "                'status': \"Found\",\n",
        "                'status_color': \"spring_green3\",\n",
        "                'details': f\"Time: {block_time.strftime('%Y-%m-%d %H:%M:%S')}, TX Count: {len(block_details['transactions'])}\",\n",
        "                'data': block_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'valid': True,  # Format is valid but block not found\n",
        "                'status': \"Valid Format, Not Found\",\n",
        "                'status_color': \"gold3\",\n",
        "                'details': f\"Error: {str(e)}\"  # No truncation\n",
        "            }\n",
        "\n",
        "    # If not int or str\n",
        "    return {\n",
        "        'valid': False,\n",
        "        'status': \"Invalid Type\",\n",
        "        'status_color': \"red3\",\n",
        "        'details': f\"Expected int or string, got {type(block_id).__name__}\"\n",
        "    }\n",
        "\n",
        "# --- Target Verification & Information Retrieval with progress indicator ---\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    console=console,\n",
        "    transient=True\n",
        ") as progress:\n",
        "    validate_task = progress.add_task(\"[info]Validating analysis targets...\", total=2)\n",
        "\n",
        "    # Validate transaction hash\n",
        "    progress.update(validate_task, description=\"[info]Analyzing transaction hash...\")\n",
        "    if 'TARGET_TX_HASH' in locals() and TARGET_TX_HASH:\n",
        "        tx_validation = validate_tx_hash(TARGET_TX_HASH)\n",
        "        tx_valid = tx_validation['valid']\n",
        "    else:\n",
        "        tx_valid = False\n",
        "        tx_validation = {\n",
        "            'status': \"Skipped\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': \"No transaction hash provided\"\n",
        "        }\n",
        "\n",
        "    progress.update(validate_task, advance=1)\n",
        "\n",
        "    # Validate block identifier\n",
        "    progress.update(validate_task, description=\"[info]Analyzing block identifier...\")\n",
        "    if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "        block_validation = validate_block_identifier(TARGET_BLOCK_IDENTIFIER)\n",
        "        block_valid = block_validation['valid']\n",
        "    else:\n",
        "        block_valid = False\n",
        "        block_validation = {\n",
        "            'status': \"Skipped\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': \"No block identifier provided\"\n",
        "        }\n",
        "\n",
        "    progress.update(validate_task, completed=1)\n",
        "\n",
        "# --- Target Status Display (Key-Value Format) ---\n",
        "console.print(\"[bold royal_blue1 size=20]🎯 Analysis Targets[/]\", justify=\"left\")\n",
        "console.print(\"────────────────────\", style=\"royal_blue1\")\n",
        "console.print(\"\\n\")  # Extra spacing\n",
        "\n",
        "# Transaction Target\n",
        "console.print(\"[bold]Target Type - Transaction Hash[/bold]\")\n",
        "if 'TARGET_TX_HASH' in locals() and TARGET_TX_HASH:\n",
        "    console.print(f\"[dim]Value:[/dim] [cyan3]{TARGET_TX_HASH}[/cyan3]\")\n",
        "else:\n",
        "    console.print(\"[dim]Value:[/dim] Nil\")\n",
        "\n",
        "console.print(f\"[dim]Status:[/dim] [{tx_validation['status_color']}]{tx_validation.get('status', 'Unknown')}[/{tx_validation['status_color']}]\")\n",
        "console.print(f\"[dim]Diagnostics:[/dim] {tx_validation.get('details', 'No information available')}\")\n",
        "\n",
        "# Separator\n",
        "console.print(\"\\n\" + \"─\" * 50 + \"\\n\")\n",
        "\n",
        "# Block Target\n",
        "console.print(\"[bold]Target Type - Block[/bold]\")\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    console.print(f\"[dim]Value:[/dim] [cyan3]{TARGET_BLOCK_IDENTIFIER}[/cyan3]\")\n",
        "else:\n",
        "    console.print(\"[dim]Value:[/dim] Nil\")\n",
        "\n",
        "console.print(f\"[dim]Status:[/dim] [{block_validation['status_color']}]{block_validation.get('status', 'Unknown')}[/{block_validation['status_color']}]\")\n",
        "console.print(f\"[dim]Diagnostics:[/dim] {block_validation.get('details', 'No information available')}\")\n",
        "\n",
        "console.print(\"\\n\")  # Extra spacing\n",
        "\n",
        "# Show target selection status message\n",
        "if not tx_valid and not block_valid:\n",
        "    console.print(\"[error]⚠️ No valid targets found. Please set either TARGET_TX_HASH or TARGET_BLOCK_IDENTIFIER.[/error]\", style=\"bold red3\")\n",
        "elif tx_valid and block_valid:\n",
        "    # Check if both targets exist but the transaction validation found the transaction and the block validation found the block\n",
        "    if tx_validation.get('status') == \"Found\" and block_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]ℹ️ Both transaction and block targets are found. Transaction analysis will take priority.[/info]\", style=\"bold royal_blue1\")\n",
        "    else:\n",
        "        console.print(\"[info]ℹ️ Both transaction and block targets are provided but at least one wasn't found. Valid target will be used.[/info]\", style=\"bold royal_blue1\")\n",
        "elif tx_valid:\n",
        "    if tx_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]✓ Transaction target is valid and found. Ready for analysis.[/info]\", style=\"bold spring_green3\")\n",
        "    else:\n",
        "        console.print(\"[warning]⚠️ Transaction target format is valid but transaction wasn't found. Check the hash.[/warning]\", style=\"bold gold3\")\n",
        "elif block_valid:\n",
        "    if block_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]✓ Block target is valid and found. Ready for analysis.[/info]\", style=\"bold spring_green3\")\n",
        "    else:\n",
        "        console.print(\"[warning]⚠️ Block target format is valid but block wasn't found. Check the number/hash.[/warning]\", style=\"bold gold3\")\n",
        "\n",
        "console.print(\"\\n\")  # Empty line for better spacing\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def make_rpc_request(method, params, network='mainnet'):\n",
        "    \"\"\"Helper function to make raw RPC requests via the specified network's provider.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "    try:\n",
        "        response = w3_client.provider.make_request(method, params)\n",
        "        if 'error' in response:\n",
        "            console.print(f\"[error]RPC Error ({method} on {network}): {response['error']['message']} (Code: {response['error']['code']})\", style=\"error\")\n",
        "            return None\n",
        "        return response.get('result')\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Exception during RPC call ({method} on {network}): {str(e)}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "# --- PYUSD Contract Helpers ---\n",
        "def is_pyusd_contract(address):\n",
        "    \"\"\"Checks if an address is a known PYUSD contract.\"\"\"\n",
        "    if not address:\n",
        "        return False\n",
        "    address_lower = address.lower() if isinstance(address, str) else str(address).lower()\n",
        "    return address_lower in PYUSD_CONTRACTS\n",
        "\n",
        "def get_contract_name(address):\n",
        "    \"\"\"Gets the friendly name for a contract address.\"\"\"\n",
        "    if not address:\n",
        "        return \"Unknown\"\n",
        "    address_lower = address.lower() if isinstance(address, str) else str(address).lower()\n",
        "    return PYUSD_CONTRACTS.get(address_lower, \"Other Contract\")\n",
        "\n",
        "def decode_pyusd_function(input_data):\n",
        "    \"\"\"Decodes PYUSD function calls using the signature registry.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"Empty call data\"\n",
        "\n",
        "    method_sig = input_data[:10]\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        return PYUSD_SIGNATURES[method_sig][\"name\"]\n",
        "    return f\"Unknown function: {method_sig}\"\n",
        "\n",
        "def get_function_category(input_data):\n",
        "    \"\"\"Gets the category of a function from its input data.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"other\"\n",
        "\n",
        "    method_sig = input_data[:10]\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        return PYUSD_SIGNATURES[method_sig][\"category\"]\n",
        "    return \"other\"\n",
        "\n",
        "def decode_pyusd_event(topic0, topics, data):\n",
        "    \"\"\"Decodes PYUSD events using the event registry.\"\"\"\n",
        "    if not topic0 or topic0 not in PYUSD_EVENTS:\n",
        "        return {\"name\": \"Unknown event\", \"details\": \"Cannot decode\"}\n",
        "\n",
        "    event_info = PYUSD_EVENTS[topic0]\n",
        "\n",
        "    try:\n",
        "        decoded = event_info[\"decoder\"](topics, data)\n",
        "        return {\n",
        "            \"name\": event_info[\"name\"],\n",
        "            \"decoded\": decoded\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"name\": event_info[\"name\"],\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# --- Formatting Helpers ---\n",
        "def format_value_pyusd(value_raw):\n",
        "    \"\"\"Formats raw PYUSD value (int) to decimal string.\"\"\"\n",
        "    if value_raw is None: return \"0 PYUSD\"\n",
        "    try:\n",
        "        decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "        value_float = int(value_raw) / (10**decimals)\n",
        "        return f\"{value_float:,.{decimals}f} PYUSD\"\n",
        "    except (ValueError, TypeError):\n",
        "        return \"Invalid PYUSD Value\"\n",
        "\n",
        "def format_value_eth(value_wei):\n",
        "    \"\"\"Formats Wei value to Ether string.\"\"\"\n",
        "    if value_wei is None: return \"0 ETH\"\n",
        "    try:\n",
        "        # Ensure value_wei is int or can be converted (handle hex strings from traces)\n",
        "        if isinstance(value_wei, str):\n",
        "            value_int = int(value_wei, 16)\n",
        "        else:\n",
        "             value_int = int(value_wei)\n",
        "        # Use mainnet client for formatting ETH value regardless of target network\n",
        "        if w3_mainnet: # Check if mainnet client exists\n",
        "            return f\"{w3_mainnet.from_wei(value_int, 'ether'):.6f} ETH\"\n",
        "        else:\n",
        "            return f\"{value_int / 1e18:.6f} ETH (approx)\" # Fallback if mainnet client missing\n",
        "    except (ValueError, TypeError, AttributeError):\n",
        "        return \"Invalid ETH Value\"\n",
        "\n",
        "def format_gas(gas):\n",
        "    \"\"\"Formats gas value (int or hex string).\"\"\"\n",
        "    if gas is None: return \"N/A\"\n",
        "    try:\n",
        "       gas_int = int(gas, 16) if isinstance(gas, str) and gas.startswith('0x') else int(gas)\n",
        "       return f\"{gas_int:,}\"\n",
        "    except (ValueError, TypeError):\n",
        "        return \"Invalid Gas Value\"\n",
        "\n",
        "def shorten_address(address):\n",
        "    \"\"\"Shortens an Ethereum address for display.\"\"\"\n",
        "    if not isinstance(address, str) or not address.startswith('0x') or len(address) != 42:\n",
        "        return str(address) # Return original if not a valid address string\n",
        "    return f\"{address[:6]}...{address[-4:]}\"\n",
        "\n",
        "def display_json(data, title=\"JSON Output\"):\n",
        "    \"\"\"Pretty prints JSON data using Rich.\"\"\"\n",
        "    if data is None:\n",
        "        console.print(f\"[warning]{title}: No data to display.\", style=\"warning\")\n",
        "        return\n",
        "    try:\n",
        "        # Use default=str to handle potential non-serializable types like HexBytes\n",
        "        json_str = json.dumps(data, indent=2, default=str)\n",
        "        console.print(Panel(Syntax(json_str, \"json\", theme=\"default\", line_numbers=False),\n",
        "                      title=title, border_style=\"cyan3\", expand=False))\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Could not display JSON for {title}: {e}\", style=\"error\")\n",
        "        # Fallback to printing raw data (limited length)\n",
        "        try:\n",
        "            raw_str = str(data)\n",
        "            console.print(raw_str[:1000] + (\"...\" if len(raw_str) > 1000 else \"\"))\n",
        "        except Exception:\n",
        "            console.print(\"[error]Could not print raw data fallback.\", style=\"error\")\n",
        "\n",
        "# --- Visualization Helpers ---\n",
        "def create_gas_usage_chart(gas_data, title=\"Gas Usage Distribution\"):\n",
        "    \"\"\"Creates a pie chart showing gas usage distribution.\"\"\"\n",
        "    try:\n",
        "        fig = px.pie(gas_data, values='gas_used', names='category',\n",
        "                      title=title)\n",
        "        fig.update_layout(template=\"plotly_white\")\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not create gas usage chart: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "def create_call_sequence_chart(calls_df, highlight_pyusd=True):\n",
        "    \"\"\"Creates a bar chart showing the sequence of calls with gas usage.\"\"\"\n",
        "    try:\n",
        "        if highlight_pyusd:\n",
        "            fig = px.bar(calls_df, x='id', y='gasUsed', color='is_pyusd',\n",
        "                         title='Gas Usage by Call Sequence',\n",
        "                         hover_data=['type', 'depth', 'from', 'to'])\n",
        "        else:\n",
        "            fig = px.bar(calls_df, x='id', y='gasUsed',\n",
        "                         title='Gas Usage by Call Sequence',\n",
        "                         hover_data=['type', 'depth', 'from', 'to'])\n",
        "\n",
        "        fig.update_layout(template=\"plotly_white\")\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not create call sequence chart: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "# --- Final Tracing Configuration Setup ---\n",
        "# Set up trace configuration based on targets\n",
        "if tx_valid and tx_validation.get('status') == \"Found\":\n",
        "    # If valid transaction hash found, prepare for transaction tracing\n",
        "    ACTIVE_TRACE_CONFIG = DEFAULT_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[info]Trace configuration ready for transaction analysis\", style=\"info\")\n",
        "elif block_valid and block_validation.get('status') == \"Found\":\n",
        "    # If valid block found, prepare for block tracing\n",
        "    ACTIVE_TRACE_CONFIG = STRUCTLOG_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[info]Trace configuration ready for block analysis\", style=\"info\")\n",
        "else:\n",
        "    # If no valid targets, set a default trace config\n",
        "    ACTIVE_TRACE_CONFIG = DEFAULT_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[warning]Using default trace configuration (no valid target found)\", style=\"warning\")\n",
        "\n",
        "# Final status message\n",
        "status_icon = \"✓\" if (tx_valid and tx_validation.get('status') == \"Found\") or (block_valid and block_validation.get('status') == \"Found\") else \"⚠️\"\n",
        "status_style = \"bold spring_green3\" if status_icon == \"✓\" else \"bold gold3\"\n",
        "console.print(f\"[{status_style}]{status_icon} Target selection and helper functions initialized[/{status_style}]\")"
      ],
      "metadata": {
        "id": "hsqesrWl-Eyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 🔍 `debug_traceTransaction` - Deep Dive into Transaction Execution\n",
        "---\n",
        "This section utilizes the powerful `debug_traceTransaction` RPC method to dissect the internal workings of a specific PYUSD transaction defined by `TARGET_TX_HASH`. This goes far beyond standard block explorers by revealing the step-by-step execution flow within the EVM. We will explore two main tracers: `callTracer` and `structLog`."
      ],
      "metadata": {
        "id": "3vkos_TxP4pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Using `callTracer`: Mapping Internal Calls, Gas & Events (Recommended)\n",
        "\n",
        "The `callTracer` provides a structured, hierarchical view of the transaction's execution flow. It's generally the most useful tracer for understanding high-level interactions, gas consumption patterns, and event emissions.\n",
        "\n",
        "> **🚀 Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `debug_traceTransaction` with `tracer: \"callTracer\"`\n",
        "> *   **Multiplier:** `50x` (Consumes 50x the quota/cost of a basic call)\n",
        "> *   **GCP Advantage:** Performing this detailed trace is computationally intensive. GCP's generous free quotas for this high-multiplier method make such in-depth analysis accessible and cost-effective.\n",
        "> *   **PYUSD Insight:** `callTracer` allows us to:\n",
        ">     *   Visualize the **exact interaction path** when PYUSD interacts with other DeFi protocols (e.g., DEXs, lending platforms).\n",
        ">     *   Identify specific **internal PYUSD function calls** (`transfer`, `approve`, `mint`, `burn`) and their parameters within the overall transaction.\n",
        ">     *   Pinpoint **gas consumption** within specific PYUSD operations vs. external contract interactions.\n",
        ">     *   Verify the **emission and content** of crucial PYUSD events like `Transfer` and `Approval`.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Trace:** The code calls `debug_traceTransaction` using the `TARGET_TX_HASH` and the `callTracer` configuration.\n",
        "2.  **Parse Data:** The complex JSON response is processed by `parse_call_trace` to extract structured information about calls, logs, gas, and state changes.\n",
        "3.  **Visualize & Summarize:** The results are presented through:\n",
        "    *   **Trace Overview & Metrics:** Key stats like call count, depth, gas, and status.\n",
        "    *   **Interaction Graphs:** High-level contract interactions and detailed call sequences (Interactive Plotly). PYUSD calls are highlighted.\n",
        "    *   **Token Flow:** A specific graph visualizing PYUSD movements (transfers, mints, burns).\n",
        "    *   **State & Gas Analysis:** Tables and charts showing PYUSD state changes and gas usage breakdown.\n",
        "    *   **Event Log Analysis:** Decoded PYUSD events emitted.\n",
        "    *   **Data Tables:** DataFrames showing key calls and high gas usage operations.\n",
        "    *   **Recommendations:** Automated observations based on trace patterns.\n",
        "    *   **Export Options:** Download parsed data (CSV/JSON) or export a report to Google Sheets (Colab).\n",
        "\n",
        "**💡 What to Look For:**\n",
        "*   **Call Graph:** Observe the sequence and depth of calls. Identify the green/blue highlighted nodes representing PYUSD/Supply Controller interactions. Note the gas usage (`Gas: ...`) on each node.\n",
        "*   **Token Flow Graph:** Track how PYUSD moved between addresses.\n",
        "*   **Gas Usage Pie Chart:** See which *types* of operations (transfer, approval, supply change) consumed the most gas.\n",
        "*   **Event Table:** Correlate events like `Transfer` with the calls shown in the graph.\n",
        "*   **Recommendations:** Check for automated insights about gas or complexity."
      ],
      "metadata": {
        "id": "VVhppRHRP8Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# 🔬 Trace Transaction using debug_traceTransaction (callTracer)\n",
        "# =============================================================================================\n",
        "# This cell validates transaction targets, initializes blockchain tracing configurations, and sets up helper functions.\n",
        "# It prepares the environment for detailed transaction analysis by:\n",
        "# - Validating the transaction hash format and existence\n",
        "# - Configuring tracer parameters for debug_traceTransaction\n",
        "# - Setting up utility functions for address formatting, value conversion, and data processing\n",
        "# - Initializing transaction-specific constants and analysis options\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Javascript\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import networkx as nx\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, tx_hash):\n",
        "    \"\"\"Export analysis data to Google Sheets with rich formatting and visualization references.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[cyan3]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD TX Analysis {tx_hash[:10]} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Transaction Analysis\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transaction Analysis\"],\n",
        "            [f\"Transaction: {tx_hash}\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # 1. Add transaction stats summary with improved formatting\n",
        "        if \"transaction_stats\" in data_dict:\n",
        "            stats = data_dict[\"transaction_stats\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Transaction Metrics\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "                if key == 'total_gas':\n",
        "                    formatted_value = f\"{value:,} gas units\"\n",
        "                else:\n",
        "                    formatted_value = str(value)\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 1  # Add space after table\n",
        "\n",
        "        # 2. Add Contract Interaction Graph reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Contract Interaction Overview\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"📊 Contract interaction visualization is available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # 3. Add Call Graph Visualization reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Detailed Call Graph Visualization\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.7, \"green\": 0.8, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"📊 Detailed call graph visualization is available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # 4. Add gas usage section\n",
        "        if \"gas_distribution\" in data_dict and data_dict[\"gas_distribution\"]:\n",
        "            gas_data = data_dict[\"gas_distribution\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Create gas usage table\n",
        "            gas_header = [\"Category\", \"Gas Used\", \"Percentage\"]\n",
        "            gas_rows = [gas_header]\n",
        "\n",
        "            total_gas = sum(item[\"gas_used\"] for item in gas_data)\n",
        "            for item in gas_data:\n",
        "                category = item[\"category\"].replace(\"_\", \" \").title()\n",
        "                gas_used = item[\"gas_used\"]\n",
        "                percentage = (gas_used / total_gas * 100) if total_gas > 0 else 0\n",
        "                gas_rows.append([category, f\"{gas_used:,}\", f\"{percentage:.1f}%\"])\n",
        "\n",
        "            gas_table_row = current_row\n",
        "            worksheet.update(f\"A{gas_table_row}\", gas_rows)\n",
        "\n",
        "            # Format gas table headers\n",
        "            worksheet.format(f\"A{gas_table_row}:C{gas_table_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(gas_rows) + 1\n",
        "\n",
        "            # Add pie chart reference\n",
        "            worksheet.update(f\"A{current_row}\", [[\"📊 Gas usage pie chart visualization is available in the notebook\"]])\n",
        "            current_row += 2\n",
        "\n",
        "        # 5. Add PYUSD Token Flow section\n",
        "        if \"pyusd_transfers\" in data_dict and data_dict[\"pyusd_transfers\"]:\n",
        "            transfers = data_dict[\"pyusd_transfers\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"PYUSD Token Flow Analysis\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.7, \"green\": 1.0, \"blue\": 0.8}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add description\n",
        "            worksheet.update(f\"A{current_row}\", [[\"This shows the movement of PYUSD tokens in this transaction.\"]])\n",
        "            current_row += 1\n",
        "\n",
        "            # Add transfer data as a table\n",
        "            transfer_header = [\"From\", \"To\", \"Amount\", \"Gas Used\"]\n",
        "            transfer_rows = [transfer_header]\n",
        "\n",
        "            for transfer in transfers:\n",
        "                from_addr = shorten_address(transfer[\"from\"])\n",
        "                to_addr = shorten_address(transfer[\"to\"])\n",
        "                amount = format_value_pyusd(transfer[\"amount\"])\n",
        "                gas = f\"{transfer.get('gas_used', 0):,}\"\n",
        "                transfer_rows.append([from_addr, to_addr, amount, gas])\n",
        "\n",
        "            transfer_table_row = current_row\n",
        "            worksheet.update(f\"A{transfer_table_row}\", transfer_rows)\n",
        "\n",
        "            # Format transfer table headers\n",
        "            worksheet.format(f\"A{transfer_table_row}:D{transfer_table_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(transfer_rows) + 1\n",
        "\n",
        "            # Add flow graph reference\n",
        "            worksheet.update(f\"A{current_row}\", [[\"🔄 Token flow visualization is available in the notebook\"]])\n",
        "            current_row += 2\n",
        "\n",
        "        # 6. Add PYUSD State Changes\n",
        "        if \"state_changes\" in data_dict and data_dict[\"state_changes\"]:\n",
        "            state_changes = data_dict[\"state_changes\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"PYUSD State Changes\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 1.0, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add description\n",
        "            worksheet.update(f\"A{current_row}\", [[\"The following state changes occurred in PYUSD contracts:\"]])\n",
        "            current_row += 1\n",
        "\n",
        "            # Create state changes table\n",
        "            if isinstance(state_changes, list) and state_changes:\n",
        "                # Define headers\n",
        "                headers = [\"contract\", \"function\", \"type\", \"amount\", \"gas_used\"]\n",
        "                display_headers = [\"Contract\", \"Function\", \"Type\", \"Amount\", \"Gas Used\"]\n",
        "\n",
        "                # Create the table data\n",
        "                state_rows = [display_headers]  # Header row\n",
        "                for change in state_changes:\n",
        "                    row_data = []\n",
        "                    for key in headers:\n",
        "                        if key == \"amount\" and \"amount\" in change:\n",
        "                            # Format PYUSD amounts nicely\n",
        "                            value = format_value_pyusd(change[\"amount\"])\n",
        "                        elif key == \"gas_used\":\n",
        "                            value = f\"{change.get(key, 0):,}\"\n",
        "                        else:\n",
        "                            value = str(change.get(key, \"\"))\n",
        "                        row_data.append(value)\n",
        "                    state_rows.append(row_data)\n",
        "\n",
        "                # Add to sheet\n",
        "                state_start_row = current_row\n",
        "                worksheet.update(f\"A{state_start_row}\", state_rows)\n",
        "\n",
        "                # Format headers\n",
        "                header_range = f\"A{state_start_row}:E{state_start_row}\"\n",
        "                worksheet.format(header_range, {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                current_row += len(state_rows) + 1\n",
        "\n",
        "        # 7. Add Event Analysis summary\n",
        "        if \"logs_df\" in data_dict and isinstance(data_dict[\"logs_df\"], pd.DataFrame) and not data_dict[\"logs_df\"].empty:\n",
        "            logs_df = data_dict[\"logs_df\"]\n",
        "            pyusd_logs = logs_df[logs_df['is_pyusd']] if 'is_pyusd' in logs_df.columns else pd.DataFrame()\n",
        "\n",
        "            if not pyusd_logs.empty:\n",
        "                # Add section title\n",
        "                worksheet.update(f\"A{current_row}\", [[\"PYUSD Events Analysis\"]])\n",
        "                worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                    \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                    \"backgroundColor\": {\"red\": 0.7, \"green\": 1.0, \"blue\": 0.8}\n",
        "                })\n",
        "                current_row += 1\n",
        "\n",
        "                # Add summary count\n",
        "                worksheet.update(f\"A{current_row}\", [[f\"Found {len(pyusd_logs)} PYUSD events in this transaction.\"]])\n",
        "                current_row += 1\n",
        "\n",
        "                # Add event counts if available\n",
        "                if 'event_name' in pyusd_logs.columns:\n",
        "                    event_counts = pyusd_logs['event_name'].value_counts()\n",
        "\n",
        "                    # Create event counts table\n",
        "                    event_table = [[\"Event Type\", \"Count\"]]  # Header row\n",
        "                    for event, count in event_counts.items():\n",
        "                        event_table.append([event, str(count)])\n",
        "\n",
        "                    # Add to sheet\n",
        "                    event_table_row = current_row\n",
        "                    worksheet.update(f\"A{event_table_row}\", event_table)\n",
        "\n",
        "                    # Format headers\n",
        "                    worksheet.format(f\"A{event_table_row}:B{event_table_row}\", {\n",
        "                        \"textFormat\": {\"bold\": True},\n",
        "                        \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                    })\n",
        "\n",
        "                    current_row += len(event_table) + 1\n",
        "\n",
        "                # Add event details\n",
        "                worksheet.update(f\"A{current_row}\", [[\"PYUSD Event Details:\"]])\n",
        "                worksheet.format(f\"A{current_row}:A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "                current_row += 1\n",
        "\n",
        "                # Display key event details\n",
        "                event_cols = ['contract', 'event_name', 'details']\n",
        "                event_cols = [col for col in event_cols if col in pyusd_logs.columns]\n",
        "\n",
        "                if event_cols:\n",
        "                    # Convert to list for sheet\n",
        "                    event_data = [event_cols]  # Header row\n",
        "                    for _, row in pyusd_logs[event_cols].iterrows():\n",
        "                        # Format each value appropriately\n",
        "                        row_values = []\n",
        "                        for col in event_cols:\n",
        "                            if pd.isnull(row[col]):\n",
        "                                value = \"\"\n",
        "                            else:\n",
        "                                value = str(row[col])\n",
        "                            row_values.append(value)\n",
        "                        event_data.append(row_values)\n",
        "\n",
        "                    # Add to sheet\n",
        "                    event_start_row = current_row\n",
        "                    worksheet.update(f\"A{event_start_row}\", event_data)\n",
        "\n",
        "                    # Format headers\n",
        "                    header_range = f\"A{event_start_row}:{chr(65+len(event_cols)-1)}{event_start_row}\"\n",
        "                    worksheet.format(header_range, {\n",
        "                        \"textFormat\": {\"bold\": True},\n",
        "                        \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                    })\n",
        "\n",
        "                    current_row += len(event_data) + 1\n",
        "\n",
        "                # Add transfer value summary if available\n",
        "                if 'amount' in pyusd_logs.columns and 'is_transfer' in pyusd_logs.columns:\n",
        "                    transfer_logs = pyusd_logs[pyusd_logs['is_transfer']]\n",
        "                    if not transfer_logs.empty:\n",
        "                        total_transferred = transfer_logs['amount'].sum()\n",
        "                        worksheet.update(f\"A{current_row}\", [[f\"Total PYUSD transferred: {format_value_pyusd(total_transferred)}\"]])\n",
        "                        current_row += 2\n",
        "\n",
        "        # 8. Add Recommendations\n",
        "        if \"recommendations\" in data_dict and data_dict[\"recommendations\"]:\n",
        "            recommendations = data_dict[\"recommendations\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Observations & Recommendations\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.7, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add each recommendation\n",
        "            for rec in recommendations:\n",
        "                worksheet.update(f\"A{current_row}\", [[rec]])\n",
        "                current_row += 1\n",
        "\n",
        "            current_row += 1  # Extra space\n",
        "\n",
        "        # 9. Add main DataFrame data (selected columns only for better readability)\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Key Contract Calls\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Select important columns to display\n",
        "            display_cols = ['id', 'type', 'depth', 'contract', 'function_category', 'gasUsed', 'is_pyusd']\n",
        "            display_cols = [col for col in display_cols if col in df.columns]\n",
        "\n",
        "            # First show PYUSD calls\n",
        "            pyusd_calls = df[df['is_pyusd']] if 'is_pyusd' in df.columns else pd.DataFrame()\n",
        "\n",
        "            if not pyusd_calls.empty:\n",
        "                worksheet.update(f\"A{current_row}\", [[f\"Found {len(pyusd_calls)} PYUSD-related calls:\"]])\n",
        "                current_row += 1\n",
        "\n",
        "                # Convert DataFrame to list of lists for the worksheet\n",
        "                pyusd_df_values = [display_cols] + pyusd_calls[display_cols].values.tolist()\n",
        "\n",
        "                # Format values for display\n",
        "                for i in range(1, len(pyusd_df_values)):\n",
        "                    for j, col in enumerate(display_cols):\n",
        "                        val = pyusd_df_values[i][j]\n",
        "                        if col == 'gasUsed' and pd.notnull(val):\n",
        "                            pyusd_df_values[i][j] = f\"{val:,}\"\n",
        "                        elif pd.isnull(val):\n",
        "                            pyusd_df_values[i][j] = \"NULL\"\n",
        "                        else:\n",
        "                            pyusd_df_values[i][j] = str(val)\n",
        "\n",
        "                worksheet.update(f\"A{current_row}\", pyusd_df_values)\n",
        "\n",
        "                # Format the DataFrame header\n",
        "                worksheet.format(f\"A{current_row}:{chr(65+len(display_cols)-1)}{current_row}\", {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                # Add alternating row colors for readability\n",
        "                data_rows = len(pyusd_df_values)\n",
        "                for i in range(2, data_rows + 1, 2):\n",
        "                    row_num = current_row + i - 1\n",
        "                    worksheet.format(f\"A{row_num}:{chr(65+len(display_cols)-1)}{row_num}\", {\n",
        "                        \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                    })\n",
        "\n",
        "                current_row += len(pyusd_df_values) + 2\n",
        "\n",
        "            # Then show highest gas usage calls\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Highest Gas Usage Calls:\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "            current_row += 1\n",
        "\n",
        "            # Get top 5 by gas usage\n",
        "            high_gas_cols = ['id', 'type', 'contract', 'function_category', 'gasUsed']\n",
        "            high_gas_cols = [col for col in high_gas_cols if col in df.columns]\n",
        "\n",
        "            high_gas_calls = df.nlargest(5, 'gasUsed') if 'gasUsed' in df.columns else pd.DataFrame()\n",
        "\n",
        "            if not high_gas_calls.empty:\n",
        "                # Convert to list for sheet\n",
        "                high_gas_data = [high_gas_cols]  # Header row\n",
        "                for _, row in high_gas_calls[high_gas_cols].iterrows():\n",
        "                    # Format each value appropriately\n",
        "                    row_values = []\n",
        "                    for col in high_gas_cols:\n",
        "                        if col == 'gasUsed':\n",
        "                            value = f\"{row[col]:,}\" if pd.notnull(row[col]) else \"0\"\n",
        "                        elif pd.isnull(row[col]):\n",
        "                            value = \"NULL\"\n",
        "                        else:\n",
        "                            value = str(row[col])\n",
        "                        row_values.append(value)\n",
        "                    high_gas_data.append(row_values)\n",
        "\n",
        "                # Add to sheet\n",
        "                worksheet.update(f\"A{current_row}\", high_gas_data)\n",
        "\n",
        "                # Format headers\n",
        "                header_range = f\"A{current_row}:{chr(65+len(high_gas_cols)-1)}{current_row}\"\n",
        "                worksheet.format(header_range, {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                # Add alternating row colors\n",
        "                for i in range(2, len(high_gas_data) + 1, 2):\n",
        "                    row_num = current_row + i - 1\n",
        "                    worksheet.format(f\"A{row_num}:{chr(65+len(high_gas_cols)-1)}{row_num}\", {\n",
        "                        \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                    })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Attempt to resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Return spreadsheet URL and title for opening\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        return (spreadsheet_url, sheet_title)\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        raise Exception(f\"Error creating Google Sheet: {str(e)}\")\n",
        "\n",
        "# Function to display loading indicator while rendering visualization\n",
        "def show_loading_indicator():\n",
        "    \"\"\"Display a loading indicator while rendering graphs\"\"\"\n",
        "    loading_html = \"\"\"\n",
        "    <div style=\"display: flex; justify-content: center; align-items: center; height: 50px;\">\n",
        "        <div style=\"text-align: center;\">\n",
        "            <div class=\"spinner-border\" role=\"status\">\n",
        "                <span class=\"sr-only\">Loading...</span>\n",
        "            </div>\n",
        "            <p style=\"margin-top: 10px; color: #555;\">Generating visualization...</p>\n",
        "        </div>\n",
        "    </div>\n",
        "    <style>\n",
        "    .spinner-border {\n",
        "        display: inline-block;\n",
        "        width: 2rem;\n",
        "        height: 2rem;\n",
        "        vertical-align: text-bottom;\n",
        "        border: 0.25em solid currentColor;\n",
        "        border-right-color: transparent;\n",
        "        border-radius: 50%;\n",
        "        animation: spinner-border .75s linear infinite;\n",
        "    }\n",
        "    @keyframes spinner-border {\n",
        "        to { transform: rotate(360deg); }\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    display(HTML(loading_html))\n",
        "\n",
        "# Function to get human-readable function descriptions\n",
        "def get_function_description(input_data, is_pyusd, contract_name):\n",
        "    \"\"\"Get a human-readable function description.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"Contract Creation\" if not input_data else \"ETH Transfer\"\n",
        "\n",
        "    # Extract method signature (first 10 characters including 0x)\n",
        "    method_sig = input_data[:10] if len(input_data) >= 10 else input_data\n",
        "\n",
        "    # Check PYUSD signatures first\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        function_info = PYUSD_SIGNATURES[method_sig]\n",
        "        return function_info[\"name\"]\n",
        "\n",
        "    # Check common ERC20/generic function signatures\n",
        "    common_sigs = {\n",
        "        '0xa9059cbb': \"transfer(address,uint256)\",\n",
        "        '0x095ea7b3': \"approve(address,uint256)\",\n",
        "        '0x23b872dd': \"transferFrom(address,address,uint256)\",\n",
        "        '0x18160ddd': \"totalSupply()\",\n",
        "        '0x70a08231': \"balanceOf(address)\",\n",
        "        '0xdd62ed3e': \"allowance(address,address)\",\n",
        "        '0x06fdde03': \"name()\",\n",
        "        '0x95d89b41': \"symbol()\",\n",
        "        '0x313ce567': \"decimals()\",\n",
        "        '0x8da5cb5b': \"owner()\",\n",
        "        '0x715018a6': \"renounceOwnership()\",\n",
        "        '0xf2fde38b': \"transferOwnership(address)\",\n",
        "        '0x01ffc9a7': \"supportsInterface(bytes4)\",\n",
        "        '0x3644e515': \"DOMAIN_SEPARATOR()\",\n",
        "        '0x7ecebe00': \"nonces(address)\",\n",
        "        '0xd505accf': \"permit(address,address,uint256,uint256,uint8,bytes32,bytes32)\"\n",
        "    }\n",
        "\n",
        "    return common_sigs.get(method_sig, f\"Function {method_sig}\")\n",
        "\n",
        "# function for creating interactive Plotly Contract Interaction Graph\n",
        "def create_plotly_contract_interaction_graph(contract_interactions):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for contract interactions with directional arrows\"\"\"\n",
        "    import math\n",
        "\n",
        "    if not contract_interactions:\n",
        "        return None\n",
        "\n",
        "    # Create a networkx graph from the interaction data\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes for all contracts in interactions\n",
        "    contracts_seen = set()\n",
        "    for src, dst in contract_interactions:\n",
        "        if src not in contracts_seen:\n",
        "            src_name = PYUSD_CONTRACTS.get(src, \"External Contract\")\n",
        "            G.add_node(src, name=src_name, is_pyusd=(src in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(src)\n",
        "\n",
        "        if dst not in contracts_seen:\n",
        "            dst_name = PYUSD_CONTRACTS.get(dst, \"External Contract\")\n",
        "            G.add_node(dst, name=dst_name, is_pyusd=(dst in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(dst)\n",
        "\n",
        "        # Add edge\n",
        "        G.add_edge(src, dst)\n",
        "\n",
        "    # Calculate layout with more spacing for readability\n",
        "    pos = nx.spring_layout(G, seed=42, k=1.5)\n",
        "\n",
        "    # Create edge traces with arrows\n",
        "    edge_traces = []\n",
        "\n",
        "    for edge in G.edges():\n",
        "        src, dst = edge\n",
        "        src_name = G.nodes[src]['name']\n",
        "        dst_name = G.nodes[dst]['name']\n",
        "\n",
        "        x0, y0 = pos[src]\n",
        "        x1, y1 = pos[dst]\n",
        "\n",
        "        # Calculate direction vector for arrow\n",
        "        dx = x1 - x0\n",
        "        dy = y1 - y0\n",
        "\n",
        "        # Normalize the vector\n",
        "        length = math.sqrt(dx**2 + dy**2)\n",
        "        if length > 0:\n",
        "            udx = dx / length\n",
        "            udy = dy / length\n",
        "        else:\n",
        "            udx, udy = 0, 0\n",
        "\n",
        "        # Position arrow slightly before the destination node (80% along the edge)\n",
        "        arrow_ratio = 0.8\n",
        "        arrow_x = x0 + arrow_ratio * dx\n",
        "        arrow_y = y0 + arrow_ratio * dy\n",
        "\n",
        "        # Angle for the arrow in degrees\n",
        "        angle = math.degrees(math.atan2(dy, dx))\n",
        "\n",
        "        # Main edge line\n",
        "        edge_trace = go.Scatter(\n",
        "            x=[x0, x1],\n",
        "            y=[y0, y1],\n",
        "            line=dict(width=1.5, color='rgba(50, 50, 50, 0.8)'),\n",
        "            hoverinfo='text',\n",
        "            text=f\"From: {src_name}<br>To: {dst_name}<br>From address: {src}<br>To address: {dst}\",\n",
        "            mode='lines',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        # Arrow marker\n",
        "        arrow_trace = go.Scatter(\n",
        "            x=[arrow_x],\n",
        "            y=[arrow_y],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                symbol='triangle-right',\n",
        "                size=12,\n",
        "                color='rgba(50, 50, 50, 0.8)',\n",
        "                angle=angle  # Apply the calculated angle\n",
        "            ),\n",
        "            hoverinfo='none',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        edge_traces.append(edge_trace)\n",
        "        edge_traces.append(arrow_trace)\n",
        "\n",
        "    # Create node trace\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    hover_texts = []\n",
        "    node_addresses = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        node_data = G.nodes[node]\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Node color based on contract type\n",
        "        if node_data['is_pyusd']:\n",
        "            if \"PYUSD Token\" in node_data['name']:\n",
        "                node_colors.append('rgba(144, 238, 144, 0.9)')  # palegreen\n",
        "            elif \"Supply Control\" in node_data['name']:\n",
        "                node_colors.append('rgba(135, 206, 250, 0.9)')  # lightskyblue\n",
        "            else:\n",
        "                node_colors.append('rgba(224, 255, 255, 0.9)')  # lightcyan\n",
        "        else:\n",
        "            node_colors.append('rgba(211, 211, 211, 0.9)')  # lightgray\n",
        "\n",
        "        # Node size: bigger for PYUSD contracts\n",
        "        node_sizes.append(25 if node_data['is_pyusd'] else 18)\n",
        "\n",
        "        # Full address for node label\n",
        "        node_addresses.append(node)\n",
        "\n",
        "        # Hover text with full contract information\n",
        "        hover_texts.append(f\"<b>{node_data['name']}</b><br>Address: {node}\")\n",
        "\n",
        "    # Create node trace with text labels showing full addresses\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_addresses,\n",
        "        textposition=\"bottom center\",\n",
        "        hovertext=hover_texts,\n",
        "        marker=dict(\n",
        "            showscale=False,\n",
        "            color=node_colors,\n",
        "            size=node_sizes,\n",
        "            line=dict(width=1, color='#000')\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"monospace\",\n",
        "            size=10,\n",
        "            color=\"black\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add legend traces for different node types\n",
        "    legend_traces = [\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'),\n",
        "            name='PYUSD Token',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'),\n",
        "            name='Supply Control',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'),\n",
        "            name='External Contract',\n",
        "            showlegend=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Create figure with styled layout\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add all traces\n",
        "    for trace in edge_traces:\n",
        "        fig.add_trace(trace)\n",
        "\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    for trace in legend_traces:\n",
        "        fig.add_trace(trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>Contract Interaction Overview</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Contract Types\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=600,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# function for creating interactive Plotly Call Graph\n",
        "def create_plotly_call_graph(call_data_list):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for the call trace hierarchy\"\"\"\n",
        "    if not call_data_list:\n",
        "        return None\n",
        "\n",
        "    # Process relationships and parent-child connections\n",
        "    # We need to reconstruct parent/child relationships based on depth\n",
        "    for i, call in enumerate(call_data_list):\n",
        "        # Initialize parent_id field if it doesn't exist\n",
        "        if 'parent_id' not in call:\n",
        "            call['parent_id'] = None\n",
        "\n",
        "        # If not root node, find parent\n",
        "        if call['depth'] > 0 and i > 0:\n",
        "            # Look backward for potential parents at the previous depth level\n",
        "            for j in range(i-1, -1, -1):\n",
        "                potential_parent = call_data_list[j]\n",
        "                if potential_parent['depth'] == call['depth'] - 1:\n",
        "                    call['parent_id'] = potential_parent['id']\n",
        "                    break\n",
        "\n",
        "    # Create a networkx graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add all nodes with their attributes\n",
        "    for call in call_data_list:\n",
        "        G.add_node(call['id'], **call)\n",
        "\n",
        "    # Add edges based on parent-child relationships\n",
        "    for call in call_data_list:\n",
        "        if call['parent_id']:\n",
        "            G.add_edge(call['parent_id'], call['id'])\n",
        "\n",
        "    # Try using graphviz layout if available\n",
        "    try:\n",
        "        import pygraphviz as pgv\n",
        "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')  # Hierarchical layout\n",
        "    except:\n",
        "        # Fallback to custom hierarchical layout\n",
        "        pos = {}\n",
        "        depth_to_nodes = {}\n",
        "\n",
        "        for node, data in G.nodes(data=True):\n",
        "            depth = data['depth']\n",
        "            if depth not in depth_to_nodes:\n",
        "                depth_to_nodes[depth] = []\n",
        "            depth_to_nodes[depth].append(node)\n",
        "\n",
        "        # Calculate positions based on depth\n",
        "        max_depth = max(depth_to_nodes.keys()) if depth_to_nodes else 0\n",
        "\n",
        "        for depth, nodes in depth_to_nodes.items():\n",
        "            nodes.sort()  # For consistent layout\n",
        "            node_count = len(nodes)\n",
        "            for i, node in enumerate(nodes):\n",
        "                # Horizontal spacing based on node count, vertical based on depth\n",
        "                x_pos = i / (node_count + 1) if node_count > 1 else 0.5\n",
        "                y_pos = 1.0 - (depth / (max_depth + 1)) if max_depth > 0 else 0.5\n",
        "                pos[node] = (x_pos, y_pos)\n",
        "\n",
        "    # Create edge traces with different colors by call type\n",
        "    edge_traces_by_type = {}\n",
        "    edge_types = set()\n",
        "\n",
        "    for edge in G.edges():\n",
        "        source, target = edge\n",
        "        source_data = G.nodes[source]\n",
        "        target_data = G.nodes[target]\n",
        "\n",
        "        call_type = target_data['type']\n",
        "        edge_types.add(call_type)\n",
        "\n",
        "        if call_type not in edge_traces_by_type:\n",
        "            edge_traces_by_type[call_type] = {\n",
        "                'x': [], 'y': [], 'text': [], 'color': '', 'style': '', 'width': 1\n",
        "            }\n",
        "\n",
        "            # Set color and style based on call type\n",
        "            if call_type == 'DELEGATECALL':\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(0, 0, 255, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'dash'\n",
        "                edge_traces_by_type[call_type]['width'] = 2\n",
        "            elif call_type == 'STATICCALL':\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(0, 128, 0, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'dot'\n",
        "                edge_traces_by_type[call_type]['width'] = 1.5\n",
        "            else:\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(128, 128, 128, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'solid'\n",
        "                edge_traces_by_type[call_type]['width'] = 1\n",
        "\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        edge_traces_by_type[call_type]['x'].extend([x0, x1, None])\n",
        "        edge_traces_by_type[call_type]['y'].extend([y0, y1, None])\n",
        "\n",
        "        # Create full hover info\n",
        "        hover_text = (\n",
        "            f\"<b>From:</b> {source_data['from']}<br>\"\n",
        "            f\"<b>To:</b> {target_data['to']}<br>\"\n",
        "            f\"<b>Type:</b> {target_data['type']}<br>\"\n",
        "            f\"<b>Depth:</b> {target_data['depth']}<br>\"\n",
        "        )\n",
        "\n",
        "        if target_data['value_eth'] > 0:\n",
        "            hover_text += f\"<b>Value:</b> {target_data['value_eth']} ETH<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Gas:</b> {target_data['gasUsed']:,}<br>\"\n",
        "\n",
        "        if target_data['is_pyusd']:\n",
        "            hover_text += f\"<b>Contract:</b> {target_data['contract']}<br>\"\n",
        "\n",
        "        if target_data.get('error'):\n",
        "            hover_text += f\"<b style='color:red'>Error:</b> {target_data['error']}<br>\"\n",
        "\n",
        "        edge_traces_by_type[call_type]['text'].append(hover_text)\n",
        "\n",
        "    # Create scatter traces for each call type\n",
        "    edge_traces = []\n",
        "    for call_type, trace_data in edge_traces_by_type.items():\n",
        "        edge_traces.append(\n",
        "            go.Scatter(\n",
        "                x=trace_data['x'],\n",
        "                y=trace_data['y'],\n",
        "                line=dict(\n",
        "                    width=trace_data['width'],\n",
        "                    color=trace_data['color'],\n",
        "                    dash=trace_data['style']\n",
        "                ),\n",
        "                hoverinfo='text',\n",
        "                text=trace_data['text'],\n",
        "                mode='lines',\n",
        "                name=call_type\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create node trace with improved hover information\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    node_text = []  # Function name displayed on node\n",
        "    hover_texts = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        node_data = G.nodes[node]\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Create more detailed text for nodes\n",
        "        function_name = get_function_description(\n",
        "            node_data.get('input_preview', '0x'),\n",
        "            node_data['is_pyusd'],\n",
        "            node_data.get('contract', 'Other')\n",
        "        )\n",
        "\n",
        "        # Short text for display (truncated for space)\n",
        "        short_name = function_name.split('(')[0] if '(' in function_name else function_name\n",
        "        if len(short_name) > 12:\n",
        "            short_name = short_name[:10] + '...'\n",
        "        node_text.append(short_name)\n",
        "\n",
        "        # Create detailed hover text\n",
        "        hover_text = f\"<b style='font-size:12px'>{node_data['type']} Call</b><br>\"\n",
        "        hover_text += f\"<b>From:</b> {node_data['from']}<br>\"\n",
        "        hover_text += f\"<b>To:</b> {node_data['to']}<br>\"\n",
        "        hover_text += f\"<b>Depth:</b> {node_data['depth']}<br>\"\n",
        "\n",
        "        if node_data['value_eth'] > 0:\n",
        "            hover_text += f\"<b>Value:</b> {node_data['value_eth']} ETH<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Gas Used:</b> {node_data['gasUsed']:,}<br>\"\n",
        "\n",
        "        if node_data['is_pyusd']:\n",
        "            hover_text += f\"<b>PYUSD Contract:</b> {node_data['contract']}<br>\"\n",
        "            hover_text += f\"<b>Function Category:</b> {node_data['function_category']}<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Function:</b> {function_name}<br>\"\n",
        "\n",
        "        if node_data.get('error'):\n",
        "            hover_text += f\"<b style='color:red'>Error:</b> {node_data['error']}<br>\"\n",
        "\n",
        "        hover_texts.append(hover_text)\n",
        "\n",
        "        # Node color based on contract type and error status\n",
        "        if node_data.get('error'):\n",
        "            node_colors.append('rgba(255, 99, 71, 0.9)')  # tomato for errors\n",
        "        elif node_data['is_pyusd']:\n",
        "            if \"PYUSD Token\" in node_data.get('contract', ''):\n",
        "                node_colors.append('rgba(144, 238, 144, 0.9)')  # palegreen\n",
        "            elif \"Supply Control\" in node_data.get('contract', ''):\n",
        "                node_colors.append('rgba(135, 206, 250, 0.9)')  # lightskyblue\n",
        "            else:\n",
        "                node_colors.append('rgba(224, 255, 255, 0.9)')  # lightcyan\n",
        "        else:\n",
        "            # Gradient based on depth for non-PYUSD calls\n",
        "            intensity = min(95, max(70, 95 - node_data['depth'] * 5))\n",
        "            rgb_val = intensity / 100.0\n",
        "            node_colors.append(f'rgba({int(rgb_val*255)}, {int(rgb_val*255)}, {int(rgb_val*255)}, 0.9)')\n",
        "\n",
        "        # Size based on gas used\n",
        "        gas_used = node_data['gasUsed']\n",
        "        # Scale node size based on gas used (within reasonable bounds)\n",
        "        size = max(15, min(40, 15 + (gas_used / 50000)))\n",
        "        node_sizes.append(size)\n",
        "\n",
        "    # Create node trace\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        textposition=\"top center\",\n",
        "        hovertext=hover_texts,\n",
        "        marker=dict(\n",
        "            showscale=False,\n",
        "            color=node_colors,\n",
        "            size=node_sizes,\n",
        "            line=dict(width=1, color='#000')\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"Arial\",\n",
        "            size=9,\n",
        "            color=\"#333\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Create legend traces for node colors\n",
        "    node_color_legend = [\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'),\n",
        "            name='PYUSD Token',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'),\n",
        "            name='Supply Control',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'),\n",
        "            name='Other Contract',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(255, 99, 71, 0.9)'),\n",
        "            name='Error',\n",
        "            showlegend=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Create figure with all traces\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add traces\n",
        "    for edge_trace in edge_traces:\n",
        "        fig.add_trace(edge_trace)\n",
        "\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    # Add legend traces\n",
        "    for legend_trace in node_color_legend:\n",
        "        fig.add_trace(legend_trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>Detailed Call Graph Visualization</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Call Types\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=40, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=700,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# New function for creating interactive Plotly PYUSD Flow Graph\n",
        "def create_plotly_flow_graph(transfers):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for PYUSD token flows\"\"\"\n",
        "    if not transfers:\n",
        "        return None\n",
        "\n",
        "    # Create a directed graph for token flows\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Track total transfer amount per edge for aggregation\n",
        "    transfer_totals = {}\n",
        "\n",
        "    # Calculate aggregate transfers\n",
        "    for transfer in transfers:\n",
        "        from_addr = transfer['from']\n",
        "        to_addr = transfer['to']\n",
        "        amount = transfer['amount']\n",
        "\n",
        "        edge_key = (from_addr, to_addr)\n",
        "        if edge_key in transfer_totals:\n",
        "            transfer_totals[edge_key] += amount\n",
        "        else:\n",
        "            transfer_totals[edge_key] = amount\n",
        "\n",
        "    # Add nodes and edges to networkx graph\n",
        "    for (from_addr, to_addr), total_amount in transfer_totals.items():\n",
        "        # Add nodes if they don't exist\n",
        "        if from_addr not in G:\n",
        "            G.add_node(from_addr, address=from_addr, label=shorten_address(from_addr))\n",
        "\n",
        "        if to_addr not in G:\n",
        "            G.add_node(to_addr, address=to_addr, label=shorten_address(to_addr))\n",
        "\n",
        "        # Add edge with amount\n",
        "        G.add_edge(from_addr, to_addr, amount=total_amount, label=format_value_pyusd(total_amount))\n",
        "\n",
        "    # Calculate layout\n",
        "    pos = nx.spring_layout(G, k=1.0, seed=42)\n",
        "\n",
        "    # Create edge trace\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edge_text = []\n",
        "    edge_amount_texts = []\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        # Calculate midpoint for displaying amount\n",
        "        mid_x = (x0 + x1) / 2\n",
        "        mid_y = (y0 + y1) / 2\n",
        "\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "        amount_str = format_value_pyusd(data['amount'])\n",
        "        edge_text.append(f\"Transfer: {amount_str}<br>From: {shorten_address(source)}<br>To: {shorten_address(target)}\")\n",
        "        edge_amount_texts.append(amount_str)\n",
        "\n",
        "    # Create edge trace with arrows\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x, y=edge_y,\n",
        "        line=dict(width=2, color='rgba(50, 150, 50, 0.8)'),\n",
        "        hoverinfo='text',\n",
        "        text=edge_text,\n",
        "        mode='lines',\n",
        "        name='Transfer'\n",
        "    )\n",
        "\n",
        "    # Create a separate trace for each edge label (amount)\n",
        "    edge_label_traces = []\n",
        "    edge_idx = 0\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        # Calculate midpoint for the label\n",
        "        mid_x = (x0 + x1) / 2\n",
        "        mid_y = (y0 + y1) / 2\n",
        "\n",
        "        # Add label trace\n",
        "        edge_label_traces.append(\n",
        "            go.Scatter(\n",
        "                x=[mid_x],\n",
        "                y=[mid_y],\n",
        "                text=[format_value_pyusd(data['amount'])],\n",
        "                mode='text',\n",
        "                hoverinfo='none',\n",
        "                showlegend=False,\n",
        "                textfont=dict(\n",
        "                    size=10,\n",
        "                    color='darkgreen'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add arrow trace (small marker at the target end)\n",
        "        # Calculate the position for the arrow (slightly before the target)\n",
        "        arrow_ratio = 0.8  # How far along the edge to place the arrow (0.8 = 80% of the way to target)\n",
        "        arrow_x = x0 + (x1 - x0) * arrow_ratio\n",
        "        arrow_y = y0 + (y1 - y0) * arrow_ratio\n",
        "\n",
        "        edge_label_traces.append(\n",
        "            go.Scatter(\n",
        "                x=[arrow_x],\n",
        "                y=[arrow_y],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    symbol='triangle-right',\n",
        "                    size=12,\n",
        "                    color='rgba(50, 150, 50, 0.8)',\n",
        "                    angle=45\n",
        "                ),\n",
        "                hoverinfo='none',\n",
        "                showlegend=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        edge_idx += 1\n",
        "\n",
        "    # Create node trace with full addresses\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    node_hover = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Use full address for display\n",
        "        node_text.append(node)\n",
        "\n",
        "        # Create hover text\n",
        "        node_hover.append(f\"<b>Address:</b> {node}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        textposition=\"bottom center\",\n",
        "        hovertext=node_hover,\n",
        "        marker=dict(\n",
        "            color='rgba(144, 238, 144, 0.8)',  # palegreen\n",
        "            size=25,\n",
        "            line=dict(width=1, color='darkgreen'),\n",
        "            symbol='circle'\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"monospace\",\n",
        "            size=9,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        name='Address'\n",
        "    )\n",
        "\n",
        "    # Create figure with styled layout\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add all traces\n",
        "    fig.add_trace(edge_trace)\n",
        "    for label_trace in edge_label_traces:\n",
        "        fig.add_trace(label_trace)\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>PYUSD Token Flow Analysis</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Elements\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=600,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def parse_call_trace(trace_result, tx_hash):\n",
        "    \"\"\"Parses the output of callTracer and generates insights & visualizations.\"\"\"\n",
        "    if not trace_result:\n",
        "        console.print(\"[warning]No trace result provided for parsing.\", style=\"warning\")\n",
        "        return None, None, None, None, None, None, None, None\n",
        "\n",
        "    # --- Basic Info Panel ---\n",
        "    to_address = trace_result.get('to', 'N/A').lower()\n",
        "    is_pyusd_tx = to_address in PYUSD_CONTRACTS\n",
        "    pyusd_label = f\"[bold green]({PYUSD_CONTRACTS[to_address]})[/bold green]\" if is_pyusd_tx else \"\"\n",
        "\n",
        "    # Extract gas metrics for analysis\n",
        "    gas_used = int(trace_result.get('gasUsed', '0x0'), 16) if isinstance(trace_result.get('gasUsed', '0x0'), str) and trace_result.get('gasUsed', '0x0').startswith('0x') else int(trace_result.get('gasUsed', 0))\n",
        "\n",
        "    overview_text = f\"\"\"\n",
        "      [bold]Trace Summary for {shorten_address(tx_hash)}[/bold] {pyusd_label}\n",
        "      Type: {trace_result.get('type', 'N/A')}\n",
        "      From: {shorten_address(trace_result.get('from', 'N/A'))}\n",
        "      To: {shorten_address(trace_result.get('to', 'N/A'))}\n",
        "      Value: {format_value_eth(trace_result.get('value', '0x0'))}\n",
        "      Gas Used: {format_gas(trace_result.get('gasUsed', '0x0'))} ({gas_used:,} units)\n",
        "      Status: [bold red]Error: {trace_result['error']}[/bold red]\"\"\" if 'error' in trace_result else \"[bold green]Success[/bold green]\"\n",
        "    console.print(Panel(overview_text, title=\"Trace Overview\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    node_counter = 0\n",
        "    call_data_list = []\n",
        "    state_changes = []\n",
        "\n",
        "    # Track PYUSD transfer data for visualization\n",
        "    pyusd_transfers = []\n",
        "\n",
        "    # Track contract interactions for relationship mapping\n",
        "    contract_interactions = set()\n",
        "\n",
        "    # Track gas usage by category\n",
        "    gas_by_category = {category: 0 for category in GAS_CATEGORIES.keys()}\n",
        "\n",
        "    def add_nodes_edges(call, parent_node_id=None, depth=0, parent_addr=None):\n",
        "        nonlocal node_counter\n",
        "        current_node_id = f\"node_{node_counter}\"\n",
        "        node_counter += 1\n",
        "\n",
        "        call_type = call.get('type', 'N/A').upper()\n",
        "\n",
        "        # Extract call data for label\n",
        "        from_addr = call.get('from', 'N/A')\n",
        "        from_addr_short = shorten_address(from_addr)\n",
        "        to_addr = call.get('to', 'N/A')\n",
        "        to_addr_lower = to_addr.lower() if to_addr else ''\n",
        "        to_addr_short = shorten_address(to_addr)\n",
        "\n",
        "        # Track contract interaction\n",
        "        if parent_addr and to_addr_lower:\n",
        "            contract_interactions.add((parent_addr.lower(), to_addr_lower))\n",
        "\n",
        "        # Check for PYUSD contracts\n",
        "        is_pyusd_call = to_addr_lower in PYUSD_CONTRACTS\n",
        "        contract_name = PYUSD_CONTRACTS.get(to_addr_lower, None)\n",
        "\n",
        "        # function signature detection for PYUSD calls\n",
        "        input_data = call.get('input', '0x')\n",
        "        function_category = \"other\"\n",
        "        if input_data != '0x':\n",
        "            method_sig = input_data[:10]\n",
        "\n",
        "            if method_sig in PYUSD_SIGNATURES:\n",
        "                function_info = PYUSD_SIGNATURES[method_sig]\n",
        "                function_name = function_info[\"name\"]\n",
        "                function_category = function_info[\"category\"]\n",
        "\n",
        "                # Process specific functions for deeper analysis\n",
        "                if is_pyusd_call and \"PYUSD Token\" in contract_name:\n",
        "                    if method_sig == '0xa9059cbb':  # transfer\n",
        "                        try:\n",
        "                            # Extract params\n",
        "                            to_offset = 10\n",
        "                            to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            pyusd_transfers.append({\n",
        "                                'from': from_addr,\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'transfer',\n",
        "                                'from': from_addr,\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                    elif method_sig == '0x40c10f19':  # mint\n",
        "                        try:\n",
        "                            to_offset = 10\n",
        "                            to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'mint',\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                    elif method_sig == '0x9dc29fac':  # burn\n",
        "                        try:\n",
        "                            from_offset = 10\n",
        "                            from_param = \"0x\" + input_data[from_offset+24:from_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'burn',\n",
        "                                'from': from_addr,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "\n",
        "        # Update gas usage by category - AFTER function_category is defined\n",
        "        call_gas = int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "        if is_pyusd_call:\n",
        "            gas_by_category[function_category] += call_gas\n",
        "        else:\n",
        "            gas_by_category[\"other\"] += call_gas\n",
        "\n",
        "        # Extract output and error data\n",
        "        output_data = call.get('output', '0x')\n",
        "        error_msg = call.get('error')\n",
        "\n",
        "        # Store call data for dataframe\n",
        "        try:\n",
        "            gas_used_val = int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "            value_raw_wei = int(call.get('value', '0x0'), 16) if call.get('value', '0x0').startswith('0x') else int(call.get('value', 0))\n",
        "            value_eth_float = float(w3_mainnet.from_wei(value_raw_wei, 'ether')) if w3_mainnet else (value_raw_wei / 1e18)\n",
        "        except (ValueError, TypeError, AttributeError):\n",
        "            gas_used_val = 0\n",
        "            value_eth_float = 0.0\n",
        "\n",
        "        # Build call info for dataframe with data\n",
        "        call_info = {\n",
        "            'id': current_node_id,\n",
        "            'parent_id': parent_node_id,  # Track parent-child relationship\n",
        "            'type': call_type,\n",
        "            'depth': depth,\n",
        "            'from': from_addr,\n",
        "            'to': to_addr,\n",
        "            'value_eth': value_eth_float,\n",
        "            'gasUsed': gas_used_val,\n",
        "            'is_pyusd': is_pyusd_call,\n",
        "            'contract': contract_name if is_pyusd_call else \"Other\",\n",
        "            'function_category': function_category,\n",
        "            'error': error_msg,\n",
        "            'input_preview': input_data[:10] + \"...\" if len(input_data) > 10 else input_data,\n",
        "            'output_preview': output_data[:10] + \"...\" if len(output_data) > 10 else output_data,\n",
        "        }\n",
        "        call_data_list.append(call_info)\n",
        "\n",
        "        # Process sub-calls recursively\n",
        "        if 'calls' in call and isinstance(call['calls'], list):\n",
        "            for sub_call in call['calls']:\n",
        "                add_nodes_edges(sub_call, current_node_id, depth + 1, to_addr)\n",
        "\n",
        "    # --- Start processing the trace from the top-level call ---\n",
        "    add_nodes_edges(trace_result, depth=0)\n",
        "\n",
        "    # Create a dataframe from collected call data\n",
        "    call_df = pd.DataFrame(call_data_list)\n",
        "\n",
        "    # Create state changes dataframe\n",
        "    state_changes_df = pd.DataFrame(state_changes) if state_changes else None\n",
        "\n",
        "    # --- Extract Logs from trace with decoding ---\n",
        "    logs_data = []\n",
        "    log_counter_trace = 0\n",
        "\n",
        "    def extract_logs_recursive(call):\n",
        "        nonlocal log_counter_trace\n",
        "        if 'logs' in call and isinstance(call['logs'], list):\n",
        "            for log in call['logs']:\n",
        "                # Ensure log is a dictionary\n",
        "                if not isinstance(log, dict): continue\n",
        "\n",
        "                log_details = {\n",
        "                    \"address\": log.get(\"address\", \"N/A\"),\n",
        "                    \"topics\": log.get(\"topics\", []),\n",
        "                    \"data\": log.get(\"data\", \"0x\"),\n",
        "                    \"log_index_trace\": log_counter_trace\n",
        "                }\n",
        "                log_counter_trace += 1\n",
        "\n",
        "                # Check if log is from PYUSD contract\n",
        "                address_lower = log_details[\"address\"].lower()\n",
        "                is_pyusd_contract = address_lower in PYUSD_CONTRACTS\n",
        "\n",
        "                # Basic data for all logs\n",
        "                log_entry = {\n",
        "                    \"log_idx_trace\": log_details[\"log_index_trace\"],\n",
        "                    \"address\": log_details[\"address\"],\n",
        "                    \"contract\": PYUSD_CONTRACTS.get(address_lower, \"Other\"),\n",
        "                    \"is_pyusd\": is_pyusd_contract,\n",
        "                    \"topic0\": log_details[\"topics\"][0] if log_details[\"topics\"] else \"N/A\",\n",
        "                    \"topic0_short\": log_details[\"topics\"][0][:10]+\"...\" if log_details[\"topics\"] else \"N/A\",\n",
        "                    \"details\": \"Not Decoded\",\n",
        "                    \"event_name\": \"Unknown\"\n",
        "                }\n",
        "\n",
        "                # event decoding with the registry\n",
        "                if is_pyusd_contract and isinstance(log_details[\"topics\"], list) and log_details[\"topics\"]:\n",
        "                    event_topic = log_details[\"topics\"][0]\n",
        "                    if event_topic in PYUSD_EVENTS:\n",
        "                        event_info = PYUSD_EVENTS[event_topic]\n",
        "                        log_entry[\"event_name\"] = event_info[\"name\"]\n",
        "\n",
        "                        try:\n",
        "                            # Decode event data using registered decoder\n",
        "                            decoded_data = event_info[\"decoder\"](log_details[\"topics\"], log_details[\"data\"])\n",
        "\n",
        "                            # Format details based on event type\n",
        "                            if \"Transfer\" in event_info[\"name\"]:\n",
        "                                value_pyusd_str = format_value_pyusd(decoded_data[\"value\"])\n",
        "                                log_entry[\"details\"] = f\"PYUSD Transfer: {value_pyusd_str} from {shorten_address(decoded_data['from'])} to {shorten_address(decoded_data['to'])}\"\n",
        "                                log_entry[\"is_transfer\"] = True\n",
        "                                log_entry[\"amount\"] = decoded_data[\"value\"]\n",
        "                                log_entry[\"from_addr\"] = decoded_data[\"from\"]\n",
        "                                log_entry[\"to_addr\"] = decoded_data[\"to\"]\n",
        "                            elif \"Approval\" in event_info[\"name\"]:\n",
        "                                value_pyusd_str = format_value_pyusd(decoded_data[\"value\"])\n",
        "                                log_entry[\"details\"] = f\"PYUSD Approval: {shorten_address(decoded_data['owner'])} approved {value_pyusd_str} for {shorten_address(decoded_data['spender'])}\"\n",
        "                                log_entry[\"is_approval\"] = True\n",
        "                                log_entry[\"amount\"] = decoded_data[\"value\"]\n",
        "                                log_entry[\"owner\"] = decoded_data[\"owner\"]\n",
        "                                log_entry[\"spender\"] = decoded_data[\"spender\"]\n",
        "                            elif \"Paused\" in event_info[\"name\"]:\n",
        "                                account = decoded_data.get(\"account\", \"N/A\")\n",
        "                                log_entry[\"details\"] = f\"PYUSD Paused by {shorten_address(account) if account else 'N/A'}\"\n",
        "                                log_entry[\"is_pause\"] = True\n",
        "                            elif \"Unpaused\" in event_info[\"name\"]:\n",
        "                                account = decoded_data.get(\"account\", \"N/A\")\n",
        "                                log_entry[\"details\"] = f\"PYUSD Unpaused by {shorten_address(account) if account else 'N/A'}\"\n",
        "                                log_entry[\"is_unpause\"] = True\n",
        "\n",
        "                        except Exception as decode_err:\n",
        "                            log_entry[\"details\"] = f\"PYUSD Event (Decode Error: {decode_err})\"\n",
        "\n",
        "                logs_data.append(log_entry)\n",
        "\n",
        "        # Check sub-calls recursively\n",
        "        if 'calls' in call and isinstance(call['calls'], list):\n",
        "            for sub_call in call['calls']:\n",
        "                extract_logs_recursive(sub_call)\n",
        "\n",
        "    # Extract logs if present in trace config\n",
        "    extract_logs_recursive(trace_result)\n",
        "    logs_df = pd.DataFrame(logs_data) if logs_data else pd.DataFrame()\n",
        "\n",
        "    # --- Create Contract Interaction Graph with Plotly ---\n",
        "    contract_graph = None\n",
        "    if contract_interactions:\n",
        "        try:\n",
        "            contract_graph = create_plotly_contract_interaction_graph(contract_interactions)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create contract interaction graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # --- Create Detailed Call Graph with Plotly ---\n",
        "    call_graph = None\n",
        "    if call_data_list:\n",
        "        try:\n",
        "            call_graph = create_plotly_call_graph(call_data_list)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create detailed call graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Create PYUSD flow graph if transfers exist\n",
        "    flow_graph = None\n",
        "    if pyusd_transfers:\n",
        "        try:\n",
        "            flow_graph = create_plotly_flow_graph(pyusd_transfers)\n",
        "        except Exception as flow_err:\n",
        "            console.print(f\"[warning]Could not create PYUSD flow graph: {flow_err}\", style=\"warning\")\n",
        "\n",
        "    # Create Gas Usage by Category\n",
        "    gas_category_df = pd.DataFrame(\n",
        "        [{\"category\": k, \"gas_used\": v} for k, v in gas_by_category.items() if v > 0]\n",
        "    )\n",
        "\n",
        "    return call_graph, call_df, logs_df, flow_graph, contract_graph, gas_category_df, state_changes_df, pyusd_transfers\n",
        "\n",
        "# =============================================================================================\n",
        "# --- Execute callTracer Analysis ---\n",
        "# =============================================================================================\n",
        "if 'TARGET_TX_HASH' in locals() and validate_tx_hash: # Use the validation flag from setup cell\n",
        "    console.print(\"\\n\\n[bold]🎯 Using callTracer on Mainnet[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"───────────────────────────────\", style=\"cyan3\")\n",
        "    console.print(f\"Target Transaction : {TARGET_TX_HASH}\")\n",
        "\n",
        "    # Use the trace config from the configuration\n",
        "    trace_result_call = make_rpc_request(\"debug_traceTransaction\",\n",
        "                                         [TARGET_TX_HASH, {\"tracer\": \"callTracer\", \"tracerConfig\": TRACE_CONFIGS[\"callTracer\"]}],\n",
        "                                         network='mainnet')\n",
        "\n",
        "    if trace_result_call:\n",
        "        console.print(\"[success]Successfully received trace data.\", style=\"success\")\n",
        "\n",
        "        # --- Parse and Visualize ---\n",
        "        try:\n",
        "            call_graph, call_df, logs_df, pyusd_flow, contract_graph, gas_category_df, state_changes_df, pyusd_transfers = parse_call_trace(trace_result_call, TARGET_TX_HASH)\n",
        "\n",
        "            # Create output widgets for each visualization (add this right after parsing the trace)\n",
        "            contract_graph_output = widgets.Output()\n",
        "            call_graph_output = widgets.Output()\n",
        "            flow_graph_output = widgets.Output()\n",
        "\n",
        "            # 1. TRANSACTION OVERVIEW DASHBOARD\n",
        "            console.print(\"\\n\\n[bold cyan3]🔍 PYUSD TRANSACTION ANALYSIS DASHBOARD[/bold cyan3]\", justify=\"left\")\n",
        "            console.print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\", style=\"cyan3\", justify=\"left\")\n",
        "\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                # Basic transaction metrics\n",
        "                tx_stats = {\n",
        "                    \"total_calls\": len(call_df),\n",
        "                    \"pyusd_calls\": len(call_df[call_df['is_pyusd']]),\n",
        "                    \"max_call_depth\": call_df['depth'].max(),\n",
        "                    \"total_gas\": call_df['gasUsed'].sum(),\n",
        "                    \"errors\": len(call_df[call_df['error'].notnull()])\n",
        "                }\n",
        "\n",
        "                stats_table = Table(title=\"Transaction Metrics\", show_header=True, header_style=\"bold cyan\")\n",
        "                stats_table.add_column(\"Metric\", style=\"dim\")\n",
        "                stats_table.add_column(\"Value\")\n",
        "\n",
        "                for k, v in tx_stats.items():\n",
        "                    if k == 'total_gas':\n",
        "                        stats_table.add_row(k.replace('_', ' ').title(), f\"{v:,} gas units\")\n",
        "                    else:\n",
        "                        stats_table.add_row(k.replace('_', ' ').title(), str(v))\n",
        "\n",
        "                console.print(stats_table)\n",
        "\n",
        "           # 2. Display Contract Interaction Graph\n",
        "            if contract_graph:\n",
        "                console.print(\"\\n\\n[bold cyan3]📊 Contract Interaction Overview[/bold cyan3]\")\n",
        "                console.print(\"─────────────────────────────────\", style=\"cyan3\")\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(contract_graph)\n",
        "                    console.print(\"\\n\\n[info]This graph shows the high-level interactions between contracts in this transaction.\", style=\"info\")\n",
        "                except Exception as viz_err:\n",
        "                    console.print(f\"[warning]Could not render contract interaction graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "            # 3. Display Call Graph Visualization\n",
        "            console.print(\"\\n\\n[bold cyan3]📊 Detailed Call Graph Visualization[/bold cyan3]\")\n",
        "            console.print(\"─────────────────────────────────────\", style=\"cyan3\")\n",
        "            if call_graph:\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(call_graph)\n",
        "                    console.print(\"\\n\\n[info]This visualization shows the detailed call hierarchy in this transaction.\", style=\"info\")\n",
        "                except Exception as viz_err:\n",
        "                    console.print(f\"[warning]Could not render visualization: {viz_err}\", style=\"warning\")\n",
        "            else:\n",
        "                console.print(\"[warning]Call graph generation failed.\", style=\"warning\")\n",
        "\n",
        "            # 4. Display PYUSD Flow Graph if available\n",
        "            if pyusd_flow:\n",
        "                console.print(\"\\n\\n[bold cyan3]🔄 PYUSD Token Flow Analysis[/bold cyan3]\")\n",
        "                console.print(\"─────────────────────────────\", style=\"cyan3\")\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(pyusd_flow)\n",
        "                    console.print(\"\\n\\n[info]This graph shows the movement of PYUSD tokens in this transaction.\", style=\"info\")\n",
        "                except Exception as flow_err:\n",
        "                    console.print(f\"[warning]Could not render PYUSD flow: {flow_err}\", style=\"warning\")\n",
        "\n",
        "            # 5. State Changes Analysis\n",
        "            if state_changes_df is not None and not state_changes_df.empty:\n",
        "                console.print(\"\\n\\n[bold cyan3]🔄 PYUSD State Changes[/bold cyan3]\")\n",
        "                console.print(\"───────────────────────\", style=\"cyan3\")\n",
        "                console.print(\"[info]The following state changes occurred in PYUSD contracts:\", style=\"info\")\n",
        "\n",
        "                # Format amounts in dataframe\n",
        "                state_changes_df['formatted_amount'] = state_changes_df['amount'].apply(format_value_pyusd)\n",
        "\n",
        "                # Display state changes with appropriate columns\n",
        "                display(state_changes_df[['contract', 'function', 'type', 'formatted_amount', 'gas_used']])\n",
        "\n",
        "                # Summary of state impact\n",
        "                if 'type' in state_changes_df.columns:\n",
        "                    changes_by_type = state_changes_df['type'].value_counts()\n",
        "                    console.print(\"\\n[bold]State Change Summary:[/bold]\")\n",
        "                    for change_type, count in changes_by_type.items():\n",
        "                        console.print(f\"- {change_type.title()}: {count} operations\")\n",
        "            else:\n",
        "                console.print(\"\\n\\n[info]No direct PYUSD state changes detected in this transaction.\", style=\"info\")\n",
        "\n",
        "            # 6. Gas Usage Analysis\n",
        "            if gas_category_df is not None and not gas_category_df.empty:\n",
        "                console.print(\"\\n\\n[bold yellow3]⛽ Gas Usage Analysis[/bold yellow3]\")\n",
        "                console.print(\"──────────────────────\", style=\"yellow3\")\n",
        "\n",
        "                # Create simple gas usage table\n",
        "                gas_table = Table(title=\"Gas Usage by Operation Category\", show_header=True, header_style=\"bold yellow3\")\n",
        "                gas_table.add_column(\"Category\", style=\"dim\")\n",
        "                gas_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "                gas_table.add_column(\"Percentage\", justify=\"right\")\n",
        "\n",
        "                total_gas = gas_category_df['gas_used'].sum()\n",
        "\n",
        "                for _, row in gas_category_df.iterrows():\n",
        "                    category = row['category'].replace('_', ' ').title()\n",
        "                    gas_used = row['gas_used']\n",
        "                    percentage = (gas_used / total_gas * 100) if total_gas > 0 else 0\n",
        "                    gas_table.add_row(\n",
        "                        category,\n",
        "                        f\"{gas_used:,}\",\n",
        "                        f\"{percentage:.1f}%\"\n",
        "                    )\n",
        "\n",
        "                console.print(gas_table)\n",
        "\n",
        "                # Gas usage visualization\n",
        "                try:\n",
        "                    # Color by operation category for better visibility\n",
        "                    fig_gas = px.pie(gas_category_df, values='gas_used', names='category',\n",
        "                                     title=f'<b>Gas Usage Distribution ({shorten_address(TARGET_TX_HASH)})</b>')\n",
        "                    fig_gas.update_layout(\n",
        "                        template=\"plotly_white\",\n",
        "                        title={\n",
        "                            'y': 0.95,\n",
        "                            'x': 0.5,\n",
        "                            'xanchor': 'center',\n",
        "                            'yanchor': 'top',\n",
        "                            'font': {'size': 16}\n",
        "                        },\n",
        "                        margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                    )\n",
        "                    fig_gas.show()\n",
        "                except Exception as plot_err:\n",
        "                    console.print(f\"[warning]Could not generate gas usage plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "            # 7. Filtered Call Data Table\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                console.print(\"\\n\\n[bold cyan3]📋 Key Contract Calls[/bold cyan3]\")\n",
        "                console.print(\"─────────────────────\", style=\"cyan3\")\n",
        "\n",
        "                # Focus on PYUSD calls for a cleaner view\n",
        "                pyusd_calls = call_df[call_df['is_pyusd']]\n",
        "\n",
        "                if not pyusd_calls.empty:\n",
        "                    console.print(f\"[success]Found {len(pyusd_calls)} PYUSD-related calls in this transaction.\", style=\"success\")\n",
        "\n",
        "                    # Style the DataFrame for better visibility\n",
        "                    def highlight_pyusd(val):\n",
        "                        return 'background-color: palegreen' if val else ''\n",
        "\n",
        "                    # Display with conditional formatting - only important columns\n",
        "                    display_cols = ['id', 'type', 'depth', 'contract', 'function_category', 'gasUsed', 'error']\n",
        "                    display(pyusd_calls[display_cols])\n",
        "                else:\n",
        "                    console.print(\"[info]No PYUSD-specific calls found in this transaction.\", style=\"info\")\n",
        "\n",
        "                # Show high gas usage calls with function names\n",
        "                console.print(\"\\n[bold yellow3]Highest Gas Usage Calls:[/bold yellow3]\")\n",
        "                high_gas_calls = call_df.nlargest(5, 'gasUsed')\n",
        "\n",
        "                # Add function description to high gas calls\n",
        "                high_gas_calls['function_name'] = high_gas_calls.apply(\n",
        "                    lambda row: get_function_description(\n",
        "                        row['input_preview'],\n",
        "                        row['is_pyusd'] if 'is_pyusd' in row else False,\n",
        "                        row['contract'] if 'contract' in row else \"Non-PYUSD Contract\"\n",
        "                    ),\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                # Display with function name instead of category if available\n",
        "                display(high_gas_calls[['id', 'type', 'contract', 'function_name', 'gasUsed']])\n",
        "\n",
        "            # 8. PYUSD Event Analysis\n",
        "            if logs_df is not None and not logs_df.empty:\n",
        "                console.print(\"\\n\\n[bold green3]📝 PYUSD Events Analysis[/bold green3]\")\n",
        "                console.print(\"─────────────────────────\", style=\"green3\")\n",
        "\n",
        "                # Highlight PYUSD logs\n",
        "                pyusd_logs = logs_df[logs_df['is_pyusd']]\n",
        "                if not pyusd_logs.empty:\n",
        "                    console.print(f\"[success]Found {len(pyusd_logs)} PYUSD events in this transaction.\", style=\"success\")\n",
        "\n",
        "                    # Group by event type\n",
        "                    if 'event_name' in pyusd_logs.columns:\n",
        "                        event_counts = pyusd_logs['event_name'].value_counts()\n",
        "\n",
        "                        event_table = Table(title=\"PYUSD Events\", show_header=True, header_style=\"bold green3\")\n",
        "                        event_table.add_column(\"Event Type\", style=\"dim\")\n",
        "                        event_table.add_column(\"Count\", justify=\"right\")\n",
        "\n",
        "                        for event, count in event_counts.items():\n",
        "                            event_table.add_row(event, str(count))\n",
        "\n",
        "                        console.print(event_table)\n",
        "\n",
        "                    # Display detailed event data\n",
        "                    console.print(\"\\n\\n[bold green3]PYUSD Event Details:[/bold green3]\")\n",
        "                    display(pyusd_logs[['contract', 'event_name', 'details']])\n",
        "\n",
        "                    # Transfer value analysis\n",
        "                    if 'amount' in pyusd_logs.columns and 'is_transfer' in pyusd_logs.columns:\n",
        "                        transfer_logs = pyusd_logs[pyusd_logs['is_transfer']]\n",
        "                        if not transfer_logs.empty:\n",
        "                            total_transferred = transfer_logs['amount'].sum()\n",
        "                            console.print(f\"\\n\\n[info][bold cyan3]Total PYUSD transferred:[bold cyan3] {format_value_pyusd(total_transferred)}\", style=\"info\")\n",
        "                else:\n",
        "                    console.print(\"[info]No PYUSD events found in this transaction.\", style=\"info\")\n",
        "            else:\n",
        "                console.print(\"[info]No logs extracted from trace.\", style=\"info\")\n",
        "\n",
        "            # 9. Add Recommendations Section\n",
        "            console.print(\"\\n\\n[bold cyan3]💡 Analysis Observations & Recommendations[/bold cyan3]\")\n",
        "            console.print(\"──────────────────────────────────────────\", style=\"cyan3\")\n",
        "\n",
        "            recommendations = []\n",
        "\n",
        "            # Check for high gas usage patterns\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                high_gas_threshold = call_df['gasUsed'].sum() * 0.25  # 25% of total gas\n",
        "                high_gas_ops = call_df[call_df['gasUsed'] > high_gas_threshold]\n",
        "                if not high_gas_ops.empty:\n",
        "                    recommendations.append(f\"- High gas operations detected: {len(high_gas_ops)} calls used >25% of transaction gas\")\n",
        "\n",
        "            # Check for deep call stack\n",
        "            if call_df is not None and 'depth' in call_df.columns:\n",
        "                max_depth = call_df['depth'].max()\n",
        "                if max_depth > 5:\n",
        "                    recommendations.append(f\"- Deep call stack detected (max depth: {max_depth})\")\n",
        "\n",
        "            # Check token flow patterns\n",
        "            if logs_df is not None and 'is_transfer' in logs_df.columns:\n",
        "                transfer_count = logs_df['is_transfer'].sum()\n",
        "                if transfer_count > 3:\n",
        "                    recommendations.append(f\"- Complex token movement detected ({transfer_count} transfers)\")\n",
        "\n",
        "            # Add general PYUSD observations\n",
        "            if call_df is not None and 'is_pyusd' in call_df.columns:\n",
        "                pyusd_calls = call_df[call_df['is_pyusd']]\n",
        "                if not pyusd_calls.empty:\n",
        "                    recommendations.append(f\"- Transaction involves {len(pyusd_calls)} PYUSD contract interactions\")\n",
        "\n",
        "            # Display recommendations\n",
        "            if recommendations:\n",
        "                for rec in recommendations:\n",
        "                    console.print(rec)\n",
        "            else:\n",
        "                console.print(\"[info]No specific observations to highlight for this transaction.\", style=\"info\")\n",
        "\n",
        "            # 10. Export Options\n",
        "            console.print(\"\\n\\n[bold cyan3]📤 Export Options:[/bold cyan3]\")\n",
        "            console.print(\"──────────────────\", style=\"cyan3\")\n",
        "\n",
        "            # Create export output area\n",
        "            export_output = widgets.Output()\n",
        "\n",
        "            # Create export buttons with proper styling\n",
        "            export_buttons = widgets.HBox([\n",
        "                widgets.Button(\n",
        "                    description='Export to CSV',\n",
        "                    button_style='primary',  # Green\n",
        "                    layout=widgets.Layout(width='150px')\n",
        "                ),\n",
        "                widgets.Button(\n",
        "                    description='Export as JSON',\n",
        "                    button_style='warning',  # Orange\n",
        "                    layout=widgets.Layout(width='150px')\n",
        "                ),\n",
        "                widgets.Button(\n",
        "                    description='Export to Google Sheets',\n",
        "                    button_style='info',     # Blue\n",
        "                    layout=widgets.Layout(width='200px')\n",
        "                )\n",
        "            ])\n",
        "\n",
        "            # Define export handlers with simplified loading indicators\n",
        "            def export_csv(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    console.print(\"[cyan3]Exporting to CSV...\", style=\"info\")\n",
        "\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.csv\"\n",
        "\n",
        "                    try:\n",
        "                        # Export to CSV\n",
        "                        result = download_csv_direct(call_df, filename)\n",
        "\n",
        "                        # Clear loading message and show success\n",
        "                        clear_output()\n",
        "                        console.print(\"✓ Successfully exported to CSV\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"❌ Error exporting to CSV: {str(e)}\", style=\"error\")\n",
        "\n",
        "            def export_json(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    console.print(\"[cyan3]Exporting to JSON...\", style=\"info\")\n",
        "\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.json\"\n",
        "\n",
        "                    try:\n",
        "                        # Prepare export data\n",
        "                        export_data = {\n",
        "                            \"transaction_hash\": TARGET_TX_HASH,\n",
        "                            \"analysis_type\": \"callTracer\",\n",
        "                            \"transaction_stats\": tx_stats if 'tx_stats' in locals() else {},\n",
        "                            \"state_changes\": state_changes_df.to_dict('records') if state_changes_df is not None and not state_changes_df.empty else [],\n",
        "                            \"gas_by_category\": gas_category_df.to_dict('records') if gas_category_df is not None and not gas_category_df.empty else [],\n",
        "                            \"pyusd_transfers\": pyusd_transfers if pyusd_transfers is not None else []\n",
        "                        }\n",
        "\n",
        "                        # Export to JSON\n",
        "                        result = download_json_direct(export_data, filename)\n",
        "\n",
        "                        # Clear loading message and show success\n",
        "                        clear_output()\n",
        "                        console.print(\"✓ Successfully exported to JSON\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"❌ Error exporting to JSON: {str(e)}\", style=\"error\")\n",
        "\n",
        "            def export_to_sheets(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    try:\n",
        "                        # Collect all data for the sheet\n",
        "                        export_data = {\n",
        "                            \"transaction_hash\": TARGET_TX_HASH,\n",
        "                            \"transaction_stats\": tx_stats if 'tx_stats' in locals() else {},\n",
        "                            \"gas_distribution\": gas_category_df.to_dict('records') if gas_category_df is not None else [],\n",
        "                            \"pyusd_transfers\": pyusd_transfers if pyusd_transfers is not None else [],\n",
        "                            \"state_changes\": state_changes_df.to_dict('records') if state_changes_df is not None and not state_changes_df.empty else [],\n",
        "                            \"logs_df\": logs_df if logs_df is not None and not logs_df.empty else None\n",
        "                        }\n",
        "\n",
        "                        # Call the export function\n",
        "                        spreadsheet_url, sheet_title = export_to_google_sheets(call_df, export_data, TARGET_TX_HASH)\n",
        "\n",
        "                        # Open the spreadsheet and display link\n",
        "                        display(Javascript(f'window.open(\"{spreadsheet_url}\", \"_blank\");'))\n",
        "\n",
        "                        # 2. Display *only* the link and success message as static HTML output\n",
        "                        clear_output(wait=True)\n",
        "                        console.print(\"✓ Successfully exported to Google Sheets\", style=\"spring_green3\")\n",
        "                        display(HTML(f'''\n",
        "                        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "                        '''))\n",
        "\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"❌ Error exporting to Google Sheets: {str(e)}\", style=\"error\")\n",
        "                        html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                        display(HTML(html))\n",
        "\n",
        "                        # Fallback to CSV\n",
        "                        console.print(\"[cyan3]Falling back to CSV download...\", style=\"info\")\n",
        "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                        filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.csv\"\n",
        "                        result = download_csv_direct(call_df, filename)\n",
        "\n",
        "                        clear_output()\n",
        "                        console.print(\"✓ CSV fallback ready\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                        display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "            # Connect handlers to buttons\n",
        "            export_buttons.children[0].on_click(export_csv)\n",
        "            export_buttons.children[1].on_click(export_json)\n",
        "            export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "            # Display button container and output area\n",
        "            display(export_buttons)\n",
        "            display(export_output)\n",
        "\n",
        "        except Exception as parse_err:\n",
        "            console.print(f\"[error]Failed during parsing or visualization: {parse_err}\", style=\"error\")\n",
        "            import traceback\n",
        "            console.print(traceback.format_exc())\n",
        "    else:\n",
        "        console.print(\"[error]Failed to retrieve trace data from RPC node.\", style=\"error\")\n",
        "else:\n",
        "    console.print(\"[warning]No valid transaction hash found. Please set TARGET_TX_HASH to a valid transaction hash.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "jlWAKP7_Qdo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Using `structLog` Tracer: Opcode-Level Execution Analysis (Use Cautiously)\n",
        "\n",
        "The `structLog` tracer dives deep into the Ethereum Virtual Machine (EVM), providing a step-by-step log of each opcode executed during the transaction. For each step, it details the program counter (PC), opcode, remaining gas, gas cost, stack contents, memory state, and storage changes (if enabled).\n",
        "\n",
        "> **⚠️ Extreme Granularity & Resource Intensity**\n",
        ">\n",
        "> *   **Method:** `debug_traceTransaction` with `tracer: \"structLog\"`\n",
        "> *   **Multiplier:** `50x` (Same base multiplier as `callTracer`, but output size is *significantly* larger)\n",
        "> *   **Output Size:** Can generate **very large** outputs (potentially hundreds of thousands of steps/lines, consuming significant memory/browser resources) for even moderately complex transactions.\n",
        "> *   **Use Case:** Best suited for highly specific debugging tasks, deep gas optimization analysis at the opcode level, or verifying precise execution paths, rather than general transaction overview. **Use with caution.**\n",
        "\n",
        "> **🚀 Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **GCP Advantage:** While the base multiplier is `50x`, the sheer volume of data returned by `structLog` makes it extremely demanding on RPC node resources. GCP's infrastructure and generous quotas make it feasible to retrieve these detailed traces where other providers might time out, restrict output size, or charge heavily.\n",
        "> *   **PYUSD Insight:** `structLog` can be used for:\n",
        ">     *   **Fine-grained Gas Profiling:** Identifying exactly which opcodes consume the most gas during PYUSD function execution (e.g., `SSTORE` during transfers/approvals).\n",
        ">     *   **Debugging Reverts:** Pinpointing the exact opcode and state (stack/memory) where a PYUSD transaction failed.\n",
        ">     *   **Security Analysis:** Examining low-level execution for potential vulnerabilities or unexpected behavior within PYUSD or interacting contracts.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Conditional Execution:** The code includes a flag (`RUN_STRUCTLOG_TRACE`) which defaults to `False`. Set this to `True` only if you specifically need this level of detail.\n",
        "2.  **Fetch Trace:** Calls `debug_traceTransaction` using `TARGET_TX_HASH` and the `structLog` configuration.\n",
        "3.  **Parse Steps:** The `parse_struct_log` function processes the potentially massive list of execution steps.\n",
        "4.  **Summarize & Visualize:**\n",
        "    *   **Overview:** Displays total steps, gas cost, call depth, and highlights PYUSD execution percentage.\n",
        "    *   **Gas Analysis:** Generates plots showing gas cost distribution by opcode *category* and by individual *opcode*.\n",
        "    *   **Execution Timeline:** Plots gas remaining over execution steps, highlighting sections executed within PYUSD contracts.\n",
        "    *   **PYUSD Focus:** Analyzes opcode frequency and gas usage specifically within PYUSD contract execution steps.\n",
        "    *   **Data Sample:** Displays the first few steps of the detailed execution trace DataFrame.\n",
        "    *   **Export Options:** Allows downloading the full (potentially large) execution step data.\n",
        "\n",
        "**💡 What to Look For:**\n",
        "*   **Gas Plots:** Identify which opcode categories (e.g., `STORAGE`, `MEMORY`, `CALL`) and specific opcodes (e.g., `SSTORE`, `CALL`, `KECCAK256`) dominate gas consumption. Compare this within PYUSD vs. non-PYUSD sections.\n",
        "*   **Execution Timeline:** Observe gas depletion patterns. Look for sharp drops corresponding to expensive operations. Note the percentage of time spent executing PYUSD code.\n",
        "*   **Data Sample:** Understand the structure of the per-opcode data (PC, gas, stack, memory).\n",
        "*   **(If Debugging):** Search the full trace data (if exported) for `REVERT` opcodes or unexpected stack/memory states near the point of failure."
      ],
      "metadata": {
        "id": "fHt4Hc9Z_gbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# 🔬 Trace Transaction using debug_traceTransaction (structLog Tracer Opcode-Level Detail)\n",
        "# =============================================================================================\n",
        "# This cell performs detailed opcode-level transaction analysis using the debug_traceTransaction method with the structLog tracer.\n",
        "# It prepares the data and presents insights by:\n",
        "# - Conditionally executing the trace based on the RUN_STRUCTLOG_TRACE flag.\n",
        "# - Parsing the raw structLog output, calculating step-by-step gas costs, categorizing opcodes, and tracking contract execution context (including PYUSD).\n",
        "# - Generating interactive Plotly visualizations for overall gas usage (by category, by opcode), execution timeline (highlighting PYUSD), and PYUSD-specific gas analysis.\n",
        "# - Displaying summary statistics (Panel, Rich tables) and a sample of the processed trace data.\n",
        "# - Providing interactive buttons for exporting the detailed trace data to CSV, JSON, or Google Sheets using helper functions.\n",
        "\n",
        "import base64\n",
        "import json\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, tx_hash):\n",
        "    \"\"\"Export StructLog analysis data to Google Sheets with rich formatting.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[cyan3]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD StructLog Analysis {tx_hash[:10]} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Execution Steps\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD StructLog Analysis\"],\n",
        "            [f\"Transaction: {tx_hash}\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # Add transaction stats summary\n",
        "        if \"summary\" in data_dict:\n",
        "            stats = data_dict[\"summary\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Summary\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "\n",
        "                # Try to format numerical values with commas\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        formatted_value = f\"{value:,}\"\n",
        "                    else:\n",
        "                        formatted_value = str(value)\n",
        "                except:\n",
        "                    formatted_value = str(value)\n",
        "\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 2  # Add extra space after table\n",
        "\n",
        "        # Add opcode distribution reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Opcode Distribution Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.7, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"📊 Opcode distribution visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add gas usage reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"📊 Gas usage visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add main DataFrame data\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Execution Steps Data\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # For StructLog data, select most important columns for readability\n",
        "            # if dataframe has too many columns\n",
        "            if len(df.columns) > 10:\n",
        "                key_cols = [\"pc\", \"op\", \"gas\", \"gasCost\", \"depth\", \"stack\", \"memory\", \"storage\"]\n",
        "                display_cols = [col for col in key_cols if col in df.columns]\n",
        "\n",
        "                # Add any custom columns that might contain analysis results\n",
        "                other_important_cols = []\n",
        "                for col in df.columns:\n",
        "                    if col not in display_cols and any(x in col.lower() for x in [\"pyusd\", \"token\", \"contract\", \"note\", \"category\"]):\n",
        "                        other_important_cols.append(col)\n",
        "\n",
        "                display_cols.extend(other_important_cols)\n",
        "                display_df = df[display_cols]\n",
        "            else:\n",
        "                display_df = df\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [display_df.columns.tolist()] + display_df.values.tolist()\n",
        "\n",
        "            # Format values for better readability\n",
        "            for i in range(1, len(df_values)):\n",
        "                for j, col in enumerate(display_df.columns):\n",
        "                    val = df_values[i][j]\n",
        "\n",
        "                    # Format different column types appropriately\n",
        "                    if pd.isnull(val):\n",
        "                        df_values[i][j] = \"\"\n",
        "                    elif col in [\"gas\", \"gasCost\"] and isinstance(val, (int, float)):\n",
        "                        df_values[i][j] = f\"{val:,}\"\n",
        "                    elif col in [\"stack\", \"memory\", \"storage\"] and isinstance(val, (list, dict)):\n",
        "                        # Truncate long data structures to prevent huge cells\n",
        "                        df_values[i][j] = str(val)[:100] + \"...\" if len(str(val)) > 100 else str(val)\n",
        "                    else:\n",
        "                        df_values[i][j] = str(val)\n",
        "\n",
        "            worksheet.update(f\"A{current_row}\", df_values)\n",
        "\n",
        "            # Format the DataFrame header\n",
        "            worksheet.format(f\"A{current_row}:{chr(65+len(display_df.columns)-1)}{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            # Add alternating row colors for readability\n",
        "            data_rows = len(df_values)\n",
        "            for i in range(2, data_rows + 1, 2):\n",
        "                row_num = current_row + i - 1\n",
        "                worksheet.format(f\"A{row_num}:{chr(65+len(display_df.columns)-1)}{row_num}\", {\n",
        "                    \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Attempt to resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Clear loading message and show success message\n",
        "        clear_output()\n",
        "        console.print(\"✓ Successfully exported to Google Sheets\", style=\"spring_green3\")\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clear loading message and show error\n",
        "        clear_output()\n",
        "        console.print(f\"❌ Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "def parse_struct_log(struct_logs_list, tx_hash):\n",
        "    \"\"\"Parses structLog output for analysis and visualization.\"\"\"\n",
        "    if not struct_logs_list or not isinstance(struct_logs_list, list):\n",
        "        console.print(\"[warning]No structLog data provided or invalid format.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    # --- Initialize tracking variables ---\n",
        "    log_data = []\n",
        "    total_gas_cost = 0\n",
        "    last_gas = 0\n",
        "    current_contracts = {}  # Map depth -> contract address\n",
        "    pyusd_execution_steps = 0\n",
        "\n",
        "    # --- Define OPCODE categories for better analysis ---\n",
        "    OPCODE_CATEGORIES = {\n",
        "        \"arithmetic\": [\"ADD\", \"MUL\", \"SUB\", \"DIV\", \"SDIV\", \"MOD\", \"SMOD\", \"ADDMOD\", \"MULMOD\", \"EXP\", \"SIGNEXTEND\"],\n",
        "        \"comparison\": [\"LT\", \"GT\", \"SLT\", \"SGT\", \"EQ\", \"ISZERO\"],\n",
        "        \"bitwise\": [\"AND\", \"OR\", \"XOR\", \"NOT\", \"BYTE\", \"SHL\", \"SHR\", \"SAR\"],\n",
        "        \"memory\": [\"MLOAD\", \"MSTORE\", \"MSTORE8\", \"MSIZE\", \"MCOPY\"],\n",
        "        \"storage\": [\"SLOAD\", \"SSTORE\"],\n",
        "        \"flow\": [\"JUMP\", \"JUMPI\", \"JUMPDEST\", \"PC\", \"STOP\", \"RETURN\", \"REVERT\"],\n",
        "        \"stack\": [\"POP\", \"PUSH1\", \"PUSH2\", \"PUSH3\", \"PUSH4\", \"PUSH5\", \"PUSH6\", \"PUSH7\", \"PUSH8\",\n",
        "                 \"PUSH9\", \"PUSH10\", \"PUSH11\", \"PUSH12\", \"PUSH13\", \"PUSH14\", \"PUSH15\", \"PUSH16\",\n",
        "                 \"PUSH17\", \"PUSH18\", \"PUSH19\", \"PUSH20\", \"PUSH21\", \"PUSH22\", \"PUSH23\", \"PUSH24\",\n",
        "                 \"PUSH25\", \"PUSH26\", \"PUSH27\", \"PUSH28\", \"PUSH29\", \"PUSH30\", \"PUSH31\", \"PUSH32\",\n",
        "                 \"DUP1\", \"DUP2\", \"DUP3\", \"DUP4\", \"DUP5\", \"DUP6\", \"DUP7\", \"DUP8\",\n",
        "                 \"DUP9\", \"DUP10\", \"DUP11\", \"DUP12\", \"DUP13\", \"DUP14\", \"DUP15\", \"DUP16\",\n",
        "                 \"SWAP1\", \"SWAP2\", \"SWAP3\", \"SWAP4\", \"SWAP5\", \"SWAP6\", \"SWAP7\", \"SWAP8\",\n",
        "                 \"SWAP9\", \"SWAP10\", \"SWAP11\", \"SWAP12\", \"SWAP13\", \"SWAP14\", \"SWAP15\", \"SWAP16\"],\n",
        "        \"environment\": [\"ADDRESS\", \"BALANCE\", \"ORIGIN\", \"CALLER\", \"CALLVALUE\", \"CALLDATALOAD\",\n",
        "                        \"CALLDATASIZE\", \"CALLDATACOPY\", \"CODESIZE\", \"CODECOPY\", \"GASPRICE\",\n",
        "                        \"EXTCODESIZE\", \"EXTCODECOPY\", \"RETURNDATASIZE\", \"RETURNDATACOPY\",\n",
        "                        \"EXTCODEHASH\", \"BLOCKHASH\", \"COINBASE\", \"TIMESTAMP\", \"NUMBER\",\n",
        "                        \"DIFFICULTY\", \"GASLIMIT\", \"CHAINID\", \"SELFBALANCE\", \"BASEFEE\"],\n",
        "        \"contract\": [\"CREATE\", \"CREATE2\", \"CALL\", \"CALLCODE\", \"DELEGATECALL\", \"STATICCALL\", \"SELFDESTRUCT\"],\n",
        "        \"logging\": [\"LOG0\", \"LOG1\", \"LOG2\", \"LOG3\", \"LOG4\"],\n",
        "        \"gas\": [\"GAS\"],\n",
        "        \"other\": []\n",
        "    }\n",
        "\n",
        "    def get_opcode_category(opcode):\n",
        "        \"\"\"Determine the category of an opcode based on predefined categories.\"\"\"\n",
        "        for category, opcodes in OPCODE_CATEGORIES.items():\n",
        "            if opcode in opcodes:\n",
        "                return category\n",
        "        return \"other\"\n",
        "\n",
        "    console.print(f\"[info]Parsing {len(struct_logs_list):,} structLog steps for {shorten_address(tx_hash)}\\n\\n\", style=\"info\")\n",
        "\n",
        "    # Get initial gas from the first step if available\n",
        "    if struct_logs_list and isinstance(struct_logs_list[0], dict) and 'gas' in struct_logs_list[0]:\n",
        "        last_gas = struct_logs_list[0].get('gas', 0)\n",
        "\n",
        "    # --- Process each execution step in the struct logs ---\n",
        "    for i, step in enumerate(struct_logs_list):\n",
        "        # Ensure step is a dictionary\n",
        "        if not isinstance(step, dict):\n",
        "            continue\n",
        "\n",
        "        # Calculate gas cost for this step\n",
        "        current_gas = step.get('gas', last_gas)\n",
        "        gas_cost = last_gas - current_gas\n",
        "        total_gas_cost += gas_cost if gas_cost > 0 else 0\n",
        "\n",
        "        # Get basic step information\n",
        "        depth = step.get('depth', 0)\n",
        "        op = step.get('op', 'N/A')\n",
        "\n",
        "        # Track contract context changes on CALL instructions\n",
        "        is_pyusd_related = False\n",
        "        if op in ['CALL', 'STATICCALL', 'DELEGATECALL']:\n",
        "            try:\n",
        "                stack = step.get('stack', [])\n",
        "                if len(stack) >= 2:  # Need at least 2 stack items for call address\n",
        "                    # Address is the second stack item for CALL, STATICCALL\n",
        "                    address_raw = stack[1]\n",
        "                    if address_raw.startswith('0x'):\n",
        "                        address = '0x' + address_raw[-40:]\n",
        "                    else:\n",
        "                        # Handle numeric representation\n",
        "                        try:\n",
        "                            address = '0x' + hex(int(address_raw, 16))[-40:].zfill(40)\n",
        "                        except ValueError:\n",
        "                            address = None\n",
        "\n",
        "                    if address:\n",
        "                        current_contracts[depth+1] = address.lower()\n",
        "                        is_pyusd_related = is_pyusd_contract(address)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Check if we're currently in a PYUSD contract\n",
        "        current_contract = current_contracts.get(depth, None)\n",
        "        is_in_pyusd = is_pyusd_contract(current_contract) if current_contract else False\n",
        "\n",
        "        if is_in_pyusd:\n",
        "            pyusd_execution_steps += 1\n",
        "\n",
        "        # Categorize the opcode\n",
        "        opcode_category = get_opcode_category(op)\n",
        "\n",
        "        # Build the execution data record\n",
        "        log_data.append({\n",
        "            'step': i,\n",
        "            'pc': step.get('pc', 0),\n",
        "            'op': op,\n",
        "            'opcode_category': opcode_category,\n",
        "            'gas': current_gas,\n",
        "            'gasCost': gas_cost if gas_cost >= 0 else 0,  # Ensure non-negative cost\n",
        "            'depth': depth,\n",
        "            'stack_depth': len(step.get('stack', [])),\n",
        "            'mem_size_bytes': len(step.get('memory', [])) * 32,  # Memory size in bytes\n",
        "            'current_contract': current_contract,\n",
        "            'is_pyusd_contract': is_in_pyusd,\n",
        "            'is_pyusd_related': is_pyusd_related or is_in_pyusd\n",
        "        })\n",
        "        last_gas = current_gas\n",
        "\n",
        "    if not log_data:\n",
        "        console.print(\"[warning]No valid steps found in structLog data after parsing.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    # --- Convert to DataFrame for analysis ---\n",
        "    df = pd.DataFrame(log_data)\n",
        "\n",
        "    # --- Display Summary ---\n",
        "    pyusd_percentage = (pyusd_execution_steps / len(df) * 100) if len(df) > 0 else 0\n",
        "\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold]structLog Trace Summary for {shorten_address(tx_hash)}[/bold]\n",
        "Total Steps Parsed: {len(df):,}\n",
        "Total Gas Cost (calc): {total_gas_cost:,}\n",
        "Max Depth: {df['depth'].max() if not df.empty else 'N/A'}\n",
        "Max Stack Depth: {df['stack_depth'].max() if not df.empty else 'N/A'}\n",
        "Max Memory (bytes): {df['mem_size_bytes'].max() if not df.empty else 'N/A'}\n",
        "Steps in PYUSD Contracts: {pyusd_execution_steps:,} ({pyusd_percentage:.1f}% of execution)\"\"\",\n",
        "        title=\"structLog Overview\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # --- Generate Visualizations ---\n",
        "    if not df.empty:\n",
        "        # --- Plot Gas Cost by Opcode Category ---\n",
        "        try:\n",
        "            # Visualization Header\n",
        "            console.print(\"\\n\\n[bold yellow3]⛽ Gas Cost by Opcode Category[/bold yellow3]\")\n",
        "            console.print(\"────────────────────────────────\", style=\"yellow3\")\n",
        "\n",
        "            # Calculate opcode category gas costs\n",
        "            category_gas = df.groupby('opcode_category')['gasCost'].sum().reset_index()\n",
        "            if not category_gas.empty:\n",
        "                # Sort categories by gas usage for better visualization\n",
        "                category_gas = category_gas.sort_values(by='gasCost', ascending=False)\n",
        "\n",
        "                # Add percentage to the name\n",
        "                total_gas = category_gas['gasCost'].sum()\n",
        "                category_gas['name_with_pct'] = category_gas.apply(\n",
        "                    lambda x: f\"{x['opcode_category']} ({x['gasCost']/total_gas*100:.1f}%)\",\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                fig_cat_gas = px.pie(\n",
        "                    category_gas,\n",
        "                    values='gasCost',\n",
        "                    names='name_with_pct',  # Use the new column with percentages\n",
        "                    title=' '  # Empty title, we'll add it in layout\n",
        "                )\n",
        "\n",
        "                # Custom settings for better visualization\n",
        "                fig_cat_gas.update_traces(\n",
        "                    textposition='inside',\n",
        "                    textinfo='percent',\n",
        "                    insidetextorientation='radial'\n",
        "                )\n",
        "\n",
        "                # Position the title with extra space and make it bold\n",
        "                fig_cat_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>Gas Cost by Opcode Category ({shorten_address(tx_hash)})</b>',  # Bold title\n",
        "                        'y': 0.95,  # Position higher for more space\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50),  # Increased top margin for title\n",
        "                )\n",
        "                fig_cat_gas.show()\n",
        "        except Exception as plot_err:\n",
        "            console.print(f\"[warning]Could not generate opcode category gas plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- Plot Gas Cost per Opcode ---\n",
        "        try:\n",
        "            # Visulization Header\n",
        "            console.print(\"\\n\\n[bold yellow3]⛽ Top 30 Opcodes by Gas Cost[/bold yellow3]\")\n",
        "            console.print(\"──────────────────────────────\", style=\"yellow3\")\n",
        "            # Calculate opcode gas costs\n",
        "            opcode_gas = df.groupby('op')['gasCost'].sum().sort_values(ascending=False).reset_index()\n",
        "            # Only show opcodes with non-zero gas cost (as requested)\n",
        "            opcode_gas = opcode_gas[opcode_gas['gasCost'] > 0]\n",
        "\n",
        "            if not opcode_gas.empty:\n",
        "                # Show all significant opcodes, not just top 30\n",
        "                significant_opcodes = len(opcode_gas) if len(opcode_gas) <= 30 else 30\n",
        "\n",
        "                fig_op_gas = px.bar(\n",
        "                    opcode_gas.head(significant_opcodes),\n",
        "                    x='op',\n",
        "                    y='gasCost',\n",
        "                    labels={'op': '<b>Opcode</b>', 'gasCost': '<b>Total Gas Cost</b>'}  # Bold axis labels\n",
        "                )\n",
        "\n",
        "                # Bold title\n",
        "                fig_op_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>Top {significant_opcodes} Opcodes by Gas Cost ({shorten_address(tx_hash)})</b>',\n",
        "                        'y': 0.95,\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                )\n",
        "                fig_op_gas.show()\n",
        "            else:\n",
        "                 console.print(\"[info]No significant gas costs found per opcode.\", style=\"info\")\n",
        "        except Exception as plot_err:\n",
        "             console.print(f\"[warning]Could not generate opcode gas plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- Plot Gas Remaining Over Steps with PYUSD Highlighting ---\n",
        "        try:\n",
        "            # Downsample if too many steps to prevent browser freezing\n",
        "            # ⚠️ WARNING: if there are too many steps it will consume lots of computes browser could crash or freeze.\n",
        "            max_points_plot = 5000\n",
        "            if len(df) > max_points_plot:\n",
        "                # Ensure consistent sampling, e.g., take every Nth point\n",
        "                indices = np.round(np.linspace(0, len(df) - 1, max_points_plot)).astype(int)\n",
        "                plot_df = df.iloc[indices]\n",
        "                plot_title = f'<b>Gas Remaining Over Execution Steps (Sampled) ({shorten_address(tx_hash)})</b>'\n",
        "                xaxis_title = '<b>Execution Step (Sampled)</b>'\n",
        "                console.print(\n",
        "                    f\"\\n\\n[bold yellow3]⛽ Plotting downsampled gas remaining[/bold yellow3] [info]({len(plot_df)} points out of {len(df)}).[/info]\\n\"\n",
        "                    f\"[yellow3]────────────────────────────────────────────────────────────────────[/yellow3]\"\n",
        "                )\n",
        "            else:\n",
        "                plot_df = df\n",
        "                plot_title = f'<b>Gas Remaining Over Execution Steps ({shorten_address(tx_hash)})</b>'\n",
        "                xaxis_title = '<b>Execution Step</b>'\n",
        "\n",
        "            # Create a more informative plot with PYUSD sections highlighted\n",
        "            fig_gas_steps = go.Figure()\n",
        "\n",
        "            # Add base gas trace\n",
        "            fig_gas_steps.add_trace(go.Scatter(\n",
        "                x=plot_df['step'],\n",
        "                y=plot_df['gas'],\n",
        "                mode='lines',\n",
        "                name='Gas Remaining',\n",
        "                line=dict(color='blue')\n",
        "            ))\n",
        "\n",
        "            # Highlight PYUSD contract execution sections\n",
        "            if 'is_pyusd_contract' in plot_df.columns:\n",
        "                pyusd_sections = []\n",
        "                current_section = None\n",
        "\n",
        "                for i, row in plot_df.iterrows():\n",
        "                    if row['is_pyusd_contract'] and current_section is None:\n",
        "                        # Start a new PYUSD section\n",
        "                        current_section = {'start': row['step']}\n",
        "                    elif not row['is_pyusd_contract'] and current_section is not None:\n",
        "                        # End the current PYUSD section\n",
        "                        current_section['end'] = plot_df.iloc[i-1]['step'] if i > 0 else row['step']\n",
        "                        pyusd_sections.append(current_section)\n",
        "                        current_section = None\n",
        "\n",
        "                # Handle case where the last section is a PYUSD section\n",
        "                if current_section is not None:\n",
        "                    current_section['end'] = plot_df.iloc[-1]['step']\n",
        "                    pyusd_sections.append(current_section)\n",
        "\n",
        "                # Add highlighted areas for PYUSD execution\n",
        "                for section in pyusd_sections:\n",
        "                    fig_gas_steps.add_shape(\n",
        "                        type=\"rect\",\n",
        "                        x0=section['start'], x1=section['end'],\n",
        "                        y0=0, y1=plot_df['gas'].max(),\n",
        "                        fillcolor=\"rgba(0,255,0,0.1)\",\n",
        "                        line=dict(width=0),\n",
        "                        layer=\"below\"\n",
        "                    )\n",
        "\n",
        "            fig_gas_steps.update_layout(\n",
        "                title={\n",
        "                    'text': plot_title,\n",
        "                    'y': 0.95,\n",
        "                    'x': 0.5,\n",
        "                    'xanchor': 'center',\n",
        "                    'yanchor': 'top',\n",
        "                    'font': {'size': 16}\n",
        "                },\n",
        "                xaxis_title=xaxis_title,\n",
        "                yaxis_title='<b>Gas</b>',  # Bold y-axis label\n",
        "                showlegend=True,\n",
        "                margin=dict(t=100, b=60, l=60, r=60)  # Increased top margin\n",
        "            )\n",
        "\n",
        "            # Add annotation for PYUSD sections - MOVED TO BOTTOM LEFT\n",
        "            if pyusd_percentage > 0:\n",
        "                fig_gas_steps.add_annotation(\n",
        "                    x=0.02, y=0.02,  # Bottom left\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    text=f\"Green sections: PYUSD contract execution ({pyusd_percentage:.1f}%)\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(color=\"green\"),\n",
        "                    bgcolor=\"white\",\n",
        "                    bordercolor=\"green\",\n",
        "                    borderwidth=1,\n",
        "                    align=\"left\"\n",
        "                )\n",
        "\n",
        "            fig_gas_steps.show()\n",
        "        except Exception as plot_err:\n",
        "             console.print(f\"[warning]Could not generate gas remaining plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- PYUSD-Specific Analysis ---\n",
        "        if 'is_pyusd_contract' in df.columns and df['is_pyusd_contract'].any():\n",
        "            console.print(\"\\n[bold green3]🧩 PYUSD Contract Execution Analysis[/bold green3]\")\n",
        "\n",
        "            # Filter for PYUSD execution steps\n",
        "            pyusd_df = df[df['is_pyusd_contract']]\n",
        "\n",
        "            # Analyze PYUSD opcodes\n",
        "            pyusd_opcodes = pyusd_df.groupby('op').size().sort_values(ascending=False)\n",
        "\n",
        "            pyusd_table = Table(title=\"Top PYUSD Contract Operations\", show_header=True, header_style=\"bold green3\")\n",
        "            pyusd_table.add_column(\"Opcode\", style=\"dim\")\n",
        "            pyusd_table.add_column(\"Count\", justify=\"right\")\n",
        "            pyusd_table.add_column(\"% of PYUSD Ops\", justify=\"right\")\n",
        "\n",
        "            for op, count in pyusd_opcodes.head(10).items():\n",
        "                percentage = (count / len(pyusd_df) * 100)\n",
        "                pyusd_table.add_row(op, str(count), f\"{percentage:.1f}%\")\n",
        "\n",
        "            console.print(pyusd_table)\n",
        "\n",
        "            # Analyze PYUSD gas usage by category\n",
        "            pyusd_gas_by_cat = pyusd_df.groupby('opcode_category')['gasCost'].sum().sort_values(ascending=False)\n",
        "\n",
        "            try:\n",
        "                # Create a pie chart for PYUSD gas usage by category\n",
        "                gas_cat_df = pd.DataFrame({'category': pyusd_gas_by_cat.index, 'gas_used': pyusd_gas_by_cat.values})\n",
        "\n",
        "                # Add percentage to the name\n",
        "                total_gas = gas_cat_df['gas_used'].sum()\n",
        "                gas_cat_df['name_with_pct'] = gas_cat_df.apply(\n",
        "                    lambda x: f\"{x['category']} ({x['gas_used']/total_gas*100:.1f}%)\",\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                fig_pyusd_gas = px.pie(\n",
        "                    gas_cat_df,\n",
        "                    values='gas_used',\n",
        "                    names='name_with_pct',\n",
        "                    title=' '  # Empty title, we'll add it in layout\n",
        "                )\n",
        "\n",
        "                # Custom settings for better visualization\n",
        "                fig_pyusd_gas.update_traces(\n",
        "                    textposition='inside',\n",
        "                    textinfo='percent',\n",
        "                    insidetextorientation='radial'\n",
        "                )\n",
        "\n",
        "                # Bold title\n",
        "                fig_pyusd_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>PYUSD Contract Gas Usage by Category ({shorten_address(tx_hash)})</b>',\n",
        "                        'y': 0.95,\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                )\n",
        "\n",
        "                fig_pyusd_gas.show()\n",
        "            except Exception as plot_err:\n",
        "                console.print(f\"[warning]Could not generate PYUSD gas category plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # Display DataFrame sample first\n",
        "        console.print(\"\\n\\n[bold cyan3]📊 structLog Data Sample (First 10 steps)[/bold cyan3]\")\n",
        "        console.print(\"──────────────────────────────────────────\", style=\"cyan3\")\n",
        "\n",
        "        # Get a more informative view by focusing on key columns\n",
        "        display_cols = ['step', 'op', 'opcode_category', 'gas', 'gasCost', 'depth', 'is_pyusd_contract']\n",
        "        display(df[display_cols].head(10))\n",
        "\n",
        "        console.print(f\"[info]Full structLog DataFrame has {len(df)} rows. Displaying only head.\", style=\"info\")\n",
        "\n",
        "        # PYUSD-specific summary\n",
        "        pyusd_steps = df['is_pyusd_contract'].sum()\n",
        "        if pyusd_steps > 0:\n",
        "            pyusd_pct = (pyusd_steps / len(df)) * 100\n",
        "            console.print(f\"[success]PYUSD-specific execution: {pyusd_steps:,} steps ({pyusd_pct:.1f}% of total)\", style=\"success\")\n",
        "\n",
        "            # Top Gas-Consuming PYUSD Operations\n",
        "            if 'is_pyusd_contract' in df.columns:\n",
        "                pyusd_ops_gas = df[df['is_pyusd_contract']].groupby('op')['gasCost'].sum().sort_values(ascending=False)\n",
        "\n",
        "                if not pyusd_ops_gas.empty:\n",
        "                    gas_table = Table(title=\"Top Gas-Consuming PYUSD Operations\", show_header=True, header_style=\"bold green\")\n",
        "                    gas_table.add_column(\"Operation\", style=\"dim\")\n",
        "                    gas_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "                    gas_table.add_column(\"% of PYUSD Gas\", justify=\"right\")\n",
        "\n",
        "                    total_pyusd_gas = pyusd_ops_gas.sum()\n",
        "                    for op, gas in pyusd_ops_gas.head(10).items():\n",
        "                        percentage = (gas / total_pyusd_gas * 100)\n",
        "                        gas_table.add_row(op, f\"{gas:,}\", f\"{percentage:.1f}%\")\n",
        "\n",
        "                    console.print(gas_table)\n",
        "\n",
        "        # Export options\n",
        "        console.print(\"\\n\\n[bold cyan3]📤 Export Options:[/bold cyan3]\")\n",
        "        console.print(\"──────────────────\", style=\"cyan3\")\n",
        "\n",
        "        # Create export output area\n",
        "        export_output = widgets.Output()\n",
        "\n",
        "        # Create export buttons with proper styling\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Export to CSV',\n",
        "                button_style='primary',  # Green\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export as JSON',\n",
        "                button_style='warning',  # Orange\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export to Google Sheets',\n",
        "                button_style='info',     # Blue\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # Define export handlers\n",
        "        def export_csv(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.csv\"\n",
        "                display(download_csv_direct(df, filename))\n",
        "\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.json\"\n",
        "                # Prepare export data with basic DataFrame stats to avoid reference issues\n",
        "                export_data = {\n",
        "                    \"transaction_hash\": tx_hash,\n",
        "                    \"analysis_type\": \"structLog\",\n",
        "                    \"summary\": {\n",
        "                        \"total_steps\": len(df),\n",
        "                        \"total_gas_cost\": total_gas_cost,\n",
        "                        \"max_depth\": df['depth'].max() if not df.empty else None,\n",
        "                        \"max_stack_depth\": df['stack_depth'].max() if not df.empty else None,\n",
        "                        \"max_memory_bytes\": df['mem_size_bytes'].max() if not df.empty else None,\n",
        "                        \"pyusd_steps\": pyusd_execution_steps,\n",
        "                        \"pyusd_percentage\": pyusd_percentage\n",
        "                    },\n",
        "                    \"opcode_categories\": category_gas.to_dict('records') if 'category_gas' in locals() and not category_gas.empty else []\n",
        "                }\n",
        "                display(download_json_direct(export_data, filename))\n",
        "\n",
        "        def export_to_sheets(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                try:\n",
        "                    # Only use variables that are in scope and defined\n",
        "                    export_data = {\n",
        "                        \"transaction_hash\": tx_hash,\n",
        "                        \"summary\": {\n",
        "                            \"total_steps\": len(df),\n",
        "                            \"total_gas_cost\": total_gas_cost,\n",
        "                            \"max_depth\": df['depth'].max() if not df.empty else None,\n",
        "                            \"max_stack_depth\": df['stack_depth'].max() if not df.empty else None,\n",
        "                            \"max_memory_bytes\": df['mem_size_bytes'].max() if not df.empty else None,\n",
        "                            \"pyusd_steps\": pyusd_execution_steps,\n",
        "                            \"pyusd_percentage\": pyusd_percentage\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    # Add opcode categories if available\n",
        "                    if 'category_gas' in locals() and not category_gas.empty:\n",
        "                        export_data[\"opcode_categories\"] = category_gas.to_dict('records')\n",
        "\n",
        "                    display(export_to_google_sheets(df, export_data, tx_hash))\n",
        "                except Exception as e:\n",
        "                    html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                    display(HTML(html))\n",
        "\n",
        "                    # Fallback to CSV\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.csv\"\n",
        "                    display(download_csv_direct(df, filename))\n",
        "                    display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "        # Connect handlers to buttons\n",
        "        export_buttons.children[0].on_click(export_csv)\n",
        "        export_buttons.children[1].on_click(export_json)\n",
        "        export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "        # Display button container and output area\n",
        "        display(export_buttons)\n",
        "        display(export_output)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- Execute Tracing ---\n",
        "# WARNING: structLog can be VERY large and slow. Default to False.\n",
        "RUN_STRUCTLOG_TRACE = True  # <<< SET TO TRUE TO RUN THIS EXPENSIVE TRACE\n",
        "\n",
        "if not validate_tx_hash:  # Check validation flag from setup cell\n",
        "    console.print(\"[warning]TARGET_TX_HASH not set or invalid. Cannot run structLog analysis.\", style=\"warning\")\n",
        "elif RUN_STRUCTLOG_TRACE:\n",
        "    console.print(\"\\n\\n[bold]🎯 Using structLog on Mainnet[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"───────────────────────────────\", style=\"cyan3\")\n",
        "    console.print(f\"Target Transaction : {TARGET_TX_HASH}\")\n",
        "\n",
        "    # Use the default tracer configuration (the one that worked)\n",
        "    tracer_config = {\"tracerConfig\": TRACE_CONFIGS[\"structLog\"]}\n",
        "\n",
        "    # Request trace on Mainnet\n",
        "    trace_result_struct = make_rpc_request(\"debug_traceTransaction\", [TARGET_TX_HASH, tracer_config], network='mainnet')\n",
        "\n",
        "    # Process result if we got one\n",
        "    if trace_result_struct:\n",
        "        # Check where structLogs might be in the response\n",
        "        struct_logs = None\n",
        "        if 'structLogs' in trace_result_struct:\n",
        "            struct_logs = trace_result_struct['structLogs']\n",
        "        elif 'result' in trace_result_struct and isinstance(trace_result_struct['result'], dict) and 'structLogs' in trace_result_struct['result']:\n",
        "            struct_logs = trace_result_struct['result']['structLogs']\n",
        "\n",
        "        if struct_logs and isinstance(struct_logs, list):\n",
        "            struct_log_df = parse_struct_log(struct_logs, TARGET_TX_HASH)\n",
        "        else:\n",
        "            console.print(\"[warning]Got response, but structLogs format was not as expected.\", style=\"warning\")\n",
        "    else:\n",
        "        console.print(f\"[warning]Failed to get trace data for {TARGET_TX_HASH}.\", style=\"warning\")\n",
        "\n",
        "elif not RUN_STRUCTLOG_TRACE:\n",
        "     console.print(\"\\n[info]Skipping trace analysis as RUN_STRUCTLOG_TRACE is False.\", style=\"info\")\n"
      ],
      "metadata": {
        "id": "axyGCZbU_k45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}