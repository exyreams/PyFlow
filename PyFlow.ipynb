{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "3vkos_TxP4pC",
        "3q7lkAOwW94n",
        "0UP-Z1dFIrES",
        "-LNSmB5aUaoK",
        "2VAJLLSVVxC_",
        "MJEWElUzqMwK"
      ],
      "authorship_tag": "ABX9TyOEj/DdzlGyYK0vE/20CLTT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìä PyFlow: Deep PYUSD Analysis with Google Cloud's Premium RPC Methods\n",
        "\n",
        "**Hackathon Context:** This notebook is developed for the **PayPal x Google Cloud Web3 Bounty**, demonstrating how **Google Cloud Platform's Blockchain Node Engine** unlocks powerful, cost-effective analysis of the **PayPal USD (PYUSD)** stablecoin on Ethereum.\n",
        "\n",
        "---\n",
        "\n",
        "## The Challenge: Unlocking Deep Blockchain Insights\n",
        "\n",
        "Understanding the intricate movements, internal logic, and real-world interactions of stablecoins like **PYUSD** often requires deep, computationally intensive blockchain analysis. Standard block explorers and basic RPC calls provide only surface-level data, while accessing advanced tracing and state inspection methods on most platforms is prohibitively expensive or heavily rate-limited due to their high computational demands.\n",
        "\n",
        "## The Solution: PyFlow leveraging GCP's Advantage\n",
        "\n",
        "This notebook, **PyFlow**, provides a comprehensive toolkit for advanced PYUSD analysis by specifically utilizing **Google Cloud Platform's premium RPC debug and trace methods**.\n",
        "\n",
        "> **üöÄ GCP's Unique Offering: Cost-Effective Access to High-Multiplier Methods**\n",
        ">\n",
        "> Many advanced RPC methods carry significant **request multipliers** due to their computational intensity. For example, a method with a `50x` multiplier consumes the equivalent quota/cost of 50 basic calls (like `eth_call`). Methods like `trace_replayTransaction` have an even higher `100x` multiplier.\n",
        ">\n",
        "> **GCP's Blockchain Node Engine stands out by offering generous free quotas even for these high-multiplier methods**, effectively democratizing access to capabilities previously reserved for specialized infrastructure or high budgets.\n",
        "\n",
        "This allows PyFlow to perform analysis typically infeasible elsewhere, such as:\n",
        "\n",
        "*   **Forensic Accounting:** Tracing PYUSD flow through complex multi-contract DeFi interactions using methods like `debug_traceTransaction` (`50x`).\n",
        "*   **Gas Optimization Analysis:** Pinpointing exact gas costs within internal PYUSD functions or integrations.\n",
        "*   **Security Investigations:** Replaying failed transactions (`trace_replayTransaction`, `100x`) or examining state changes (`stateDiff` via replay).\n",
        "*   **Smart Contract Auditing:** Verifying internal logic, storage layout (`debug_storageRangeAt`, `50x`), and event emission (`eth_getLogs`, `50x`).\n",
        "*   **Network Health Insights:** Analyzing pending transaction queues (`txpool_status`, `50x`) and estimating confirmation times.\n",
        "\n",
        "## üõ†Ô∏è Methods Explored (with GCP Request Multipliers):\n",
        "\n",
        "This notebook provides practical implementations and analysis using the following GCP-powered methods for PYUSD on Ethereum. Multipliers indicate the relative request cost compared to a standard call:\n",
        "\n",
        "*   **Detailed Tracing:**\n",
        "    *   `debug_traceTransaction` (`50x`): In-depth EVM execution trace (using `callTracer` & `structLog`).\n",
        "    *   `trace_transaction` (`50x`): Alternative transaction tracing method.\n",
        "*   **Block-Level Analysis:**\n",
        "    *   `trace_block` (`50x`, Mainnet only): Trace all transactions within a specified block.\n",
        "    *   `debug_traceBlockByNumber` / `debug_traceBlockByHash` (`50x`): Alternative block tracing.\n",
        "*   **State Replay & Simulation:**\n",
        "    *   `trace_replayTransaction` (`100x`, Mainnet only): Re-execute a past transaction with tracers.\n",
        "    *   `trace_replayBlockTransactions` (`100x`, Mainnet only): Re-execute all transactions in a block with tracers.\n",
        "    *   `trace_call` (`50x`, Mainnet only): Simulate transaction calls without sending to the network.\n",
        "*   **State & Data Retrieval:**\n",
        "    *   `eth_getLogs` (`50x`): Efficiently fetch specific PYUSD events (e.g., Transfers, Approvals).\n",
        "    *   `eth_getCode` (`10x`): Retrieve deployed contract bytecode.\n",
        "    *   `debug_storageRangeAt` (`50x`): Inspect raw contract storage slots.\n",
        "    *   `eth_getProof` (`50x`): Fetch Merkle proofs for state verification.\n",
        "*   **Network Monitoring:**\n",
        "    *   `txpool_status` (`50x`): Analyze pending/queued transaction counts.\n",
        "\n",
        "*(Note: Multipliers are based on GCP documentation and highlight the computational intensity absorbed by the service.)*\n",
        "\n",
        "---\n",
        "\n",
        "**üí° Goal:** By the end of this notebook, you will understand how to leverage GCP's unique RPC capabilities, including high-multiplier methods offered with generous quotas, to perform advanced, cost-effective blockchain intelligence specifically tailored for the PYUSD stablecoin.\n"
      ],
      "metadata": {
        "id": "F-UdW5sIniuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Environment Setup: Installing Dependencies for PyFlow\n",
        "---\n",
        "\n",
        "This cell installs the necessary Python packages to run the PyFlow analysis notebook. It sets up a complete environment for interacting with the Ethereum blockchain (via GCP), analyzing PYUSD data, generating visualizations, and connecting to Google Cloud services.\n",
        "\n",
        "### üìä Key Dependencies & Purpose:\n",
        "\n",
        "| Category                 | Packages                                                       | Purpose                                                             |\n",
        "| :----------------------- | :------------------------------------------------------------- | :------------------------------------------------------------------ |\n",
        "| **Core Blockchain/Data** | `web3`, `pandas`, `numpy`                                    | Ethereum RPC interaction, data manipulation                         |\n",
        "| **Visualization**        | `matplotlib`, `plotly`, `seaborn`, `networkx`, `graphviz`, `pygraphviz`    | Charts, transaction graphs, visual analysis                         |\n",
        "| **Google Cloud**         |  `gspread`, `oauth2client` | Accessing Google Sheets export, Authentication |\n",
        "| **Ethereum Utilities**   | `eth-utils`, `rlp`, `tqdm`                                   | Cryptographic functions, RLP encoding, progress bars                |\n",
        "| **Notebook Enhancement** | `ipywidgets`, `rich`                                         | Interactive controls, improved console output                     |\n",
        "\n",
        "### ‚öôÔ∏è Runtime Notes:\n",
        "\n",
        "*   **Environment:** Designed primarily for Google Colab.\n",
        "*   **Resources:** A standard Colab runtime is usually sufficient, but a High-RAM runtime is recommended for analyzing very large blocks or complex transaction traces. GPU is generally not required.\n",
        "*   **Colab Features:** The setup automatically installs system-level `graphviz` and enables interactive data tables within Colab.\n",
        "\n",
        "> **‚è≥ Installation Time:** The process uses `pip` and typically completes in **1-2 minutes**. Please ensure this cell executes successfully before proceeding."
      ],
      "metadata": {
        "id": "Zn0aZAlQop7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üõ†Ô∏è Environment Setup and Package Installation\n",
        "# =============================================================================================\n",
        "# This cell installs and configures all necessary packages for blockchain data analysis.\n",
        "# The setup process may take 1-2 minutes to complete.\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",          # Informational messages\n",
        "    \"success\": \"spring_green3\", # Success indicators\n",
        "    \"warning\": \"gold3\",       # Warning messages\n",
        "    \"error\": \"red3\",          # Error messages\n",
        "    \"highlight\": \"royal_blue1\"  # Highlighted information\n",
        "})\n",
        "\n",
        "# Create console with auto color system detection for better visual feedback\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "console.print(\"\\n‚ú® Environment Setup and Package Installation ‚ú®\", style=\"bold cyan3\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "console.print(\"üîÑ Starting package installation process...\", style=\"info\")\n",
        "\n",
        "# Function to install packages and handle errors with better formatting\n",
        "# This provides visual feedback during the installation process\n",
        "def install_packages(packages, description):\n",
        "    \"\"\"Install specified packages with progress indicator and error handling\"\"\"\n",
        "    with Progress(\n",
        "        SpinnerColumn(),\n",
        "        TextColumn(f\"[info]Installing {description}...\"),\n",
        "        transient=True,\n",
        "    ) as progress:\n",
        "        task = progress.add_task(\"\", total=None)\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages.split())\n",
        "            console.print(f\"‚úì {description} installed\", style=\"success\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError:\n",
        "            console.print(f\"‚ùå Error installing {description}\", style=\"error\")\n",
        "            return False\n",
        "\n",
        "# =============================================================================================\n",
        "# Core Libraries Installation\n",
        "# =============================================================================================\n",
        "\n",
        "# Install core data processing libraries\n",
        "# - web3: For blockchain interaction and smart contract calls\n",
        "# - pandas: For data manipulation and analysis\n",
        "# - numpy: For numerical operations\n",
        "# - matplotlib: For basic visualization\n",
        "success = install_packages(\"web3==6.11.1 pandas numpy matplotlib\",\n",
        "                         \"Core data libraries (web3, pandas, numpy, matplotlib)\")\n",
        "\n",
        "# Install advanced visualization and analysis libraries\n",
        "# - plotly: For interactive charts\n",
        "# - seaborn: For statistical visualizations\n",
        "# - networkx: For blockchain transaction network analysis\n",
        "if success:\n",
        "    success = install_packages(\"plotly seaborn networkx\",\n",
        "                             \"Visualization and analysis libraries (plotly, seaborn, networkx)\")\n",
        "\n",
        "# Install visualization export libraries\n",
        "# - kaleido: For high-quality Plotly chart exports to PNG/PDF/SVG\n",
        "if success:\n",
        "    success = install_packages(\"kaleido\",\n",
        "                             \"Visualization export library (required for exporting charts to images)\")\n",
        "\n",
        "# Install Google API libraries for data access and storage\n",
        "# - gspread: For Google Sheets integration\n",
        "# - oauth2client: For authentication with Google services\n",
        "if success:\n",
        "    success = install_packages(\"gspread oauth2client\",\n",
        "                             \"Google API libraries (gspread, oauth2client)\")\n",
        "\n",
        "# Install interactive widgets for Jupyter/Colab notebooks\n",
        "# - ipywidgets: For creating interactive controls and dashboards\n",
        "if success:\n",
        "    success = install_packages(\"ipywidgets\",\n",
        "                             \"Interactive widgets for Jupyter notebooks\")\n",
        "\n",
        "# Install Ethereum proof verification and analysis libraries\n",
        "# - eth-utils: For cryptographic functions and general Ethereum utilities\n",
        "# - rlp: For Recursive Length Prefix encoding used in Ethereum\n",
        "# - tqdm: For progress visualization in notebook environments\n",
        "# - graphviz: For visualizing Merkle proofs and contract structures\n",
        "if success:\n",
        "    success = install_packages(\"eth-utils rlp tqdm graphviz\",\n",
        "                             \"Ethereum proof verification libraries\")\n",
        "\n",
        "# For Colab environments, install system-level graphviz for visualization\n",
        "\n",
        "try:\n",
        "    # Check if running in Google Colab\n",
        "    import google.colab\n",
        "    console.print(\"\\n\\nüîÑ Installing system dependencies for visualization...\", style=\"info\")\n",
        "    # Install graphviz system package (used for rendering graphs)\n",
        "    subprocess.check_call(['apt-get', '-qq', 'install', 'graphviz'])\n",
        "    console.print(\"‚úì System-level graphviz installed for advanced visualizations\", style=\"success\")\n",
        "\n",
        "    # Install libgraphviz-dev system package\n",
        "    console.print(\"\\n\\nüîÑ Installing libgraphviz Python package...\")\n",
        "    subprocess.check_call(['apt-get', '-qq', 'install', 'libgraphviz-dev'])\n",
        "    console.print(\"‚úì System-level graphviz installed for advanced visualizations\", style=\"success\")\n",
        "\n",
        "    # Install libgraphviz-dev system package\n",
        "    console.print(\"\\n\\nüîÑ Installing pygraphviz Python package...\")\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'pygraphviz'])\n",
        "    console.print(\"‚úì pygraphviz Python connector installed.\", style=\"success\")\n",
        "\n",
        "    # Enable enhanced data visualization and export capabilities\n",
        "    console.print(\"\\n\\nüîÑ Enabling enhanced data visualization and export...\", style=\"info\")\n",
        "\n",
        "    # Enable interactive data tables from Google Colab\n",
        "    try:\n",
        "        from google.colab import data_table\n",
        "        data_table.enable_dataframe_formatter()\n",
        "        console.print(\"‚úì Interactive data tables enabled\", style=\"success\")\n",
        "    except ImportError:\n",
        "        console.print(\"‚ö†Ô∏è Could not enable interactive data tables\", style=\"warning\")\n",
        "\n",
        "    # Import additional components for file exports and Google Sheets integration\n",
        "    try:\n",
        "        # For direct CSV/JSON downloads\n",
        "        import base64\n",
        "        import io\n",
        "\n",
        "        # For Google Sheets export\n",
        "        from google.colab import output\n",
        "        from googleapiclient.discovery import build\n",
        "        from googleapiclient.http import MediaInMemoryUpload\n",
        "\n",
        "        console.print(\"‚úì Export functionality enabled\", style=\"success\")\n",
        "    except ImportError:\n",
        "        console.print(\"‚ö†Ô∏è Some export functions may be limited\", style=\"warning\")\n",
        "\n",
        "    # Verify data table display\n",
        "    try:\n",
        "        from IPython.display import display, HTML\n",
        "        console.print(\"‚úì Data table display verified\", style=\"success\")\n",
        "    except:\n",
        "        console.print(\"‚ö†Ô∏è Data table display verification failed\", style=\"warning\")\n",
        "\n",
        "except ImportError:\n",
        "    console.print(\"‚ÑπÔ∏è Not running in Colab, skipping system-level installations\", style=\"info\")\n",
        "except Exception as e:\n",
        "    console.print(f\"‚ö†Ô∏è Note: Could not install graphviz system package: {e}. Some visualizations may be limited.\", style=\"warning\")\n",
        "\n",
        "# Final status message with extra spacing\n",
        "if success:\n",
        "    console.print(\"\\n\\nüì¶ ‚úì All required packages installed successfully!\", style=\"success\")\n",
        "else:\n",
        "    console.print(\"\\n\\n‚ö†Ô∏è [bold]Some packages failed to install. Please check the errors above.[/bold]\", style=\"warning\")\n",
        "\n",
        "# =============================================================================================\n",
        "# Environment Verification\n",
        "# =============================================================================================\n",
        "# Verify all packages imported correctly and set up the analytics environment\n",
        "\n",
        "try:\n",
        "    # Core data and utility libraries\n",
        "    import os\n",
        "    import json\n",
        "    import time\n",
        "    import warnings\n",
        "    import hashlib\n",
        "\n",
        "    # Data analysis stack\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    # Network and graph analysis\n",
        "    import networkx as nx\n",
        "\n",
        "    # Visualization libraries\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "\n",
        "    # Date handling\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    # Collections and data structures\n",
        "    from collections import defaultdict, Counter\n",
        "\n",
        "    # Blockchain interaction libraries\n",
        "    from web3 import Web3\n",
        "    from web3.exceptions import TransactionNotFound\n",
        "    from web3.middleware import geth_poa_middleware\n",
        "    from hexbytes import HexBytes\n",
        "\n",
        "    # Google Cloud and authentication (for gspread)\n",
        "    from google.colab import auth # Kept for potential gspread auth if needed in Colab\n",
        "    from google.oauth2 import service_account\n",
        "    import gspread\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "    # Import ipywidgets components for interactive dashboards\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "    # Rich components for improved CLI-style output\n",
        "    from rich.panel import Panel\n",
        "    from rich.syntax import Syntax\n",
        "    from rich.table import Table\n",
        "\n",
        "    # Ethereum specific utilities for cryptography and data structures\n",
        "    from eth_utils import keccak, to_bytes, to_hex\n",
        "    import rlp\n",
        "    from tqdm.notebook import tqdm\n",
        "    from graphviz import Digraph\n",
        "\n",
        "    # Suppress warnings for cleaner output\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # Configure pandas display settings for better readability\n",
        "    pd.set_option('display.max_columns', None)  # Show all columns\n",
        "    pd.set_option('display.max_rows', 100)      # Reasonable number of rows\n",
        "    pd.set_option('display.float_format', '{:.6f}'.format)  # Format for amounts\n",
        "\n",
        "    # Setup Plotly for better Jupyter/Colab integration\n",
        "    import plotly.io as pio\n",
        "    pio.templates.default = \"plotly_white\"\n",
        "\n",
        "    console.print(\"\\n\\nüöÄ ‚úì Setup complete! Analytics platform initialized.\", style=\"success\")\n",
        "except ImportError as e:\n",
        "    console.print(f\"\\n\\n‚ùå Error importing libraries: {e}\", style=\"error\")\n",
        "    console.print(\"‚ö†Ô∏è Some required packages may not have been installed correctly.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "jDFZ9R4Iotee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Configuration & Authentication: Connecting to GCP and Ethereum RPC\n",
        "---\n",
        "\n",
        "This crucial cell configures PyFlow to connect to Google Cloud Platform services (for authentication and Google Sheets) and the necessary Ethereum networks via GCP's Blockchain Node Engine. **You MUST edit this cell with your specific credentials before running it.**\n",
        "\n",
        "### üìã Step 1: Provide Your GCP Credentials\n",
        "\n",
        "To use GCP's Blockchain RPC and potentially Google Sheets, you need:\n",
        "\n",
        "1.  **Your GCP Project ID:**\n",
        "    *   **Purpose:** Identifies your Google Cloud project, primarily used here to scope authentication requests for Google Drive/Sheets access.\n",
        "    *   **How to Obtain:** If you don't have one, create it at [GCP Console](https://console.cloud.google.com/projectcreate).\n",
        "    *   **‚û°Ô∏è ACTION REQUIRED:** Find the `GCP_PROJECT_ID` variable in the code below and replace `\"YOUR_PROJECT_ID\"` with your actual Project ID string.\n",
        "2.  **Your GCP Blockchain RPC Endpoints (with API Key):**\n",
        "    *   **Purpose:** Secure URLs to connect to Ethereum Mainnet and testnets via GCP. This is key to interacting with the blockchain using `web3.py`.\n",
        "    *   **How to Obtain:**\n",
        "        1.  Go to the [GCP Blockchain Node Engine Console](https://console.cloud.google.com/blockchain/node-engine) in your project.\n",
        "        2.  Enable the API if you haven't already.\n",
        "        3.  Copy the **full HTTPS RPC endpoint URL** (including `?key=...`) for **Ethereum Mainnet**. Optionally, copy URLs for testnets (Holesky, Sepolia) if needed.\n",
        "    *   **‚û°Ô∏è ACTION REQUIRED:** Find the `BLOCKCHAIN_RPC` dictionary in the code below. Replace the placeholder URLs (e.g., `\"https://blockchain.googleapis.com/...\"`) with your *complete* copied endpoint URLs for `'mainnet'`, `'holesky'`, and `'sepolia'`.\n",
        "\n",
        "    *Example Format (Use your actual URLs):*\n",
        "    ```python\n",
        "    BLOCKCHAIN_RPC = {\n",
        "        'ethereum': {\n",
        "            'mainnet': 'https://YOUR_MAINNET_ENDPOINT_URL?key=YOUR_API_KEY',\n",
        "            # Optional testnets:\n",
        "            'holesky': 'https://YOUR_HOLESKY_ENDPOINT_URL?key=YOUR_API_KEY',\n",
        "            'sepolia': 'https://YOUR_SEPOLIA_ENDPOINT_URL?key=YOUR_API_KEY'\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "\n",
        "### üåê Step 2: Enable Required GCP APIs\n",
        "\n",
        "Ensure the following APIs are **enabled** in your GCP Project *before* running this cell for authentication and Google Sheets integration to work correctly:\n",
        "\n",
        "*   **Blockchain Node Engine API:** ([Enable Link](Coming Soon))\n",
        "*   **Google Drive API:** Required for Google Sheets export/import functionality via `gspread`. ([Enable Link](https://console.cloud.google.com/apis/library/drive.googleapis.com))\n",
        "*   **Google Sheets API:** Required for Google Sheets export/import functionality via `gspread`. ([Enable Link](https://console.cloud.google.com/apis/library/sheets.googleapis.com))\n",
        "\n",
        "> #### **üí°Tip: Follow README for Video Instructions.**\n",
        "\n",
        "### üîê Step 3: Run the Cell & Authenticate\n",
        "\n",
        "When you execute the code cell below:\n",
        "\n",
        "1.  It will define constants (like PYUSD contract addresses) and configurations (trace settings).\n",
        "2.  It will attempt to **authenticate** your Google account (via a pop-up in Colab) to grant access to the enabled GCP services needed for Google Sheets (Drive, Sheets). Follow the prompts.\n",
        "3.  It will initialize `web3.py` clients using your provided RPC endpoints.\n",
        "4.  It will initialize a client for Google Sheets (`gspread`).\n",
        "5.  It will perform **connection tests** (check RPC node block height) and display a status summary.\n",
        "\n",
        "> **‚ö†Ô∏è IMPORTANT:** Double-check that you have replaced the placeholder `GCP_PROJECT_ID` and the **full** `BLOCKCHAIN_RPC` URLs before running. The notebook relies heavily on a successful connection to the **Ethereum Mainnet** endpoint via GCP for most subsequent analysis."
      ],
      "metadata": {
        "id": "caZ8zeBkpW9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üìã Configuration and Authentication for Blockchain Analytics\n",
        "# =============================================================================================\n",
        "# This cell configures & Authenticates for blockchain data analysis.\n",
        "\n",
        "# Import necessary libraries\n",
        "import google.auth\n",
        "\n",
        "try:\n",
        "    from google.colab import auth\n",
        "except ImportError:\n",
        "    auth = None\n",
        "    print(\"Note: Not running in Google Colab, standard gcloud auth will be used if available.\")\n",
        "\n",
        "import gspread\n",
        "from web3 import Web3\n",
        "from web3.middleware import geth_poa_middleware\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn, TimeElapsedColumn\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",\n",
        "    \"success\": \"spring_green3\",\n",
        "    \"warning\": \"gold3\",\n",
        "    \"error\": \"red3\",\n",
        "    \"highlight\": \"royal_blue1\"\n",
        "})\n",
        "\n",
        "# Ensure console is created with the theme\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# =============================================================================================\n",
        "# Contract Configuration: PYUSD Stablecoin Addresses\n",
        "# =============================================================================================\n",
        "\n",
        "# Main PYUSD Contract addresses (used for querying transactions and events)\n",
        "PYUSD_PROXY = Web3.to_checksum_address('0x6c3ea9036406852006290770bedfcaba0e23a0e8')\n",
        "PYUSD_IMPLEMENTATION = Web3.to_checksum_address('0x8EcaE0B0402E29694B3Af35d5943D4631Ee568dC')\n",
        "SUPPLY_CONTROL_PROXY = Web3.to_checksum_address('0x31d9bDEa6F104606C954f8FE6ba614F1BD347Ec3')\n",
        "SUPPLY_CONTROL_IMPLEMENTATION = Web3.to_checksum_address('0xFaB5891ED867a1195303251912013b92c4fc3a1D')\n",
        "\n",
        "# PYUSD Contract Registry with implementation contracts\n",
        "PYUSD_CONTRACTS = {\n",
        "    PYUSD_PROXY.lower(): \"PYUSD Token\",\n",
        "    PYUSD_IMPLEMENTATION.lower(): \"PYUSD Implementation\",\n",
        "    SUPPLY_CONTROL_PROXY.lower(): \"Supply Control\",\n",
        "    SUPPLY_CONTROL_IMPLEMENTATION.lower(): \"Supply Control Impl\"\n",
        "}\n",
        "\n",
        "# Define event topics first\n",
        "TRANSFER_EVENT_TOPIC = Web3.keccak(text=\"Transfer(address,address,uint256)\").hex()\n",
        "APPROVAL_EVENT_TOPIC = Web3.keccak(text=\"Approval(address,address,uint256)\").hex()\n",
        "PAUSED_EVENT_TOPIC = Web3.keccak(text=\"Paused(address)\").hex()\n",
        "UNPAUSED_EVENT_TOPIC = Web3.keccak(text=\"Unpaused(address)\").hex()\n",
        "\n",
        "# Comprehensive PYUSD configuration\n",
        "PYUSD_CONFIG = {\n",
        "    'ethereum': {\n",
        "        'address': PYUSD_PROXY,\n",
        "        'implementation': PYUSD_IMPLEMENTATION,\n",
        "        'decimals': 6,\n",
        "        'symbol': 'PYUSD',\n",
        "        'deployment_block': 15921958,\n",
        "        'transfer_event_topic': TRANSFER_EVENT_TOPIC,\n",
        "        'approval_event_topic': APPROVAL_EVENT_TOPIC,\n",
        "        'pause_event_topic': PAUSED_EVENT_TOPIC,\n",
        "        'unpause_event_topic': UNPAUSED_EVENT_TOPIC\n",
        "    }\n",
        "}\n",
        "\n",
        "PYUSD_ADDRESS_LOWER_ETH = PYUSD_CONFIG['ethereum']['address'].lower()\n",
        "\n",
        "# PYUSD Function Signature Registry\n",
        "PYUSD_SIGNATURES = {\n",
        "    '0xa9059cbb': {\"name\": \"transfer(address,uint256)\", \"type\": \"function\", \"category\": \"token_movement\"},\n",
        "    '0x095ea7b3': {\"name\": \"approve(address,uint256)\", \"type\": \"function\", \"category\": \"allowance\"},\n",
        "    '0x23b872dd': {\"name\": \"transferFrom(address,address,uint256)\", \"type\": \"function\", \"category\": \"token_movement\"},\n",
        "    '0x40c10f19': {\"name\": \"mint(address,uint256)\", \"type\": \"function\", \"category\": \"supply_change\"},\n",
        "    '0x42966c68': {\"name\": \"burn(uint256)\", \"type\": \"function\", \"category\": \"supply_change\"},\n",
        "    '0x18160ddd': {\"name\": \"totalSupply()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x70a08231': {\"name\": \"balanceOf(address)\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0xdd62ed3e': {\"name\": \"allowance(address,address)\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x313ce567': {\"name\": \"decimals()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x06fdde03': {\"name\": \"name()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x95d89b41': {\"name\": \"symbol()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x8456cb59': {\"name\": \"pause()\", \"type\": \"function\", \"category\": \"control\"},\n",
        "    '0x3f4ba83a': {\"name\": \"unpause()\", \"type\": \"function\", \"category\": \"control\"},\n",
        "    '0x5c975abb': {\"name\": \"paused()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0xf2fde38b': {\"name\": \"transferOwnership(address)\", \"type\": \"function\", \"category\": \"admin\"},\n",
        "    '0x8da5cb5b': {\"name\": \"owner()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x715018a6': {\"name\": \"renounceOwnership()\", \"type\": \"function\", \"category\": \"admin\"}\n",
        "}\n",
        "\n",
        "# PYUSD Event Signature Registry with decoders - using the defined event topics\n",
        "PYUSD_EVENTS = {\n",
        "    TRANSFER_EVENT_TOPIC: {\n",
        "        \"name\": \"Transfer(address,address,uint256)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"from\": Web3.to_checksum_address('0x' + topics[1][-40:]),\n",
        "            \"to\": Web3.to_checksum_address('0x' + topics[2][-40:]),\n",
        "            \"value\": int(data, 16)\n",
        "        }\n",
        "    },\n",
        "    APPROVAL_EVENT_TOPIC: {\n",
        "        \"name\": \"Approval(address,address,uint256)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"owner\": Web3.to_checksum_address('0x' + topics[1][-40:]),\n",
        "            \"spender\": Web3.to_checksum_address('0x' + topics[2][-40:]),\n",
        "            \"value\": int(data, 16)\n",
        "        }\n",
        "    },\n",
        "    PAUSED_EVENT_TOPIC: {\n",
        "        \"name\": \"Paused(address)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"account\": Web3.to_checksum_address('0x' + topics[1][-40:]) if len(topics) > 1 else None\n",
        "        }\n",
        "    },\n",
        "    UNPAUSED_EVENT_TOPIC: {\n",
        "        \"name\": \"Unpaused(address)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"account\": Web3.to_checksum_address('0x' + topics[1][-40:]) if len(topics) > 1 else None\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Tracing configurations\n",
        "TRACE_CONFIGS = {\n",
        "    \"callTracer\": {\n",
        "        \"withLog\": True,\n",
        "        \"enableReturnData\": True,\n",
        "        \"enableMemory\": True,\n",
        "        \"enableStack\": True\n",
        "    },\n",
        "    \"structLog\": {\n",
        "        \"disableStorage\": False,\n",
        "        \"disableMemory\": False,\n",
        "        \"disableStack\": False,\n",
        "        \"fullStorage\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "# Gas analysis categories\n",
        "GAS_CATEGORIES = {\n",
        "    \"token_movement\": [\"transfer\", \"transferFrom\"],\n",
        "    \"supply_change\": [\"mint\", \"burn\"],\n",
        "    \"allowance\": [\"approve\", \"increaseAllowance\", \"decreaseAllowance\"],\n",
        "    \"control\": [\"pause\", \"unpause\"],\n",
        "    \"admin\": [\"transferOwnership\", \"renounceOwnership\", \"addMinter\", \"removeMinter\"],\n",
        "    \"view\": [\"balanceOf\", \"allowance\", \"totalSupply\", \"decimals\", \"name\", \"symbol\", \"paused\", \"owner\"],\n",
        "    \"other\": []\n",
        "}\n",
        "\n",
        "\n",
        "# =============================================================================================\n",
        "# Data Source Configuration: Google Cloud & Blockchain RPC\n",
        "# =============================================================================================\n",
        "\n",
        "# Replace \"YOUR_PROJECT_ID\" with your actual GCP Project ID (needed for GSheets auth scope)\n",
        "GCP_PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
        "if \"YOUR_PROJECT_ID\" in GCP_PROJECT_ID or not GCP_PROJECT_ID:\n",
        "    console.print(\"[error]üö® CRITICAL: Please replace placeholder or provide your actual GCP Project ID in GCP_PROJECT_ID.\", style=\"bold red\")\n",
        "\n",
        "# Replace \"YOUR_MAINNET_BLOCKCHAIN_RPC_URL\", \"YOUR_HOLESKY_BLOCKCHAIN_RPC_URL\", \"YOUR_SEPOLIA_BLOCKCHAIN_RPC_URL\" with your FULL RPC endpoint URLs including your API key.\n",
        "# e.g., 'mainnet': 'https://blockchain.googleapis.com/v1/projects/...........'\n",
        "BLOCKCHAIN_RPC = {\n",
        "    'ethereum': {\n",
        "        'holesky': 'YOUR_HOLESKY_BLOCKCHAIN_RPC_URL',\n",
        "        'mainnet': 'YOUR_MAINNET_BLOCKCHAIN_RPC_URL',\n",
        "        'sepolia': 'YOUR_SEPOLIA_BLOCKCHAIN_RPC_URL'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Basic Validation checks for placeholders in URLs\n",
        "rpc_urls_valid = True\n",
        "if 'ethereum' not in BLOCKCHAIN_RPC or not BLOCKCHAIN_RPC['ethereum']: # Check if ethereum key exists and has entries\n",
        "    console.print(\"[error]üö® CRITICAL: BLOCKCHAIN_RPC['ethereum'] is missing or empty.\", style=\"bold red\")\n",
        "    rpc_urls_valid = False\n",
        "else:\n",
        "    for network, url in BLOCKCHAIN_RPC.get('ethereum', {}).items():\n",
        "        # More robust check for placeholders or incomplete URLs\n",
        "        if not url or \"xxx\" in url.lower() or \"/v1/\" not in url or \"key=\" not in url or url.endswith(\"key=\"):\n",
        "            console.print(f\"[error]üö® CRITICAL: RPC URL for '{network}' seems invalid or uses placeholder ('{url}'). Use full URL with API key.\", style=\"bold red\")\n",
        "            rpc_urls_valid = False\n",
        "\n",
        "# Transaction tracing configuration (for detailed transaction analysis)\n",
        "# Increased timeout for complex traces\n",
        "DEFAULT_TRACE_CONFIG = {\n",
        "    'tracer': 'callTracer',\n",
        "    'timeout': '120s',\n",
        "    'tracerConfig': {\n",
        "        'onlyTopCall': False,\n",
        "        'withLog': True,\n",
        "    }\n",
        "}\n",
        "\n",
        "STRUCTLOG_TRACE_CONFIG = {\n",
        "    'tracer': 'structLog',\n",
        "    # 'timeout': '120s',\n",
        "}\n",
        "\n",
        "# =============================================================================================\n",
        "# Global Client Variables\n",
        "# =============================================================================================\n",
        "gc_sheets = None\n",
        "w3_clients = {}\n",
        "\n",
        "# =============================================================================================\n",
        "# Utility Functions: Testing & System Verification\n",
        "# =============================================================================================\n",
        "\n",
        "def authenticate_gcp(progress, task_id):\n",
        "    \"\"\"Authenticate to GCP, initialize Google Sheets client (updates progress descriptively).\"\"\"\n",
        "    global gc_sheets\n",
        "    progress.update(task_id, description=\"[info]Initiating GCP Authentication...\")\n",
        "    if not GCP_PROJECT_ID or \"project_id\" in GCP_PROJECT_ID:\n",
        "         progress.update(task_id, description=\"[error]GCP Auth Failed (No Project ID)\")\n",
        "         return False\n",
        "    auth_success = False\n",
        "    gs_init_success = False\n",
        "    effective_project_id = GCP_PROJECT_ID\n",
        "\n",
        "    try:\n",
        "        # Step 1: Authentication (Colab vs. Default)\n",
        "        creds = None\n",
        "        if auth: # If google.colab.auth was imported successfully\n",
        "            progress.update(task_id, description=\"[info]Waiting for Colab user authentication...\")\n",
        "            auth.authenticate_user(project_id=effective_project_id) # Use project ID here if needed by Colab auth context\n",
        "            auth_success = True\n",
        "            progress.update(task_id, description=\"[info]Colab user authenticated. Getting credentials...\")\n",
        "            creds, _ = google.auth.default() # Get default credentials after Colab auth\n",
        "        else:\n",
        "            # Attempt standard ADC (Application Default Credentials) - works in VM, Cloud Shell, local gcloud auth login\n",
        "            progress.update(task_id, description=\"[info]Attempting default GCP authentication...\")\n",
        "            try:\n",
        "                creds, inferred_project_id = google.auth.default()\n",
        "                if not creds:\n",
        "                     raise Exception(\"Could not get default credentials.\")\n",
        "                auth_success = True\n",
        "                progress.update(task_id, description=\"[info]Default GCP credentials obtained.\")\n",
        "            except Exception as adc_error:\n",
        "                progress.update(task_id, description=\"[error]Default GCP Authentication Failed!\")\n",
        "                console.print(f\"‚ùå Default GCP Auth error: {adc_error}\", style=\"error\")\n",
        "                return False # Hard stop if auth fails\n",
        "\n",
        "        # Ensure we have credentials before proceeding\n",
        "        if not creds:\n",
        "             progress.update(task_id, description=\"[error]Credentials not obtained after auth attempt.\")\n",
        "             return False\n",
        "\n",
        "        # Step 2: Initialize Google Sheets Client\n",
        "        progress.update(task_id, description=\"[info]Initializing Google Sheets client...\")\n",
        "        gc_sheets = gspread.authorize(creds)\n",
        "        # Perform a minimal check (e.g., list spreadsheets) if needed, but authorize usually suffices\n",
        "        # gc_sheets.list_spreadsheet_files(max_results=1)\n",
        "        gs_init_success = True\n",
        "\n",
        "        progress.update(task_id, description=\"[success]GCP Authentication & GSheets Client Initialized\")\n",
        "        return True # Overall success\n",
        "\n",
        "    except Exception as e:\n",
        "        error_stage = \"GCP Setup Error!\"\n",
        "        if not auth_success:\n",
        "            error_stage = \"GCP Authentication Failed!\"\n",
        "        elif not gs_init_success:\n",
        "            error_stage = \"Google Sheets Client Init Failed!\"\n",
        "        progress.update(task_id, description=f\"[error]{error_stage}\")\n",
        "        console.print(f\"‚ùå {error_stage}: {str(e)}\", style=\"error\")\n",
        "        if not gs_init_success: gc_sheets = None\n",
        "        return False\n",
        "\n",
        "\n",
        "def initialize_all_web3_clients(progress, task_id):\n",
        "    \"\"\"Initializes Web3 clients for all networks (updates progress descriptively).\"\"\"\n",
        "    global w3_clients\n",
        "    progress.update(task_id, description=\"[info]Initializing Web3 Clients...\")\n",
        "    w3_clients = {}\n",
        "    success_count = 0\n",
        "    total_networks = 0\n",
        "    if 'ethereum' not in BLOCKCHAIN_RPC or not BLOCKCHAIN_RPC['ethereum']:\n",
        "        progress.update(task_id, description=\"[error]No valid RPC Config found!\")\n",
        "        return False\n",
        "    total_networks = len(BLOCKCHAIN_RPC['ethereum'])\n",
        "    network_statuses = []\n",
        "\n",
        "    for network, rpc_url in BLOCKCHAIN_RPC['ethereum'].items():\n",
        "        progress.update(task_id, description=f\"[info]Connecting to {network.capitalize()}...\")\n",
        "        time.sleep(0.1) # Small delay for visual update\n",
        "        # Find the original url value before the loop modified it\n",
        "        original_url = BLOCKCHAIN_RPC.get('ethereum', {}).get(network, \"\")\n",
        "        is_invalid_url = not original_url or \"xxx\" in original_url.lower() or \"/v1/\" not in original_url or \"key=\" not in original_url or original_url.endswith(\"key=\")\n",
        "        if is_invalid_url:\n",
        "            w3_clients[network] = None\n",
        "            network_statuses.append(f\"{network.capitalize()}:[error]Skipped (Invalid URL)[/error]\")\n",
        "            progress.update(task_id, description=f\"[warning]Skipping {network.capitalize()} (Invalid URL)...\")\n",
        "            continue\n",
        "        try:\n",
        "            # Increased timeout slightly for potentially slower network conditions\n",
        "            provider = Web3.HTTPProvider(rpc_url, request_kwargs={'timeout': 120})\n",
        "            w3_client = Web3(provider)\n",
        "            # Inject middleware only if needed (e.g., for PoA testnets like Goerli, Rinkeby - less relevant for Mainnet/Sepolia/Holesky now)\n",
        "            # Check chain ID if necessary to decide on middleware, but generally safe to add\n",
        "            w3_client.middleware_onion.inject(geth_poa_middleware, layer=0)\n",
        "\n",
        "            # Test connection with get_block_number\n",
        "            block_num = w3_client.eth.get_block_number()\n",
        "            w3_clients[network] = w3_client\n",
        "            success_count += 1\n",
        "            network_statuses.append(f\"{network.capitalize()}:[success]OK (Block: {block_num:,})[/success]\")\n",
        "            progress.update(task_id, description=f\"[info]Connecting... ({success_count}/{total_networks} OK)\")\n",
        "        except Exception as e:\n",
        "            error_short = type(e).__name__\n",
        "            # Add more detail for common errors\n",
        "            if \"Max retries exceeded\" in str(e): error_short = \"ConnectionTimeout\"\n",
        "            elif \"Failed to establish a new connection\" in str(e): error_short = \"ConnectionRefused\"\n",
        "            network_statuses.append(f\"{network.capitalize()}:[error]{error_short}[/error]\")\n",
        "            w3_clients[network] = None\n",
        "            progress.update(task_id, description=f\"[warning]Failed {network.capitalize()} ({error_short})...\")\n",
        "            console.print(f\"[warning]Web3 connection error for {network.capitalize()}: {e}\", style=\"warning\")\n",
        "\n",
        "\n",
        "    final_web3_status = f\"[success]Web3 Clients Initialized ({success_count}/{total_networks} OK)\"\n",
        "    if success_count == 0:\n",
        "        final_web3_status = \"[error]Web3 Client Init Failed (All Networks)\"\n",
        "    elif success_count < total_networks:\n",
        "         final_web3_status = f\"[warning]Web3 Clients Initialized ({success_count}/{total_networks} OK)\"\n",
        "    progress.update(task_id, description=final_web3_status)\n",
        "\n",
        "    # Return True if mainnet client initialized successfully\n",
        "    return w3_clients.get('mainnet') is not None\n",
        "\n",
        "# =============================================================================================\n",
        "# Main Execution: System Initialization and Status Check (with Progress)\n",
        "# =============================================================================================\n",
        "\n",
        "# --- Title Display ---\n",
        "console.print(\"\\n‚ú® Configuration and Authentication ‚ú®\", style=\"bold cyan3\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "# Initialize status variables\n",
        "gcp_auth_success = False\n",
        "any_web3_success = False\n",
        "mainnet_ready = False\n",
        "\n",
        "# Use Rich Progress for initialization steps\n",
        "# Set transient=True to make the progress bar disappear on completion\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    TimeElapsedColumn(),\n",
        "    console=console, # Ensure progress uses the themed console\n",
        "    transient=True # Make spinner disappear when done\n",
        ") as progress:\n",
        "    # Add tasks for each step (total=1 means they complete in one update)\n",
        "    auth_task = progress.add_task(\"GCP Authentication...\", total=1)\n",
        "    web3_task = progress.add_task(\"Initializing Web3 Clients...\", total=1)\n",
        "\n",
        "    # --- Run Initialization Steps (functions update progress description) ---\n",
        "    gcp_auth_success = authenticate_gcp(progress, auth_task)\n",
        "    progress.update(auth_task, completed=1) # Mark as done\n",
        "\n",
        "    if rpc_urls_valid:\n",
        "        any_web3_success = initialize_all_web3_clients(progress, web3_task)\n",
        "    else:\n",
        "        progress.update(web3_task, description=\"[error]Skipped Web3 Init (Invalid URLs)\")\n",
        "    progress.update(web3_task, completed=1)\n",
        "\n",
        "\n",
        "# --- Get Final Status ---\n",
        "mainnet_ready = any_web3_success # mainnet_ready directly reflects if mainnet client succeeded\n",
        "overall_success = gcp_auth_success and mainnet_ready\n",
        "\n",
        "# --- Display Intermediate Success Messages (Now that progress is done) ---\n",
        "if gcp_auth_success:\n",
        "    console.print(f\"‚úì User authentication successful!\", style=\"success\")\n",
        "    if gc_sheets: console.print(f\"‚úì Google Sheets client initialized\", style=\"success\")\n",
        "else:\n",
        "    console.print(f\"‚ùå GCP authentication failed.\", style=\"error\")\n",
        "\n",
        "# Updated Web3 success message based on w3_clients dictionary\n",
        "if w3_clients:\n",
        "    connected_nets = [net.capitalize() for net, client in w3_clients.items() if client]\n",
        "    if connected_nets:\n",
        "        console.print(f\"‚úì Web3 clients connected: {', '.join(connected_nets)}\", style=\"success\")\n",
        "    elif rpc_urls_valid: # Only show warning if init was attempted but failed all\n",
        "         console.print(\"[warning]Web3 clients initialized, but none connected successfully.\", style=\"warning\")\n",
        "else:\n",
        "     # This case occurs if rpc_urls_valid was False\n",
        "     console.print(\"[error]Web3 client initialization skipped due to invalid RPC URLs.\", style=\"error\")\n",
        "\n",
        "\n",
        "# --- Display Final System Status Summary ---\n",
        "console.print(\"\\n\\nüìä System Status Summary\", style=\"highlight\")\n",
        "# RPC Status\n",
        "if w3_clients:\n",
        "    for network, client in w3_clients.items():\n",
        "        connected = client is not None\n",
        "        status_msg = \"[red]Failed/Skipped[/red]\" # Default if not connected\n",
        "        if connected:\n",
        "             try:\n",
        "                 block_num = client.eth.block_number # Get block number again for final status\n",
        "                 block_num_str = f\"(Block #{block_num:,})\"\n",
        "                 status_msg = f\"[green]Connected[/green] {block_num_str}\"\n",
        "             except Exception as e:\n",
        "                  # If client exists but fails here, mark as unresponsive\n",
        "                  status_msg = f\"[orange3]Unresponsive ({type(e).__name__})[/orange3]\"\n",
        "                  w3_clients[network] = None # Clear bad client for consistency\n",
        "                  console.print(f\"[warning]RPC ({network.capitalize()}) became unresponsive: {e}\", style=\"warning\")\n",
        "        else:\n",
        "            # Add reason if skipped due to invalid URL during init\n",
        "            original_url = BLOCKCHAIN_RPC.get('ethereum', {}).get(network, \"\")\n",
        "            if not original_url or \"xxx\" in original_url.lower():\n",
        "                 status_msg = \"[red]Skipped (Invalid URL)[/red]\"\n",
        "\n",
        "        console.print(f\"  ‚Ä¢ Ethereum RPC ({network.capitalize()}): {status_msg}\")\n",
        "elif not rpc_urls_valid:\n",
        "    console.print(\"  ‚Ä¢ Ethereum RPC: [red]Skipped (Invalid URLs)[/red]\")\n",
        "else:\n",
        "    console.print(\"  ‚Ä¢ Ethereum RPC: [red]Initialization Failed[/red]\")\n",
        "\n",
        "# GCP Status\n",
        "status_auth = \"[green]Successful[/green]\" if gcp_auth_success else \"[red]Failed[/red]\"\n",
        "console.print(f\"  ‚Ä¢ GCP Authentication: {status_auth}\")\n",
        "\n",
        "# Google Sheets Status\n",
        "status_gs = \"[green]Initialized[/green]\" if gc_sheets else \"[red]Not Initialized[/red]\"\n",
        "if not gcp_auth_success: # Also mark skipped if auth failed\n",
        "    status_gs = \"[yellow]Skipped[/yellow]\"\n",
        "console.print(f\"  ‚Ä¢ Google Sheets Client: {status_gs}\")\n",
        "\n",
        "# --- Final Ready/Failure Message with Checkmark ---\n",
        "if overall_success:\n",
        "    console.print(\"\\n\\n[bold green]‚úì Configuration Complete:[/bold green] System Ready for Ethereum Blockchain Analytics (via RPC) and Google Sheets\")\n",
        "    # Optional warnings for testnets can still be useful\n",
        "    if 'holesky' in w3_clients and w3_clients.get('holesky') is None: console.print(\"  [warning](Note: Holesky testnet connection failed/skipped/unresponsive)\", style=\"warning\")\n",
        "    if 'sepolia' in w3_clients and w3_clients.get('sepolia') is None: console.print(\"  [warning](Note: Sepolia testnet connection failed/skipped/unresponsive)\", style=\"warning\")\n",
        "else:\n",
        "     failure_reasons = []\n",
        "     if not gcp_auth_success: failure_reasons.append(\"GCP Auth Failed\")\n",
        "     if not w3_clients.get('mainnet'): failure_reasons.append(\"Mainnet RPC Connection Failed/Skipped\")\n",
        "     if gcp_auth_success and not gc_sheets: failure_reasons.append(\"Google Sheets Client Failed\") # Check if GSheets failed despite auth success\n",
        "     if not rpc_urls_valid: failure_reasons.append(\"Invalid RPC URL Placeholders\")\n",
        "\n",
        "\n",
        "     reason_str = ', '.join(failure_reasons) if failure_reasons else \"Unknown Issues\"\n",
        "     console.print(f\"\\n\\n[bold red]‚ùå Configuration Failed:[/bold red] System setup encountered issues ({reason_str}). Review status messages above.\")"
      ],
      "metadata": {
        "id": "PLaPz_r4paFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 üéØ Analysis Targets & Utility Functions\n",
        "---\n",
        "\n",
        "This cell handles target validation and prepares the essential utilities needed for transaction/block analysis:\n",
        "\n",
        "1.  **üåê Network Verification:**\n",
        "    *   Verifies connectivity to Ethereum Mainnet and available testnets\n",
        "    *   Displays current block heights and chain IDs\n",
        "    *   Attempts reconnection if mainnet client is unavailable\n",
        "\n",
        "2.  **üéØ Define Analysis Targets:**\n",
        "    *   Set the specific Ethereum Mainnet **transaction hash** (`TARGET_TX_HASH`) or **block identifier** (`TARGET_BLOCK_IDENTIFIER`) you wish to analyze\n",
        "    *   **ACTION:** Modify these values to analyze different transactions or blocks relevant to PYUSD\n",
        "    *   Targets are automatically validated for proper format and existence on-chain\n",
        "\n",
        "3.  **üîß Helper Function Library:**\n",
        "    *   Initializes essential functions used throughout the notebook for:\n",
        "        *   Making raw RPC requests (`make_rpc_request`) to Ethereum nodes\n",
        "        *   Decoding PYUSD-specific function calls and events\n",
        "        *   Formatting blockchain values (ETH/PYUSD amounts, gas)\n",
        "        *   Handling addresses and transaction data\n",
        "        *   Creating visualizations for transaction analysis\n",
        "\n",
        "> **Note:** If a target validation fails, specific diagnostic information will be displayed to help troubleshoot the issue."
      ],
      "metadata": {
        "id": "5vZzVowv-D0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üéØ Target Selection & Helper Functions for Tracing\n",
        "# =============================================================================================\n",
        "# This cell validates targets, initializes tracing configurations, and sets up helper functions.\n",
        "\n",
        "# Ensure web3 clients dictionary is loaded from the previous cell\n",
        "if 'w3_clients' not in locals() or not isinstance(w3_clients, dict):\n",
        "     raise NameError(\"Web3 clients dictionary 'w3_clients' not initialized. Please run 'üîë Configuration & Authentication: Connecting to GCP and Ethereum RPC' Cell\")\n",
        "\n",
        "# --- Network Status Verification ---\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    console=console,\n",
        "    transient=True\n",
        ") as progress:\n",
        "    verification_task = progress.add_task(\"[info]Verifying network connections...\", total=1)\n",
        "\n",
        "    w3_mainnet = w3_clients.get('mainnet')\n",
        "    if not w3_mainnet or not w3_mainnet.is_connected():\n",
        "         # Attempt re-initialization with visual feedback\n",
        "         progress.update(verification_task, description=\"[warning]‚ö†Ô∏è Mainnet client not found. Attempting re-initialization...\")\n",
        "         web3_task = progress.add_task(\"[info]Reinitializing Web3 clients...\", total=1)\n",
        "         initialize_all_web3_clients(progress, web3_task)\n",
        "         progress.update(web3_task, completed=1)\n",
        "\n",
        "         # Check if reconnection succeeded\n",
        "         w3_mainnet = w3_clients.get('mainnet')\n",
        "         if not w3_mainnet or not w3_mainnet.is_connected():\n",
        "              raise ConnectionError(\"Cannot proceed without a connected Mainnet Web3 client. Check your RPC endpoints.\")\n",
        "\n",
        "    # Get testnet client if available (for testing function implementations)\n",
        "    progress.update(verification_task, description=\"[info]Checking for testnet availability...\")\n",
        "    w3_testnet = w3_clients.get('sepolia') or w3_clients.get('holesky') # Prefer Sepolia if available\n",
        "    if w3_testnet and w3_testnet.is_connected():\n",
        "        # Find the network name ('holesky' or 'sepolia')\n",
        "        testnet_name = next((name for name in ['sepolia', 'holesky'] if w3_clients.get(name) == w3_testnet), None)\n",
        "    else:\n",
        "        testnet_name = None # No connections with testnet\n",
        "\n",
        "    progress.update(verification_task, completed=1)\n",
        "\n",
        "# --- Network Status Table ---\n",
        "console.print(\"[bold cyan3 size=20]üåê Network Connections[/]\", justify=\"left\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "network_table = Table(show_header=True, header_style=\"bold cyan3\")\n",
        "network_table.add_column(\"Network\", style=\"dim\")\n",
        "network_table.add_column(\"Status\", justify=\"center\")\n",
        "network_table.add_column(\"Block Height\", justify=\"right\")\n",
        "network_table.add_column(\"Chain ID\", justify=\"right\")\n",
        "\n",
        "# Add Mainnet info\n",
        "latest_block_mainnet = w3_mainnet.eth.block_number if w3_mainnet else \"N/A\"\n",
        "chain_id_mainnet = w3_mainnet.eth.chain_id if w3_mainnet else \"N/A\"\n",
        "network_table.add_row(\n",
        "    \"Ethereum Mainnet\",\n",
        "    \"[spring_green3]Connected[/spring_green3]\" if w3_mainnet and w3_mainnet.is_connected() else \"[red3]Disconnected[/red3]\",\n",
        "    f\"{latest_block_mainnet:,}\" if isinstance(latest_block_mainnet, int) else str(latest_block_mainnet),\n",
        "    str(chain_id_mainnet)\n",
        ")\n",
        "\n",
        "# Add Testnet info if available\n",
        "if testnet_name:\n",
        "    latest_block_testnet = w3_testnet.eth.block_number if w3_testnet else \"N/A\"\n",
        "    chain_id_testnet = w3_testnet.eth.chain_id if w3_testnet else \"N/A\"\n",
        "    network_table.add_row(\n",
        "        f\"{testnet_name.capitalize()} Testnet\",\n",
        "        \"[spring_green3]Connected[/spring_green3]\" if w3_testnet and w3_testnet.is_connected() else \"[red3]Disconnected[/red3]\",\n",
        "        f\"{latest_block_testnet:,}\" if isinstance(latest_block_testnet, int) else str(latest_block_testnet),\n",
        "        str(chain_id_testnet)\n",
        "    )\n",
        "else:\n",
        "    network_table.add_row(\"Testnet\", \"[gold3]Not Available[/gold3]\", \"N/A\", \"N/A\")\n",
        "\n",
        "# Display the network connection table\n",
        "console.print(network_table)\n",
        "console.print(\"\\n\\n\")  # Empty lines for better spacing\n",
        "\n",
        "############################################################\n",
        "# üéØ DEFINE YOUR ETHEREUM ANALYSIS TARGET\n",
        "# Set BOTH values below for optimal analysis capabilities.\n",
        "############################################################\n",
        "\n",
        "# Transaction Hash for analysis\n",
        "# Required by certain analysis functions.\n",
        "TARGET_TX_HASH = \"YOUR_TARGET_TX_HASH\"\n",
        "\n",
        "# Block Number/Identifier for analysis\n",
        "# Required by other analysis functions (often related to block context).\n",
        "# Use the block containing the target transaction, or the specific block you want to analyze.\n",
        "TARGET_BLOCK_IDENTIFIER = YOUR_TARGET_BLOCK_NUMBER # Or block hash, \"latest\", etc.\n",
        "\n",
        "# Important Notes:\n",
        "# - Full analysis experience requires both TARGET_TX_HASH and TARGET_BLOCK_IDENTIFIER.\n",
        "# - Some functions specifically need the block context, others the transaction details.\n",
        "# - If both values are set, TARGET_TX_HASH takes precedence in situations where\n",
        "#   only one identifier can be used as the primary target.\n",
        "############################################################\n",
        "\n",
        "# Import necessary packages for helper functions\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from graphviz import Digraph\n",
        "from IPython.display import display, Javascript\n",
        "from hexbytes import HexBytes\n",
        "from rich.panel import Panel\n",
        "from rich.syntax import Syntax\n",
        "from rich.table import Table\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Plotly configuration for Colab\n",
        "try:\n",
        "    display(Javascript('''\n",
        "        require.config({\n",
        "            paths: {\n",
        "                plotly: 'https://cdn.plot.ly/plotly-latest.min.js'\n",
        "            }\n",
        "        });\n",
        "    '''))\n",
        "except Exception as e:\n",
        "    console.print(f\"[warning]Could not re-configure Plotly: {e}\", style=\"warning\")\n",
        "\n",
        "# --- Target Validation Functions ---\n",
        "def validate_tx_hash(tx_hash):\n",
        "    \"\"\"Validates a transaction hash with detailed diagnostics\"\"\"\n",
        "    if not tx_hash:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Missing\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Transaction hash not provided\"\n",
        "        }\n",
        "\n",
        "    if not isinstance(tx_hash, str):\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Type\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Expected string, got {type(tx_hash).__name__}\"\n",
        "        }\n",
        "\n",
        "    if not tx_hash.startswith('0x'):\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Format\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Transaction hash must start with '0x'\"\n",
        "        }\n",
        "\n",
        "    if len(tx_hash) < 66:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Too Short\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Length is {len(tx_hash)}, should be 66 characters\"\n",
        "        }\n",
        "\n",
        "    if len(tx_hash) > 66:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Too Long\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Length is {len(tx_hash)}, should be 66 characters (including '0x')\"\n",
        "        }\n",
        "\n",
        "    # Check if characters are valid hex\n",
        "    try:\n",
        "        int(tx_hash[2:], 16)\n",
        "    except ValueError:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Hex\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Contains non-hexadecimal characters\"\n",
        "        }\n",
        "\n",
        "    # At this point, the format is valid, try to retrieve it\n",
        "    try:\n",
        "        tx_receipt = w3_mainnet.eth.get_transaction_receipt(tx_hash[:66])  # Truncate to valid length for retrieval\n",
        "        tx_details = w3_mainnet.eth.get_transaction(tx_hash[:66])\n",
        "\n",
        "        # Format gas info\n",
        "        gas_used = tx_receipt.get('gasUsed', 0)\n",
        "        gas_limit = tx_details.get('gas', 0)\n",
        "        gas_percentage = (gas_used / gas_limit * 100) if gas_limit else 0\n",
        "\n",
        "        # Check if transaction was successful\n",
        "        is_success = tx_receipt.get('status') == 1\n",
        "\n",
        "        return {\n",
        "            'valid': True,\n",
        "            'status': \"Found\" if is_success else \"Failed Transaction\",\n",
        "            'status_color': \"spring_green3\" if is_success else \"gold3\",\n",
        "            'details': f\"Block: {tx_receipt.get('blockNumber')}, Gas: {gas_used:,}/{gas_limit:,} ({gas_percentage:.1f}%)\",\n",
        "            'data': {\n",
        "                'receipt': tx_receipt,\n",
        "                'transaction': tx_details,\n",
        "                'success': is_success\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'valid': True,  # Format is valid but transaction not found\n",
        "            'status': \"Valid Format, Not Found\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': f\"Error: {str(e)}\"  # No truncation\n",
        "        }\n",
        "\n",
        "def validate_block_identifier(block_id):\n",
        "    \"\"\"Validates a block identifier with detailed diagnostics\"\"\"\n",
        "    if block_id is None:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Missing\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Block identifier not provided\"\n",
        "        }\n",
        "\n",
        "    # For integer block numbers\n",
        "    if isinstance(block_id, int):\n",
        "        if block_id < 0:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Negative Number\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Block number cannot be negative\"\n",
        "            }\n",
        "\n",
        "        # Check if block is within realistic range\n",
        "        latest_block = w3_mainnet.eth.block_number if w3_mainnet else None\n",
        "        if latest_block and block_id > latest_block:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Future Block\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': f\"Block {block_id:,} exceeds current mainnet height ({latest_block:,})\"\n",
        "            }\n",
        "\n",
        "        # Block is valid by format, try to retrieve it\n",
        "        try:\n",
        "            block_details = w3_mainnet.eth.get_block(block_id)\n",
        "\n",
        "            # Format timestamp from Unix timestamp\n",
        "            block_time = datetime.fromtimestamp(block_details.timestamp)\n",
        "\n",
        "            return {\n",
        "                'valid': True,\n",
        "                'status': \"Found\",\n",
        "                'status_color': \"spring_green3\",\n",
        "                'details': f\"Time: {block_time.strftime('%Y-%m-%d %H:%M:%S')}, TX Count: {len(block_details['transactions'])}\",\n",
        "                'data': block_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'valid': True,  # Format is valid but block not found\n",
        "                'status': \"Valid Format, Not Found\",\n",
        "                'status_color': \"gold3\",\n",
        "                'details': f\"Error: {str(e)}\"  # No truncation\n",
        "            }\n",
        "\n",
        "    # For hex string or hash\n",
        "    if isinstance(block_id, str):\n",
        "        if not block_id.startswith('0x'):\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Invalid Format\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Block hash must start with '0x'\"\n",
        "            }\n",
        "\n",
        "        # Check if characters are valid hex\n",
        "        try:\n",
        "            int(block_id[2:], 16)\n",
        "        except ValueError:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Invalid Hex\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Contains non-hexadecimal characters\"\n",
        "            }\n",
        "\n",
        "        # Block hash is valid by format, try to retrieve it\n",
        "        try:\n",
        "            block_details = w3_mainnet.eth.get_block(block_id)\n",
        "\n",
        "            # Format timestamp from Unix timestamp\n",
        "            block_time = datetime.fromtimestamp(block_details.timestamp)\n",
        "\n",
        "            return {\n",
        "                'valid': True,\n",
        "                'status': \"Found\",\n",
        "                'status_color': \"spring_green3\",\n",
        "                'details': f\"Time: {block_time.strftime('%Y-%m-%d %H:%M:%S')}, TX Count: {len(block_details['transactions'])}\",\n",
        "                'data': block_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'valid': True,  # Format is valid but block not found\n",
        "                'status': \"Valid Format, Not Found\",\n",
        "                'status_color': \"gold3\",\n",
        "                'details': f\"Error: {str(e)}\"  # No truncation\n",
        "            }\n",
        "\n",
        "    # If not int or str\n",
        "    return {\n",
        "        'valid': False,\n",
        "        'status': \"Invalid Type\",\n",
        "        'status_color': \"red3\",\n",
        "        'details': f\"Expected int or string, got {type(block_id).__name__}\"\n",
        "    }\n",
        "\n",
        "# --- Target Verification & Information Retrieval with progress indicator ---\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    console=console,\n",
        "    transient=True\n",
        ") as progress:\n",
        "    validate_task = progress.add_task(\"[info]Validating analysis targets...\", total=2)\n",
        "\n",
        "    # Validate transaction hash\n",
        "    progress.update(validate_task, description=\"[info]Analyzing transaction hash...\")\n",
        "    if 'TARGET_TX_HASH' in locals() and TARGET_TX_HASH:\n",
        "        tx_validation = validate_tx_hash(TARGET_TX_HASH)\n",
        "        tx_valid = tx_validation['valid']\n",
        "    else:\n",
        "        tx_valid = False\n",
        "        tx_validation = {\n",
        "            'status': \"Skipped\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': \"No transaction hash provided\"\n",
        "        }\n",
        "\n",
        "    progress.update(validate_task, advance=1)\n",
        "\n",
        "    # Validate block identifier\n",
        "    progress.update(validate_task, description=\"[info]Analyzing block identifier...\")\n",
        "    if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "        block_validation = validate_block_identifier(TARGET_BLOCK_IDENTIFIER)\n",
        "        block_valid = block_validation['valid']\n",
        "    else:\n",
        "        block_valid = False\n",
        "        block_validation = {\n",
        "            'status': \"Skipped\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': \"No block identifier provided\"\n",
        "        }\n",
        "\n",
        "    progress.update(validate_task, completed=1)\n",
        "\n",
        "# --- Target Status Display (Key-Value Format) ---\n",
        "console.print(\"[bold royal_blue1 size=20]üéØ Analysis Targets[/]\", justify=\"left\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"royal_blue1\")\n",
        "console.print(\"\\n\")  # Extra spacing\n",
        "\n",
        "# Transaction Target\n",
        "console.print(\"[bold]Target Type - Transaction Hash[/bold]\")\n",
        "if 'TARGET_TX_HASH' in locals() and TARGET_TX_HASH:\n",
        "    console.print(f\"[dim]Value:[/dim] [cyan3]{TARGET_TX_HASH}[/cyan3]\")\n",
        "else:\n",
        "    console.print(\"[dim]Value:[/dim] Nil\")\n",
        "\n",
        "console.print(f\"[dim]Status:[/dim] [{tx_validation['status_color']}]{tx_validation.get('status', 'Unknown')}[/{tx_validation['status_color']}]\")\n",
        "console.print(f\"[dim]Diagnostics:[/dim] {tx_validation.get('details', 'No information available')}\")\n",
        "\n",
        "# Separator\n",
        "console.print(\"\\n\" + \"‚îÄ\" * 50 + \"\\n\")\n",
        "\n",
        "# Block Target\n",
        "console.print(\"[bold]Target Type - Block[/bold]\")\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    console.print(f\"[dim]Value:[/dim] [cyan3]{TARGET_BLOCK_IDENTIFIER}[/cyan3]\")\n",
        "else:\n",
        "    console.print(\"[dim]Value:[/dim] Nil\")\n",
        "\n",
        "console.print(f\"[dim]Status:[/dim] [{block_validation['status_color']}]{block_validation.get('status', 'Unknown')}[/{block_validation['status_color']}]\")\n",
        "console.print(f\"[dim]Diagnostics:[/dim] {block_validation.get('details', 'No information available')}\")\n",
        "\n",
        "console.print(\"\\n\")  # Extra spacing\n",
        "\n",
        "# Show target selection status message\n",
        "if not tx_valid and not block_valid:\n",
        "    console.print(\"[error]‚ö†Ô∏è No valid targets found. Please set either TARGET_TX_HASH or TARGET_BLOCK_IDENTIFIER.[/error]\", style=\"bold red3\")\n",
        "elif tx_valid and block_valid:\n",
        "    # Check if both targets exist but the transaction validation found the transaction and the block validation found the block\n",
        "    if tx_validation.get('status') == \"Found\" and block_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]‚ÑπÔ∏è Both transaction and block targets are found. Transaction analysis will take priority.[/info]\", style=\"bold royal_blue1\")\n",
        "    else:\n",
        "        console.print(\"[info]‚ÑπÔ∏è Both transaction and block targets are provided but at least one wasn't found. Valid target will be used.[/info]\", style=\"bold royal_blue1\")\n",
        "elif tx_valid:\n",
        "    if tx_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]‚úì Transaction target is valid and found. Ready for analysis.[/info]\", style=\"bold spring_green3\")\n",
        "    else:\n",
        "        console.print(\"[warning]‚ö†Ô∏è Transaction target format is valid but transaction wasn't found. Check the hash.[/warning]\", style=\"bold gold3\")\n",
        "elif block_valid:\n",
        "    if block_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]‚úì Block target is valid and found. Ready for analysis.[/info]\", style=\"bold spring_green3\")\n",
        "    else:\n",
        "        console.print(\"[warning]‚ö†Ô∏è Block target format is valid but block wasn't found. Check the number/hash.[/warning]\", style=\"bold gold3\")\n",
        "\n",
        "console.print(\"\\n\")  # Empty line for better spacing\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def make_rpc_request(method, params, network='mainnet'):\n",
        "    \"\"\"Helper function to make raw RPC requests via the specified network's provider.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "    try:\n",
        "        response = w3_client.provider.make_request(method, params)\n",
        "        if 'error' in response:\n",
        "            console.print(f\"[error]RPC Error ({method} on {network}): {response['error']['message']} (Code: {response['error']['code']})\", style=\"error\")\n",
        "            return None\n",
        "        return response.get('result')\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Exception during RPC call ({method} on {network}): {str(e)}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "# --- PYUSD Contract Helpers ---\n",
        "def is_pyusd_contract(address):\n",
        "    \"\"\"Checks if an address is a known PYUSD contract.\"\"\"\n",
        "    if not address:\n",
        "        return False\n",
        "    address_lower = address.lower() if isinstance(address, str) else str(address).lower()\n",
        "    return address_lower in PYUSD_CONTRACTS\n",
        "\n",
        "def get_contract_name(address):\n",
        "    \"\"\"Gets the friendly name for a contract address.\"\"\"\n",
        "    if not address:\n",
        "        return \"Unknown\"\n",
        "    address_lower = address.lower() if isinstance(address, str) else str(address).lower()\n",
        "    return PYUSD_CONTRACTS.get(address_lower, \"Other Contract\")\n",
        "\n",
        "def decode_pyusd_function(input_data):\n",
        "    \"\"\"Decodes PYUSD function calls using the signature registry.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"Empty call data\"\n",
        "\n",
        "    method_sig = input_data[:10]\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        return PYUSD_SIGNATURES[method_sig][\"name\"]\n",
        "    return f\"Unknown function: {method_sig}\"\n",
        "\n",
        "def get_function_category(input_data):\n",
        "    \"\"\"Gets the category of a function from its input data.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"other\"\n",
        "\n",
        "    method_sig = input_data[:10]\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        return PYUSD_SIGNATURES[method_sig][\"category\"]\n",
        "    return \"other\"\n",
        "\n",
        "def decode_pyusd_event(topic0, topics, data):\n",
        "    \"\"\"Decodes PYUSD events using the event registry.\"\"\"\n",
        "    if not topic0 or topic0 not in PYUSD_EVENTS:\n",
        "        return {\"name\": \"Unknown event\", \"details\": \"Cannot decode\"}\n",
        "\n",
        "    event_info = PYUSD_EVENTS[topic0]\n",
        "\n",
        "    try:\n",
        "        decoded = event_info[\"decoder\"](topics, data)\n",
        "        return {\n",
        "            \"name\": event_info[\"name\"],\n",
        "            \"decoded\": decoded\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"name\": event_info[\"name\"],\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# --- Formatting Helpers ---\n",
        "def format_value_pyusd(value_raw):\n",
        "    \"\"\"Formats raw PYUSD value (int) to decimal string.\"\"\"\n",
        "    if value_raw is None: return \"0 PYUSD\"\n",
        "    try:\n",
        "        decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "        value_float = int(value_raw) / (10**decimals)\n",
        "        return f\"{value_float:,.{decimals}f} PYUSD\"\n",
        "    except (ValueError, TypeError):\n",
        "        return \"Invalid PYUSD Value\"\n",
        "\n",
        "def format_value_eth(value_wei):\n",
        "    \"\"\"Formats Wei value to Ether string.\"\"\"\n",
        "    if value_wei is None: return \"0 ETH\"\n",
        "    try:\n",
        "        # Ensure value_wei is int or can be converted (handle hex strings from traces)\n",
        "        if isinstance(value_wei, str):\n",
        "            value_int = int(value_wei, 16)\n",
        "        else:\n",
        "             value_int = int(value_wei)\n",
        "        # Use mainnet client for formatting ETH value regardless of target network\n",
        "        if w3_mainnet: # Check if mainnet client exists\n",
        "            return f\"{w3_mainnet.from_wei(value_int, 'ether'):.6f} ETH\"\n",
        "        else:\n",
        "            return f\"{value_int / 1e18:.6f} ETH (approx)\" # Fallback if mainnet client missing\n",
        "    except (ValueError, TypeError, AttributeError):\n",
        "        return \"Invalid ETH Value\"\n",
        "\n",
        "def format_gas(gas):\n",
        "    \"\"\"Formats gas value (int or hex string).\"\"\"\n",
        "    if gas is None: return \"N/A\"\n",
        "    try:\n",
        "       gas_int = int(gas, 16) if isinstance(gas, str) and gas.startswith('0x') else int(gas)\n",
        "       return f\"{gas_int:,}\"\n",
        "    except (ValueError, TypeError):\n",
        "        return \"Invalid Gas Value\"\n",
        "\n",
        "def shorten_address(address):\n",
        "    \"\"\"Shortens an Ethereum address for display.\"\"\"\n",
        "    if not isinstance(address, str) or not address.startswith('0x') or len(address) != 42:\n",
        "        return str(address) # Return original if not a valid address string\n",
        "    return f\"{address[:6]}...{address[-4:]}\"\n",
        "\n",
        "def display_json(data, title=\"JSON Output\"):\n",
        "    \"\"\"Pretty prints JSON data using Rich.\"\"\"\n",
        "    if data is None:\n",
        "        console.print(f\"[warning]{title}: No data to display.\", style=\"warning\")\n",
        "        return\n",
        "    try:\n",
        "        # Use default=str to handle potential non-serializable types like HexBytes\n",
        "        json_str = json.dumps(data, indent=2, default=str)\n",
        "        console.print(Panel(Syntax(json_str, \"json\", theme=\"default\", line_numbers=False),\n",
        "                      title=title, border_style=\"cyan3\", expand=False))\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Could not display JSON for {title}: {e}\", style=\"error\")\n",
        "        # Fallback to printing raw data (limited length)\n",
        "        try:\n",
        "            raw_str = str(data)\n",
        "            console.print(raw_str[:1000] + (\"...\" if len(raw_str) > 1000 else \"\"))\n",
        "        except Exception:\n",
        "            console.print(\"[error]Could not print raw data fallback.\", style=\"error\")\n",
        "\n",
        "# --- Visualization Helpers ---\n",
        "def create_gas_usage_chart(gas_data, title=\"Gas Usage Distribution\"):\n",
        "    \"\"\"Creates a pie chart showing gas usage distribution.\"\"\"\n",
        "    try:\n",
        "        fig = px.pie(gas_data, values='gas_used', names='category',\n",
        "                      title=title)\n",
        "        fig.update_layout(template=\"plotly_white\")\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not create gas usage chart: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "def create_call_sequence_chart(calls_df, highlight_pyusd=True):\n",
        "    \"\"\"Creates a bar chart showing the sequence of calls with gas usage.\"\"\"\n",
        "    try:\n",
        "        if highlight_pyusd:\n",
        "            fig = px.bar(calls_df, x='id', y='gasUsed', color='is_pyusd',\n",
        "                         title='Gas Usage by Call Sequence',\n",
        "                         hover_data=['type', 'depth', 'from', 'to'])\n",
        "        else:\n",
        "            fig = px.bar(calls_df, x='id', y='gasUsed',\n",
        "                         title='Gas Usage by Call Sequence',\n",
        "                         hover_data=['type', 'depth', 'from', 'to'])\n",
        "\n",
        "        fig.update_layout(template=\"plotly_white\")\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not create call sequence chart: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "# --- Final Tracing Configuration Setup ---\n",
        "# Set up trace configuration based on targets\n",
        "if tx_valid and tx_validation.get('status') == \"Found\":\n",
        "    # If valid transaction hash found, prepare for transaction tracing\n",
        "    ACTIVE_TRACE_CONFIG = DEFAULT_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[info]Trace configuration ready for transaction analysis\", style=\"info\")\n",
        "elif block_valid and block_validation.get('status') == \"Found\":\n",
        "    # If valid block found, prepare for block tracing\n",
        "    ACTIVE_TRACE_CONFIG = STRUCTLOG_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[info]Trace configuration ready for block analysis\", style=\"info\")\n",
        "else:\n",
        "    # If no valid targets, set a default trace config\n",
        "    ACTIVE_TRACE_CONFIG = DEFAULT_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[warning]Using default trace configuration (no valid target found)\", style=\"warning\")\n",
        "\n",
        "# Final status message\n",
        "status_icon = \"‚úì\" if (tx_valid and tx_validation.get('status') == \"Found\") or (block_valid and block_validation.get('status') == \"Found\") else \"‚ö†Ô∏è\"\n",
        "status_style = \"bold spring_green3\" if status_icon == \"‚úì\" else \"bold gold3\"\n",
        "console.print(f\"[{status_style}]{status_icon} Target selection and helper functions initialized[/{status_style}]\")"
      ],
      "metadata": {
        "id": "hsqesrWl-Eyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 üîç `debug_traceTransaction` - Deep Dive into Transaction Execution\n",
        "---\n",
        "This section utilizes the powerful `debug_traceTransaction` RPC method to dissect the internal workings of a specific PYUSD transaction defined by `TARGET_TX_HASH`. This goes far beyond standard block explorers by revealing the step-by-step execution flow within the EVM. We will explore two main tracers: `callTracer` and `structLog`."
      ],
      "metadata": {
        "id": "3vkos_TxP4pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Using `callTracer`: Mapping Internal Calls, Gas & Events (Recommended)\n",
        "\n",
        "The `callTracer` provides a structured, hierarchical view of the transaction's execution flow. It's generally the most useful tracer for understanding high-level interactions, gas consumption patterns, and event emissions.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `debug_traceTransaction` with `tracer: \"callTracer\"`\n",
        "> *   **Multiplier:** `50x` (Consumes 50x the quota/cost of a basic call)\n",
        "> *   **GCP Advantage:** Performing this detailed trace is computationally intensive. GCP's generous free quotas for this high-multiplier method make such in-depth analysis accessible and cost-effective.\n",
        "> *   **PYUSD Insight:** `callTracer` allows us to:\n",
        ">     *   Visualize the **exact interaction path** when PYUSD interacts with other DeFi protocols (e.g., DEXs, lending platforms).\n",
        ">     *   Identify specific **internal PYUSD function calls** (`transfer`, `approve`, `mint`, `burn`) and their parameters within the overall transaction.\n",
        ">     *   Pinpoint **gas consumption** within specific PYUSD operations vs. external contract interactions.\n",
        ">     *   Verify the **emission and content** of crucial PYUSD events like `Transfer` and `Approval`.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Trace:** The code calls `debug_traceTransaction` using the `TARGET_TX_HASH` and the `callTracer` configuration.\n",
        "2.  **Parse Data:** The complex JSON response is processed by `parse_call_trace` to extract structured information about calls, logs, gas, and state changes.\n",
        "3.  **Visualize & Summarize:** The results are presented through:\n",
        "    *   **Trace Overview & Metrics:** Key stats like call count, depth, gas, and status.\n",
        "    *   **Interaction Graphs:** High-level contract interactions and detailed call sequences (Interactive Plotly). PYUSD calls are highlighted.\n",
        "    *   **Token Flow:** A specific graph visualizing PYUSD movements (transfers, mints, burns).\n",
        "    *   **State & Gas Analysis:** Tables and charts showing PYUSD state changes and gas usage breakdown.\n",
        "    *   **Event Log Analysis:** Decoded PYUSD events emitted.\n",
        "    *   **Data Tables:** DataFrames showing key calls and high gas usage operations.\n",
        "    *   **Recommendations:** Automated observations based on trace patterns.\n",
        "    *   **Export Options:** Download parsed data (CSV/JSON) or export a report to Google Sheets (Colab).\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Call Graph:** Observe the sequence and depth of calls. Identify the green/blue highlighted nodes representing PYUSD/Supply Controller interactions. Note the gas usage (`Gas: ...`) on each node.\n",
        "*   **Token Flow Graph:** Track how PYUSD moved between addresses.\n",
        "*   **Gas Usage Pie Chart:** See which *types* of operations (transfer, approval, supply change) consumed the most gas.\n",
        "*   **Event Table:** Correlate events like `Transfer` with the calls shown in the graph.\n",
        "*   **Recommendations:** Check for automated insights about gas or complexity."
      ],
      "metadata": {
        "id": "VVhppRHRP8Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üî¨ Trace Transaction using debug_traceTransaction (callTracer)\n",
        "# =============================================================================================\n",
        "# This cell validates transaction targets, initializes blockchain tracing configurations, and sets up helper functions.\n",
        "# It prepares the environment for detailed transaction analysis by:\n",
        "# - Validating the transaction hash format and existence\n",
        "# - Configuring tracer parameters for debug_traceTransaction\n",
        "# - Setting up utility functions for address formatting, value conversion, and data processing\n",
        "# - Initializing transaction-specific constants and analysis options\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Javascript\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import networkx as nx\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, tx_hash):\n",
        "    \"\"\"Export analysis data to Google Sheets with rich formatting and visualization references.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[cyan3]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD TX Analysis {tx_hash[:10]} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Transaction Analysis\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transaction Analysis\"],\n",
        "            [f\"Transaction: {tx_hash}\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # 1. Add transaction stats summary with improved formatting\n",
        "        if \"transaction_stats\" in data_dict:\n",
        "            stats = data_dict[\"transaction_stats\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Transaction Metrics\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "                if key == 'total_gas':\n",
        "                    formatted_value = f\"{value:,} gas units\"\n",
        "                else:\n",
        "                    formatted_value = str(value)\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 1  # Add space after table\n",
        "\n",
        "        # 2. Add Contract Interaction Graph reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Contract Interaction Overview\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Contract interaction visualization is available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # 3. Add Call Graph Visualization reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Detailed Call Graph Visualization\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.7, \"green\": 0.8, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Detailed call graph visualization is available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # 4. Add gas usage section\n",
        "        if \"gas_distribution\" in data_dict and data_dict[\"gas_distribution\"]:\n",
        "            gas_data = data_dict[\"gas_distribution\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Create gas usage table\n",
        "            gas_header = [\"Category\", \"Gas Used\", \"Percentage\"]\n",
        "            gas_rows = [gas_header]\n",
        "\n",
        "            total_gas = sum(item[\"gas_used\"] for item in gas_data)\n",
        "            for item in gas_data:\n",
        "                category = item[\"category\"].replace(\"_\", \" \").title()\n",
        "                gas_used = item[\"gas_used\"]\n",
        "                percentage = (gas_used / total_gas * 100) if total_gas > 0 else 0\n",
        "                gas_rows.append([category, f\"{gas_used:,}\", f\"{percentage:.1f}%\"])\n",
        "\n",
        "            gas_table_row = current_row\n",
        "            worksheet.update(f\"A{gas_table_row}\", gas_rows)\n",
        "\n",
        "            # Format gas table headers\n",
        "            worksheet.format(f\"A{gas_table_row}:C{gas_table_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(gas_rows) + 1\n",
        "\n",
        "            # Add pie chart reference\n",
        "            worksheet.update(f\"A{current_row}\", [[\"üìä Gas usage pie chart visualization is available in the notebook\"]])\n",
        "            current_row += 2\n",
        "\n",
        "        # 5. Add PYUSD Token Flow section\n",
        "        if \"pyusd_transfers\" in data_dict and data_dict[\"pyusd_transfers\"]:\n",
        "            transfers = data_dict[\"pyusd_transfers\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"PYUSD Token Flow Analysis\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.7, \"green\": 1.0, \"blue\": 0.8}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add description\n",
        "            worksheet.update(f\"A{current_row}\", [[\"This shows the movement of PYUSD tokens in this transaction.\"]])\n",
        "            current_row += 1\n",
        "\n",
        "            # Add transfer data as a table\n",
        "            transfer_header = [\"From\", \"To\", \"Amount\", \"Gas Used\"]\n",
        "            transfer_rows = [transfer_header]\n",
        "\n",
        "            for transfer in transfers:\n",
        "                from_addr = shorten_address(transfer[\"from\"])\n",
        "                to_addr = shorten_address(transfer[\"to\"])\n",
        "                amount = format_value_pyusd(transfer[\"amount\"])\n",
        "                gas = f\"{transfer.get('gas_used', 0):,}\"\n",
        "                transfer_rows.append([from_addr, to_addr, amount, gas])\n",
        "\n",
        "            transfer_table_row = current_row\n",
        "            worksheet.update(f\"A{transfer_table_row}\", transfer_rows)\n",
        "\n",
        "            # Format transfer table headers\n",
        "            worksheet.format(f\"A{transfer_table_row}:D{transfer_table_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(transfer_rows) + 1\n",
        "\n",
        "            # Add flow graph reference\n",
        "            worksheet.update(f\"A{current_row}\", [[\"üîÑ Token flow visualization is available in the notebook\"]])\n",
        "            current_row += 2\n",
        "\n",
        "        # 6. Add PYUSD State Changes\n",
        "        if \"state_changes\" in data_dict and data_dict[\"state_changes\"]:\n",
        "            state_changes = data_dict[\"state_changes\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"PYUSD State Changes\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 1.0, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add description\n",
        "            worksheet.update(f\"A{current_row}\", [[\"The following state changes occurred in PYUSD contracts:\"]])\n",
        "            current_row += 1\n",
        "\n",
        "            # Create state changes table\n",
        "            if isinstance(state_changes, list) and state_changes:\n",
        "                # Define headers\n",
        "                headers = [\"contract\", \"function\", \"type\", \"amount\", \"gas_used\"]\n",
        "                display_headers = [\"Contract\", \"Function\", \"Type\", \"Amount\", \"Gas Used\"]\n",
        "\n",
        "                # Create the table data\n",
        "                state_rows = [display_headers]  # Header row\n",
        "                for change in state_changes:\n",
        "                    row_data = []\n",
        "                    for key in headers:\n",
        "                        if key == \"amount\" and \"amount\" in change:\n",
        "                            # Format PYUSD amounts nicely\n",
        "                            value = format_value_pyusd(change[\"amount\"])\n",
        "                        elif key == \"gas_used\":\n",
        "                            value = f\"{change.get(key, 0):,}\"\n",
        "                        else:\n",
        "                            value = str(change.get(key, \"\"))\n",
        "                        row_data.append(value)\n",
        "                    state_rows.append(row_data)\n",
        "\n",
        "                # Add to sheet\n",
        "                state_start_row = current_row\n",
        "                worksheet.update(f\"A{state_start_row}\", state_rows)\n",
        "\n",
        "                # Format headers\n",
        "                header_range = f\"A{state_start_row}:E{state_start_row}\"\n",
        "                worksheet.format(header_range, {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                current_row += len(state_rows) + 1\n",
        "\n",
        "        # 7. Add Event Analysis summary\n",
        "        if \"logs_df\" in data_dict and isinstance(data_dict[\"logs_df\"], pd.DataFrame) and not data_dict[\"logs_df\"].empty:\n",
        "            logs_df = data_dict[\"logs_df\"]\n",
        "            pyusd_logs = logs_df[logs_df['is_pyusd']] if 'is_pyusd' in logs_df.columns else pd.DataFrame()\n",
        "\n",
        "            if not pyusd_logs.empty:\n",
        "                # Add section title\n",
        "                worksheet.update(f\"A{current_row}\", [[\"PYUSD Events Analysis\"]])\n",
        "                worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                    \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                    \"backgroundColor\": {\"red\": 0.7, \"green\": 1.0, \"blue\": 0.8}\n",
        "                })\n",
        "                current_row += 1\n",
        "\n",
        "                # Add summary count\n",
        "                worksheet.update(f\"A{current_row}\", [[f\"Found {len(pyusd_logs)} PYUSD events in this transaction.\"]])\n",
        "                current_row += 1\n",
        "\n",
        "                # Add event counts if available\n",
        "                if 'event_name' in pyusd_logs.columns:\n",
        "                    event_counts = pyusd_logs['event_name'].value_counts()\n",
        "\n",
        "                    # Create event counts table\n",
        "                    event_table = [[\"Event Type\", \"Count\"]]  # Header row\n",
        "                    for event, count in event_counts.items():\n",
        "                        event_table.append([event, str(count)])\n",
        "\n",
        "                    # Add to sheet\n",
        "                    event_table_row = current_row\n",
        "                    worksheet.update(f\"A{event_table_row}\", event_table)\n",
        "\n",
        "                    # Format headers\n",
        "                    worksheet.format(f\"A{event_table_row}:B{event_table_row}\", {\n",
        "                        \"textFormat\": {\"bold\": True},\n",
        "                        \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                    })\n",
        "\n",
        "                    current_row += len(event_table) + 1\n",
        "\n",
        "                # Add event details\n",
        "                worksheet.update(f\"A{current_row}\", [[\"PYUSD Event Details:\"]])\n",
        "                worksheet.format(f\"A{current_row}:A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "                current_row += 1\n",
        "\n",
        "                # Display key event details\n",
        "                event_cols = ['contract', 'event_name', 'details']\n",
        "                event_cols = [col for col in event_cols if col in pyusd_logs.columns]\n",
        "\n",
        "                if event_cols:\n",
        "                    # Convert to list for sheet\n",
        "                    event_data = [event_cols]  # Header row\n",
        "                    for _, row in pyusd_logs[event_cols].iterrows():\n",
        "                        # Format each value appropriately\n",
        "                        row_values = []\n",
        "                        for col in event_cols:\n",
        "                            if pd.isnull(row[col]):\n",
        "                                value = \"\"\n",
        "                            else:\n",
        "                                value = str(row[col])\n",
        "                            row_values.append(value)\n",
        "                        event_data.append(row_values)\n",
        "\n",
        "                    # Add to sheet\n",
        "                    event_start_row = current_row\n",
        "                    worksheet.update(f\"A{event_start_row}\", event_data)\n",
        "\n",
        "                    # Format headers\n",
        "                    header_range = f\"A{event_start_row}:{chr(65+len(event_cols)-1)}{event_start_row}\"\n",
        "                    worksheet.format(header_range, {\n",
        "                        \"textFormat\": {\"bold\": True},\n",
        "                        \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                    })\n",
        "\n",
        "                    current_row += len(event_data) + 1\n",
        "\n",
        "                # Add transfer value summary if available\n",
        "                if 'amount' in pyusd_logs.columns and 'is_transfer' in pyusd_logs.columns:\n",
        "                    transfer_logs = pyusd_logs[pyusd_logs['is_transfer']]\n",
        "                    if not transfer_logs.empty:\n",
        "                        total_transferred = transfer_logs['amount'].sum()\n",
        "                        worksheet.update(f\"A{current_row}\", [[f\"Total PYUSD transferred: {format_value_pyusd(total_transferred)}\"]])\n",
        "                        current_row += 2\n",
        "\n",
        "        # 8. Add Recommendations\n",
        "        if \"recommendations\" in data_dict and data_dict[\"recommendations\"]:\n",
        "            recommendations = data_dict[\"recommendations\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Observations & Recommendations\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.7, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add each recommendation\n",
        "            for rec in recommendations:\n",
        "                worksheet.update(f\"A{current_row}\", [[rec]])\n",
        "                current_row += 1\n",
        "\n",
        "            current_row += 1  # Extra space\n",
        "\n",
        "        # 9. Add main DataFrame data (selected columns only for better readability)\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Key Contract Calls\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Select important columns to display\n",
        "            display_cols = ['id', 'type', 'depth', 'contract', 'function_category', 'gasUsed', 'is_pyusd']\n",
        "            display_cols = [col for col in display_cols if col in df.columns]\n",
        "\n",
        "            # First show PYUSD calls\n",
        "            pyusd_calls = df[df['is_pyusd']] if 'is_pyusd' in df.columns else pd.DataFrame()\n",
        "\n",
        "            if not pyusd_calls.empty:\n",
        "                worksheet.update(f\"A{current_row}\", [[f\"Found {len(pyusd_calls)} PYUSD-related calls:\"]])\n",
        "                current_row += 1\n",
        "\n",
        "                # Convert DataFrame to list of lists for the worksheet\n",
        "                pyusd_df_values = [display_cols] + pyusd_calls[display_cols].values.tolist()\n",
        "\n",
        "                # Format values for display\n",
        "                for i in range(1, len(pyusd_df_values)):\n",
        "                    for j, col in enumerate(display_cols):\n",
        "                        val = pyusd_df_values[i][j]\n",
        "                        if col == 'gasUsed' and pd.notnull(val):\n",
        "                            pyusd_df_values[i][j] = f\"{val:,}\"\n",
        "                        elif pd.isnull(val):\n",
        "                            pyusd_df_values[i][j] = \"NULL\"\n",
        "                        else:\n",
        "                            pyusd_df_values[i][j] = str(val)\n",
        "\n",
        "                worksheet.update(f\"A{current_row}\", pyusd_df_values)\n",
        "\n",
        "                # Format the DataFrame header\n",
        "                worksheet.format(f\"A{current_row}:{chr(65+len(display_cols)-1)}{current_row}\", {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                # Add alternating row colors for readability\n",
        "                data_rows = len(pyusd_df_values)\n",
        "                for i in range(2, data_rows + 1, 2):\n",
        "                    row_num = current_row + i - 1\n",
        "                    worksheet.format(f\"A{row_num}:{chr(65+len(display_cols)-1)}{row_num}\", {\n",
        "                        \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                    })\n",
        "\n",
        "                current_row += len(pyusd_df_values) + 2\n",
        "\n",
        "            # Then show highest gas usage calls\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Highest Gas Usage Calls:\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "            current_row += 1\n",
        "\n",
        "            # Get top 5 by gas usage\n",
        "            high_gas_cols = ['id', 'type', 'contract', 'function_category', 'gasUsed']\n",
        "            high_gas_cols = [col for col in high_gas_cols if col in df.columns]\n",
        "\n",
        "            high_gas_calls = df.nlargest(5, 'gasUsed') if 'gasUsed' in df.columns else pd.DataFrame()\n",
        "\n",
        "            if not high_gas_calls.empty:\n",
        "                # Convert to list for sheet\n",
        "                high_gas_data = [high_gas_cols]  # Header row\n",
        "                for _, row in high_gas_calls[high_gas_cols].iterrows():\n",
        "                    # Format each value appropriately\n",
        "                    row_values = []\n",
        "                    for col in high_gas_cols:\n",
        "                        if col == 'gasUsed':\n",
        "                            value = f\"{row[col]:,}\" if pd.notnull(row[col]) else \"0\"\n",
        "                        elif pd.isnull(row[col]):\n",
        "                            value = \"NULL\"\n",
        "                        else:\n",
        "                            value = str(row[col])\n",
        "                        row_values.append(value)\n",
        "                    high_gas_data.append(row_values)\n",
        "\n",
        "                # Add to sheet\n",
        "                worksheet.update(f\"A{current_row}\", high_gas_data)\n",
        "\n",
        "                # Format headers\n",
        "                header_range = f\"A{current_row}:{chr(65+len(high_gas_cols)-1)}{current_row}\"\n",
        "                worksheet.format(header_range, {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                # Add alternating row colors\n",
        "                for i in range(2, len(high_gas_data) + 1, 2):\n",
        "                    row_num = current_row + i - 1\n",
        "                    worksheet.format(f\"A{row_num}:{chr(65+len(high_gas_cols)-1)}{row_num}\", {\n",
        "                        \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                    })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Attempt to resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Return spreadsheet URL and title for opening\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        return (spreadsheet_url, sheet_title)\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        raise Exception(f\"Error creating Google Sheet: {str(e)}\")\n",
        "\n",
        "# Function to display loading indicator while rendering visualization\n",
        "def show_loading_indicator():\n",
        "    \"\"\"Display a loading indicator while rendering graphs\"\"\"\n",
        "    loading_html = \"\"\"\n",
        "    <div style=\"display: flex; justify-content: center; align-items: center; height: 50px;\">\n",
        "        <div style=\"text-align: center;\">\n",
        "            <div class=\"spinner-border\" role=\"status\">\n",
        "                <span class=\"sr-only\">Loading...</span>\n",
        "            </div>\n",
        "            <p style=\"margin-top: 10px; color: #555;\">Generating visualization...</p>\n",
        "        </div>\n",
        "    </div>\n",
        "    <style>\n",
        "    .spinner-border {\n",
        "        display: inline-block;\n",
        "        width: 2rem;\n",
        "        height: 2rem;\n",
        "        vertical-align: text-bottom;\n",
        "        border: 0.25em solid currentColor;\n",
        "        border-right-color: transparent;\n",
        "        border-radius: 50%;\n",
        "        animation: spinner-border .75s linear infinite;\n",
        "    }\n",
        "    @keyframes spinner-border {\n",
        "        to { transform: rotate(360deg); }\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    display(HTML(loading_html))\n",
        "\n",
        "# Function to get human-readable function descriptions\n",
        "def get_function_description(input_data, is_pyusd, contract_name):\n",
        "    \"\"\"Get a human-readable function description.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"Contract Creation\" if not input_data else \"ETH Transfer\"\n",
        "\n",
        "    # Extract method signature (first 10 characters including 0x)\n",
        "    method_sig = input_data[:10] if len(input_data) >= 10 else input_data\n",
        "\n",
        "    # Check PYUSD signatures first\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        function_info = PYUSD_SIGNATURES[method_sig]\n",
        "        return function_info[\"name\"]\n",
        "\n",
        "    # Check common ERC20/generic function signatures\n",
        "    common_sigs = {\n",
        "        '0xa9059cbb': \"transfer(address,uint256)\",\n",
        "        '0x095ea7b3': \"approve(address,uint256)\",\n",
        "        '0x23b872dd': \"transferFrom(address,address,uint256)\",\n",
        "        '0x18160ddd': \"totalSupply()\",\n",
        "        '0x70a08231': \"balanceOf(address)\",\n",
        "        '0xdd62ed3e': \"allowance(address,address)\",\n",
        "        '0x06fdde03': \"name()\",\n",
        "        '0x95d89b41': \"symbol()\",\n",
        "        '0x313ce567': \"decimals()\",\n",
        "        '0x8da5cb5b': \"owner()\",\n",
        "        '0x715018a6': \"renounceOwnership()\",\n",
        "        '0xf2fde38b': \"transferOwnership(address)\",\n",
        "        '0x01ffc9a7': \"supportsInterface(bytes4)\",\n",
        "        '0x3644e515': \"DOMAIN_SEPARATOR()\",\n",
        "        '0x7ecebe00': \"nonces(address)\",\n",
        "        '0xd505accf': \"permit(address,address,uint256,uint256,uint8,bytes32,bytes32)\"\n",
        "    }\n",
        "\n",
        "    return common_sigs.get(method_sig, f\"Function {method_sig}\")\n",
        "\n",
        "# function for creating interactive Plotly Contract Interaction Graph\n",
        "def create_plotly_contract_interaction_graph(contract_interactions):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for contract interactions with directional arrows\"\"\"\n",
        "    import math\n",
        "\n",
        "    if not contract_interactions:\n",
        "        return None\n",
        "\n",
        "    # Create a networkx graph from the interaction data\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes for all contracts in interactions\n",
        "    contracts_seen = set()\n",
        "    for src, dst in contract_interactions:\n",
        "        if src not in contracts_seen:\n",
        "            src_name = PYUSD_CONTRACTS.get(src, \"External Contract\")\n",
        "            G.add_node(src, name=src_name, is_pyusd=(src in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(src)\n",
        "\n",
        "        if dst not in contracts_seen:\n",
        "            dst_name = PYUSD_CONTRACTS.get(dst, \"External Contract\")\n",
        "            G.add_node(dst, name=dst_name, is_pyusd=(dst in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(dst)\n",
        "\n",
        "        # Add edge\n",
        "        G.add_edge(src, dst)\n",
        "\n",
        "    # Calculate layout with more spacing for readability\n",
        "    pos = nx.spring_layout(G, seed=42, k=1.5)\n",
        "\n",
        "    # Create edge traces with arrows\n",
        "    edge_traces = []\n",
        "\n",
        "    for edge in G.edges():\n",
        "        src, dst = edge\n",
        "        src_name = G.nodes[src]['name']\n",
        "        dst_name = G.nodes[dst]['name']\n",
        "\n",
        "        x0, y0 = pos[src]\n",
        "        x1, y1 = pos[dst]\n",
        "\n",
        "        # Calculate direction vector for arrow\n",
        "        dx = x1 - x0\n",
        "        dy = y1 - y0\n",
        "\n",
        "        # Normalize the vector\n",
        "        length = math.sqrt(dx**2 + dy**2)\n",
        "        if length > 0:\n",
        "            udx = dx / length\n",
        "            udy = dy / length\n",
        "        else:\n",
        "            udx, udy = 0, 0\n",
        "\n",
        "        # Position arrow slightly before the destination node (80% along the edge)\n",
        "        arrow_ratio = 0.8\n",
        "        arrow_x = x0 + arrow_ratio * dx\n",
        "        arrow_y = y0 + arrow_ratio * dy\n",
        "\n",
        "        # Angle for the arrow in degrees\n",
        "        angle = math.degrees(math.atan2(dy, dx))\n",
        "\n",
        "        # Main edge line\n",
        "        edge_trace = go.Scatter(\n",
        "            x=[x0, x1],\n",
        "            y=[y0, y1],\n",
        "            line=dict(width=1.5, color='rgba(50, 50, 50, 0.8)'),\n",
        "            hoverinfo='text',\n",
        "            text=f\"From: {src_name}<br>To: {dst_name}<br>From address: {src}<br>To address: {dst}\",\n",
        "            mode='lines',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        # Arrow marker\n",
        "        arrow_trace = go.Scatter(\n",
        "            x=[arrow_x],\n",
        "            y=[arrow_y],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                symbol='triangle-right',\n",
        "                size=12,\n",
        "                color='rgba(50, 50, 50, 0.8)',\n",
        "                angle=angle  # Apply the calculated angle\n",
        "            ),\n",
        "            hoverinfo='none',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        edge_traces.append(edge_trace)\n",
        "        edge_traces.append(arrow_trace)\n",
        "\n",
        "    # Create node trace\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    hover_texts = []\n",
        "    node_addresses = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        node_data = G.nodes[node]\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Node color based on contract type\n",
        "        if node_data['is_pyusd']:\n",
        "            if \"PYUSD Token\" in node_data['name']:\n",
        "                node_colors.append('rgba(144, 238, 144, 0.9)')  # palegreen\n",
        "            elif \"Supply Control\" in node_data['name']:\n",
        "                node_colors.append('rgba(135, 206, 250, 0.9)')  # lightskyblue\n",
        "            else:\n",
        "                node_colors.append('rgba(224, 255, 255, 0.9)')  # lightcyan\n",
        "        else:\n",
        "            node_colors.append('rgba(211, 211, 211, 0.9)')  # lightgray\n",
        "\n",
        "        # Node size: bigger for PYUSD contracts\n",
        "        node_sizes.append(25 if node_data['is_pyusd'] else 18)\n",
        "\n",
        "        # Full address for node label\n",
        "        node_addresses.append(node)\n",
        "\n",
        "        # Hover text with full contract information\n",
        "        hover_texts.append(f\"<b>{node_data['name']}</b><br>Address: {node}\")\n",
        "\n",
        "    # Create node trace with text labels showing full addresses\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_addresses,\n",
        "        textposition=\"bottom center\",\n",
        "        hovertext=hover_texts,\n",
        "        marker=dict(\n",
        "            showscale=False,\n",
        "            color=node_colors,\n",
        "            size=node_sizes,\n",
        "            line=dict(width=1, color='#000')\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"monospace\",\n",
        "            size=10,\n",
        "            color=\"black\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add legend traces for different node types\n",
        "    legend_traces = [\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'),\n",
        "            name='PYUSD Token',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'),\n",
        "            name='Supply Control',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'),\n",
        "            name='External Contract',\n",
        "            showlegend=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Create figure with styled layout\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add all traces\n",
        "    for trace in edge_traces:\n",
        "        fig.add_trace(trace)\n",
        "\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    for trace in legend_traces:\n",
        "        fig.add_trace(trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>Contract Interaction Overview</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Contract Types\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=600,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# function for creating interactive Plotly Call Graph\n",
        "def create_plotly_call_graph(call_data_list):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for the call trace hierarchy\"\"\"\n",
        "    if not call_data_list:\n",
        "        return None\n",
        "\n",
        "    # Process relationships and parent-child connections\n",
        "    # We need to reconstruct parent/child relationships based on depth\n",
        "    for i, call in enumerate(call_data_list):\n",
        "        # Initialize parent_id field if it doesn't exist\n",
        "        if 'parent_id' not in call:\n",
        "            call['parent_id'] = None\n",
        "\n",
        "        # If not root node, find parent\n",
        "        if call['depth'] > 0 and i > 0:\n",
        "            # Look backward for potential parents at the previous depth level\n",
        "            for j in range(i-1, -1, -1):\n",
        "                potential_parent = call_data_list[j]\n",
        "                if potential_parent['depth'] == call['depth'] - 1:\n",
        "                    call['parent_id'] = potential_parent['id']\n",
        "                    break\n",
        "\n",
        "    # Create a networkx graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add all nodes with their attributes\n",
        "    for call in call_data_list:\n",
        "        G.add_node(call['id'], **call)\n",
        "\n",
        "    # Add edges based on parent-child relationships\n",
        "    for call in call_data_list:\n",
        "        if call['parent_id']:\n",
        "            G.add_edge(call['parent_id'], call['id'])\n",
        "\n",
        "    # Try using graphviz layout if available\n",
        "    try:\n",
        "        import pygraphviz as pgv\n",
        "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')  # Hierarchical layout\n",
        "    except:\n",
        "        # Fallback to custom hierarchical layout\n",
        "        pos = {}\n",
        "        depth_to_nodes = {}\n",
        "\n",
        "        for node, data in G.nodes(data=True):\n",
        "            depth = data['depth']\n",
        "            if depth not in depth_to_nodes:\n",
        "                depth_to_nodes[depth] = []\n",
        "            depth_to_nodes[depth].append(node)\n",
        "\n",
        "        # Calculate positions based on depth\n",
        "        max_depth = max(depth_to_nodes.keys()) if depth_to_nodes else 0\n",
        "\n",
        "        for depth, nodes in depth_to_nodes.items():\n",
        "            nodes.sort()  # For consistent layout\n",
        "            node_count = len(nodes)\n",
        "            for i, node in enumerate(nodes):\n",
        "                # Horizontal spacing based on node count, vertical based on depth\n",
        "                x_pos = i / (node_count + 1) if node_count > 1 else 0.5\n",
        "                y_pos = 1.0 - (depth / (max_depth + 1)) if max_depth > 0 else 0.5\n",
        "                pos[node] = (x_pos, y_pos)\n",
        "\n",
        "    # Create edge traces with different colors by call type\n",
        "    edge_traces_by_type = {}\n",
        "    edge_types = set()\n",
        "\n",
        "    for edge in G.edges():\n",
        "        source, target = edge\n",
        "        source_data = G.nodes[source]\n",
        "        target_data = G.nodes[target]\n",
        "\n",
        "        call_type = target_data['type']\n",
        "        edge_types.add(call_type)\n",
        "\n",
        "        if call_type not in edge_traces_by_type:\n",
        "            edge_traces_by_type[call_type] = {\n",
        "                'x': [], 'y': [], 'text': [], 'color': '', 'style': '', 'width': 1\n",
        "            }\n",
        "\n",
        "            # Set color and style based on call type\n",
        "            if call_type == 'DELEGATECALL':\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(0, 0, 255, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'dash'\n",
        "                edge_traces_by_type[call_type]['width'] = 2\n",
        "            elif call_type == 'STATICCALL':\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(0, 128, 0, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'dot'\n",
        "                edge_traces_by_type[call_type]['width'] = 1.5\n",
        "            else:\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(128, 128, 128, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'solid'\n",
        "                edge_traces_by_type[call_type]['width'] = 1\n",
        "\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        edge_traces_by_type[call_type]['x'].extend([x0, x1, None])\n",
        "        edge_traces_by_type[call_type]['y'].extend([y0, y1, None])\n",
        "\n",
        "        # Create full hover info\n",
        "        hover_text = (\n",
        "            f\"<b>From:</b> {source_data['from']}<br>\"\n",
        "            f\"<b>To:</b> {target_data['to']}<br>\"\n",
        "            f\"<b>Type:</b> {target_data['type']}<br>\"\n",
        "            f\"<b>Depth:</b> {target_data['depth']}<br>\"\n",
        "        )\n",
        "\n",
        "        if target_data['value_eth'] > 0:\n",
        "            hover_text += f\"<b>Value:</b> {target_data['value_eth']} ETH<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Gas:</b> {target_data['gasUsed']:,}<br>\"\n",
        "\n",
        "        if target_data['is_pyusd']:\n",
        "            hover_text += f\"<b>Contract:</b> {target_data['contract']}<br>\"\n",
        "\n",
        "        if target_data.get('error'):\n",
        "            hover_text += f\"<b style='color:red'>Error:</b> {target_data['error']}<br>\"\n",
        "\n",
        "        edge_traces_by_type[call_type]['text'].append(hover_text)\n",
        "\n",
        "    # Create scatter traces for each call type\n",
        "    edge_traces = []\n",
        "    for call_type, trace_data in edge_traces_by_type.items():\n",
        "        edge_traces.append(\n",
        "            go.Scatter(\n",
        "                x=trace_data['x'],\n",
        "                y=trace_data['y'],\n",
        "                line=dict(\n",
        "                    width=trace_data['width'],\n",
        "                    color=trace_data['color'],\n",
        "                    dash=trace_data['style']\n",
        "                ),\n",
        "                hoverinfo='text',\n",
        "                text=trace_data['text'],\n",
        "                mode='lines',\n",
        "                name=call_type\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create node trace with improved hover information\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    node_text = []  # Function name displayed on node\n",
        "    hover_texts = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        node_data = G.nodes[node]\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Create more detailed text for nodes\n",
        "        function_name = get_function_description(\n",
        "            node_data.get('input_preview', '0x'),\n",
        "            node_data['is_pyusd'],\n",
        "            node_data.get('contract', 'Other')\n",
        "        )\n",
        "\n",
        "        # Short text for display (truncated for space)\n",
        "        short_name = function_name.split('(')[0] if '(' in function_name else function_name\n",
        "        if len(short_name) > 12:\n",
        "            short_name = short_name[:10] + '...'\n",
        "        node_text.append(short_name)\n",
        "\n",
        "        # Create detailed hover text\n",
        "        hover_text = f\"<b style='font-size:12px'>{node_data['type']} Call</b><br>\"\n",
        "        hover_text += f\"<b>From:</b> {node_data['from']}<br>\"\n",
        "        hover_text += f\"<b>To:</b> {node_data['to']}<br>\"\n",
        "        hover_text += f\"<b>Depth:</b> {node_data['depth']}<br>\"\n",
        "\n",
        "        if node_data['value_eth'] > 0:\n",
        "            hover_text += f\"<b>Value:</b> {node_data['value_eth']} ETH<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Gas Used:</b> {node_data['gasUsed']:,}<br>\"\n",
        "\n",
        "        if node_data['is_pyusd']:\n",
        "            hover_text += f\"<b>PYUSD Contract:</b> {node_data['contract']}<br>\"\n",
        "            hover_text += f\"<b>Function Category:</b> {node_data['function_category']}<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Function:</b> {function_name}<br>\"\n",
        "\n",
        "        if node_data.get('error'):\n",
        "            hover_text += f\"<b style='color:red'>Error:</b> {node_data['error']}<br>\"\n",
        "\n",
        "        hover_texts.append(hover_text)\n",
        "\n",
        "        # Node color based on contract type and error status\n",
        "        if node_data.get('error'):\n",
        "            node_colors.append('rgba(255, 99, 71, 0.9)')  # tomato for errors\n",
        "        elif node_data['is_pyusd']:\n",
        "            if \"PYUSD Token\" in node_data.get('contract', ''):\n",
        "                node_colors.append('rgba(144, 238, 144, 0.9)')  # palegreen\n",
        "            elif \"Supply Control\" in node_data.get('contract', ''):\n",
        "                node_colors.append('rgba(135, 206, 250, 0.9)')  # lightskyblue\n",
        "            else:\n",
        "                node_colors.append('rgba(224, 255, 255, 0.9)')  # lightcyan\n",
        "        else:\n",
        "            # Gradient based on depth for non-PYUSD calls\n",
        "            intensity = min(95, max(70, 95 - node_data['depth'] * 5))\n",
        "            rgb_val = intensity / 100.0\n",
        "            node_colors.append(f'rgba({int(rgb_val*255)}, {int(rgb_val*255)}, {int(rgb_val*255)}, 0.9)')\n",
        "\n",
        "        # Size based on gas used\n",
        "        gas_used = node_data['gasUsed']\n",
        "        # Scale node size based on gas used (within reasonable bounds)\n",
        "        size = max(15, min(40, 15 + (gas_used / 50000)))\n",
        "        node_sizes.append(size)\n",
        "\n",
        "    # Create node trace\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        textposition=\"top center\",\n",
        "        hovertext=hover_texts,\n",
        "        marker=dict(\n",
        "            showscale=False,\n",
        "            color=node_colors,\n",
        "            size=node_sizes,\n",
        "            line=dict(width=1, color='#000')\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"Arial\",\n",
        "            size=9,\n",
        "            color=\"#333\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Create legend traces for node colors\n",
        "    node_color_legend = [\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'),\n",
        "            name='PYUSD Token',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'),\n",
        "            name='Supply Control',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'),\n",
        "            name='Other Contract',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(255, 99, 71, 0.9)'),\n",
        "            name='Error',\n",
        "            showlegend=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Create figure with all traces\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add traces\n",
        "    for edge_trace in edge_traces:\n",
        "        fig.add_trace(edge_trace)\n",
        "\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    # Add legend traces\n",
        "    for legend_trace in node_color_legend:\n",
        "        fig.add_trace(legend_trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>Detailed Call Graph Visualization</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Call Types\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=40, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=700,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# New function for creating interactive Plotly PYUSD Flow Graph\n",
        "def create_plotly_flow_graph(transfers):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for PYUSD token flows\"\"\"\n",
        "    if not transfers:\n",
        "        return None\n",
        "\n",
        "    # Create a directed graph for token flows\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Track total transfer amount per edge for aggregation\n",
        "    transfer_totals = {}\n",
        "\n",
        "    # Calculate aggregate transfers\n",
        "    for transfer in transfers:\n",
        "        from_addr = transfer['from']\n",
        "        to_addr = transfer['to']\n",
        "        amount = transfer['amount']\n",
        "\n",
        "        edge_key = (from_addr, to_addr)\n",
        "        if edge_key in transfer_totals:\n",
        "            transfer_totals[edge_key] += amount\n",
        "        else:\n",
        "            transfer_totals[edge_key] = amount\n",
        "\n",
        "    # Add nodes and edges to networkx graph\n",
        "    for (from_addr, to_addr), total_amount in transfer_totals.items():\n",
        "        # Add nodes if they don't exist\n",
        "        if from_addr not in G:\n",
        "            G.add_node(from_addr, address=from_addr, label=shorten_address(from_addr))\n",
        "\n",
        "        if to_addr not in G:\n",
        "            G.add_node(to_addr, address=to_addr, label=shorten_address(to_addr))\n",
        "\n",
        "        # Add edge with amount\n",
        "        G.add_edge(from_addr, to_addr, amount=total_amount, label=format_value_pyusd(total_amount))\n",
        "\n",
        "    # Calculate layout\n",
        "    pos = nx.spring_layout(G, k=1.0, seed=42)\n",
        "\n",
        "    # Create edge trace\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edge_text = []\n",
        "    edge_amount_texts = []\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        # Calculate midpoint for displaying amount\n",
        "        mid_x = (x0 + x1) / 2\n",
        "        mid_y = (y0 + y1) / 2\n",
        "\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "        amount_str = format_value_pyusd(data['amount'])\n",
        "        edge_text.append(f\"Transfer: {amount_str}<br>From: {shorten_address(source)}<br>To: {shorten_address(target)}\")\n",
        "        edge_amount_texts.append(amount_str)\n",
        "\n",
        "    # Create edge trace with arrows\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x, y=edge_y,\n",
        "        line=dict(width=2, color='rgba(50, 150, 50, 0.8)'),\n",
        "        hoverinfo='text',\n",
        "        text=edge_text,\n",
        "        mode='lines',\n",
        "        name='Transfer'\n",
        "    )\n",
        "\n",
        "    # Create a separate trace for each edge label (amount)\n",
        "    edge_label_traces = []\n",
        "    edge_idx = 0\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        # Calculate midpoint for the label\n",
        "        mid_x = (x0 + x1) / 2\n",
        "        mid_y = (y0 + y1) / 2\n",
        "\n",
        "        # Add label trace\n",
        "        edge_label_traces.append(\n",
        "            go.Scatter(\n",
        "                x=[mid_x],\n",
        "                y=[mid_y],\n",
        "                text=[format_value_pyusd(data['amount'])],\n",
        "                mode='text',\n",
        "                hoverinfo='none',\n",
        "                showlegend=False,\n",
        "                textfont=dict(\n",
        "                    size=10,\n",
        "                    color='darkgreen'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add arrow trace (small marker at the target end)\n",
        "        # Calculate the position for the arrow (slightly before the target)\n",
        "        arrow_ratio = 0.8  # How far along the edge to place the arrow (0.8 = 80% of the way to target)\n",
        "        arrow_x = x0 + (x1 - x0) * arrow_ratio\n",
        "        arrow_y = y0 + (y1 - y0) * arrow_ratio\n",
        "\n",
        "        edge_label_traces.append(\n",
        "            go.Scatter(\n",
        "                x=[arrow_x],\n",
        "                y=[arrow_y],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    symbol='triangle-right',\n",
        "                    size=12,\n",
        "                    color='rgba(50, 150, 50, 0.8)',\n",
        "                    angle=45\n",
        "                ),\n",
        "                hoverinfo='none',\n",
        "                showlegend=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        edge_idx += 1\n",
        "\n",
        "    # Create node trace with full addresses\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    node_hover = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Use full address for display\n",
        "        node_text.append(node)\n",
        "\n",
        "        # Create hover text\n",
        "        node_hover.append(f\"<b>Address:</b> {node}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        textposition=\"bottom center\",\n",
        "        hovertext=node_hover,\n",
        "        marker=dict(\n",
        "            color='rgba(144, 238, 144, 0.8)',  # palegreen\n",
        "            size=25,\n",
        "            line=dict(width=1, color='darkgreen'),\n",
        "            symbol='circle'\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"monospace\",\n",
        "            size=9,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        name='Address'\n",
        "    )\n",
        "\n",
        "    # Create figure with styled layout\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add all traces\n",
        "    fig.add_trace(edge_trace)\n",
        "    for label_trace in edge_label_traces:\n",
        "        fig.add_trace(label_trace)\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>PYUSD Token Flow Analysis</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Elements\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=600,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def parse_call_trace(trace_result, tx_hash):\n",
        "    \"\"\"Parses the output of callTracer and generates insights & visualizations.\"\"\"\n",
        "    if not trace_result:\n",
        "        console.print(\"[warning]No trace result provided for parsing.\", style=\"warning\")\n",
        "        return None, None, None, None, None, None, None, None\n",
        "\n",
        "    # --- Basic Info Panel ---\n",
        "    to_address = trace_result.get('to', 'N/A').lower()\n",
        "    is_pyusd_tx = to_address in PYUSD_CONTRACTS\n",
        "    pyusd_label = f\"[bold green]({PYUSD_CONTRACTS[to_address]})[/bold green]\" if is_pyusd_tx else \"\"\n",
        "\n",
        "    # Extract gas metrics for analysis\n",
        "    gas_used = int(trace_result.get('gasUsed', '0x0'), 16) if isinstance(trace_result.get('gasUsed', '0x0'), str) and trace_result.get('gasUsed', '0x0').startswith('0x') else int(trace_result.get('gasUsed', 0))\n",
        "\n",
        "    overview_text = f\"\"\"\n",
        "      [bold]Trace Summary for {shorten_address(tx_hash)}[/bold] {pyusd_label}\n",
        "      Type: {trace_result.get('type', 'N/A')}\n",
        "      From: {shorten_address(trace_result.get('from', 'N/A'))}\n",
        "      To: {shorten_address(trace_result.get('to', 'N/A'))}\n",
        "      Value: {format_value_eth(trace_result.get('value', '0x0'))}\n",
        "      Gas Used: {format_gas(trace_result.get('gasUsed', '0x0'))} ({gas_used:,} units)\n",
        "      Status: [bold red]Error: {trace_result['error']}[/bold red]\"\"\" if 'error' in trace_result else \"[bold green]Success[/bold green]\"\n",
        "    console.print(Panel(overview_text, title=\"Trace Overview\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    node_counter = 0\n",
        "    call_data_list = []\n",
        "    state_changes = []\n",
        "\n",
        "    # Track PYUSD transfer data for visualization\n",
        "    pyusd_transfers = []\n",
        "\n",
        "    # Track contract interactions for relationship mapping\n",
        "    contract_interactions = set()\n",
        "\n",
        "    # Track gas usage by category\n",
        "    gas_by_category = {category: 0 for category in GAS_CATEGORIES.keys()}\n",
        "\n",
        "    def add_nodes_edges(call, parent_node_id=None, depth=0, parent_addr=None):\n",
        "        nonlocal node_counter\n",
        "        current_node_id = f\"node_{node_counter}\"\n",
        "        node_counter += 1\n",
        "\n",
        "        call_type = call.get('type', 'N/A').upper()\n",
        "\n",
        "        # Extract call data for label\n",
        "        from_addr = call.get('from', 'N/A')\n",
        "        from_addr_short = shorten_address(from_addr)\n",
        "        to_addr = call.get('to', 'N/A')\n",
        "        to_addr_lower = to_addr.lower() if to_addr else ''\n",
        "        to_addr_short = shorten_address(to_addr)\n",
        "\n",
        "        # Track contract interaction\n",
        "        if parent_addr and to_addr_lower:\n",
        "            contract_interactions.add((parent_addr.lower(), to_addr_lower))\n",
        "\n",
        "        # Check for PYUSD contracts\n",
        "        is_pyusd_call = to_addr_lower in PYUSD_CONTRACTS\n",
        "        contract_name = PYUSD_CONTRACTS.get(to_addr_lower, None)\n",
        "\n",
        "        # function signature detection for PYUSD calls\n",
        "        input_data = call.get('input', '0x')\n",
        "        function_category = \"other\"\n",
        "        if input_data != '0x':\n",
        "            method_sig = input_data[:10]\n",
        "\n",
        "            if method_sig in PYUSD_SIGNATURES:\n",
        "                function_info = PYUSD_SIGNATURES[method_sig]\n",
        "                function_name = function_info[\"name\"]\n",
        "                function_category = function_info[\"category\"]\n",
        "\n",
        "                # Process specific functions for deeper analysis\n",
        "                if is_pyusd_call and \"PYUSD Token\" in contract_name:\n",
        "                    if method_sig == '0xa9059cbb':  # transfer\n",
        "                        try:\n",
        "                            # Extract params\n",
        "                            to_offset = 10\n",
        "                            to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            pyusd_transfers.append({\n",
        "                                'from': from_addr,\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'transfer',\n",
        "                                'from': from_addr,\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                    elif method_sig == '0x40c10f19':  # mint\n",
        "                        try:\n",
        "                            to_offset = 10\n",
        "                            to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'mint',\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                    elif method_sig == '0x9dc29fac':  # burn\n",
        "                        try:\n",
        "                            from_offset = 10\n",
        "                            from_param = \"0x\" + input_data[from_offset+24:from_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'burn',\n",
        "                                'from': from_addr,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "\n",
        "        # Update gas usage by category - AFTER function_category is defined\n",
        "        call_gas = int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "        if is_pyusd_call:\n",
        "            gas_by_category[function_category] += call_gas\n",
        "        else:\n",
        "            gas_by_category[\"other\"] += call_gas\n",
        "\n",
        "        # Extract output and error data\n",
        "        output_data = call.get('output', '0x')\n",
        "        error_msg = call.get('error')\n",
        "\n",
        "        # Store call data for dataframe\n",
        "        try:\n",
        "            gas_used_val = int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "            value_raw_wei = int(call.get('value', '0x0'), 16) if call.get('value', '0x0').startswith('0x') else int(call.get('value', 0))\n",
        "            value_eth_float = float(w3_mainnet.from_wei(value_raw_wei, 'ether')) if w3_mainnet else (value_raw_wei / 1e18)\n",
        "        except (ValueError, TypeError, AttributeError):\n",
        "            gas_used_val = 0\n",
        "            value_eth_float = 0.0\n",
        "\n",
        "        # Build call info for dataframe with data\n",
        "        call_info = {\n",
        "            'id': current_node_id,\n",
        "            'parent_id': parent_node_id,  # Track parent-child relationship\n",
        "            'type': call_type,\n",
        "            'depth': depth,\n",
        "            'from': from_addr,\n",
        "            'to': to_addr,\n",
        "            'value_eth': value_eth_float,\n",
        "            'gasUsed': gas_used_val,\n",
        "            'is_pyusd': is_pyusd_call,\n",
        "            'contract': contract_name if is_pyusd_call else \"Other\",\n",
        "            'function_category': function_category,\n",
        "            'error': error_msg,\n",
        "            'input_preview': input_data[:10] + \"...\" if len(input_data) > 10 else input_data,\n",
        "            'output_preview': output_data[:10] + \"...\" if len(output_data) > 10 else output_data,\n",
        "        }\n",
        "        call_data_list.append(call_info)\n",
        "\n",
        "        # Process sub-calls recursively\n",
        "        if 'calls' in call and isinstance(call['calls'], list):\n",
        "            for sub_call in call['calls']:\n",
        "                add_nodes_edges(sub_call, current_node_id, depth + 1, to_addr)\n",
        "\n",
        "    # --- Start processing the trace from the top-level call ---\n",
        "    add_nodes_edges(trace_result, depth=0)\n",
        "\n",
        "    # Create a dataframe from collected call data\n",
        "    call_df = pd.DataFrame(call_data_list)\n",
        "\n",
        "    # Create state changes dataframe\n",
        "    state_changes_df = pd.DataFrame(state_changes) if state_changes else None\n",
        "\n",
        "    # --- Extract Logs from trace with decoding ---\n",
        "    logs_data = []\n",
        "    log_counter_trace = 0\n",
        "\n",
        "    def extract_logs_recursive(call):\n",
        "        nonlocal log_counter_trace\n",
        "        if 'logs' in call and isinstance(call['logs'], list):\n",
        "            for log in call['logs']:\n",
        "                # Ensure log is a dictionary\n",
        "                if not isinstance(log, dict): continue\n",
        "\n",
        "                log_details = {\n",
        "                    \"address\": log.get(\"address\", \"N/A\"),\n",
        "                    \"topics\": log.get(\"topics\", []),\n",
        "                    \"data\": log.get(\"data\", \"0x\"),\n",
        "                    \"log_index_trace\": log_counter_trace\n",
        "                }\n",
        "                log_counter_trace += 1\n",
        "\n",
        "                # Check if log is from PYUSD contract\n",
        "                address_lower = log_details[\"address\"].lower()\n",
        "                is_pyusd_contract = address_lower in PYUSD_CONTRACTS\n",
        "\n",
        "                # Basic data for all logs\n",
        "                log_entry = {\n",
        "                    \"log_idx_trace\": log_details[\"log_index_trace\"],\n",
        "                    \"address\": log_details[\"address\"],\n",
        "                    \"contract\": PYUSD_CONTRACTS.get(address_lower, \"Other\"),\n",
        "                    \"is_pyusd\": is_pyusd_contract,\n",
        "                    \"topic0\": log_details[\"topics\"][0] if log_details[\"topics\"] else \"N/A\",\n",
        "                    \"topic0_short\": log_details[\"topics\"][0][:10]+\"...\" if log_details[\"topics\"] else \"N/A\",\n",
        "                    \"details\": \"Not Decoded\",\n",
        "                    \"event_name\": \"Unknown\"\n",
        "                }\n",
        "\n",
        "                # event decoding with the registry\n",
        "                if is_pyusd_contract and isinstance(log_details[\"topics\"], list) and log_details[\"topics\"]:\n",
        "                    event_topic = log_details[\"topics\"][0]\n",
        "                    if event_topic in PYUSD_EVENTS:\n",
        "                        event_info = PYUSD_EVENTS[event_topic]\n",
        "                        log_entry[\"event_name\"] = event_info[\"name\"]\n",
        "\n",
        "                        try:\n",
        "                            # Decode event data using registered decoder\n",
        "                            decoded_data = event_info[\"decoder\"](log_details[\"topics\"], log_details[\"data\"])\n",
        "\n",
        "                            # Format details based on event type\n",
        "                            if \"Transfer\" in event_info[\"name\"]:\n",
        "                                value_pyusd_str = format_value_pyusd(decoded_data[\"value\"])\n",
        "                                log_entry[\"details\"] = f\"PYUSD Transfer: {value_pyusd_str} from {shorten_address(decoded_data['from'])} to {shorten_address(decoded_data['to'])}\"\n",
        "                                log_entry[\"is_transfer\"] = True\n",
        "                                log_entry[\"amount\"] = decoded_data[\"value\"]\n",
        "                                log_entry[\"from_addr\"] = decoded_data[\"from\"]\n",
        "                                log_entry[\"to_addr\"] = decoded_data[\"to\"]\n",
        "                            elif \"Approval\" in event_info[\"name\"]:\n",
        "                                value_pyusd_str = format_value_pyusd(decoded_data[\"value\"])\n",
        "                                log_entry[\"details\"] = f\"PYUSD Approval: {shorten_address(decoded_data['owner'])} approved {value_pyusd_str} for {shorten_address(decoded_data['spender'])}\"\n",
        "                                log_entry[\"is_approval\"] = True\n",
        "                                log_entry[\"amount\"] = decoded_data[\"value\"]\n",
        "                                log_entry[\"owner\"] = decoded_data[\"owner\"]\n",
        "                                log_entry[\"spender\"] = decoded_data[\"spender\"]\n",
        "                            elif \"Paused\" in event_info[\"name\"]:\n",
        "                                account = decoded_data.get(\"account\", \"N/A\")\n",
        "                                log_entry[\"details\"] = f\"PYUSD Paused by {shorten_address(account) if account else 'N/A'}\"\n",
        "                                log_entry[\"is_pause\"] = True\n",
        "                            elif \"Unpaused\" in event_info[\"name\"]:\n",
        "                                account = decoded_data.get(\"account\", \"N/A\")\n",
        "                                log_entry[\"details\"] = f\"PYUSD Unpaused by {shorten_address(account) if account else 'N/A'}\"\n",
        "                                log_entry[\"is_unpause\"] = True\n",
        "\n",
        "                        except Exception as decode_err:\n",
        "                            log_entry[\"details\"] = f\"PYUSD Event (Decode Error: {decode_err})\"\n",
        "\n",
        "                logs_data.append(log_entry)\n",
        "\n",
        "        # Check sub-calls recursively\n",
        "        if 'calls' in call and isinstance(call['calls'], list):\n",
        "            for sub_call in call['calls']:\n",
        "                extract_logs_recursive(sub_call)\n",
        "\n",
        "    # Extract logs if present in trace config\n",
        "    extract_logs_recursive(trace_result)\n",
        "    logs_df = pd.DataFrame(logs_data) if logs_data else pd.DataFrame()\n",
        "\n",
        "    # --- Create Contract Interaction Graph with Plotly ---\n",
        "    contract_graph = None\n",
        "    if contract_interactions:\n",
        "        try:\n",
        "            contract_graph = create_plotly_contract_interaction_graph(contract_interactions)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create contract interaction graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # --- Create Detailed Call Graph with Plotly ---\n",
        "    call_graph = None\n",
        "    if call_data_list:\n",
        "        try:\n",
        "            call_graph = create_plotly_call_graph(call_data_list)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create detailed call graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Create PYUSD flow graph if transfers exist\n",
        "    flow_graph = None\n",
        "    if pyusd_transfers:\n",
        "        try:\n",
        "            flow_graph = create_plotly_flow_graph(pyusd_transfers)\n",
        "        except Exception as flow_err:\n",
        "            console.print(f\"[warning]Could not create PYUSD flow graph: {flow_err}\", style=\"warning\")\n",
        "\n",
        "    # Create Gas Usage by Category\n",
        "    gas_category_df = pd.DataFrame(\n",
        "        [{\"category\": k, \"gas_used\": v} for k, v in gas_by_category.items() if v > 0]\n",
        "    )\n",
        "\n",
        "    return call_graph, call_df, logs_df, flow_graph, contract_graph, gas_category_df, state_changes_df, pyusd_transfers\n",
        "\n",
        "# =============================================================================================\n",
        "# --- Execute callTracer Analysis ---\n",
        "# =============================================================================================\n",
        "if 'TARGET_TX_HASH' in locals() and validate_tx_hash: # Use the validation flag from setup cell\n",
        "    console.print(\"\\n\\n[bold]üéØ Using callTracer on Mainnet[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    console.print(f\"Target Transaction : {TARGET_TX_HASH}\")\n",
        "\n",
        "    # Use the trace config from the configuration\n",
        "    trace_result_call = make_rpc_request(\"debug_traceTransaction\",\n",
        "                                         [TARGET_TX_HASH, {\"tracer\": \"callTracer\", \"tracerConfig\": TRACE_CONFIGS[\"callTracer\"]}],\n",
        "                                         network='mainnet')\n",
        "\n",
        "    if trace_result_call:\n",
        "        console.print(\"[success]Successfully received trace data.\", style=\"success\")\n",
        "\n",
        "        # --- Parse and Visualize ---\n",
        "        try:\n",
        "            call_graph, call_df, logs_df, pyusd_flow, contract_graph, gas_category_df, state_changes_df, pyusd_transfers = parse_call_trace(trace_result_call, TARGET_TX_HASH)\n",
        "\n",
        "            # Create output widgets for each visualization (add this right after parsing the trace)\n",
        "            contract_graph_output = widgets.Output()\n",
        "            call_graph_output = widgets.Output()\n",
        "            flow_graph_output = widgets.Output()\n",
        "\n",
        "            # 1. TRANSACTION OVERVIEW DASHBOARD\n",
        "            console.print(\"\\n\\n[bold cyan3]üîç PYUSD TRANSACTION ANALYSIS DASHBOARD[/bold cyan3]\", justify=\"left\")\n",
        "            console.print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\", style=\"cyan3\", justify=\"left\")\n",
        "\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                # Basic transaction metrics\n",
        "                tx_stats = {\n",
        "                    \"total_calls\": len(call_df),\n",
        "                    \"pyusd_calls\": len(call_df[call_df['is_pyusd']]),\n",
        "                    \"max_call_depth\": call_df['depth'].max(),\n",
        "                    \"total_gas\": call_df['gasUsed'].sum(),\n",
        "                    \"errors\": len(call_df[call_df['error'].notnull()])\n",
        "                }\n",
        "\n",
        "                stats_table = Table(title=\"Transaction Metrics\", show_header=True, header_style=\"bold cyan\")\n",
        "                stats_table.add_column(\"Metric\", style=\"dim\")\n",
        "                stats_table.add_column(\"Value\")\n",
        "\n",
        "                for k, v in tx_stats.items():\n",
        "                    if k == 'total_gas':\n",
        "                        stats_table.add_row(k.replace('_', ' ').title(), f\"{v:,} gas units\")\n",
        "                    else:\n",
        "                        stats_table.add_row(k.replace('_', ' ').title(), str(v))\n",
        "\n",
        "                console.print(stats_table)\n",
        "\n",
        "           # 2. Display Contract Interaction Graph\n",
        "            if contract_graph:\n",
        "                console.print(\"\\n\\n[bold cyan3]üìä Contract Interaction Overview[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(contract_graph)\n",
        "                    console.print(\"\\n\\n[info]This graph shows the high-level interactions between contracts in this transaction.\", style=\"info\")\n",
        "                except Exception as viz_err:\n",
        "                    console.print(f\"[warning]Could not render contract interaction graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "            # 3. Display Call Graph Visualization\n",
        "            console.print(\"\\n\\n[bold cyan3]üìä Detailed Call Graph Visualization[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "            if call_graph:\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(call_graph)\n",
        "                    console.print(\"\\n\\n[info]This visualization shows the detailed call hierarchy in this transaction.\", style=\"info\")\n",
        "                except Exception as viz_err:\n",
        "                    console.print(f\"[warning]Could not render visualization: {viz_err}\", style=\"warning\")\n",
        "            else:\n",
        "                console.print(\"[warning]Call graph generation failed.\", style=\"warning\")\n",
        "\n",
        "            # 4. Display PYUSD Flow Graph if available\n",
        "            if pyusd_flow:\n",
        "                console.print(\"\\n\\n[bold cyan3]üîÑ PYUSD Token Flow Analysis[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(pyusd_flow)\n",
        "                    console.print(\"\\n\\n[info]This graph shows the movement of PYUSD tokens in this transaction.\", style=\"info\")\n",
        "                except Exception as flow_err:\n",
        "                    console.print(f\"[warning]Could not render PYUSD flow: {flow_err}\", style=\"warning\")\n",
        "\n",
        "            # 5. State Changes Analysis\n",
        "            if state_changes_df is not None and not state_changes_df.empty:\n",
        "                console.print(\"\\n\\n[bold cyan3]üîÑ PYUSD State Changes[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "                console.print(\"[info]The following state changes occurred in PYUSD contracts:\", style=\"info\")\n",
        "\n",
        "                # Format amounts in dataframe\n",
        "                state_changes_df['formatted_amount'] = state_changes_df['amount'].apply(format_value_pyusd)\n",
        "\n",
        "                # Display state changes with appropriate columns\n",
        "                display(state_changes_df[['contract', 'function', 'type', 'formatted_amount', 'gas_used']])\n",
        "\n",
        "                # Summary of state impact\n",
        "                if 'type' in state_changes_df.columns:\n",
        "                    changes_by_type = state_changes_df['type'].value_counts()\n",
        "                    console.print(\"\\n[bold]State Change Summary:[/bold]\")\n",
        "                    for change_type, count in changes_by_type.items():\n",
        "                        console.print(f\"- {change_type.title()}: {count} operations\")\n",
        "            else:\n",
        "                console.print(\"\\n\\n[info]No direct PYUSD state changes detected in this transaction.\", style=\"info\")\n",
        "\n",
        "            # 6. Gas Usage Analysis\n",
        "            if gas_category_df is not None and not gas_category_df.empty:\n",
        "                console.print(\"\\n\\n[bold yellow3]‚õΩ Gas Usage Analysis[/bold yellow3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "                # Create simple gas usage table\n",
        "                gas_table = Table(title=\"Gas Usage by Operation Category\", show_header=True, header_style=\"bold yellow3\")\n",
        "                gas_table.add_column(\"Category\", style=\"dim\")\n",
        "                gas_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "                gas_table.add_column(\"Percentage\", justify=\"right\")\n",
        "\n",
        "                total_gas = gas_category_df['gas_used'].sum()\n",
        "\n",
        "                for _, row in gas_category_df.iterrows():\n",
        "                    category = row['category'].replace('_', ' ').title()\n",
        "                    gas_used = row['gas_used']\n",
        "                    percentage = (gas_used / total_gas * 100) if total_gas > 0 else 0\n",
        "                    gas_table.add_row(\n",
        "                        category,\n",
        "                        f\"{gas_used:,}\",\n",
        "                        f\"{percentage:.1f}%\"\n",
        "                    )\n",
        "\n",
        "                console.print(gas_table)\n",
        "\n",
        "                # Gas usage visualization\n",
        "                try:\n",
        "                    # Color by operation category for better visibility\n",
        "                    fig_gas = px.pie(gas_category_df, values='gas_used', names='category',\n",
        "                                     title=f'<b>Gas Usage Distribution ({shorten_address(TARGET_TX_HASH)})</b>')\n",
        "                    fig_gas.update_layout(\n",
        "                        template=\"plotly_white\",\n",
        "                        title={\n",
        "                            'y': 0.95,\n",
        "                            'x': 0.5,\n",
        "                            'xanchor': 'center',\n",
        "                            'yanchor': 'top',\n",
        "                            'font': {'size': 16}\n",
        "                        },\n",
        "                        margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                    )\n",
        "                    fig_gas.show()\n",
        "                except Exception as plot_err:\n",
        "                    console.print(f\"[warning]Could not generate gas usage plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "            # 7. Filtered Call Data Table\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                console.print(\"\\n\\n[bold cyan3]üìã Key Contract Calls[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "                # Focus on PYUSD calls for a cleaner view\n",
        "                pyusd_calls = call_df[call_df['is_pyusd']]\n",
        "\n",
        "                if not pyusd_calls.empty:\n",
        "                    console.print(f\"[success]Found {len(pyusd_calls)} PYUSD-related calls in this transaction.\", style=\"success\")\n",
        "\n",
        "                    # Style the DataFrame for better visibility\n",
        "                    def highlight_pyusd(val):\n",
        "                        return 'background-color: palegreen' if val else ''\n",
        "\n",
        "                    # Display with conditional formatting - only important columns\n",
        "                    display_cols = ['id', 'type', 'depth', 'contract', 'function_category', 'gasUsed', 'error']\n",
        "                    display(pyusd_calls[display_cols])\n",
        "                else:\n",
        "                    console.print(\"[info]No PYUSD-specific calls found in this transaction.\", style=\"info\")\n",
        "\n",
        "                # Show high gas usage calls with function names\n",
        "                console.print(\"\\n[bold yellow3]Highest Gas Usage Calls:[/bold yellow3]\")\n",
        "                high_gas_calls = call_df.nlargest(5, 'gasUsed')\n",
        "\n",
        "                # Add function description to high gas calls\n",
        "                high_gas_calls['function_name'] = high_gas_calls.apply(\n",
        "                    lambda row: get_function_description(\n",
        "                        row['input_preview'],\n",
        "                        row['is_pyusd'] if 'is_pyusd' in row else False,\n",
        "                        row['contract'] if 'contract' in row else \"Non-PYUSD Contract\"\n",
        "                    ),\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                # Display with function name instead of category if available\n",
        "                display(high_gas_calls[['id', 'type', 'contract', 'function_name', 'gasUsed']])\n",
        "\n",
        "            # 8. PYUSD Event Analysis\n",
        "            if logs_df is not None and not logs_df.empty:\n",
        "                console.print(\"\\n\\n[bold green3]üìù PYUSD Events Analysis[/bold green3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "\n",
        "                # Highlight PYUSD logs\n",
        "                pyusd_logs = logs_df[logs_df['is_pyusd']]\n",
        "                if not pyusd_logs.empty:\n",
        "                    console.print(f\"[success]Found {len(pyusd_logs)} PYUSD events in this transaction.\", style=\"success\")\n",
        "\n",
        "                    # Group by event type\n",
        "                    if 'event_name' in pyusd_logs.columns:\n",
        "                        event_counts = pyusd_logs['event_name'].value_counts()\n",
        "\n",
        "                        event_table = Table(title=\"PYUSD Events\", show_header=True, header_style=\"bold green3\")\n",
        "                        event_table.add_column(\"Event Type\", style=\"dim\")\n",
        "                        event_table.add_column(\"Count\", justify=\"right\")\n",
        "\n",
        "                        for event, count in event_counts.items():\n",
        "                            event_table.add_row(event, str(count))\n",
        "\n",
        "                        console.print(event_table)\n",
        "\n",
        "                    # Display detailed event data\n",
        "                    console.print(\"\\n\\n[bold green3]PYUSD Event Details:[/bold green3]\")\n",
        "                    display(pyusd_logs[['contract', 'event_name', 'details']])\n",
        "\n",
        "                    # Transfer value analysis\n",
        "                    if 'amount' in pyusd_logs.columns and 'is_transfer' in pyusd_logs.columns:\n",
        "                        transfer_logs = pyusd_logs[pyusd_logs['is_transfer']]\n",
        "                        if not transfer_logs.empty:\n",
        "                            total_transferred = transfer_logs['amount'].sum()\n",
        "                            console.print(f\"\\n\\n[info][bold cyan3]Total PYUSD transferred:[bold cyan3] {format_value_pyusd(total_transferred)}\", style=\"info\")\n",
        "                else:\n",
        "                    console.print(\"[info]No PYUSD events found in this transaction.\", style=\"info\")\n",
        "            else:\n",
        "                console.print(\"[info]No logs extracted from trace.\", style=\"info\")\n",
        "\n",
        "            # 9. Add Recommendations Section\n",
        "            console.print(\"\\n\\n[bold cyan3]üí° Analysis Observations & Recommendations[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            recommendations = []\n",
        "\n",
        "            # Check for high gas usage patterns\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                high_gas_threshold = call_df['gasUsed'].sum() * 0.25  # 25% of total gas\n",
        "                high_gas_ops = call_df[call_df['gasUsed'] > high_gas_threshold]\n",
        "                if not high_gas_ops.empty:\n",
        "                    recommendations.append(f\"- High gas operations detected: {len(high_gas_ops)} calls used >25% of transaction gas\")\n",
        "\n",
        "            # Check for deep call stack\n",
        "            if call_df is not None and 'depth' in call_df.columns:\n",
        "                max_depth = call_df['depth'].max()\n",
        "                if max_depth > 5:\n",
        "                    recommendations.append(f\"- Deep call stack detected (max depth: {max_depth})\")\n",
        "\n",
        "            # Check token flow patterns\n",
        "            if logs_df is not None and 'is_transfer' in logs_df.columns:\n",
        "                transfer_count = logs_df['is_transfer'].sum()\n",
        "                if transfer_count > 3:\n",
        "                    recommendations.append(f\"- Complex token movement detected ({transfer_count} transfers)\")\n",
        "\n",
        "            # Add general PYUSD observations\n",
        "            if call_df is not None and 'is_pyusd' in call_df.columns:\n",
        "                pyusd_calls = call_df[call_df['is_pyusd']]\n",
        "                if not pyusd_calls.empty:\n",
        "                    recommendations.append(f\"- Transaction involves {len(pyusd_calls)} PYUSD contract interactions\")\n",
        "\n",
        "            # Display recommendations\n",
        "            if recommendations:\n",
        "                for rec in recommendations:\n",
        "                    console.print(rec)\n",
        "            else:\n",
        "                console.print(\"[info]No specific observations to highlight for this transaction.\", style=\"info\")\n",
        "\n",
        "            # 10. Export Options\n",
        "            console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            # Create export output area\n",
        "            export_output = widgets.Output()\n",
        "\n",
        "            # Create export buttons with proper styling\n",
        "            export_buttons = widgets.HBox([\n",
        "                widgets.Button(\n",
        "                    description='Export to CSV',\n",
        "                    button_style='primary',  # Green\n",
        "                    layout=widgets.Layout(width='150px')\n",
        "                ),\n",
        "                widgets.Button(\n",
        "                    description='Export as JSON',\n",
        "                    button_style='warning',  # Orange\n",
        "                    layout=widgets.Layout(width='150px')\n",
        "                ),\n",
        "                widgets.Button(\n",
        "                    description='Export to Google Sheets',\n",
        "                    button_style='info',     # Blue\n",
        "                    layout=widgets.Layout(width='200px')\n",
        "                )\n",
        "            ])\n",
        "\n",
        "            # Define export handlers with simplified loading indicators\n",
        "            def export_csv(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    console.print(\"[cyan3]Exporting to CSV...\", style=\"info\")\n",
        "\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.csv\"\n",
        "\n",
        "                    try:\n",
        "                        # Export to CSV\n",
        "                        result = download_csv_direct(call_df, filename)\n",
        "\n",
        "                        # Clear loading message and show success\n",
        "                        clear_output()\n",
        "                        console.print(\"‚úì Successfully exported to CSV\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"‚ùå Error exporting to CSV: {str(e)}\", style=\"error\")\n",
        "\n",
        "            def export_json(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    console.print(\"[cyan3]Exporting to JSON...\", style=\"info\")\n",
        "\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.json\"\n",
        "\n",
        "                    try:\n",
        "                        # Prepare export data\n",
        "                        export_data = {\n",
        "                            \"transaction_hash\": TARGET_TX_HASH,\n",
        "                            \"analysis_type\": \"callTracer\",\n",
        "                            \"transaction_stats\": tx_stats if 'tx_stats' in locals() else {},\n",
        "                            \"state_changes\": state_changes_df.to_dict('records') if state_changes_df is not None and not state_changes_df.empty else [],\n",
        "                            \"gas_by_category\": gas_category_df.to_dict('records') if gas_category_df is not None and not gas_category_df.empty else [],\n",
        "                            \"pyusd_transfers\": pyusd_transfers if pyusd_transfers is not None else []\n",
        "                        }\n",
        "\n",
        "                        # Export to JSON\n",
        "                        result = download_json_direct(export_data, filename)\n",
        "\n",
        "                        # Clear loading message and show success\n",
        "                        clear_output()\n",
        "                        console.print(\"‚úì Successfully exported to JSON\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"‚ùå Error exporting to JSON: {str(e)}\", style=\"error\")\n",
        "\n",
        "            def export_to_sheets(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    try:\n",
        "                        # Collect all data for the sheet\n",
        "                        export_data = {\n",
        "                            \"transaction_hash\": TARGET_TX_HASH,\n",
        "                            \"transaction_stats\": tx_stats if 'tx_stats' in locals() else {},\n",
        "                            \"gas_distribution\": gas_category_df.to_dict('records') if gas_category_df is not None else [],\n",
        "                            \"pyusd_transfers\": pyusd_transfers if pyusd_transfers is not None else [],\n",
        "                            \"state_changes\": state_changes_df.to_dict('records') if state_changes_df is not None and not state_changes_df.empty else [],\n",
        "                            \"logs_df\": logs_df if logs_df is not None and not logs_df.empty else None\n",
        "                        }\n",
        "\n",
        "                        # Call the export function\n",
        "                        spreadsheet_url, sheet_title = export_to_google_sheets(call_df, export_data, TARGET_TX_HASH)\n",
        "\n",
        "                        # Open the spreadsheet and display link\n",
        "                        display(Javascript(f'window.open(\"{spreadsheet_url}\", \"_blank\");'))\n",
        "\n",
        "                        # 2. Display *only* the link and success message as static HTML output\n",
        "                        clear_output(wait=True)\n",
        "                        console.print(\"‚úì Successfully exported to Google Sheets\", style=\"spring_green3\")\n",
        "                        display(HTML(f'''\n",
        "                        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "                        '''))\n",
        "\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"‚ùå Error exporting to Google Sheets: {str(e)}\", style=\"error\")\n",
        "                        html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                        display(HTML(html))\n",
        "\n",
        "                        # Fallback to CSV\n",
        "                        console.print(\"[cyan3]Falling back to CSV download...\", style=\"info\")\n",
        "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                        filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.csv\"\n",
        "                        result = download_csv_direct(call_df, filename)\n",
        "\n",
        "                        clear_output()\n",
        "                        console.print(\"‚úì CSV fallback ready\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                        display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "            # Connect handlers to buttons\n",
        "            export_buttons.children[0].on_click(export_csv)\n",
        "            export_buttons.children[1].on_click(export_json)\n",
        "            export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "            # Display button container and output area\n",
        "            display(export_buttons)\n",
        "            display(export_output)\n",
        "\n",
        "        except Exception as parse_err:\n",
        "            console.print(f\"[error]Failed during parsing or visualization: {parse_err}\", style=\"error\")\n",
        "            import traceback\n",
        "            console.print(traceback.format_exc())\n",
        "    else:\n",
        "        console.print(\"[error]Failed to retrieve trace data from RPC node.\", style=\"error\")\n",
        "else:\n",
        "    console.print(\"[warning]No valid transaction hash found. Please set TARGET_TX_HASH to a valid transaction hash.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "jlWAKP7_Qdo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Using `structLog` Tracer: Opcode-Level Execution Analysis (Use Cautiously)\n",
        "\n",
        "The `structLog` tracer dives deep into the Ethereum Virtual Machine (EVM), providing a step-by-step log of each opcode executed during the transaction. For each step, it details the program counter (PC), opcode, remaining gas, gas cost, stack contents, memory state, and storage changes (if enabled).\n",
        "\n",
        "> **‚ö†Ô∏è Extreme Granularity & Resource Intensity**\n",
        ">\n",
        "> *   **Method:** `debug_traceTransaction` with `tracer: \"structLog\"`\n",
        "> *   **Multiplier:** `50x` (Same base multiplier as `callTracer`, but output size is *significantly* larger)\n",
        "> *   **Output Size:** Can generate **very large** outputs (potentially hundreds of thousands of steps/lines, consuming significant memory/browser resources) for even moderately complex transactions.\n",
        "> *   **Use Case:** Best suited for highly specific debugging tasks, deep gas optimization analysis at the opcode level, or verifying precise execution paths, rather than general transaction overview. **Use with caution.**\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **GCP Advantage:** While the base multiplier is `50x`, the sheer volume of data returned by `structLog` makes it extremely demanding on RPC node resources. GCP's infrastructure and generous quotas make it feasible to retrieve these detailed traces where other providers might time out, restrict output size, or charge heavily.\n",
        "> *   **PYUSD Insight:** `structLog` can be used for:\n",
        ">     *   **Fine-grained Gas Profiling:** Identifying exactly which opcodes consume the most gas during PYUSD function execution (e.g., `SSTORE` during transfers/approvals).\n",
        ">     *   **Debugging Reverts:** Pinpointing the exact opcode and state (stack/memory) where a PYUSD transaction failed.\n",
        ">     *   **Security Analysis:** Examining low-level execution for potential vulnerabilities or unexpected behavior within PYUSD or interacting contracts.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Conditional Execution:** The code includes a flag (`RUN_STRUCTLOG_TRACE`) which defaults to `False`. Set this to `True` only if you specifically need this level of detail.\n",
        "2.  **Fetch Trace:** Calls `debug_traceTransaction` using `TARGET_TX_HASH` and the `structLog` configuration.\n",
        "3.  **Parse Steps:** The `parse_struct_log` function processes the potentially massive list of execution steps.\n",
        "4.  **Summarize & Visualize:**\n",
        "    *   **Overview:** Displays total steps, gas cost, call depth, and highlights PYUSD execution percentage.\n",
        "    *   **Gas Analysis:** Generates plots showing gas cost distribution by opcode *category* and by individual *opcode*.\n",
        "    *   **Execution Timeline:** Plots gas remaining over execution steps, highlighting sections executed within PYUSD contracts.\n",
        "    *   **PYUSD Focus:** Analyzes opcode frequency and gas usage specifically within PYUSD contract execution steps.\n",
        "    *   **Data Sample:** Displays the first few steps of the detailed execution trace DataFrame.\n",
        "    *   **Export Options:** Allows downloading the full (potentially large) execution step data.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Gas Plots:** Identify which opcode categories (e.g., `STORAGE`, `MEMORY`, `CALL`) and specific opcodes (e.g., `SSTORE`, `CALL`, `KECCAK256`) dominate gas consumption. Compare this within PYUSD vs. non-PYUSD sections.\n",
        "*   **Execution Timeline:** Observe gas depletion patterns. Look for sharp drops corresponding to expensive operations. Note the percentage of time spent executing PYUSD code.\n",
        "*   **Data Sample:** Understand the structure of the per-opcode data (PC, gas, stack, memory).\n",
        "*   **(If Debugging):** Search the full trace data (if exported) for `REVERT` opcodes or unexpected stack/memory states near the point of failure."
      ],
      "metadata": {
        "id": "fHt4Hc9Z_gbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üî¨ Trace Transaction using debug_traceTransaction (structLog Tracer Opcode-Level Detail)\n",
        "# =============================================================================================\n",
        "# This cell performs detailed opcode-level transaction analysis using the debug_traceTransaction method with the structLog tracer.\n",
        "# It prepares the data and presents insights by:\n",
        "# - Conditionally executing the trace based on the RUN_STRUCTLOG_TRACE flag.\n",
        "# - Parsing the raw structLog output, calculating step-by-step gas costs, categorizing opcodes, and tracking contract execution context (including PYUSD).\n",
        "# - Generating interactive Plotly visualizations for overall gas usage (by category, by opcode), execution timeline (highlighting PYUSD), and PYUSD-specific gas analysis.\n",
        "# - Displaying summary statistics (Panel, Rich tables) and a sample of the processed trace data.\n",
        "# - Providing interactive buttons for exporting the detailed trace data to CSV, JSON, or Google Sheets using helper functions.\n",
        "\n",
        "import base64\n",
        "import json\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, tx_hash):\n",
        "    \"\"\"Export StructLog analysis data to Google Sheets with rich formatting.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[cyan3]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD StructLog Analysis {tx_hash[:10]} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Execution Steps\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD StructLog Analysis\"],\n",
        "            [f\"Transaction: {tx_hash}\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # Add transaction stats summary\n",
        "        if \"summary\" in data_dict:\n",
        "            stats = data_dict[\"summary\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Summary\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "\n",
        "                # Try to format numerical values with commas\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        formatted_value = f\"{value:,}\"\n",
        "                    else:\n",
        "                        formatted_value = str(value)\n",
        "                except:\n",
        "                    formatted_value = str(value)\n",
        "\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 2  # Add extra space after table\n",
        "\n",
        "        # Add opcode distribution reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Opcode Distribution Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.7, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Opcode distribution visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add gas usage reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Gas usage visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add main DataFrame data\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Execution Steps Data\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # For StructLog data, select most important columns for readability\n",
        "            # if dataframe has too many columns\n",
        "            if len(df.columns) > 10:\n",
        "                key_cols = [\"pc\", \"op\", \"gas\", \"gasCost\", \"depth\", \"stack\", \"memory\", \"storage\"]\n",
        "                display_cols = [col for col in key_cols if col in df.columns]\n",
        "\n",
        "                # Add any custom columns that might contain analysis results\n",
        "                other_important_cols = []\n",
        "                for col in df.columns:\n",
        "                    if col not in display_cols and any(x in col.lower() for x in [\"pyusd\", \"token\", \"contract\", \"note\", \"category\"]):\n",
        "                        other_important_cols.append(col)\n",
        "\n",
        "                display_cols.extend(other_important_cols)\n",
        "                display_df = df[display_cols]\n",
        "            else:\n",
        "                display_df = df\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [display_df.columns.tolist()] + display_df.values.tolist()\n",
        "\n",
        "            # Format values for better readability\n",
        "            for i in range(1, len(df_values)):\n",
        "                for j, col in enumerate(display_df.columns):\n",
        "                    val = df_values[i][j]\n",
        "\n",
        "                    # Format different column types appropriately\n",
        "                    if pd.isnull(val):\n",
        "                        df_values[i][j] = \"\"\n",
        "                    elif col in [\"gas\", \"gasCost\"] and isinstance(val, (int, float)):\n",
        "                        df_values[i][j] = f\"{val:,}\"\n",
        "                    elif col in [\"stack\", \"memory\", \"storage\"] and isinstance(val, (list, dict)):\n",
        "                        # Truncate long data structures to prevent huge cells\n",
        "                        df_values[i][j] = str(val)[:100] + \"...\" if len(str(val)) > 100 else str(val)\n",
        "                    else:\n",
        "                        df_values[i][j] = str(val)\n",
        "\n",
        "            worksheet.update(f\"A{current_row}\", df_values)\n",
        "\n",
        "            # Format the DataFrame header\n",
        "            worksheet.format(f\"A{current_row}:{chr(65+len(display_df.columns)-1)}{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            # Add alternating row colors for readability\n",
        "            data_rows = len(df_values)\n",
        "            for i in range(2, data_rows + 1, 2):\n",
        "                row_num = current_row + i - 1\n",
        "                worksheet.format(f\"A{row_num}:{chr(65+len(display_df.columns)-1)}{row_num}\", {\n",
        "                    \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Attempt to resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Clear loading message and show success message\n",
        "        clear_output()\n",
        "        console.print(\"‚úì Successfully exported to Google Sheets\", style=\"spring_green3\")\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clear loading message and show error\n",
        "        clear_output()\n",
        "        console.print(f\"‚ùå Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "def parse_struct_log(struct_logs_list, tx_hash):\n",
        "    \"\"\"Parses structLog output for analysis and visualization.\"\"\"\n",
        "    if not struct_logs_list or not isinstance(struct_logs_list, list):\n",
        "        console.print(\"[warning]No structLog data provided or invalid format.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    # --- Initialize tracking variables ---\n",
        "    log_data = []\n",
        "    total_gas_cost = 0\n",
        "    last_gas = 0\n",
        "    current_contracts = {}  # Map depth -> contract address\n",
        "    pyusd_execution_steps = 0\n",
        "\n",
        "    # --- Define OPCODE categories for better analysis ---\n",
        "    OPCODE_CATEGORIES = {\n",
        "        \"arithmetic\": [\"ADD\", \"MUL\", \"SUB\", \"DIV\", \"SDIV\", \"MOD\", \"SMOD\", \"ADDMOD\", \"MULMOD\", \"EXP\", \"SIGNEXTEND\"],\n",
        "        \"comparison\": [\"LT\", \"GT\", \"SLT\", \"SGT\", \"EQ\", \"ISZERO\"],\n",
        "        \"bitwise\": [\"AND\", \"OR\", \"XOR\", \"NOT\", \"BYTE\", \"SHL\", \"SHR\", \"SAR\"],\n",
        "        \"memory\": [\"MLOAD\", \"MSTORE\", \"MSTORE8\", \"MSIZE\", \"MCOPY\"],\n",
        "        \"storage\": [\"SLOAD\", \"SSTORE\"],\n",
        "        \"flow\": [\"JUMP\", \"JUMPI\", \"JUMPDEST\", \"PC\", \"STOP\", \"RETURN\", \"REVERT\"],\n",
        "        \"stack\": [\"POP\", \"PUSH1\", \"PUSH2\", \"PUSH3\", \"PUSH4\", \"PUSH5\", \"PUSH6\", \"PUSH7\", \"PUSH8\",\n",
        "                 \"PUSH9\", \"PUSH10\", \"PUSH11\", \"PUSH12\", \"PUSH13\", \"PUSH14\", \"PUSH15\", \"PUSH16\",\n",
        "                 \"PUSH17\", \"PUSH18\", \"PUSH19\", \"PUSH20\", \"PUSH21\", \"PUSH22\", \"PUSH23\", \"PUSH24\",\n",
        "                 \"PUSH25\", \"PUSH26\", \"PUSH27\", \"PUSH28\", \"PUSH29\", \"PUSH30\", \"PUSH31\", \"PUSH32\",\n",
        "                 \"DUP1\", \"DUP2\", \"DUP3\", \"DUP4\", \"DUP5\", \"DUP6\", \"DUP7\", \"DUP8\",\n",
        "                 \"DUP9\", \"DUP10\", \"DUP11\", \"DUP12\", \"DUP13\", \"DUP14\", \"DUP15\", \"DUP16\",\n",
        "                 \"SWAP1\", \"SWAP2\", \"SWAP3\", \"SWAP4\", \"SWAP5\", \"SWAP6\", \"SWAP7\", \"SWAP8\",\n",
        "                 \"SWAP9\", \"SWAP10\", \"SWAP11\", \"SWAP12\", \"SWAP13\", \"SWAP14\", \"SWAP15\", \"SWAP16\"],\n",
        "        \"environment\": [\"ADDRESS\", \"BALANCE\", \"ORIGIN\", \"CALLER\", \"CALLVALUE\", \"CALLDATALOAD\",\n",
        "                        \"CALLDATASIZE\", \"CALLDATACOPY\", \"CODESIZE\", \"CODECOPY\", \"GASPRICE\",\n",
        "                        \"EXTCODESIZE\", \"EXTCODECOPY\", \"RETURNDATASIZE\", \"RETURNDATACOPY\",\n",
        "                        \"EXTCODEHASH\", \"BLOCKHASH\", \"COINBASE\", \"TIMESTAMP\", \"NUMBER\",\n",
        "                        \"DIFFICULTY\", \"GASLIMIT\", \"CHAINID\", \"SELFBALANCE\", \"BASEFEE\"],\n",
        "        \"contract\": [\"CREATE\", \"CREATE2\", \"CALL\", \"CALLCODE\", \"DELEGATECALL\", \"STATICCALL\", \"SELFDESTRUCT\"],\n",
        "        \"logging\": [\"LOG0\", \"LOG1\", \"LOG2\", \"LOG3\", \"LOG4\"],\n",
        "        \"gas\": [\"GAS\"],\n",
        "        \"other\": []\n",
        "    }\n",
        "\n",
        "    def get_opcode_category(opcode):\n",
        "        \"\"\"Determine the category of an opcode based on predefined categories.\"\"\"\n",
        "        for category, opcodes in OPCODE_CATEGORIES.items():\n",
        "            if opcode in opcodes:\n",
        "                return category\n",
        "        return \"other\"\n",
        "\n",
        "    console.print(f\"[info]Parsing {len(struct_logs_list):,} structLog steps for {shorten_address(tx_hash)}\\n\\n\", style=\"info\")\n",
        "\n",
        "    # Get initial gas from the first step if available\n",
        "    if struct_logs_list and isinstance(struct_logs_list[0], dict) and 'gas' in struct_logs_list[0]:\n",
        "        last_gas = struct_logs_list[0].get('gas', 0)\n",
        "\n",
        "    # --- Process each execution step in the struct logs ---\n",
        "    for i, step in enumerate(struct_logs_list):\n",
        "        # Ensure step is a dictionary\n",
        "        if not isinstance(step, dict):\n",
        "            continue\n",
        "\n",
        "        # Calculate gas cost for this step\n",
        "        current_gas = step.get('gas', last_gas)\n",
        "        gas_cost = last_gas - current_gas\n",
        "        total_gas_cost += gas_cost if gas_cost > 0 else 0\n",
        "\n",
        "        # Get basic step information\n",
        "        depth = step.get('depth', 0)\n",
        "        op = step.get('op', 'N/A')\n",
        "\n",
        "        # Track contract context changes on CALL instructions\n",
        "        is_pyusd_related = False\n",
        "        if op in ['CALL', 'STATICCALL', 'DELEGATECALL']:\n",
        "            try:\n",
        "                stack = step.get('stack', [])\n",
        "                if len(stack) >= 2:  # Need at least 2 stack items for call address\n",
        "                    # Address is the second stack item for CALL, STATICCALL\n",
        "                    address_raw = stack[1]\n",
        "                    if address_raw.startswith('0x'):\n",
        "                        address = '0x' + address_raw[-40:]\n",
        "                    else:\n",
        "                        # Handle numeric representation\n",
        "                        try:\n",
        "                            address = '0x' + hex(int(address_raw, 16))[-40:].zfill(40)\n",
        "                        except ValueError:\n",
        "                            address = None\n",
        "\n",
        "                    if address:\n",
        "                        current_contracts[depth+1] = address.lower()\n",
        "                        is_pyusd_related = is_pyusd_contract(address)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Check if we're currently in a PYUSD contract\n",
        "        current_contract = current_contracts.get(depth, None)\n",
        "        is_in_pyusd = is_pyusd_contract(current_contract) if current_contract else False\n",
        "\n",
        "        if is_in_pyusd:\n",
        "            pyusd_execution_steps += 1\n",
        "\n",
        "        # Categorize the opcode\n",
        "        opcode_category = get_opcode_category(op)\n",
        "\n",
        "        # Build the execution data record\n",
        "        log_data.append({\n",
        "            'step': i,\n",
        "            'pc': step.get('pc', 0),\n",
        "            'op': op,\n",
        "            'opcode_category': opcode_category,\n",
        "            'gas': current_gas,\n",
        "            'gasCost': gas_cost if gas_cost >= 0 else 0,  # Ensure non-negative cost\n",
        "            'depth': depth,\n",
        "            'stack_depth': len(step.get('stack', [])),\n",
        "            'mem_size_bytes': len(step.get('memory', [])) * 32,  # Memory size in bytes\n",
        "            'current_contract': current_contract,\n",
        "            'is_pyusd_contract': is_in_pyusd,\n",
        "            'is_pyusd_related': is_pyusd_related or is_in_pyusd\n",
        "        })\n",
        "        last_gas = current_gas\n",
        "\n",
        "    if not log_data:\n",
        "        console.print(\"[warning]No valid steps found in structLog data after parsing.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    # --- Convert to DataFrame for analysis ---\n",
        "    df = pd.DataFrame(log_data)\n",
        "\n",
        "    # --- Display Summary ---\n",
        "    pyusd_percentage = (pyusd_execution_steps / len(df) * 100) if len(df) > 0 else 0\n",
        "\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold]structLog Trace Summary for {shorten_address(tx_hash)}[/bold]\n",
        "Total Steps Parsed: {len(df):,}\n",
        "Total Gas Cost (calc): {total_gas_cost:,}\n",
        "Max Depth: {df['depth'].max() if not df.empty else 'N/A'}\n",
        "Max Stack Depth: {df['stack_depth'].max() if not df.empty else 'N/A'}\n",
        "Max Memory (bytes): {df['mem_size_bytes'].max() if not df.empty else 'N/A'}\n",
        "Steps in PYUSD Contracts: {pyusd_execution_steps:,} ({pyusd_percentage:.1f}% of execution)\"\"\",\n",
        "        title=\"structLog Overview\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # --- Generate Visualizations ---\n",
        "    if not df.empty:\n",
        "        # --- Plot Gas Cost by Opcode Category ---\n",
        "        try:\n",
        "            # Visualization Header\n",
        "            console.print(\"\\n\\n[bold yellow3]‚õΩ Gas Cost by Opcode Category[/bold yellow3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "            # Calculate opcode category gas costs\n",
        "            category_gas = df.groupby('opcode_category')['gasCost'].sum().reset_index()\n",
        "            if not category_gas.empty:\n",
        "                # Sort categories by gas usage for better visualization\n",
        "                category_gas = category_gas.sort_values(by='gasCost', ascending=False)\n",
        "\n",
        "                # Add percentage to the name\n",
        "                total_gas = category_gas['gasCost'].sum()\n",
        "                category_gas['name_with_pct'] = category_gas.apply(\n",
        "                    lambda x: f\"{x['opcode_category']} ({x['gasCost']/total_gas*100:.1f}%)\",\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                fig_cat_gas = px.pie(\n",
        "                    category_gas,\n",
        "                    values='gasCost',\n",
        "                    names='name_with_pct',  # Use the new column with percentages\n",
        "                    title=' '  # Empty title, we'll add it in layout\n",
        "                )\n",
        "\n",
        "                # Custom settings for better visualization\n",
        "                fig_cat_gas.update_traces(\n",
        "                    textposition='inside',\n",
        "                    textinfo='percent',\n",
        "                    insidetextorientation='radial'\n",
        "                )\n",
        "\n",
        "                # Position the title with extra space and make it bold\n",
        "                fig_cat_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>Gas Cost by Opcode Category ({shorten_address(tx_hash)})</b>',  # Bold title\n",
        "                        'y': 0.95,  # Position higher for more space\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50),  # Increased top margin for title\n",
        "                )\n",
        "                fig_cat_gas.show()\n",
        "        except Exception as plot_err:\n",
        "            console.print(f\"[warning]Could not generate opcode category gas plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- Plot Gas Cost per Opcode ---\n",
        "        try:\n",
        "            # Visulization Header\n",
        "            console.print(\"\\n\\n[bold yellow3]‚õΩ Top 30 Opcodes by Gas Cost[/bold yellow3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "            # Calculate opcode gas costs\n",
        "            opcode_gas = df.groupby('op')['gasCost'].sum().sort_values(ascending=False).reset_index()\n",
        "            # Only show opcodes with non-zero gas cost (as requested)\n",
        "            opcode_gas = opcode_gas[opcode_gas['gasCost'] > 0]\n",
        "\n",
        "            if not opcode_gas.empty:\n",
        "                # Show all significant opcodes, not just top 30\n",
        "                significant_opcodes = len(opcode_gas) if len(opcode_gas) <= 30 else 30\n",
        "\n",
        "                fig_op_gas = px.bar(\n",
        "                    opcode_gas.head(significant_opcodes),\n",
        "                    x='op',\n",
        "                    y='gasCost',\n",
        "                    labels={'op': '<b>Opcode</b>', 'gasCost': '<b>Total Gas Cost</b>'}  # Bold axis labels\n",
        "                )\n",
        "\n",
        "                # Bold title\n",
        "                fig_op_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>Top {significant_opcodes} Opcodes by Gas Cost ({shorten_address(tx_hash)})</b>',\n",
        "                        'y': 0.95,\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                )\n",
        "                fig_op_gas.show()\n",
        "            else:\n",
        "                 console.print(\"[info]No significant gas costs found per opcode.\", style=\"info\")\n",
        "        except Exception as plot_err:\n",
        "             console.print(f\"[warning]Could not generate opcode gas plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- Plot Gas Remaining Over Steps with PYUSD Highlighting ---\n",
        "        try:\n",
        "            # Downsample if too many steps to prevent browser freezing\n",
        "            # ‚ö†Ô∏è WARNING: if there are too many steps it will consume lots of computes browser could crash or freeze.\n",
        "            max_points_plot = 5000\n",
        "            if len(df) > max_points_plot:\n",
        "                # Ensure consistent sampling, e.g., take every Nth point\n",
        "                indices = np.round(np.linspace(0, len(df) - 1, max_points_plot)).astype(int)\n",
        "                plot_df = df.iloc[indices]\n",
        "                plot_title = f'<b>Gas Remaining Over Execution Steps (Sampled) ({shorten_address(tx_hash)})</b>'\n",
        "                xaxis_title = '<b>Execution Step (Sampled)</b>'\n",
        "                console.print(\n",
        "                    f\"\\n\\n[bold yellow3]‚õΩ Plotting downsampled gas remaining[/bold yellow3] [info]({len(plot_df)} points out of {len(df)}).[/info]\\n\"\n",
        "                    f\"[yellow3]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[/yellow3]\"\n",
        "                )\n",
        "            else:\n",
        "                plot_df = df\n",
        "                plot_title = f'<b>Gas Remaining Over Execution Steps ({shorten_address(tx_hash)})</b>'\n",
        "                xaxis_title = '<b>Execution Step</b>'\n",
        "\n",
        "            # Create a more informative plot with PYUSD sections highlighted\n",
        "            fig_gas_steps = go.Figure()\n",
        "\n",
        "            # Add base gas trace\n",
        "            fig_gas_steps.add_trace(go.Scatter(\n",
        "                x=plot_df['step'],\n",
        "                y=plot_df['gas'],\n",
        "                mode='lines',\n",
        "                name='Gas Remaining',\n",
        "                line=dict(color='blue')\n",
        "            ))\n",
        "\n",
        "            # Highlight PYUSD contract execution sections\n",
        "            if 'is_pyusd_contract' in plot_df.columns:\n",
        "                pyusd_sections = []\n",
        "                current_section = None\n",
        "\n",
        "                for i, row in plot_df.iterrows():\n",
        "                    if row['is_pyusd_contract'] and current_section is None:\n",
        "                        # Start a new PYUSD section\n",
        "                        current_section = {'start': row['step']}\n",
        "                    elif not row['is_pyusd_contract'] and current_section is not None:\n",
        "                        # End the current PYUSD section\n",
        "                        current_section['end'] = plot_df.iloc[i-1]['step'] if i > 0 else row['step']\n",
        "                        pyusd_sections.append(current_section)\n",
        "                        current_section = None\n",
        "\n",
        "                # Handle case where the last section is a PYUSD section\n",
        "                if current_section is not None:\n",
        "                    current_section['end'] = plot_df.iloc[-1]['step']\n",
        "                    pyusd_sections.append(current_section)\n",
        "\n",
        "                # Add highlighted areas for PYUSD execution\n",
        "                for section in pyusd_sections:\n",
        "                    fig_gas_steps.add_shape(\n",
        "                        type=\"rect\",\n",
        "                        x0=section['start'], x1=section['end'],\n",
        "                        y0=0, y1=plot_df['gas'].max(),\n",
        "                        fillcolor=\"rgba(0,255,0,0.1)\",\n",
        "                        line=dict(width=0),\n",
        "                        layer=\"below\"\n",
        "                    )\n",
        "\n",
        "            fig_gas_steps.update_layout(\n",
        "                title={\n",
        "                    'text': plot_title,\n",
        "                    'y': 0.95,\n",
        "                    'x': 0.5,\n",
        "                    'xanchor': 'center',\n",
        "                    'yanchor': 'top',\n",
        "                    'font': {'size': 16}\n",
        "                },\n",
        "                xaxis_title=xaxis_title,\n",
        "                yaxis_title='<b>Gas</b>',  # Bold y-axis label\n",
        "                showlegend=True,\n",
        "                margin=dict(t=100, b=60, l=60, r=60)  # Increased top margin\n",
        "            )\n",
        "\n",
        "            # Add annotation for PYUSD sections - MOVED TO BOTTOM LEFT\n",
        "            if pyusd_percentage > 0:\n",
        "                fig_gas_steps.add_annotation(\n",
        "                    x=0.02, y=0.02,  # Bottom left\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    text=f\"Green sections: PYUSD contract execution ({pyusd_percentage:.1f}%)\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(color=\"green\"),\n",
        "                    bgcolor=\"white\",\n",
        "                    bordercolor=\"green\",\n",
        "                    borderwidth=1,\n",
        "                    align=\"left\"\n",
        "                )\n",
        "\n",
        "            fig_gas_steps.show()\n",
        "        except Exception as plot_err:\n",
        "             console.print(f\"[warning]Could not generate gas remaining plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- PYUSD-Specific Analysis ---\n",
        "        if 'is_pyusd_contract' in df.columns and df['is_pyusd_contract'].any():\n",
        "            console.print(\"\\n[bold green3]üß© PYUSD Contract Execution Analysis[/bold green3]\")\n",
        "\n",
        "            # Filter for PYUSD execution steps\n",
        "            pyusd_df = df[df['is_pyusd_contract']]\n",
        "\n",
        "            # Analyze PYUSD opcodes\n",
        "            pyusd_opcodes = pyusd_df.groupby('op').size().sort_values(ascending=False)\n",
        "\n",
        "            pyusd_table = Table(title=\"Top PYUSD Contract Operations\", show_header=True, header_style=\"bold green3\")\n",
        "            pyusd_table.add_column(\"Opcode\", style=\"dim\")\n",
        "            pyusd_table.add_column(\"Count\", justify=\"right\")\n",
        "            pyusd_table.add_column(\"% of PYUSD Ops\", justify=\"right\")\n",
        "\n",
        "            for op, count in pyusd_opcodes.head(10).items():\n",
        "                percentage = (count / len(pyusd_df) * 100)\n",
        "                pyusd_table.add_row(op, str(count), f\"{percentage:.1f}%\")\n",
        "\n",
        "            console.print(pyusd_table)\n",
        "\n",
        "            # Analyze PYUSD gas usage by category\n",
        "            pyusd_gas_by_cat = pyusd_df.groupby('opcode_category')['gasCost'].sum().sort_values(ascending=False)\n",
        "\n",
        "            try:\n",
        "                # Create a pie chart for PYUSD gas usage by category\n",
        "                gas_cat_df = pd.DataFrame({'category': pyusd_gas_by_cat.index, 'gas_used': pyusd_gas_by_cat.values})\n",
        "\n",
        "                # Add percentage to the name\n",
        "                total_gas = gas_cat_df['gas_used'].sum()\n",
        "                gas_cat_df['name_with_pct'] = gas_cat_df.apply(\n",
        "                    lambda x: f\"{x['category']} ({x['gas_used']/total_gas*100:.1f}%)\",\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                fig_pyusd_gas = px.pie(\n",
        "                    gas_cat_df,\n",
        "                    values='gas_used',\n",
        "                    names='name_with_pct',\n",
        "                    title=' '  # Empty title, we'll add it in layout\n",
        "                )\n",
        "\n",
        "                # Custom settings for better visualization\n",
        "                fig_pyusd_gas.update_traces(\n",
        "                    textposition='inside',\n",
        "                    textinfo='percent',\n",
        "                    insidetextorientation='radial'\n",
        "                )\n",
        "\n",
        "                # Bold title\n",
        "                fig_pyusd_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>PYUSD Contract Gas Usage by Category ({shorten_address(tx_hash)})</b>',\n",
        "                        'y': 0.95,\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                )\n",
        "\n",
        "                fig_pyusd_gas.show()\n",
        "            except Exception as plot_err:\n",
        "                console.print(f\"[warning]Could not generate PYUSD gas category plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # Display DataFrame sample first\n",
        "        console.print(\"\\n\\n[bold cyan3]üìä structLog Data Sample (First 10 steps)[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        # Get a more informative view by focusing on key columns\n",
        "        display_cols = ['step', 'op', 'opcode_category', 'gas', 'gasCost', 'depth', 'is_pyusd_contract']\n",
        "        display(df[display_cols].head(10))\n",
        "\n",
        "        console.print(f\"[info]Full structLog DataFrame has {len(df)} rows. Displaying only head.\", style=\"info\")\n",
        "\n",
        "        # PYUSD-specific summary\n",
        "        pyusd_steps = df['is_pyusd_contract'].sum()\n",
        "        if pyusd_steps > 0:\n",
        "            pyusd_pct = (pyusd_steps / len(df)) * 100\n",
        "            console.print(f\"[success]PYUSD-specific execution: {pyusd_steps:,} steps ({pyusd_pct:.1f}% of total)\", style=\"success\")\n",
        "\n",
        "            # Top Gas-Consuming PYUSD Operations\n",
        "            if 'is_pyusd_contract' in df.columns:\n",
        "                pyusd_ops_gas = df[df['is_pyusd_contract']].groupby('op')['gasCost'].sum().sort_values(ascending=False)\n",
        "\n",
        "                if not pyusd_ops_gas.empty:\n",
        "                    gas_table = Table(title=\"Top Gas-Consuming PYUSD Operations\", show_header=True, header_style=\"bold green\")\n",
        "                    gas_table.add_column(\"Operation\", style=\"dim\")\n",
        "                    gas_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "                    gas_table.add_column(\"% of PYUSD Gas\", justify=\"right\")\n",
        "\n",
        "                    total_pyusd_gas = pyusd_ops_gas.sum()\n",
        "                    for op, gas in pyusd_ops_gas.head(10).items():\n",
        "                        percentage = (gas / total_pyusd_gas * 100)\n",
        "                        gas_table.add_row(op, f\"{gas:,}\", f\"{percentage:.1f}%\")\n",
        "\n",
        "                    console.print(gas_table)\n",
        "\n",
        "        # Export options\n",
        "        console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        # Create export output area\n",
        "        export_output = widgets.Output()\n",
        "\n",
        "        # Create export buttons with proper styling\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Export to CSV',\n",
        "                button_style='primary',  # Green\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export as JSON',\n",
        "                button_style='warning',  # Orange\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export to Google Sheets',\n",
        "                button_style='info',     # Blue\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # Define export handlers\n",
        "        def export_csv(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.csv\"\n",
        "                display(download_csv_direct(df, filename))\n",
        "\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.json\"\n",
        "                # Prepare export data with basic DataFrame stats to avoid reference issues\n",
        "                export_data = {\n",
        "                    \"transaction_hash\": tx_hash,\n",
        "                    \"analysis_type\": \"structLog\",\n",
        "                    \"summary\": {\n",
        "                        \"total_steps\": len(df),\n",
        "                        \"total_gas_cost\": total_gas_cost,\n",
        "                        \"max_depth\": df['depth'].max() if not df.empty else None,\n",
        "                        \"max_stack_depth\": df['stack_depth'].max() if not df.empty else None,\n",
        "                        \"max_memory_bytes\": df['mem_size_bytes'].max() if not df.empty else None,\n",
        "                        \"pyusd_steps\": pyusd_execution_steps,\n",
        "                        \"pyusd_percentage\": pyusd_percentage\n",
        "                    },\n",
        "                    \"opcode_categories\": category_gas.to_dict('records') if 'category_gas' in locals() and not category_gas.empty else []\n",
        "                }\n",
        "                display(download_json_direct(export_data, filename))\n",
        "\n",
        "        def export_to_sheets(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                try:\n",
        "                    # Only use variables that are in scope and defined\n",
        "                    export_data = {\n",
        "                        \"transaction_hash\": tx_hash,\n",
        "                        \"summary\": {\n",
        "                            \"total_steps\": len(df),\n",
        "                            \"total_gas_cost\": total_gas_cost,\n",
        "                            \"max_depth\": df['depth'].max() if not df.empty else None,\n",
        "                            \"max_stack_depth\": df['stack_depth'].max() if not df.empty else None,\n",
        "                            \"max_memory_bytes\": df['mem_size_bytes'].max() if not df.empty else None,\n",
        "                            \"pyusd_steps\": pyusd_execution_steps,\n",
        "                            \"pyusd_percentage\": pyusd_percentage\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    # Add opcode categories if available\n",
        "                    if 'category_gas' in locals() and not category_gas.empty:\n",
        "                        export_data[\"opcode_categories\"] = category_gas.to_dict('records')\n",
        "\n",
        "                    display(export_to_google_sheets(df, export_data, tx_hash))\n",
        "                except Exception as e:\n",
        "                    html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                    display(HTML(html))\n",
        "\n",
        "                    # Fallback to CSV\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.csv\"\n",
        "                    display(download_csv_direct(df, filename))\n",
        "                    display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "        # Connect handlers to buttons\n",
        "        export_buttons.children[0].on_click(export_csv)\n",
        "        export_buttons.children[1].on_click(export_json)\n",
        "        export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "        # Display button container and output area\n",
        "        display(export_buttons)\n",
        "        display(export_output)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- Execute Tracing ---\n",
        "# WARNING: structLog can be VERY large and slow. Default to False.\n",
        "RUN_STRUCTLOG_TRACE = True  # <<< SET TO TRUE TO RUN THIS EXPENSIVE TRACE\n",
        "\n",
        "if not validate_tx_hash:  # Check validation flag from setup cell\n",
        "    console.print(\"[warning]TARGET_TX_HASH not set or invalid. Cannot run structLog analysis.\", style=\"warning\")\n",
        "elif RUN_STRUCTLOG_TRACE:\n",
        "    console.print(\"\\n\\n[bold]üéØ Using structLog on Mainnet[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    console.print(f\"Target Transaction : {TARGET_TX_HASH}\")\n",
        "\n",
        "    # Use the default tracer configuration (the one that worked)\n",
        "    tracer_config = {\"tracerConfig\": TRACE_CONFIGS[\"structLog\"]}\n",
        "\n",
        "    # Request trace on Mainnet\n",
        "    trace_result_struct = make_rpc_request(\"debug_traceTransaction\", [TARGET_TX_HASH, tracer_config], network='mainnet')\n",
        "\n",
        "    # Process result if we got one\n",
        "    if trace_result_struct:\n",
        "        # Check where structLogs might be in the response\n",
        "        struct_logs = None\n",
        "        if 'structLogs' in trace_result_struct:\n",
        "            struct_logs = trace_result_struct['structLogs']\n",
        "        elif 'result' in trace_result_struct and isinstance(trace_result_struct['result'], dict) and 'structLogs' in trace_result_struct['result']:\n",
        "            struct_logs = trace_result_struct['result']['structLogs']\n",
        "\n",
        "        if struct_logs and isinstance(struct_logs, list):\n",
        "            struct_log_df = parse_struct_log(struct_logs, TARGET_TX_HASH)\n",
        "        else:\n",
        "            console.print(\"[warning]Got response, but structLogs format was not as expected.\", style=\"warning\")\n",
        "    else:\n",
        "        console.print(f\"[warning]Failed to get trace data for {TARGET_TX_HASH}.\", style=\"warning\")\n",
        "\n",
        "elif not RUN_STRUCTLOG_TRACE:\n",
        "     console.print(\"\\n[info]Skipping trace analysis as RUN_STRUCTLOG_TRACE is False.\", style=\"info\")\n"
      ],
      "metadata": {
        "id": "axyGCZbU_k45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 üìú `eth_getLogs`: Efficiently Fetching PYUSD Events\n",
        "---\n",
        "\n",
        "This section focuses on retrieving specific **event logs** emitted by the PYUSD smart contract. Events are a crucial mechanism for contracts to signal occurrences (like transfers or approvals) to the outside world. `eth_getLogs` provides a highly efficient way to query these events directly from the blockchain's indexed log data, avoiding the need to process non-relevant transactions or blocks.\n",
        "\n",
        "Here, we specifically target the standard ERC-20 `Transfer(address,address,uint256)` event emitted by the PYUSD contract to track token movements.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Blockchain Node Engine**\n",
        ">\n",
        "> *   **Method:** `eth_getLogs`\n",
        "> *   **Quota Multiplier:** `50x` (Indicates this method consumes 50x the request quota compared to a basic call like `eth_getBlockByNumber` under GCP's Blockchain Node Engine pricing model).\n",
        "> *   **GCP Integration & Limits:** While `eth_getLogs` is standard, node performance and limitations vary. Public or lower-tier nodes often impose strict limits on the query block range (e.g., 10,000 blocks) or total logs returned (e.g., 10,000 logs). Furthermore, specific endpoints, like the Google Blockchain Node Engine endpoint potentially used here (`blockchain.googleapis.com`), may enforce even tighter constraints (like the **5-block range limit** handled explicitly in the code). GCP's advantage often lies in providing reliable performance, consistent availability, and potentially higher throughput or more permissive limits on its paid tiers compared to shared public endpoints.\n",
        "> *   **PYUSD Insight:** `eth_getLogs` enables us to:\n",
        ">     *   Quickly find **all PYUSD `Transfer` events** within a specific block or a (potentially limited) range of blocks.\n",
        ">     *   Efficiently track PYUSD **velocity and volume** over time by fetching logs incrementally.\n",
        ">     *   Identify **top senders and receivers** of PYUSD within a given period.\n",
        ">     *   Monitor other PYUSD events (like `Approval`, `Paused`, `Unpaused`) by changing the queried `topic`.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Define Filter:** The code configures a filter targeting the main PYUSD contract address (`PYUSD_CONFIG['ethereum']['address']`) and the specific topic hash for the `Transfer` event. It also specifies the target block(s) (e.g., `TARGET_BLOCK_IDENTIFIER`, 'latest', or a range).\n",
        "2.  **Fetch Logs:** Calls `eth_getLogs` via the `web3.py` client. If a Google API endpoint is detected, it uses direct JSON-RPC requests to handle potential specific constraints (like the 5-block limit).\n",
        "3.  **Parse & Decode:** The returned raw log data is parsed, extracting the `from` address, `to` address, and `value` (amount) for each `Transfer` event. PYUSD amounts are formatted using the correct 6 decimals (`PYUSD_CONFIG['ethereum']['decimals']`). Timestamps are fetched for context.\n",
        "4.  **Analyze & Visualize:**\n",
        "    *   **Data Table:** Displays a sample of the fetched transfer events (showing full addresses).\n",
        "    *   **Statistics:** Calculates and shows key metrics (total transfers, volume, unique addresses) in a summary table.\n",
        "    *   **Top Movers:** Identifies and tables the top senders and receivers by volume (showing full addresses).\n",
        "    *   **Visualizations:** Generates plots showing transfer size distribution, volume over time (if timestamps available), and a network graph (Sankey diagram) of top transfer flows.\n",
        "    *   **Export Options:** Provides buttons to download the parsed transfer data (CSV, JSON) or export to Google Sheets.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Transfer Volume & Count:** Assess the PYUSD activity level within the queried block(s)/range.\n",
        "*   **Top Senders/Receivers:** Identify major players interacting with PYUSD. Are they exchanges, bridges, protocols, or individual wallets?\n",
        "*   **Network Graph:** Visualize the primary flow of PYUSD between addresses for the top flows.\n",
        "*   **Timestamp Data (if available):** Observe any time-based patterns in transfer activity."
      ],
      "metadata": {
        "id": "3q7lkAOwW94n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üìú PYUSD Transfer Logs using eth_getLogs\n",
        "# =============================================================================================\n",
        "# This cell retrieves and analyzes PYUSD token transfer events using the eth_getLogs RPC method.\n",
        "#  Functionality includes:\n",
        "# - Fetching PYUSD ERC-20 Transfer events respecting the 5-block maximum range limit.\n",
        "# - Calculating key statistical metrics (total volume, average transfer size, unique participants).\n",
        "# - Generating detailed visualizations: transfer size distribution, volume timeline, and token flow networks.\n",
        "# - Network visualization using a Sankey diagram showing the top 50 transfer flows between addresses.\n",
        "# - Displaying ranked tables of top senders and receivers with volume and transaction counts.\n",
        "# - Providing interactive exports to CSV, JSON, or Google Sheets with complete analysis data.\n",
        "# - Handling both individual block analysis and small block ranges for detailed examination.\n",
        "\n",
        "import base64\n",
        "import json\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, title_prefix):\n",
        "    \"\"\"Export analysis data to Google Sheets using the existing gspread client.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with main data\n",
        "        data_dict: Dictionary with additional structured data\n",
        "        title_prefix: Prefix for sheet title\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD Transfer Analysis {title_prefix} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Transfer Data\")\n",
        "\n",
        "        # Set up a header with analysis info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transfer Analysis\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header\n",
        "        worksheet.format(\"A1:A1\", {\"textFormat\": {\"bold\": True, \"fontSize\": 14}})\n",
        "\n",
        "        # Add summary stats if available\n",
        "        if \"statistics\" in data_dict:\n",
        "            stats = data_dict[\"statistics\"]\n",
        "            stats_rows = [[\"Analysis Summary\"], [\"\"]]\n",
        "            for key, value in stats.items():\n",
        "                stats_rows.append([key.replace(\"_\", \" \").title(), str(value)])\n",
        "\n",
        "            # Add stats after the header (row 4)\n",
        "            worksheet.update(\"A4\", stats_rows)\n",
        "            stats_end_row = 4 + len(stats_rows)\n",
        "        else:\n",
        "            stats_end_row = 4\n",
        "\n",
        "        # Add main DataFrame data below the stats\n",
        "        if not df.empty:\n",
        "            start_row = stats_end_row + 2  # Leave a gap\n",
        "\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{start_row}\", [[\"Transfer Data\"]])\n",
        "            worksheet.format(f\"A{start_row}:A{start_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [df.columns.tolist()] + df.values.tolist()\n",
        "            worksheet.update(f\"A{start_row+1}\", df_values)\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "def fetch_pyusd_transfer_logs(from_block='latest', to_block='latest', network='mainnet'):\n",
        "    \"\"\"Fetches PYUSD Transfer events using eth_getLogs on the specified network.\n",
        "\n",
        "    Handles both direct Web3.py calls and JSON-RPC requests for compatibility with Google Blockchain API,\n",
        "    which has a 5-block maximum range limitation.\n",
        "    \"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    pyusd_checksum_address = Web3.to_checksum_address(PYUSD_CONFIG['ethereum']['address'])\n",
        "    transfer_topic = PYUSD_CONFIG['ethereum']['transfer_event_topic']\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]Fetching PYUSD Transfer logs...[/bold cyan3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Network[/bold]  : [yellow3]{network.capitalize()}[/yellow3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Contract[/bold] : [bold magenta3]{pyusd_checksum_address}[/bold magenta3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Blocks[/bold]   : [bold green3]{from_block} ‚Üí {to_block}[/bold green3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Topic[/bold]    : [dim]{transfer_topic}[/dim]\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Detect if we're using Google Blockchain API\n",
        "        is_google_api = False\n",
        "        if hasattr(w3_client, 'provider') and hasattr(w3_client.provider, 'endpoint_uri'):\n",
        "            endpoint_uri = str(w3_client.provider.endpoint_uri)\n",
        "            is_google_api = \"blockchain.googleapis.com\" in endpoint_uri\n",
        "\n",
        "        if is_google_api:\n",
        "            import requests\n",
        "\n",
        "            # Format block parameters for JSON-RPC\n",
        "            def format_block_param_json(block_id):\n",
        "                if block_id == 'latest' or block_id == 'pending' or block_id == 'earliest':\n",
        "                    return block_id\n",
        "                elif isinstance(block_id, int):\n",
        "                    return hex(block_id)\n",
        "                elif isinstance(block_id, str):\n",
        "                    if block_id.startswith(\"0x\"):\n",
        "                        return block_id\n",
        "                    else:\n",
        "                        try:\n",
        "                            return hex(int(block_id))\n",
        "                        except ValueError:\n",
        "                            raise ValueError(f\"Invalid block identifier: {block_id}\")\n",
        "                else:\n",
        "                    raise ValueError(f\"Invalid block identifier type: {type(block_id)}\")\n",
        "\n",
        "            # Prepare the JSON-RPC payload\n",
        "            payload = {\n",
        "                \"jsonrpc\": \"2.0\",\n",
        "                \"method\": \"eth_getLogs\",\n",
        "                \"params\": [{\n",
        "                    \"fromBlock\": format_block_param_json(from_block),\n",
        "                    \"toBlock\": format_block_param_json(to_block),\n",
        "                    \"address\": pyusd_checksum_address,\n",
        "                    \"topics\": [transfer_topic]\n",
        "                }],\n",
        "                \"id\": 1\n",
        "            }\n",
        "\n",
        "            headers = {\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"Accept\": \"application/json\"\n",
        "            }\n",
        "\n",
        "            # Extract API key from the endpoint URI if present\n",
        "            api_key = None\n",
        "            if \"?key=\" in endpoint_uri:\n",
        "                api_key = endpoint_uri.split(\"?key=\")[1]\n",
        "                # Remove the key from the URI for the request\n",
        "                endpoint_uri = endpoint_uri.split(\"?key=\")[0]\n",
        "\n",
        "            # Make direct request to the API\n",
        "            response = requests.post(\n",
        "                endpoint_uri,\n",
        "                json=payload,\n",
        "                headers=headers,\n",
        "                params={\"key\": api_key} if api_key else None\n",
        "            )\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                console.print(f\"[error]API request failed with status {response.status_code}: {response.text}\", style=\"error\")\n",
        "                return None\n",
        "\n",
        "            result = response.json()\n",
        "\n",
        "            if \"error\" in result:\n",
        "                console.print(f\"[error]JSON-RPC error: {result['error']}\", style=\"error\")\n",
        "                return None\n",
        "\n",
        "            # Parse the logs from the response\n",
        "            logs = result.get(\"result\", [])\n",
        "\n",
        "            if not logs:\n",
        "                console.print(f\"[info]No PYUSD Transfer logs found in the specified range ({from_block} - {to_block}) on {network.capitalize()}.\", style=\"info\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            console.print(f\"[success]Found {len(logs)} PYUSD Transfer logs on {network.capitalize()}.\", style=\"success\")\n",
        "        else:\n",
        "            # Use standard web3.py method for non-Google providers\n",
        "            # eth_getLogs expects block numbers as hex strings or integer/tags\n",
        "            def format_block_param(block_id):\n",
        "                \"\"\"Formats block identifier for eth_getLogs.\"\"\"\n",
        "                if isinstance(block_id, int):\n",
        "                    return hex(block_id) # Prefer hex for consistency with RPC spec\n",
        "                elif isinstance(block_id, str):\n",
        "                     # Check if it's already hex or a known tag\n",
        "                    if block_id.startswith(\"0x\") or block_id in [\"latest\", \"pending\", \"earliest\"]:\n",
        "                        return block_id\n",
        "                    else: # Try converting potential numeric strings\n",
        "                        try:\n",
        "                            return hex(int(str(block_id)))\n",
        "                        except ValueError:\n",
        "                            console.print(f\"[error]Invalid block identifier format for eth_getLogs: {block_id}. Use int, hex string, or tag.\", style=\"error\")\n",
        "                            raise ValueError(f\"Invalid block identifier: {block_id}\")\n",
        "                else: # Handle None or other types\n",
        "                     raise ValueError(f\"Invalid block identifier type: {type(block_id)}\")\n",
        "\n",
        "            log_filter = {\n",
        "                \"fromBlock\": format_block_param(from_block),\n",
        "                \"toBlock\": format_block_param(to_block),\n",
        "                \"address\": pyusd_checksum_address,\n",
        "                \"topics\": [transfer_topic] # Topic0 is the event signature\n",
        "            }\n",
        "\n",
        "            # Make the eth_getLogs request using standard web3.py method on the correct client\n",
        "            logs = w3_client.eth.get_logs(log_filter)\n",
        "\n",
        "            if not logs:\n",
        "                console.print(f\"[info]No PYUSD Transfer logs found in the specified range ({from_block} - {to_block}) on {network.capitalize()}.\", style=\"info\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            console.print(f\"[success]Found {len(logs)} PYUSD Transfer logs on {network.capitalize()}.\", style=\"success\")\n",
        "\n",
        "        # Parse the logs (common for both methods)\n",
        "        parsed_logs = []\n",
        "        timestamps = {}  # Cache for block timestamps\n",
        "\n",
        "        for log in logs:\n",
        "            # Ensure log is a dictionary-like object\n",
        "            if isinstance(log, dict):\n",
        "                # For JSON-RPC response, convert hex strings to int where needed\n",
        "                log_dict = log\n",
        "                topics = log_dict.get('topics', [])\n",
        "                data = log_dict.get('data', '')\n",
        "                block_number = int(log_dict.get('blockNumber', '0x0'), 16)\n",
        "                tx_hash = log_dict.get('transactionHash', '')\n",
        "                log_index = int(log_dict.get('logIndex', '0x0'), 16)\n",
        "            else:\n",
        "                # For web3.py response\n",
        "                if not hasattr(log, 'topics') or not hasattr(log, 'data'): continue\n",
        "                topics = log['topics']\n",
        "                data = log['data']\n",
        "                block_number = log['blockNumber']\n",
        "                tx_hash = log['transactionHash']\n",
        "                log_index = log['logIndex']\n",
        "                # Convert bytes to hex strings for consistency\n",
        "                if isinstance(topics[0], bytes):\n",
        "                    topics = [t.hex() if isinstance(t, bytes) else t for t in topics]\n",
        "                if isinstance(data, bytes):\n",
        "                    data = data.hex()\n",
        "                if isinstance(tx_hash, bytes):\n",
        "                    tx_hash = tx_hash.hex()\n",
        "\n",
        "            try:\n",
        "                # Check for standard ERC20 Transfer signature (3 topics)\n",
        "                if len(topics) == 3:\n",
        "                    # Extract addresses from topics (remove 0x if present and take last 40 chars)\n",
        "                    topic1 = topics[1].replace('0x', '') if isinstance(topics[1], str) else topics[1].hex()\n",
        "                    topic2 = topics[2].replace('0x', '') if isinstance(topics[2], str) else topics[2].hex()\n",
        "\n",
        "                    from_addr = Web3.to_checksum_address('0x' + topic1[-40:])\n",
        "                    to_addr = Web3.to_checksum_address('0x' + topic2[-40:])\n",
        "\n",
        "                    # Extract value from data\n",
        "                    data_hex = data if isinstance(data, str) else data.hex()\n",
        "                    data_hex = data_hex.replace('0x', '')\n",
        "                    value_raw = int(data_hex, 16)\n",
        "                    value_pyusd = value_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                    # Get block timestamp (cache to avoid redundant queries)\n",
        "                    if block_number not in timestamps:\n",
        "                        try:\n",
        "                            block = w3_client.eth.get_block(block_number)\n",
        "                            timestamps[block_number] = block.timestamp\n",
        "                        except Exception:\n",
        "                            timestamps[block_number] = None\n",
        "\n",
        "                    # Ensure transaction hash has 0x prefix\n",
        "                    tx_hash_hex = tx_hash if isinstance(tx_hash, str) else tx_hash.hex()\n",
        "                    if not tx_hash_hex.startswith('0x'):\n",
        "                        tx_hash_hex = '0x' + tx_hash_hex\n",
        "\n",
        "                    parsed_logs.append({\n",
        "                        \"blockNumber\": block_number,\n",
        "                        \"transactionHash\": tx_hash_hex,\n",
        "                        \"logIndex\": log_index,\n",
        "                        \"from\": from_addr,\n",
        "                        \"from_short\": shorten_address(from_addr),\n",
        "                        \"to\": to_addr,\n",
        "                        \"to_short\": shorten_address(to_addr),\n",
        "                        \"value_pyusd\": value_pyusd,\n",
        "                        \"value_raw\": value_raw,\n",
        "                        \"timestamp\": timestamps.get(block_number)\n",
        "                    })\n",
        "                else:\n",
        "                    # Log unexpected topic count for debugging\n",
        "                    tx_hash_str = tx_hash if isinstance(tx_hash, str) else tx_hash.hex()\n",
        "                    console.print(f\"[warning]Log index {log_index} tx {shorten_address(tx_hash_str)} has {len(topics)} topics (expected 3 for Transfer). Skipping.\", style=\"warning\")\n",
        "            except Exception as e:\n",
        "                # Handle parsing errors\n",
        "                tx_hash_str = tx_hash if isinstance(tx_hash, str) else tx_hash.hex()\n",
        "                console.print(f\"[warning]Could not parse log index {log_index} tx {shorten_address(tx_hash_str)}: {e}\", style=\"warning\")\n",
        "\n",
        "        return pd.DataFrame(parsed_logs)\n",
        "\n",
        "    except ValueError as ve: # Catch specific invalid block identifier error\n",
        "        console.print(f\"[error]Invalid block parameter for eth_getLogs: {ve}\", style=\"error\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error fetching logs with eth_getLogs on {network.capitalize()}: {e}\", style=\"error\")\n",
        "        # Add hints for common errors\n",
        "        if \"filter not found\" in str(e):\n",
        "            console.print(\"[info]Hint: This might happen with very large block ranges on some nodes.\", style=\"info\")\n",
        "        elif \"exceeds block range limit\" in str(e) or \"block range is too large\" in str(e):\n",
        "            console.print(\"[info]Hint: Reduce the block range (e.g., fetch logs for smaller chunks of blocks).\", style=\"info\")\n",
        "        elif \"invalid topic\" in str(e).lower():\n",
        "             console.print(f\"[error]Hint: Check if transfer_topic '{transfer_topic}' is correct.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "def analyze_pyusd_transfers(df):\n",
        "    \"\"\"Generates enhanced analytics for PYUSD transfer data\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        console.print(\"[warning]No transfer data to analyze.\", style=\"warning\")\n",
        "        return\n",
        "\n",
        "    # Basic statistics\n",
        "    stats = {\n",
        "        \"total_transfers\": len(df),\n",
        "        \"total_volume\": df['value_pyusd'].sum(),\n",
        "        \"avg_transfer\": df['value_pyusd'].mean(),\n",
        "        \"median_transfer\": df['value_pyusd'].median(),\n",
        "        \"max_transfer\": df['value_pyusd'].max(),\n",
        "        \"min_transfer\": df['value_pyusd'].min(),\n",
        "        \"unique_senders\": df['from'].nunique(),\n",
        "        \"unique_receivers\": df['to'].nunique()\n",
        "    }\n",
        "\n",
        "    # Create statistics table\n",
        "    console.print(\"\\n\\n[bold cyan3]PYUSD Transfer Metrices[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    stats_table = Table(title=\"\", header_style=\"bold cyan3\")\n",
        "    stats_table.add_column(\"Metric\")\n",
        "    stats_table.add_column(\"Value\", justify=\"right\")\n",
        "\n",
        "    decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "    stats_table.add_row(\"Total Transfers\", f\"{stats['total_transfers']:,}\")\n",
        "    stats_table.add_row(\"Total Volume\", f\"{stats['total_volume']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Average Transfer\", f\"{stats['avg_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Median Transfer\", f\"{stats['median_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Maximum Transfer\", f\"{stats['max_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Minimum Transfer\", f\"{stats['min_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Unique Senders\", f\"{stats['unique_senders']:,}\")\n",
        "    stats_table.add_row(\"Unique Receivers\", f\"{stats['unique_receivers']:,}\")\n",
        "\n",
        "    console.print(stats_table)\n",
        "\n",
        "    # Top senders analysis\n",
        "    if len(df) > 0:\n",
        "        console.print(\"\\n\\n[bold cyan3]Top PYUSD Senders[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        top_senders = df.groupby('from').agg({\n",
        "            'value_pyusd': ['sum', 'count'],\n",
        "            'from_short': 'first'\n",
        "        }).reset_index()\n",
        "\n",
        "        top_senders.columns = ['address', 'total_value', 'transactions', 'address_short']\n",
        "        top_senders = top_senders.sort_values('total_value', ascending=False).head(10)\n",
        "\n",
        "        sender_table = Table(show_header=True, header_style=\"bold cyan\")\n",
        "        sender_table.add_column(\"Sender\")\n",
        "        sender_table.add_column(\"Total Sent (PYUSD)\", justify=\"right\")\n",
        "        sender_table.add_column(\"Transactions\", justify=\"right\")\n",
        "        sender_table.add_column(\"% of Volume\", justify=\"right\")\n",
        "\n",
        "        for _, row in top_senders.iterrows():\n",
        "            pct_volume = (row['total_value'] / stats['total_volume'] * 100)\n",
        "            sender_table.add_row(\n",
        "                row['address'],\n",
        "                f\"{row['total_value']:,.{decimals}f}\",\n",
        "                f\"{row['transactions']:,}\",\n",
        "                f\"{pct_volume:.1f}%\"\n",
        "            )\n",
        "\n",
        "        console.print(sender_table)\n",
        "\n",
        "        # Top receivers analysis\n",
        "        console.print(\"\\n\\n[bold cyan3]Top PYUSD Receivers[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        top_receivers = df.groupby('to').agg({\n",
        "            'value_pyusd': ['sum', 'count'],\n",
        "            'to_short': 'first'\n",
        "        }).reset_index()\n",
        "\n",
        "        top_receivers.columns = ['address', 'total_value', 'transactions', 'address_short']\n",
        "        top_receivers = top_receivers.sort_values('total_value', ascending=False).head(10)\n",
        "\n",
        "        receiver_table = Table(show_header=True, header_style=\"bold cyan\")\n",
        "        receiver_table.add_column(\"Receiver\")\n",
        "        receiver_table.add_column(\"Total Received (PYUSD)\", justify=\"right\")\n",
        "        receiver_table.add_column(\"Transactions\", justify=\"right\")\n",
        "        receiver_table.add_column(\"% of Volume\", justify=\"right\")\n",
        "\n",
        "        for _, row in top_receivers.iterrows():\n",
        "            pct_volume = (row['total_value'] / stats['total_volume'] * 100)\n",
        "            receiver_table.add_row(\n",
        "                row['address'],\n",
        "                f\"{row['total_value']:,.{decimals}f}\",\n",
        "                f\"{row['transactions']:,}\",\n",
        "                f\"{pct_volume:.1f}%\"\n",
        "            )\n",
        "\n",
        "        console.print(receiver_table)\n",
        "\n",
        "    # Visualizations\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]PYUSD Transfer Size Distribution[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "        # 1. Transfer Size Distribution visualization\n",
        "\n",
        "        fig_dist = px.histogram(\n",
        "            df, x='value_pyusd',\n",
        "            title='PYUSD Transfer Size Distribution',\n",
        "            labels={'value_pyusd': 'Transfer Size (PYUSD)', 'count': 'Number of Transfers'},\n",
        "            nbins=50,\n",
        "            opacity=0.75,\n",
        "            color_discrete_sequence=['rgba(0, 123, 255, 0.8)']\n",
        "        )\n",
        "\n",
        "        # Configure histogram layout\n",
        "        fig_dist.update_layout(\n",
        "            template=\"plotly_white\",\n",
        "            bargap=0.1,\n",
        "            plot_bgcolor='white',\n",
        "            margin=dict(l=50, r=50, t=80, b=50),\n",
        "            title_font=dict(size=20),\n",
        "            yaxis_title=\"Number of Transfers\",\n",
        "            xaxis_title=\"Transfer Size (PYUSD)\"\n",
        "        )\n",
        "\n",
        "        # Add range slider to better handle outliers in the distribution\n",
        "        q1 = df['value_pyusd'].quantile(0.25)\n",
        "        q3 = df['value_pyusd'].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        upper_bound = q3 + (1.5 * iqr)\n",
        "\n",
        "        if df['value_pyusd'].max() > upper_bound:\n",
        "            fig_dist.update_layout(\n",
        "                xaxis=dict(\n",
        "                    rangeslider=dict(visible=True),\n",
        "                    type='linear'\n",
        "                )\n",
        "            )\n",
        "\n",
        "        fig_dist.show()\n",
        "\n",
        "        # 2. Transfer Volume Over Time visualization\n",
        "        console.print(\"\\n\\n[bold]PYUSD Transfer Volume Over Time[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        if 'timestamp' in df.columns and df['timestamp'].notna().any():\n",
        "            df_with_time = df[df['timestamp'].notna()].copy()\n",
        "            df_with_time['datetime'] = pd.to_datetime(df_with_time['timestamp'], unit='s')\n",
        "\n",
        "            # Aggregate by hour for cleaner visualization\n",
        "            df_with_time['hour'] = df_with_time['datetime'].dt.floor('H')\n",
        "            hourly_volume = df_with_time.groupby('hour')['value_pyusd'].sum().reset_index()\n",
        "\n",
        "            # Ensure data exists before creating visualization\n",
        "            if not hourly_volume.empty:\n",
        "                fig_time = px.line(\n",
        "                    hourly_volume, x='hour', y='value_pyusd',\n",
        "                    title='PYUSD Transfer Volume Over Time',\n",
        "                    labels={'hour': 'Time', 'value_pyusd': 'Volume (PYUSD)'}\n",
        "                )\n",
        "\n",
        "                # Configure time series chart layout\n",
        "                fig_time.update_layout(\n",
        "                    template=\"plotly_white\",\n",
        "                    plot_bgcolor='white',\n",
        "                    margin=dict(l=50, r=50, t=80, b=50),\n",
        "                    title_font=dict(size=20),\n",
        "                    xaxis_title=\"Time\",\n",
        "                    yaxis_title=\"Volume (PYUSD)\",\n",
        "                    hovermode=\"x unified\"\n",
        "                )\n",
        "\n",
        "                # Style the line for better visibility\n",
        "                fig_time.update_traces(\n",
        "                    line=dict(width=3, color='rgb(0, 123, 255)'),\n",
        "                    mode='lines+markers',\n",
        "                    marker=dict(size=8, color='rgb(0, 123, 255)')\n",
        "                )\n",
        "\n",
        "                fig_time.show()\n",
        "            else:\n",
        "                console.print(\"[warning]No time-based data available for visualization.\", style=\"warning\")\n",
        "\n",
        "        # 3. Network graph using Sankey diagram\n",
        "        if len(df) > 0:\n",
        "            console.print(\"\\n\\n[bold magenta3]PYUSD Transfer Flow - Top 50 Transfers[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "            # Aggregate transfers between address pairs\n",
        "            pair_transfers = df.groupby(['from', 'to'])['value_pyusd'].sum().reset_index()\n",
        "            pair_transfers = pair_transfers.sort_values('value_pyusd', ascending=False).head(50)\n",
        "\n",
        "            # Prepare data for Sankey diagram\n",
        "            labels = []\n",
        "            address_to_idx = {}\n",
        "\n",
        "            # Create a unique index for each address\n",
        "            for _, row in pair_transfers.iterrows():\n",
        "                if row['from'] not in address_to_idx:\n",
        "                    address_to_idx[row['from']] = len(labels)\n",
        "                    labels.append(shorten_address(row['from']))\n",
        "                if row['to'] not in address_to_idx:\n",
        "                    address_to_idx[row['to']] = len(labels)\n",
        "                    labels.append(shorten_address(row['to']))\n",
        "\n",
        "            # Create source, target, and value arrays for Sankey\n",
        "            sources = [address_to_idx[row['from']] for _, row in pair_transfers.iterrows()]\n",
        "            targets = [address_to_idx[row['to']] for _, row in pair_transfers.iterrows()]\n",
        "            values = pair_transfers['value_pyusd'].tolist()\n",
        "\n",
        "            # Create Sankey diagram with flow direction\n",
        "            fig_sankey = go.Figure(data=[go.Sankey(\n",
        "                node=dict(\n",
        "                    pad=15,\n",
        "                    thickness=20,\n",
        "                    line=dict(color=\"black\", width=0.5),\n",
        "                    label=labels,\n",
        "                    color=\"blue\"\n",
        "                ),\n",
        "                link=dict(\n",
        "                    source=sources,\n",
        "                    target=targets,\n",
        "                    value=values,\n",
        "                    color=\"rgba(0,100,200,0.3)\"\n",
        "                )\n",
        "            )])\n",
        "\n",
        "            # Configure Sankey layout\n",
        "            fig_sankey.update_layout(\n",
        "                title_text=\"PYUSD Transfer Flow - Top 50 Transfers\",\n",
        "                font=dict(size=12),\n",
        "                width=1000,\n",
        "                height=800\n",
        "            )\n",
        "\n",
        "            fig_sankey.show()\n",
        "\n",
        "    except Exception as viz_error:\n",
        "        console.print(f\"[warning]Visualization error: {viz_error}\", style=\"warning\")\n",
        "\n",
        "    # --- Add Export Options Section ---\n",
        "    console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create export output area\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Create export buttons with proper styling\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Define export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_transfers_{timestamp}.csv\"\n",
        "            display(download_csv_direct(df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_transfers_{timestamp}.json\"\n",
        "            # Prepare export data with basic DataFrame stats\n",
        "            export_data = {\n",
        "                \"analysis_type\": \"PYUSD Transfers\",\n",
        "                \"analysis_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"statistics\": stats,\n",
        "                \"top_senders\": top_senders.to_dict('records') if 'top_senders' in locals() else [],\n",
        "                \"top_receivers\": top_receivers.to_dict('records') if 'top_receivers' in locals() else []\n",
        "            }\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                # Prepare export data\n",
        "                export_data = {\n",
        "                    \"statistics\": stats,\n",
        "                    \"top_senders\": top_senders.to_dict('records') if 'top_senders' in locals() else [],\n",
        "                    \"top_receivers\": top_receivers.to_dict('records') if 'top_receivers' in locals() else []\n",
        "                }\n",
        "\n",
        "                display(export_to_google_sheets(df, export_data, \"Transfers\"))\n",
        "            except Exception as e:\n",
        "                html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                display(HTML(html))\n",
        "\n",
        "                # Fallback to CSV\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"pyusd_transfers_{timestamp}.csv\"\n",
        "                display(download_csv_direct(df, filename))\n",
        "                display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "    # Connect handlers to buttons\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    # Display button container and output area\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- Execute Transfer Log Analysis ---\n",
        "# Set parameters for fetching logs\n",
        "FETCH_TRANSFERS = True\n",
        "BLOCKS_TO_FETCH = 1000\n",
        "\n",
        "if FETCH_TRANSFERS:\n",
        "    if BLOCKS_TO_FETCH == 'latest':\n",
        "        # Just fetch latest block\n",
        "        transfers_df = fetch_pyusd_transfer_logs(from_block='latest', to_block='latest')\n",
        "    else:\n",
        "        # Always respect the 5-block limit for Google Blockchain API\n",
        "        try:\n",
        "            latest_block = w3_clients['mainnet'].eth.block_number\n",
        "\n",
        "            # Strictly respect the 5-block maximum range\n",
        "            start_block = latest_block - 4  # This gives exactly 5 blocks including the latest\n",
        "            console.print(\"\\n\\n[bold]üìú Fetching Logs via eth_getLogs[/bold]\", style=\"cyan3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "            console.print(f\"\\n\\n[bold chartreuse1]üì° Querying Recent PYUSD Transfers [Block {start_block:,} to {latest_block:,} (latest)] (Max 5-Block Limit)[/bold chartreuse1]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "            transfers_df = fetch_pyusd_transfer_logs(from_block=start_block, to_block=latest_block)\n",
        "        except Exception as e:\n",
        "            console.print(f\"[warning]Error fetching latest blocks: {e}. Falling back to single block query.\", style=\"warning\")\n",
        "            transfers_df = fetch_pyusd_transfer_logs(from_block='latest', to_block='latest')\n",
        "\n",
        "    if transfers_df is not None and not transfers_df.empty:\n",
        "        # Display a sample of the data\n",
        "        console.print(\"\\n\\n[bold cyan3]Transfer Data Sample (First 5 rows)[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        sample_display_cols = ['blockNumber', 'transactionHash', 'from', 'to', 'value_pyusd', 'timestamp']\n",
        "        display(transfers_df[sample_display_cols].head())\n",
        "\n",
        "        # Run analysis\n",
        "        analyze_pyusd_transfers(transfers_df)\n",
        "    else:\n",
        "        console.print(\"[warning]No PYUSD transfers found or error occurred.\", style=\"warning\")\n",
        "\n",
        "# --- Execute Log Fetching for Target Block on Mainnet ---\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_getlogs = TARGET_BLOCK_IDENTIFIER\n",
        "    console.print(f\"\\n\\n[bold chartreuse1]üì° Querying PYUSD logs for Target Block Identifier: {block_id_getlogs} on Mainnet[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    # Fetch for a single block by setting from_block and to_block to the same identifier\n",
        "    pyusd_logs_df = fetch_pyusd_transfer_logs(from_block=block_id_getlogs, to_block=block_id_getlogs, network='mainnet')\n",
        "\n",
        "    if pyusd_logs_df is not None and not pyusd_logs_df.empty:\n",
        "        console.print(\"\\n\\n[bold cyan3]üìä PYUSD Transfer Logs (Mainnet Block)[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        # Show full addresses instead of shortened ones\n",
        "        display_cols = ['blockNumber', 'from', 'to', 'value_pyusd', 'transactionHash']\n",
        "        display(pyusd_logs_df[display_cols])\n",
        "\n",
        "        # Run analysis on block data\n",
        "        analyze_pyusd_transfers(pyusd_logs_df)\n",
        "\n",
        "    elif pyusd_logs_df is not None:\n",
        "        console.print(f\"[info]No PYUSD transfers found in block {block_id_getlogs} on Mainnet.\", style=\"info\")\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping Mainnet eth_getLogs analysis.\", style=\"warning\")\n",
        "\n",
        "# --- Optional: Query for a Block Range Instead of Single Block ---\n",
        "RUN_BLOCK_RANGE_FETCH = True\n",
        "\n",
        "if RUN_BLOCK_RANGE_FETCH and 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    # Use TARGET_BLOCK_IDENTIFIER as the center of a smaller range\n",
        "    block_center = TARGET_BLOCK_IDENTIFIER if isinstance(TARGET_BLOCK_IDENTIFIER, int) else int(TARGET_BLOCK_IDENTIFIER, 16) if isinstance(TARGET_BLOCK_IDENTIFIER, str) and TARGET_BLOCK_IDENTIFIER.startswith('0x') else None\n",
        "\n",
        "    if block_center:\n",
        "        # Respect the 5-block limit for Google Blockchain API\n",
        "        # Use center block plus 2 on each side (5 blocks total)\n",
        "        range_start = block_center - 2\n",
        "        range_end = block_center + 2\n",
        "        console.print(f\"[info]Fetching PYUSD logs with 5-block range: {range_start}-{range_end}\", style=\"info\")\n",
        "\n",
        "        range_logs_df = fetch_pyusd_transfer_logs(from_block=range_start, to_block=range_end, network='mainnet')\n",
        "\n",
        "        if range_logs_df is not None and not range_logs_df.empty:\n",
        "            console.print(f\"\\n\\n[bold chartreuse1]üì° Querying PYUSD Transfer Logs (Block Range {range_start}-{range_end})[/bold chartreuse1]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "            # Show full addresses in this display too\n",
        "            display_cols = ['blockNumber', 'from', 'to', 'value_pyusd', 'transactionHash']\n",
        "            display(range_logs_df[display_cols])\n",
        "\n",
        "            # Run analysis on range data\n",
        "            analyze_pyusd_transfers(range_logs_df)\n",
        "\n",
        "        elif range_logs_df is not None:\n",
        "            console.print(f\"[info]No PYUSD transfers found in block range {range_start}-{range_end} on Mainnet.\", style=\"info\")\n",
        "    else:\n",
        "        console.print(\"[warning]Could not determine a numeric block center for range query.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "WBTX90A3XBja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 üìÑ `eth_getCode`: Fetching and Analyzing Contract Bytecode\n",
        "---\n",
        "\n",
        "This section uses the `eth_getCode` RPC method to retrieve the **runtime bytecode** associated with a specific Ethereum address at a given block state. This allows us to inspect the actual executable code deployed on the blockchain.\n",
        "\n",
        "Analyzing bytecode is essential for:\n",
        "\n",
        "*   **Verification:** Confirming whether an address belongs to a smart contract or an Externally Owned Account (EOA). EOAs have no code.\n",
        "*   **Proxy Analysis:** Comparing the minimal bytecode of a proxy contract (like `PYUSD_PROXY`) with the extensive logic bytecode of its implementation contract (`PYUSD_IMPLEMENTATION`).\n",
        "*   **Basic Functionality Identification:** Detecting potential function signatures (like standard ERC-20 functions or *potentially* PYUSD-specific ones *if included in the tool's known signature set*) present within the bytecode. *Note that this relies on matching known 4-byte selectors found via bytecode patterns and is a heuristic approach, not a full decompilation.*\n",
        "*   **Pattern Recognition:** Identifying common contract patterns (e.g., Ownable, Pausable, Proxy types) based on embedded function selectors.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Capabilities**\n",
        ">\n",
        "> *   **Method:** `eth_getCode`\n",
        "> *   **Multiplier:** `10x` (More efficient than tracing, but still higher than basic calls)\n",
        "> *   **GCP Advantage:** While a standard call, reliable access via GCP ensures consistent retrieval of bytecode for analysis, even for large contracts or during high network load.\n",
        "> *   **PYUSD Insight:** Allows us to:\n",
        ">     *   Directly compare the lean **PYUSD proxy** contract code with its feature-rich **implementation** code.\n",
        ">     *   Verify the bytecode of the **Supply Controller** contract.\n",
        ">     *   Potentially identify known PYUSD function signatures *if available in the analysis tool's predefined signature dictionary* directly from the bytecode of any interacting contract.\n",
        "\n",
        "**Analysis Workflow & Features:**\n",
        "\n",
        "This section provides an interactive bytecode analysis tool with multiple modes accessed via tabs:\n",
        "\n",
        "1.  **PYUSD Analysis Tab:**\n",
        "    *   Automatically fetches and analyzes the bytecode for the official PYUSD Proxy, Implementation, and Supply Controller contracts on Mainnet.\n",
        "    *   Performs individual analysis (`analyze_bytecode`) showing size, detected standards/patterns, and known functions.\n",
        "    *   Compares the Proxy and Implementation contracts (`compare_proxy_implementation`), highlighting differences in size and function signatures.\n",
        "    *   Visualizes the proxy architecture and contract relationships using Graphviz (*Note: Requires Graphviz installation and PATH configuration for diagrams to display*).\n",
        "2.  **From Transaction Tab:**\n",
        "    *   Takes a transaction hash as input.\n",
        "    *   Identifies all contract addresses involved (target, event emitters, created contracts) using `get_contracts_from_tx`.\n",
        "    *   Fetches and analyzes the bytecode for each identified contract.\n",
        "    *   If multiple contracts are found, performs a similarity comparison (`compare_multiple_contracts`) based on known function signatures.\n",
        "3.  **Custom Contracts Tab:**\n",
        "    *   Allows entering up to three arbitrary contract addresses.\n",
        "    *   Fetches and analyzes the bytecode for each provided address.\n",
        "    *   Performs comparisons (Proxy vs. Impl if 2 addresses, Multi-contract if 3 addresses).\n",
        "4.  **Export Options:** Available within each tab to download the analysis results (JSON) or export to Google Sheets (Colab).\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Bytecode Size:** Note the significant size difference between proxy and implementation contracts.\n",
        "*   **Detected Patterns/Standards:** See if contracts adhere to ERC standards or implement common patterns like Ownable/Pausable.\n",
        "*   **Proxy Analysis:** Understand the implementation address linked to the PYUSD proxy.\n",
        "*   **Function Signatures:** Observe which known functions are detected within the bytecode (*remembering this is based on matching predefined signatures found via bytecode heuristics and is not a complete list of all functions*).\n",
        "*   **Comparisons:** Identify shared vs. unique functions between related contracts."
      ],
      "metadata": {
        "id": "0UP-Z1dFIrES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üìÑ Advanced Contract Bytecode Analysis using eth_getCode\n",
        "# =============================================================================================\n",
        "# This cell provides comprehensive bytecode analysis for Ethereum smart contracts through multiple approaches.\n",
        "# Functionality includes:\n",
        "# - Fetching and analyzing contract bytecode with detection of ERC standards, proxy patterns, and security features\n",
        "# - Comparing proxy contracts with their implementations to visualize delegation patterns\n",
        "# - Analyzing multiple contracts from transactions to understand their relationships\n",
        "# - Comparing different stablecoins (PYUSD, USDC, USDT) or other contract types side-by-side\n",
        "# - Generating interactive visualizations of contract sizes, function distributions, and similarity metrics\n",
        "# - Creating proxy architecture diagrams and contract relationship visualizations\n",
        "# - Exporting complete analysis results to JSON or Google Sheets for further investigation\n",
        "# - Supporting mainnet, sepolia, and holesky networks with flexible contract selection options\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display, clear_output\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from web3 import Web3\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.text import Text\n",
        "from rich.theme import Theme\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",\n",
        "    \"error\": \"red3\",\n",
        "    \"warning\": \"yellow3\",\n",
        "    \"success\": \"green3\",\n",
        "    \"spring_green3\": \"spring_green3\",\n",
        "    \"dim\": \"grey50\",\n",
        "})\n",
        "\n",
        "# Ensure console is created with the theme\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# --- Globals (Ensure these are defined/initialized in a prior cell) ---\n",
        "\n",
        "# Some known signatures into a single dictionary for efficient lookup\n",
        "ALL_KNOWN_SIGNATURES = {\n",
        "    **(ERC20_SIGNATURES if 'ERC20_SIGNATURES' in globals() else {}),\n",
        "    **(ERC721_SIGNATURES if 'ERC721_SIGNATURES' in globals() else {}),\n",
        "    **(ERC1155_SIGNATURES if 'ERC1155_SIGNATURES' in globals() else {}),\n",
        "    **(PROXY_PATTERNS if 'PROXY_PATTERNS' in globals() else {}),\n",
        "    **(UUPS_PATTERNS if 'UUPS_PATTERNS' in globals() else {}),\n",
        "    **(DIAMOND_PATTERNS if 'DIAMOND_PATTERNS' in globals() else {}),\n",
        "    **(SECURITY_PATTERNS if 'SECURITY_PATTERNS' in globals() else {}),\n",
        "    **(DEFI_PATTERNS if 'DEFI_PATTERNS' in globals() else {}),\n",
        "    **(GAS_PATTERNS if 'GAS_PATTERNS' in globals() else {})\n",
        "}\n",
        "if 'PYUSD_SIGNATURES' in globals():\n",
        "    ALL_KNOWN_SIGNATURES.update(PYUSD_SIGNATURES)\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def shorten_address(address, chars=4):\n",
        "    \"\"\"Displays full blockchain address, adding line breaks if too long.\"\"\"\n",
        "    if not isinstance(address, str) or not address.startswith(\"0x\"):\n",
        "        return str(address)  # Return original if not a valid address string\n",
        "\n",
        "    # uncomment if you want to truncate addresses\n",
        "    # # If address is very long (like more than 25 chars), add a line break\n",
        "    # if len(address) > 25:\n",
        "    #     return f\"{address[:14]}\\n{address[14:]}\"\n",
        "    return address\n",
        "\n",
        "# --- Core Analysis Functions ---\n",
        "\n",
        "def get_contract_code(contract_address, block_identifier=\"latest\", network='mainnet'):\n",
        "    \"\"\"Fetches the runtime bytecode for a contract address using the configured Web3 client.\"\"\"\n",
        "    if 'w3_clients' not in globals() or network not in w3_clients:\n",
        "        print(f\"[error]Web3 client for '{network}' network not configured.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        print(f\"[error]Web3 client for '{network}' is not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        checksum_address = Web3.to_checksum_address(contract_address)\n",
        "    except ValueError:\n",
        "        console.print(f\"[error]Invalid contract address format provided: {contract_address}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"[info]Fetching bytecode for {checksum_address} at block '{block_identifier}' on {network.capitalize()}.\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        code_bytes = w3_client.eth.get_code(checksum_address, block_identifier=block_identifier)\n",
        "        hex_code = code_bytes.hex() # Includes '0x' prefix\n",
        "\n",
        "        if hex_code == \"0x\":\n",
        "            console.print(f\"[warning]No bytecode found at {checksum_address} (Block: {block_identifier}, Network: {network.capitalize()}). It might be an EOA or a destroyed contract.\", style=\"warning\")\n",
        "            return None\n",
        "        else:\n",
        "            bytecode_size = len(code_bytes)\n",
        "            console.print(f\"[success]Successfully retrieved bytecode for {checksum_address}.\", style=\"success\")\n",
        "            # Display summary using Rich Table\n",
        "            console.print(\"\\n\\n[bold]üî¨ Contract Bytecode Information[/bold]\", style=\"magenta3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "            table = Table(show_header=False, box=None, padding=(0,1), title=\"\")\n",
        "            table.add_column(\"Field\")\n",
        "            table.add_column(\"Value\")\n",
        "            table.add_row(\"[bold]Address:[/bold]\", checksum_address)\n",
        "            table.add_row(\"[bold]Network:[/bold]\", network.capitalize())\n",
        "            table.add_row(\"[bold]Block:[/bold]\", str(block_identifier))\n",
        "            table.add_row(\"[bold]Bytecode Size:[/bold]\", f\"{bytecode_size:,} bytes\")\n",
        "            table.add_row(\"[bold]Preview:[/bold]\", f\"{hex_code[:100]}...\")\n",
        "            console.print(table)\n",
        "            return hex_code\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error fetching bytecode for {checksum_address} on {network.capitalize()}: {e}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_contracts_from_tx(tx_hash, network='mainnet'):\n",
        "    \"\"\"Extracts contract addresses involved in a transaction (to, logs, creation) and verifies they have bytecode.\"\"\"\n",
        "    if 'w3_clients' not in globals() or network not in w3_clients:\n",
        "         print(f\"[error]Web3 client for '{network}' network not configured.\", style=\"error\")\n",
        "         return None\n",
        "\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        console.print(f\"[info]Fetching transaction details for {tx_hash} on {network.capitalize()}...\", style=\"info\")\n",
        "        tx = w3_client.eth.get_transaction(tx_hash)\n",
        "        if not tx:\n",
        "             console.print(f\"[error]Transaction {tx_hash} not found on {network}.\", style=\"error\")\n",
        "             return None\n",
        "        receipt = w3_client.eth.get_transaction_receipt(tx_hash)\n",
        "        if not receipt:\n",
        "             # This can happen if the transaction hasn't been mined yet\n",
        "             console.print(f\"[warning]Transaction receipt for {tx_hash} not found on {network}. Transaction might be pending.\", style=\"warning\")\n",
        "             return None\n",
        "\n",
        "        contracts = {} # {address: name}\n",
        "        processed_addresses = set() # Avoid duplicate lookups\n",
        "\n",
        "        # Helper to check address for bytecode and add to contracts dict\n",
        "        def check_and_add_contract(address, name_prefix):\n",
        "            if not address or address in processed_addresses:\n",
        "                return\n",
        "            try:\n",
        "                code = w3_client.eth.get_code(address)\n",
        "                # Check if code exists and is not empty bytecode marker\n",
        "                if code and code != b'\\x00' and code.hex() != '0x':\n",
        "                    contract_name = f\"{name_prefix} ({shorten_address(address)})\"\n",
        "                    contracts[address] = contract_name\n",
        "                processed_addresses.add(address)\n",
        "            except Exception as e:\n",
        "                console.print(f\"[warning]Could not check code for address {address}: {e}\", style=\"warning\")\n",
        "\n",
        "        # Check 'to' address\n",
        "        check_and_add_contract(tx.to, \"Target Contract\")\n",
        "\n",
        "        # Check addresses from event logs\n",
        "        for log in receipt.logs:\n",
        "            check_and_add_contract(log.address, \"Event Emitter\")\n",
        "\n",
        "        # Check contract creation address\n",
        "        check_and_add_contract(receipt.contractAddress, \"Created Contract\")\n",
        "\n",
        "        if contracts:\n",
        "            console.print(f\"[success]Found {len(contracts)} address(es) with bytecode involved in transaction {tx_hash}.\", style=\"success\")\n",
        "        else:\n",
        "            console.print(f\"[warning]Found 0 addresses with bytecode involved in transaction {tx_hash}. Transaction might not interact with contracts or contracts might be destroyed.\", style=\"warning\")\n",
        "        return contracts\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error processing transaction {tx_hash}: {str(e)}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def analyze_bytecode(bytecode, contract_name=\"Contract\"):\n",
        "    \"\"\"Analyzes contract bytecode for size, standards, known functions, and common patterns.\"\"\"\n",
        "    if not bytecode or bytecode == \"0x\":\n",
        "        console.print(f\"[warning]No bytecode provided for analysis of '{contract_name}'.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    code = bytecode[2:] if bytecode.startswith('0x') else bytecode\n",
        "    if not code:\n",
        "        console.print(f\"[warning]Empty bytecode provided for analysis of '{contract_name}'.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    results = {\n",
        "        \"contract_name\": contract_name,\n",
        "        \"address\": contract_name.split(\"(\")[-1].strip(\")\") if \"(\" in contract_name and \"...\" in contract_name else \"N/A\",\n",
        "        \"size_bytes\": len(code) // 2,\n",
        "        \"standards\": [],\n",
        "        \"erc20_functionality\": {\"compatible\": False, \"functions\": []},\n",
        "        \"erc721_functionality\": {\"compatible\": False, \"functions\": []},\n",
        "        \"erc1155_functionality\": {\"compatible\": False, \"functions\": []},\n",
        "        \"proxy_functionality\": {\"is_proxy\": False, \"proxy_type\": None, \"functions\": []},\n",
        "        \"security_functionality\": {\"has_security_controls\": False, \"functions\": []},\n",
        "        \"defi_functionality\": {\"has_defi_features\": False, \"functions\": []},\n",
        "        \"gas_optimization\": {\"optimized\": False, \"features\": []},\n",
        "        \"detected_patterns\": [],\n",
        "        \"all_detected_functions\": [], # Stores tuples (signature, name, category) for known functions\n",
        "        \"bytecode_metrics\": {\n",
        "            \"size\": len(code) // 2,\n",
        "            \"complexity_estimate\": max(1, len(code) // 200), # Avoid 0, estimate based on size\n",
        "            \"method_count_estimate\": 0, # Based on known methods found\n",
        "            \"has_loops_or_recursion\": \"Unknown\" # Requires deeper analysis\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Find potential 4-byte signatures using PUSH4 opcode heuristic\n",
        "    potential_sigs_hex = set(re.findall(r'63([0-9a-f]{8})', code))\n",
        "    potential_sigs = set(f\"0x{s}\" for s in potential_sigs_hex) # Add '0x' prefix\n",
        "\n",
        "    found_known_sigs = set() # Track signatures already categorized\n",
        "\n",
        "    # Check against known signature categories\n",
        "    categories_config = {\n",
        "        \"ERC20\": {\"signatures\": ERC20_SIGNATURES if 'ERC20_SIGNATURES' in globals() else {}, \"threshold\": 5, \"result_key\": \"erc20_functionality\"},\n",
        "        \"ERC721\": {\"signatures\": ERC721_SIGNATURES if 'ERC721_SIGNATURES' in globals() else {}, \"threshold\": 4, \"result_key\": \"erc721_functionality\"},\n",
        "        \"ERC1155\": {\"signatures\": ERC1155_SIGNATURES if 'ERC1155_SIGNATURES' in globals() else {}, \"threshold\": 4, \"result_key\": \"erc1155_functionality\"},\n",
        "        \"Proxy\": {\"signatures\": {**(PROXY_PATTERNS if 'PROXY_PATTERNS' in globals() else {}), **(UUPS_PATTERNS if 'UUPS_PATTERNS' in globals() else {}), **(DIAMOND_PATTERNS if 'DIAMOND_PATTERNS' in globals() else {})}, \"threshold\": 1, \"result_key\": \"proxy_functionality\"},\n",
        "        \"Security\": {\"signatures\": SECURITY_PATTERNS if 'SECURITY_PATTERNS' in globals() else {}, \"threshold\": 1, \"result_key\": \"security_functionality\"},\n",
        "        \"DeFi\": {\"signatures\": DEFI_PATTERNS if 'DEFI_PATTERNS' in globals() else {}, \"threshold\": 1, \"result_key\": \"defi_functionality\"},\n",
        "        \"Gas Opt\": {\"signatures\": GAS_PATTERNS if 'GAS_PATTERNS' in globals() else {}, \"threshold\": 1, \"result_key\": \"gas_optimization\"}\n",
        "    }\n",
        "\n",
        "    for category_name, config in categories_config.items():\n",
        "        count = 0\n",
        "        signatures_dict = config[\"signatures\"]\n",
        "        result_key = config[\"result_key\"]\n",
        "        functions_list = []\n",
        "\n",
        "        for signature, func_name in signatures_dict.items():\n",
        "            if signature in potential_sigs:\n",
        "                count += 1\n",
        "                functions_list.append(func_name)\n",
        "                # Add to the overall list if not already seen\n",
        "                if signature not in found_known_sigs:\n",
        "                    results[\"all_detected_functions\"].append((signature, func_name, category_name))\n",
        "                    found_known_sigs.add(signature)\n",
        "\n",
        "        # Store identified functions for this category\n",
        "        if \"functions\" in results[result_key]:\n",
        "            results[result_key][\"functions\"] = sorted(list(set(functions_list))) # Unique sorted list\n",
        "\n",
        "        # Determine compatibility/presence based on threshold\n",
        "        if count >= config[\"threshold\"]:\n",
        "            if \"compatible\" in results[result_key]: results[result_key][\"compatible\"] = True\n",
        "            elif \"is_proxy\" in results[result_key]: results[result_key][\"is_proxy\"] = True\n",
        "            elif \"has_security_controls\" in results[result_key]: results[result_key][\"has_security_controls\"] = True\n",
        "            elif \"has_defi_features\" in results[result_key]: results[result_key][\"has_defi_features\"] = True\n",
        "            elif \"optimized\" in results[result_key]: results[result_key][\"optimized\"] = True\n",
        "\n",
        "    # Update total known method count estimate\n",
        "    results[\"all_detected_functions\"].sort(key=lambda x: (x[2], x[1])) # Sort by category, then name\n",
        "    results[\"bytecode_metrics\"][\"method_count_estimate\"] = len(results[\"all_detected_functions\"])\n",
        "\n",
        "    # Identify standards\n",
        "    if results[\"erc20_functionality\"][\"compatible\"]: results[\"standards\"].append(\"ERC20\")\n",
        "    if results[\"erc721_functionality\"][\"compatible\"]: results[\"standards\"].append(\"ERC721\")\n",
        "    if results[\"erc1155_functionality\"][\"compatible\"]: results[\"standards\"].append(\"ERC1155\")\n",
        "\n",
        "    # Refine proxy type identification\n",
        "    if results[\"proxy_functionality\"][\"is_proxy\"]:\n",
        "        proxy_funcs_found = {f[0] for f in results[\"all_detected_functions\"] if f[2] == 'Proxy'}\n",
        "        # Check based on signature sets defined globally\n",
        "        is_eip1967 = any(s in proxy_funcs_found for s in (PROXY_PATTERNS if 'PROXY_PATTERNS' in globals() else {}))\n",
        "        is_uups = any(s in proxy_funcs_found for s in (UUPS_PATTERNS if 'UUPS_PATTERNS' in globals() else {}))\n",
        "        is_diamond = any(s in proxy_funcs_found for s in (DIAMOND_PATTERNS if 'DIAMOND_PATTERNS' in globals() else {}))\n",
        "\n",
        "        proxy_type = \"Basic/Unknown Proxy\" # Default\n",
        "        pattern_desc = \"Proxy Pattern: Basic/Unknown\"\n",
        "        if is_diamond:\n",
        "            proxy_type = \"Diamond Proxy (EIP-2535)\"\n",
        "            pattern_desc = \"Proxy Pattern: Diamond\"\n",
        "        elif is_uups: # UUPS often uses EIP-1967 storage, so check first\n",
        "            proxy_type = \"UUPS Proxy (EIP-1822 / EIP-1967)\"\n",
        "            pattern_desc = \"Proxy Pattern: UUPS\"\n",
        "        elif is_eip1967:\n",
        "            proxy_type = \"Transparent Proxy (EIP-1967)\"\n",
        "            pattern_desc = \"Proxy Pattern: Transparent\"\n",
        "\n",
        "        results[\"proxy_functionality\"][\"proxy_type\"] = proxy_type\n",
        "        results[\"detected_patterns\"].append(pattern_desc)\n",
        "\n",
        "    # Check for common library patterns based on security functions found\n",
        "    sec_funcs = set(results[\"security_functionality\"][\"functions\"])\n",
        "    if \"pause()\" in sec_funcs and \"unpause()\" in sec_funcs: results[\"detected_patterns\"].append(\"Pattern: Pausable\")\n",
        "    if \"owner()\" in sec_funcs and \"transferOwnership(address)\" in sec_funcs: results[\"detected_patterns\"].append(\"Pattern: Ownable\")\n",
        "\n",
        "    # Check for other bytecode string patterns\n",
        "    # Note: Simple string checks are prone to false positives but can be indicative\n",
        "    if re.search(r'e3010170.{68}0033', code): results[\"detected_patterns\"].append(\"Metadata: IPFS Hash (CBOR)\")\n",
        "    if \"create2\" in code: results[\"detected_patterns\"].append(\"Opcode Hint: CREATE2\")\n",
        "    if \"selfdestruct\" in code: results[\"detected_patterns\"].append(\"Opcode Hint: SELFDESTRUCT\")\n",
        "\n",
        "    # --- Output Results ---\n",
        "    console.print(f\"\\n\\n[bold yellow3]üìä Bytecode Analysis Results: {contract_name}[/bold yellow3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "    # Summary Table using Rich\n",
        "    analysis_table = Table(show_header=False, box=None, padding=(0,1))\n",
        "    analysis_table.add_column(\"Property\")\n",
        "    analysis_table.add_column(\"Value\")\n",
        "    analysis_table.add_row(\"Size:\", f\"{results['size_bytes']:,} bytes\")\n",
        "    if results[\"standards\"]: analysis_table.add_row(\"Standards:\", \", \".join(results[\"standards\"]))\n",
        "    if results[\"proxy_functionality\"][\"is_proxy\"]:\n",
        "        analysis_table.add_row(\"Proxy Contract:\", \"‚úÖ Yes\")\n",
        "        if results[\"proxy_functionality\"][\"proxy_type\"]: analysis_table.add_row(\"Proxy Type:\", results[\"proxy_functionality\"][\"proxy_type\"])\n",
        "    if results[\"security_functionality\"][\"has_security_controls\"]: analysis_table.add_row(\"Security Controls:\", \"‚úÖ Yes\")\n",
        "    if results[\"defi_functionality\"][\"has_defi_features\"]: analysis_table.add_row(\"DeFi Features:\", \"‚úÖ Yes\")\n",
        "    if results[\"detected_patterns\"]: analysis_table.add_row(\"Other Patterns/Hints:\", Text(\", \".join(results[\"detected_patterns\"]), overflow=\"fold\"))\n",
        "    complexity_val = results[\"bytecode_metrics\"][\"complexity_estimate\"]\n",
        "    complexity_label = \"Low\" if complexity_val < 10 else \"Medium\" if complexity_val < 50 else \"High\"\n",
        "    analysis_table.add_row(\"[bold]Complexity Estimate:[/bold]\", complexity_label)\n",
        "    analysis_table.add_row(\"[bold]Known Methods Found:[/bold]\", str(results[\"bytecode_metrics\"][\"method_count_estimate\"]))\n",
        "    console.print(analysis_table)\n",
        "\n",
        "    # Overview DataFrame using Pandas\n",
        "    result_df_data = [\n",
        "        {\"Property\": \"Size\", \"Value\": f\"{results['size_bytes']:,} bytes\"},\n",
        "        {\"Property\": \"Standards\", \"Value\": \", \".join(results[\"standards\"]) if results[\"standards\"] else \"None detected\"},\n",
        "        {\"Property\": \"Is Proxy\", \"Value\": \"Yes\" if results[\"proxy_functionality\"][\"is_proxy\"] else \"No\"},\n",
        "        {\"Property\": \"Proxy Type\", \"Value\": results[\"proxy_functionality\"][\"proxy_type\"] if results[\"proxy_functionality\"][\"is_proxy\"] else \"N/A\"},\n",
        "        {\"Property\": \"Security Controls\", \"Value\": \"Yes\" if results[\"security_functionality\"][\"has_security_controls\"] else \"No\"},\n",
        "        {\"Property\": \"Complexity\", \"Value\": complexity_label},\n",
        "        {\"Property\": \"Known Method Count\", \"Value\": results[\"bytecode_metrics\"][\"method_count_estimate\"]}\n",
        "    ]\n",
        "    result_df = pd.DataFrame(result_df_data)\n",
        "    display(HTML(\"<h4>Contract Overview</h4>\"))\n",
        "    display(result_df)\n",
        "\n",
        "    # Detected Known Functions DataFrame using Pandas\n",
        "    if results[\"all_detected_functions\"]:\n",
        "        func_df_data = [{\"Category\": cat, \"Signature\": sig, \"Function Name\": name}\n",
        "                        for sig, name, cat in results[\"all_detected_functions\"]]\n",
        "        func_df = pd.DataFrame(func_df_data)\n",
        "        display(HTML(f\"<h4>Detected Known Functions ({len(func_df)} entries)</h4>\"))\n",
        "        with pd.option_context('display.max_rows', 100): # Limit display length in notebook\n",
        "             display(func_df)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def compare_proxy_implementation(proxy_code, impl_code, proxy_name=\"Proxy\", impl_name=\"Implementation\"):\n",
        "    \"\"\"Compares proxy and implementation contracts focusing on size and known function signatures.\"\"\"\n",
        "    if not proxy_code or proxy_code == '0x' or not impl_code or impl_code == '0x':\n",
        "        console.print(\"[warning]Missing or empty bytecode provided for proxy-implementation comparison.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    proxy_size = len(proxy_code[2:]) // 2 if proxy_code.startswith('0x') else len(proxy_code) // 2\n",
        "    impl_size = len(impl_code[2:]) // 2 if impl_code.startswith('0x') else len(impl_code) // 2\n",
        "\n",
        "    console.print(\"\\n\\n[bold]üîÑ Proxy vs. Implementation Comparison:[/bold]\", style=\"chartreuse1\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "    console.print(f\"\\n\\n{proxy_name} & {impl_name}\", style=\"chartreuse1\")\n",
        "\n",
        "    # --- Size Comparison ---\n",
        "    display(HTML(\"<h4>Size Comparison</h4>\"))\n",
        "    sizes_df = pd.DataFrame({\n",
        "        'Contract': [proxy_name, impl_name],\n",
        "        'Size (bytes)': [proxy_size, impl_size],\n",
        "        'Notes': [\"Delegates calls, minimal logic\", \"Contains main business logic\"]\n",
        "    })\n",
        "    display(sizes_df)\n",
        "\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Contract Size Comparison (Bytes)[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create size comparison chart using matplotlib\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        bars = plt.bar(sizes_df['Contract'], sizes_df['Size (bytes)'], color=['skyblue', 'lightcoral'])\n",
        "\n",
        "        # Add data labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                    f'{int(height):,}', ha='center', va='bottom')\n",
        "\n",
        "        plt.title('Contract Size Comparison (Bytes)')\n",
        "        plt.ylabel('Size (bytes)')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        display(plt.gcf())\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not generate size comparison chart: {e}\", style=\"warning\")\n",
        "\n",
        "    comparison_results = {\n",
        "        \"proxy_name\": proxy_name, \"implementation_name\": impl_name,\n",
        "        \"proxy_size\": proxy_size, \"implementation_size\": impl_size,\n",
        "        \"size_ratio\": impl_size / proxy_size if proxy_size > 0 else float('inf')\n",
        "    }\n",
        "\n",
        "    # Add spacing between visualizations\n",
        "    display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "    # --- Function Signature Analysis (Known Signatures Only) ---\n",
        "    console.print(\"\\n[bold]Function Signature Analysis (Known Signatures)[/bold]\", style=\"magenta3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "    # Helper to extract known signatures from bytecode\n",
        "    def get_known_signatures(bytecode):\n",
        "        code_str = bytecode[2:] if bytecode.startswith('0x') else bytecode\n",
        "        sigs_hex = set(re.findall(r'63([0-9a-f]{8})', code_str)) # PUSH4 heuristic\n",
        "        return set(f\"0x{s}\" for s in sigs_hex if f\"0x{s}\" in ALL_KNOWN_SIGNATURES)\n",
        "\n",
        "    proxy_known_sigs = get_known_signatures(proxy_code)\n",
        "    impl_known_sigs = get_known_signatures(impl_code)\n",
        "\n",
        "    shared_sigs = proxy_known_sigs.intersection(impl_known_sigs)\n",
        "    proxy_unique = proxy_known_sigs - shared_sigs\n",
        "    impl_unique = impl_known_sigs - shared_sigs\n",
        "\n",
        "    console.print(f\"Analysis based on signatures found in the known dictionary:\")\n",
        "    console.print(f\"[bold]Shared Known Signatures:[/bold] {len(shared_sigs)}\")\n",
        "    console.print(f\"[bold]Proxy-Only Known Signatures:[/bold] {len(proxy_unique)}\")\n",
        "    console.print(f\"[bold]Implementation-Only Known Signatures:[/bold] {len(impl_unique)}\")\n",
        "\n",
        "        # --- Generate Function Distribution Chart (Excluding 0% Categories) ---\n",
        "    try:\n",
        "        # Define original categories, their corresponding values, and consistent colors\n",
        "        all_categories = ['Shared Known', 'Proxy Only Known', 'Implementation Only Known']\n",
        "        all_values = [len(shared_sigs), len(proxy_unique), len(impl_unique)]\n",
        "        # Use a map to ensure colors stay consistent with categories after filtering\n",
        "        color_map = {\n",
        "            'Shared Known': 'mediumseagreen',\n",
        "            'Proxy Only Known': 'skyblue',\n",
        "            'Implementation Only Known': 'salmon'\n",
        "        }\n",
        "\n",
        "        # Filter out categories with zero signatures to avoid cluttering the chart\n",
        "        filtered_categories = []\n",
        "        filtered_values = []\n",
        "        filtered_colors = []\n",
        "        for category, value in zip(all_categories, all_values):\n",
        "            if value > 0:\n",
        "                filtered_categories.append(category)\n",
        "                filtered_values.append(value)\n",
        "                filtered_colors.append(color_map[category])\n",
        "\n",
        "        # Proceed only if there are non-zero categories to display\n",
        "        if filtered_values:\n",
        "            try:\n",
        "                # Display header for the chart section\n",
        "                console.print(\"\\n\\n[bold]Distribution of Known Function Signatures (Non-Zero)[/bold]\", style=\"magenta3\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                # Create the pie chart using the filtered data\n",
        "                plt.figure(figsize=(8, 4)) # Use smaller dimensions to reduce rendering size\n",
        "                plt.pie(\n",
        "                    filtered_values,\n",
        "                    labels=filtered_categories,\n",
        "                    autopct='%1.1f%%',\n",
        "                    colors=filtered_colors,\n",
        "                    startangle=90,\n",
        "                    pctdistance=0.85, # Place percentage labels slightly inside slices (helps with overlap)\n",
        "                )\n",
        "                plt.axis('equal') # Ensure the pie chart is drawn as a circle\n",
        "\n",
        "                # Add a legend showing counts for each displayed category\n",
        "                plt.legend(\n",
        "                    [f\"{cat} ({val})\" for cat, val in zip(filtered_categories, filtered_values)],\n",
        "                    loc=\"best\" # Position legend automatically\n",
        "                )\n",
        "\n",
        "                plt.tight_layout() # Adjust plot to prevent labels from clipping\n",
        "                display(plt.gcf()) # Display the plot in the notebook\n",
        "                plt.close() # Close the plot object to release memory\n",
        "\n",
        "                # --- Display Filtered Data in a Table ---\n",
        "                # Calculate percentages based on the filtered data sum\n",
        "                func_dist_df_data = []\n",
        "                total_sum = sum(filtered_values)\n",
        "                for cat, val in zip(filtered_categories, filtered_values):\n",
        "                     func_dist_df_data.append({\n",
        "                         'Category': cat,\n",
        "                         'Count': val,\n",
        "                         'Percentage': f\"{val/total_sum*100:.1f}%\" if total_sum > 0 else \"0.0%\"\n",
        "                     })\n",
        "                func_dist_df = pd.DataFrame(func_dist_df_data)\n",
        "\n",
        "                # Display the DataFrame with a clear title\n",
        "                display(HTML(\"<h5>Known Signature Distribution (Non-Zero)</h5>\"))\n",
        "                display(func_dist_df)\n",
        "\n",
        "            except Exception as e:\n",
        "                console.print(f\"[error]Error creating pie chart: {e}\", style=\"error\")\n",
        "                # Fallback: Display the DataFrame even if the chart fails, if data exists\n",
        "                if 'func_dist_df' in locals() and not func_dist_df.empty:\n",
        "                    display(HTML(\"<h5>Known Signature Distribution (Chart Generation Failed)</h5>\"))\n",
        "                    display(func_dist_df)\n",
        "\n",
        "        else:\n",
        "            # If all categories filtered out, display a notification message\n",
        "             display(HTML(\"\"\"\n",
        "            <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "                <strong>Note:</strong> No known function signatures were found in either contract for comparison.\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any unexpected errors during the analysis process\n",
        "        console.print(f\"[error]Error in signature distribution analysis: {e}\", style=\"error\")\n",
        "\n",
        "    # Add spacing between visualizations\n",
        "    display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "    # Prepare DataFrame with identified functions for display\n",
        "    try:\n",
        "        # Convert signatures to function names for better readability\n",
        "        shared_funcs = [ALL_KNOWN_SIGNATURES.get(sig, sig) for sig in shared_sigs]\n",
        "        proxy_funcs = [ALL_KNOWN_SIGNATURES.get(sig, sig) for sig in proxy_unique]\n",
        "        impl_funcs = [ALL_KNOWN_SIGNATURES.get(sig, sig) for sig in impl_unique]\n",
        "\n",
        "        # Create DataFrames for each category\n",
        "        shared_df = pd.DataFrame({'Signature': list(shared_sigs), 'Function': shared_funcs, 'Category': 'Shared'}) if shared_sigs else None\n",
        "        proxy_only_df = pd.DataFrame({'Signature': list(proxy_unique), 'Function': proxy_funcs, 'Category': 'Proxy Only'}) if proxy_unique else None\n",
        "        impl_only_df = pd.DataFrame({'Signature': list(impl_unique), 'Function': impl_funcs, 'Category': 'Implementation Only'}) if impl_unique else None\n",
        "\n",
        "        # Display each DataFrame if it exists\n",
        "        if shared_df is not None and not shared_df.empty:\n",
        "            display(HTML(\"<h5>Shared Known Functions</h5>\"))\n",
        "            display(shared_df)\n",
        "        if proxy_only_df is not None and not proxy_only_df.empty:\n",
        "            display(HTML(\"<h5>Proxy-Only Known Functions</h5>\"))\n",
        "            display(proxy_only_df)\n",
        "        if impl_only_df is not None and not impl_only_df.empty:\n",
        "            display(HTML(\"<h5>Implementation-Only Known Functions</h5>\"))\n",
        "            display(impl_only_df)\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error displaying function details: {e}\", style=\"error\")\n",
        "\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "    <strong>Note on Function Identification:</strong> This analysis focuses on function signatures present in our predefined dictionaries (ERC20, Proxy, Security, etc.), identified using bytecode patterns. Bytecode contains many 4-byte sequences; those not matching known signatures or patterns are not listed here. Full identification requires comprehensive databases (e.g., <a href=\"https://www.4byte.directory/\" target=\"_blank\">4byte.directory</a>) or decompilation tools.\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    # Add signature data to comparison results (as list of dicts for easier JSON export)\n",
        "    comparison_results[\"shared_functions\"] = shared_df.to_dict('records') if shared_df is not None else []\n",
        "    comparison_results[\"proxy_only_functions\"] = proxy_only_df.to_dict('records') if proxy_only_df is not None else []\n",
        "    comparison_results[\"implementation_only_functions\"] = impl_only_df.to_dict('records') if impl_only_df is not None else []\n",
        "\n",
        "    return comparison_results\n",
        "\n",
        "\n",
        "def compare_multiple_contracts(contract_codes, contract_names):\n",
        "    \"\"\"Compares multiple contracts based on size and similarity of known function signatures.\"\"\"\n",
        "    if len(contract_codes) < 2:\n",
        "        console.print(\"[warning]Need at least two contracts with valid bytecode for comparison.\", style=\"warning\")\n",
        "        return None\n",
        "    if len(contract_codes) != len(contract_names):\n",
        "        console.print(\"[error]Internal error: Number of contract codes and names provided for comparison do not match.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]üìä Multi-Contract Comparison ({len(contract_names)} Contracts)[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # --- Size Comparison ---\n",
        "    display(HTML(\"<h4>Size Comparison</h4>\"))\n",
        "    sizes = [len(code[2:]) // 2 if code.startswith('0x') else len(code) // 2 for code in contract_codes]\n",
        "    sizes_df = pd.DataFrame({'Contract': contract_names, 'Size (bytes)': sizes})\n",
        "    display(sizes_df.sort_values('Size (bytes)', ascending=False))\n",
        "\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Contract Size Comparison (Bytes)[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create size comparison chart using matplotlib\n",
        "        plt.figure(figsize=(12, max(6, 0.5 * len(contract_names))))\n",
        "\n",
        "        # Sort data for better visualization\n",
        "        sorted_sizes_df = sizes_df.sort_values('Size (bytes)', ascending=True)\n",
        "\n",
        "        # Create horizontal bar chart for better fit with many contracts\n",
        "        bars = plt.barh(sorted_sizes_df['Contract'], sorted_sizes_df['Size (bytes)'],\n",
        "                      color=plt.cm.Paired(np.linspace(0, 1, len(sorted_sizes_df))))\n",
        "\n",
        "        # Add text labels next to bars\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(width + 0.1, bar.get_y() + bar.get_height()/2, f\"{int(width):,}\",\n",
        "                    ha='left', va='center')\n",
        "\n",
        "        plt.title('Contract Size Comparison (Bytes)')\n",
        "        plt.xlabel('Size (bytes)')\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        display(plt.gcf())\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not generate multi-contract size chart: {e}\", style=\"warning\")\n",
        "\n",
        "    # Add spacing between visualizations\n",
        "    display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "    # --- Function Signature Similarity (Known Signatures Only) ---\n",
        "    display(HTML(\"<h4>Function Signature Similarity (Based on Known Signatures)</h4>\"))\n",
        "    console.print(\"[dim]Comparing contracts based on the Jaccard similarity of their known function signatures.\", style=\"dim\")\n",
        "\n",
        "    # Helper to extract known signatures\n",
        "    def get_known_signatures(bytecode):\n",
        "        code_str = bytecode[2:] if bytecode.startswith('0x') else bytecode\n",
        "        sigs_hex = set(re.findall(r'63([0-9a-f]{8})', code_str))\n",
        "        return set(f\"0x{s}\" for s in sigs_hex if f\"0x{s}\" in ALL_KNOWN_SIGNATURES)\n",
        "\n",
        "    all_signatures_known = {name: get_known_signatures(code) for name, code in zip(contract_names, contract_codes)}\n",
        "\n",
        "    similarity_data = []\n",
        "    for i in range(len(contract_names)):\n",
        "        for j in range(i + 1, len(contract_names)):\n",
        "            name_i, name_j = contract_names[i], contract_names[j]\n",
        "            sigs_i, sigs_j = all_signatures_known[name_i], all_signatures_known[name_j]\n",
        "\n",
        "            intersection_size = len(sigs_i.intersection(sigs_j))\n",
        "            union_size = len(sigs_i.union(sigs_j))\n",
        "            similarity = (intersection_size / union_size * 100) if union_size > 0 else 0\n",
        "\n",
        "            similarity_data.append({\n",
        "                'Contract Pair': f\"{name_i} & {name_j}\",\n",
        "                'Shared Known Signatures': intersection_size,\n",
        "                'Total Unique Known Signatures': union_size,\n",
        "                'Similarity (%)': similarity\n",
        "            })\n",
        "\n",
        "    if not similarity_data:\n",
        "        console.print(\"[info]No contract pairs to compare or no known signatures found in multiple contracts.\", style=\"info\")\n",
        "        # Return basic info even if comparison fails\n",
        "        return {\"contract_names\": contract_names, \"sizes\": dict(zip(contract_names, sizes)), \"similarity_data\": []}\n",
        "\n",
        "    similarity_df = pd.DataFrame(similarity_data).sort_values('Similarity (%)', ascending=False)\n",
        "    similarity_df['Similarity (%)'] = similarity_df['Similarity (%)'].round(2)\n",
        "\n",
        "    display(HTML(\"<h5>Pairwise Similarity (Jaccard Index of Known Signatures)</h5>\"))\n",
        "    display(similarity_df)\n",
        "\n",
        "    # Similarity Bar Chart\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Contract Similarity (% Shared Known Signatures)[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "        console.print(\"[italic]Enlarge small visualization previews by clicking.[/italic]\", style=\"cyan\")\n",
        "\n",
        "        # Create similarity bar chart using matplotlib\n",
        "        plt.figure(figsize=(10, max(6, 0.6 * len(similarity_df))))\n",
        "\n",
        "        # Sort data by similarity for better visualization\n",
        "        sorted_df = similarity_df.sort_values('Similarity (%)')\n",
        "\n",
        "        # Create horizontal bar chart with color gradient\n",
        "        cmap = plt.cm.viridis\n",
        "        norm = plt.Normalize(min(sorted_df['Similarity (%)']), max(sorted_df['Similarity (%)']))\n",
        "        colors = cmap(norm(sorted_df['Similarity (%)']))\n",
        "\n",
        "        bars = plt.barh(sorted_df['Contract Pair'], sorted_df['Similarity (%)'], color=colors)\n",
        "\n",
        "        # Add percentage labels\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(width + 1, bar.get_y() + bar.get_height()/2, f\"{width:.1f}%\",\n",
        "                    ha='left', va='center')\n",
        "\n",
        "        plt.title('Contract Similarity (% Shared Known Signatures)')\n",
        "        plt.xlabel('Similarity (%)')\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        display(plt.gcf())\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Could not generate similarity chart: {str(e)}\", style=\"error\")\n",
        "        # Try to display the data in a simpler format as fallback\n",
        "        display(HTML(f\"<h5>Contract Similarity Data (Chart Generation Failed)</h5>\"))\n",
        "        display(similarity_df)\n",
        "\n",
        "    # Use light-theme friendly version for the note\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "    <strong>Note:</strong> Similarity calculation uses only function signatures found in the predefined dictionaries. Higher similarity indicates more shared known functionality.\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    return {\n",
        "        \"contract_names\": contract_names,\n",
        "        \"sizes\": dict(zip(contract_names, sizes)),\n",
        "        \"signature_count_known\": {name: len(sigs) for name, sigs in all_signatures_known.items()},\n",
        "        \"similarity_data\": similarity_df.to_dict('records')\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Export Functions ---\n",
        "\n",
        "def export_to_google_sheets(analysis_results, comparison_results=None, multi_contract_comparison=None):\n",
        "    \"\"\"Exports the analysis data to a new Google Sheet.\"\"\"\n",
        "    if 'gc_sheets' not in globals() or gc_sheets is None:\n",
        "         console.print(\"[error]Google Sheets client (gc_sheets) is not initialized. Cannot export.\", style=\"error\")\n",
        "         return HTML(\"<div style='color:red'>Error: Google Sheets client not initialized.</div>\")\n",
        "\n",
        "    try:\n",
        "        console.print(\"[cyan3]Exporting analysis results to Google Sheets...\", style=\"info\")\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"Smart Contract Bytecode Analysis {timestamp}\"\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Bytecode Analysis Report\")\n",
        "\n",
        "        # --- Populate Sheet (Adapt based on required detail level) ---\n",
        "        current_row = 1\n",
        "        header_values = [\n",
        "            [f\"Smart Contract Bytecode Analysis Report\"],\n",
        "            [f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"], [\"\"]\n",
        "        ]\n",
        "        worksheet.update(f\"A{current_row}\", header_values)\n",
        "        worksheet.format(f\"A1:A1\", {\"textFormat\": {\"bold\": True, \"fontSize\": 14}})\n",
        "        current_row += len(header_values)\n",
        "\n",
        "        # Individual Contract Analysis Sections\n",
        "        for contract_name, results in analysis_results.items():\n",
        "            worksheet.update(f\"A{current_row}\", [[f\"Analysis: {contract_name}\"]])\n",
        "            worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True, \"fontSize\": 12}, \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}})\n",
        "            current_row += 1\n",
        "\n",
        "            info_table = [[\"Property\", \"Value\"]]\n",
        "            info_table.append([\"Size\", f\"{results.get('size_bytes', 0):,} bytes\"])\n",
        "            if results.get(\"standards\"): info_table.append([\"Standards\", \", \".join(results[\"standards\"])])\n",
        "            if results.get(\"proxy_functionality\", {}).get(\"is_proxy\"):\n",
        "                info_table.append([\"Is Proxy\", \"Yes\"])\n",
        "                info_table.append([\"Proxy Type\", results[\"proxy_functionality\"].get(\"proxy_type\", \"N/A\")])\n",
        "            # Add more fields as needed...\n",
        "            worksheet.update(f\"A{current_row}\", info_table)\n",
        "            worksheet.format(f\"A{current_row}:B{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "            current_row += len(info_table) + 1 # Add spacing\n",
        "\n",
        "            # Detected Functions Table\n",
        "            if results.get(\"all_detected_functions\"):\n",
        "                 func_table = [[\"Category\", \"Signature\", \"Function Name\"]]\n",
        "                 for sig, name, cat in results[\"all_detected_functions\"][:30]: # Limit rows in export\n",
        "                     func_table.append([cat, sig, name])\n",
        "                 if len(results[\"all_detected_functions\"]) > 30:\n",
        "                      func_table.append([\"...\", \"...\", f\"(and {len(results['all_detected_functions']) - 30} more)\"])\n",
        "\n",
        "                 worksheet.update(f\"A{current_row}\", [[\"Detected Known Functions\"]])\n",
        "                 worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "                 current_row +=1\n",
        "                 worksheet.update(f\"A{current_row}\", func_table)\n",
        "                 worksheet.format(f\"A{current_row}:C{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "                 current_row += len(func_table) + 1\n",
        "\n",
        "\n",
        "        # Proxy-Implementation Comparison Section\n",
        "        if comparison_results:\n",
        "             worksheet.update(f\"A{current_row}\", [[\"Proxy vs. Implementation Comparison\"]])\n",
        "             worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True, \"fontSize\": 12}, \"backgroundColor\": {\"red\": 0.9, \"green\": 1.0, \"blue\": 0.9}})\n",
        "             current_row += 1\n",
        "             comp_table = [[\"Contract\", \"Size (bytes)\"],\n",
        "                           [comparison_results.get(\"proxy_name\", \"Proxy\"), f\"{comparison_results.get('proxy_size', 0):,}\"],\n",
        "                           [comparison_results.get(\"implementation_name\", \"Impl\"), f\"{comparison_results.get('implementation_size', 0):,}\"]]\n",
        "             worksheet.update(f\"A{current_row}\", comp_table)\n",
        "             worksheet.format(f\"A{current_row}:B{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "             current_row += len(comp_table) + 1\n",
        "             # Add function comparison tables if needed...\n",
        "\n",
        "        # Multi-Contract Comparison Section\n",
        "        if multi_contract_comparison:\n",
        "             worksheet.update(f\"A{current_row}\", [[\"Multi-Contract Comparison\"]])\n",
        "             worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True, \"fontSize\": 12}, \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.9}})\n",
        "             current_row += 1\n",
        "             # Add size table...\n",
        "             # Add similarity table...\n",
        "             sim_table = [[\"Contract Pair\", \"Similarity (%)\", \"Shared Known Sigs\"]]\n",
        "             for item in multi_contract_comparison.get(\"similarity_data\", [])[:30]: # Limit rows\n",
        "                 sim_table.append([item.get(\"Contract Pair\"), f\"{item.get('Similarity (%)', 0):.1f}%\", item.get(\"Shared Known Signatures\")])\n",
        "             if len(multi_contract_comparison.get(\"similarity_data\", [])) > 30:\n",
        "                 sim_table.append([\"...\", \"...\", \"...\"])\n",
        "\n",
        "             worksheet.update(f\"A{current_row}\", [[\"Similarity (Known Signatures)\"]])\n",
        "             worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "             current_row += 1\n",
        "             worksheet.update(f\"A{current_row}\", sim_table)\n",
        "             worksheet.format(f\"A{current_row}:C{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "             current_row += len(sim_table) + 1\n",
        "\n",
        "        # Auto-resize columns for readability (optional, might fail on complex sheets)\n",
        "        try: worksheet.columns_auto_resize(0, 5)\n",
        "        except: pass\n",
        "\n",
        "        # --- Finalize and Return Link ---\n",
        "        clear_output()\n",
        "        console.print(\"‚úì Successfully exported analysis to Google Sheets!\", style=\"spring_green3\")\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script> window.open(\"{spreadsheet_url}\", \"_blank\"); </script>\n",
        "        <div>Spreadsheet created: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a> (Opened in new tab)</div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        clear_output()\n",
        "        console.print(f\"‚ùå Error exporting to Google Sheets: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red; font-weight:bold;'>Error exporting to Google Sheets: {str(e)}</div>\")\n",
        "\n",
        "\n",
        "def download_analysis_json(analysis_results, comparison_results=None, multi_contract_comparison=None, filename=None):\n",
        "    \"\"\"Creates a JSON file containing the analysis results for download.\"\"\"\n",
        "    console.print(\"[cyan3]Preparing JSON export...\", style=\"info\")\n",
        "\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"bytecode_analysis_{timestamp}.json\"\n",
        "\n",
        "    export_data = {\n",
        "        \"analysis_metadata\": {\n",
        "             \"export_time\": datetime.now().isoformat(),\n",
        "             \"tool_version\": \"1.0\" # Example version\n",
        "        },\n",
        "        \"contract_analysis\": analysis_results,\n",
        "    }\n",
        "    if comparison_results: export_data[\"proxy_implementation_comparison\"] = comparison_results\n",
        "    if multi_contract_comparison: export_data[\"multi_contract_comparison\"] = multi_contract_comparison\n",
        "\n",
        "    try:\n",
        "        json_str = json.dumps(export_data, default=str, indent=2)\n",
        "        b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "        clear_output() # Clear the \"preparing\" message\n",
        "        console.print(f\"‚úì Successfully prepared JSON file: {filename}\", style=\"spring_green3\")\n",
        "\n",
        "        # Create HTML for direct download link/trigger\n",
        "        html = f'''\n",
        "        <a download=\"{filename}\" href=\"data:application/json;base64,{b64}\" style=\"text-decoration:none;\">\n",
        "            <button style=\"padding: 8px 12px; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer;\">\n",
        "                Download {filename}\n",
        "            </button>\n",
        "        </a>\n",
        "        <script>\n",
        "        // Optional: uncomment to auto-trigger download immediately\n",
        "        /*\n",
        "        (function() {{\n",
        "            const link = document.createElement('a');\n",
        "            link.href = \"data:application/json;base64,{b64}\";\n",
        "            link.download = \"{filename}\";\n",
        "            document.body.appendChild(link);\n",
        "            link.click();\n",
        "            document.body.removeChild(link);\n",
        "        }})();\n",
        "        */\n",
        "        </script>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "    except Exception as e:\n",
        "         clear_output()\n",
        "         console.print(f\"‚ùå Error creating JSON export: {str(e)}\", style=\"error\")\n",
        "         return HTML(f\"<div style='color:red; font-weight:bold;'>Error creating JSON: {str(e)}</div>\")\n",
        "\n",
        "\n",
        "# --- UI Setup and Tab Definitions ---\n",
        "\n",
        "# Global containers for results (cleared by analysis functions)\n",
        "analysis_results = {}\n",
        "comparison_data = None\n",
        "multi_comparison_data = None\n",
        "\n",
        "# Main Tab Interface\n",
        "analysis_tabs = widgets.Tab()\n",
        "\n",
        "# Apply Custom CSS for better UI (ensure this matches your notebook theme)\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        ".jupyter-widgets-output-area .jupyter-widgets .widget-tab > .p-TabBar-tabLabel {\n",
        "    font-weight: bold;\n",
        "}\n",
        ".jupyter-widgets-output-area .jupyter-widgets .widget-tab-contents {\n",
        "    border: 1px solid #ccc;\n",
        "    padding: 15px;\n",
        "}\n",
        ".jupyter-widgets-output-area .jupyter-widgets .jupyter-button {\n",
        "    color: white;\n",
        "}\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "def show_export_options(parent_output=None):\n",
        "    \"\"\"Displays export buttons (JSON, Google Sheets) using global result variables.\"\"\"\n",
        "    global analysis_results, comparison_data, multi_comparison_data\n",
        "\n",
        "    # Check if there are any results to export\n",
        "    has_analysis = isinstance(analysis_results, dict) and analysis_results\n",
        "    has_comparison = isinstance(comparison_data, dict) and comparison_data\n",
        "    has_multi = isinstance(multi_comparison_data, dict) and multi_comparison_data\n",
        "\n",
        "    if not has_analysis:\n",
        "        # Display message within the provided output widget or directly\n",
        "        message = \"[warning]No analysis results currently available to export.[/warning]\"\n",
        "        if parent_output:\n",
        "             with parent_output: console.print(message, style=\"warning\")\n",
        "        else: console.print(message, style=\"warning\")\n",
        "        return\n",
        "\n",
        "    # Create buttons and output area for export actions\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(description='Export as JSON', button_style='warning', icon='download', layout=widgets.Layout(width='auto')),\n",
        "        widgets.Button(description='Export to Google Sheets', button_style='info', icon='table', layout=widgets.Layout(width='auto'))\n",
        "    ])\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Define button click handlers\n",
        "    def export_json_handler(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            result_html = download_analysis_json(\n",
        "                analysis_results if has_analysis else {},\n",
        "                comparison_data if has_comparison else None,\n",
        "                multi_comparison_data if has_multi else None\n",
        "            )\n",
        "            display(result_html)\n",
        "\n",
        "    def export_sheets_handler(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            result_html = export_to_google_sheets(\n",
        "                analysis_results if has_analysis else {},\n",
        "                comparison_data if has_comparison else None,\n",
        "                multi_comparison_data if has_multi else None\n",
        "            )\n",
        "            display(result_html)\n",
        "\n",
        "    # Assign handlers\n",
        "    export_buttons.children[0].on_click(export_json_handler)\n",
        "    export_buttons.children[1].on_click(export_sheets_handler)\n",
        "\n",
        "    header_output = widgets.Output()\n",
        "    with header_output: # Capture prints into this widget\n",
        "      console.print(\"\\n\\n[bold]Export Analysis Results:[/bold]\", style=\"magenta3\")\n",
        "      console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "    # Combine into a VBox for display\n",
        "    export_widget = widgets.VBox([\n",
        "        header_output,\n",
        "        export_buttons,\n",
        "        export_output\n",
        "    ])\n",
        "\n",
        "    # Display within the parent output widget or directly\n",
        "    if parent_output:\n",
        "        with parent_output: display(export_widget)\n",
        "    else: display(export_widget)\n",
        "\n",
        "\n",
        "# --- Tab Content Generation Functions ---\n",
        "\n",
        "def analyze_pyusd_tab():\n",
        "    \"\"\"Creates the UI and logic for the PYUSD analysis tab.\"\"\"\n",
        "    pyusd_tab = widgets.VBox()\n",
        "    pyusd_output = widgets.Output()\n",
        "    analyze_button = widgets.Button(description='Re-Analyze PYUSD Contracts', button_style='primary', icon='refresh', layout=widgets.Layout(width='auto'))\n",
        "\n",
        "    def analyze_pyusd_action(b):\n",
        "        # Access and reset global result containers\n",
        "        global analysis_results, comparison_data, multi_comparison_data\n",
        "        analysis_results = {}\n",
        "        comparison_data = None\n",
        "        multi_comparison_data = None\n",
        "\n",
        "        with pyusd_output:\n",
        "            clear_output()\n",
        "            display(HTML(\"<h4 style='color: #00d7af;'>Analyzing Official PYUSD Contracts on Mainnet</h4>\"))\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            # Define contracts to analyze (ensure these globals exist)\n",
        "            contracts_to_analyze = {}\n",
        "            if 'PYUSD_PROXY' in globals(): contracts_to_analyze[\"PYUSD Proxy\"] = PYUSD_PROXY\n",
        "            if 'PYUSD_IMPLEMENTATION' in globals(): contracts_to_analyze[\"PYUSD Implementation\"] = PYUSD_IMPLEMENTATION\n",
        "            if 'SUPPLY_CONTROL_PROXY' in globals(): contracts_to_analyze[\"Supply Controller Proxy\"] = SUPPLY_CONTROL_PROXY\n",
        "            # Add Supply Controller Impl if needed for specific comparisons\n",
        "\n",
        "            codes = {}\n",
        "            analyses = {}\n",
        "\n",
        "            # Fetch and analyze each contract\n",
        "            for name, address in contracts_to_analyze.items():\n",
        "                if not address:\n",
        "                    console.print(f\"[warning]Skipping {name}: Address not defined.\", style=\"warning\")\n",
        "                    continue\n",
        "                code = get_contract_code(address, network='mainnet')\n",
        "                if code:\n",
        "                    codes[name] = code\n",
        "                    contract_display_name = f\"{name} ({shorten_address(address)})\"\n",
        "                    analysis = analyze_bytecode(code, contract_display_name)\n",
        "                    if analysis:\n",
        "                        analyses[name] = analysis\n",
        "                        analysis_results[contract_display_name] = analysis # Use display name as key\n",
        "\n",
        "            # Perform Proxy-Implementation comparison if both analyzed\n",
        "            proxy_name = \"PYUSD Proxy\"\n",
        "            impl_name = \"PYUSD Implementation\"\n",
        "            if proxy_name in analyses and impl_name in analyses:\n",
        "                comparison_data = compare_proxy_implementation(\n",
        "                    codes[proxy_name], codes[impl_name],\n",
        "                    analyses[proxy_name][\"contract_name\"], analyses[impl_name][\"contract_name\"]\n",
        "                )\n",
        "\n",
        "            # Generate architecture/relationship diagrams (using Graphviz)\n",
        "            # Ensure Graphviz is installed and on the system PATH\n",
        "            try:\n",
        "                # Proxy Architecture Diagram\n",
        "                if proxy_name in analyses and impl_name in analyses and analyses[proxy_name][\"proxy_functionality\"][\"is_proxy\"]:\n",
        "                    display(HTML(\"<h4>PYUSD Proxy Architecture Diagram</h4>\"))\n",
        "                    arch_graph = Digraph(comment=\"PYUSD Proxy Architecture\", format='png')\n",
        "                    arch_graph.attr(rankdir='LR', bgcolor='transparent', node_sep='0.5', rank_sep='1')\n",
        "                    arch_graph.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "                    arch_graph.node('user', 'User / DApp', fillcolor='lightblue')\n",
        "                    arch_graph.node('proxy', analyses[proxy_name][\"contract_name\"], fillcolor='palegreen')\n",
        "                    arch_graph.node('impl', analyses[impl_name][\"contract_name\"], fillcolor='lightcoral')\n",
        "                    # Optionally add Admin Proxy node if known\n",
        "                    # arch_graph.node('admin', 'Proxy Admin\\n(Upgrade Control)', fillcolor='lightyellow')\n",
        "                    arch_graph.edge('user', 'proxy', label='Calls')\n",
        "                    arch_graph.edge('proxy', 'impl', label='delegatecall')\n",
        "                    # arch_graph.edge('admin', 'proxy', label='Upgrades')\n",
        "                    display(arch_graph)\n",
        "\n",
        "                # Add spacing between diagrams\n",
        "                display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "                # Contract Relationship Diagram (PYUSD + Supply Controller)\n",
        "                supply_proxy_name = \"Supply Controller Proxy\"\n",
        "                if proxy_name in analyses and supply_proxy_name in analyses:\n",
        "\n",
        "                     console.print(\"\\n\\n[bold]PYUSD Contract Relationships Diagram[/bold]\", style=\"magenta3\")\n",
        "                     console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "                     rel_graph = Digraph(comment=\"PYUSD Contract Relationships\", format='png')\n",
        "                     rel_graph.attr(bgcolor='transparent', node_sep='0.5', rank_sep='0.7')\n",
        "                     rel_graph.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "                     pyusd_node_name = analyses[proxy_name][\"contract_name\"]\n",
        "                     supply_node_name = analyses[supply_proxy_name][\"contract_name\"]\n",
        "                     rel_graph.node('pyusd', pyusd_node_name, fillcolor='palegreen')\n",
        "                     if impl_name in analyses:\n",
        "                         rel_graph.node('pyusd_impl', analyses[impl_name][\"contract_name\"], fillcolor='lightcyan')\n",
        "                         rel_graph.edge('pyusd', 'pyusd_impl', label='delegates to')\n",
        "                     rel_graph.node('supply', supply_node_name, fillcolor='lightsalmon')\n",
        "                     # Add Supply Impl if analyzed\n",
        "                     # rel_graph.node('supply_impl', 'Supply Impl\\n(...)', fillcolor='lightpink')\n",
        "                     # rel_graph.edge('supply', 'supply_impl', label='delegates to')\n",
        "                     rel_graph.edge('supply', 'pyusd', label='controls supply (mint/burn)')\n",
        "                     display(rel_graph)\n",
        "\n",
        "            except Exception as viz_err:\n",
        "                 console.print(f\"[warning]Could not render architecture/relationship diagram. Ensure Graphviz is installed and in PATH. Error: {viz_err}\", style=\"warning\")\n",
        "\n",
        "            # Show export options if analysis produced results\n",
        "            if analysis_results:\n",
        "                show_export_options(pyusd_output)\n",
        "            else:\n",
        "                console.print(\"\\n[error]No analysis results were generated for PYUSD contracts. Check network connection and contract addresses.\", style=\"error\")\n",
        "\n",
        "    analyze_button.on_click(analyze_pyusd_action)\n",
        "\n",
        "    # Layout for the tab\n",
        "    pyusd_tab.children = [\n",
        "        widgets.HTML(\"<h3>Analyze Official PYUSD Contracts</h3>\"),\n",
        "        widgets.HTML(\"<p>Analyzes the main PYUSD token proxy, implementation, and supply controller contracts on Ethereum Mainnet. Fetches bytecode, performs analysis, and visualizes relationships.</p>\"),\n",
        "        analyze_button,\n",
        "        pyusd_output\n",
        "    ]\n",
        "\n",
        "    # Automatically run the analysis when the tab is first created\n",
        "    analyze_pyusd_action(None)\n",
        "\n",
        "    return pyusd_tab\n",
        "\n",
        "\n",
        "def analyze_tx_tab():\n",
        "    \"\"\"Creates the UI and logic for the Transaction-based analysis tab.\"\"\"\n",
        "    tx_tab = widgets.VBox()\n",
        "    tx_input = widgets.Text(placeholder='Enter transaction hash (e.g., 0xabc...)', description='Tx Hash:', layout=widgets.Layout(width='90%'))\n",
        "    network_selector = widgets.Dropdown(options=['mainnet', 'sepolia', 'holesky'], value='mainnet', description='Network:', layout=widgets.Layout(width='auto'))\n",
        "    analyze_button = widgets.Button(description='Analyze Contracts in Tx', button_style='primary', icon='search', layout=widgets.Layout(width='auto'))\n",
        "    tx_output = widgets.Output()\n",
        "\n",
        "    def analyze_tx_action(b, tx_hash_override=None): # Allow passing hash for auto-run\n",
        "        # Access and reset global result containers\n",
        "        global analysis_results, multi_comparison_data, comparison_data\n",
        "        analysis_results = {}\n",
        "        multi_comparison_data = None\n",
        "        comparison_data = None # Reset single comparison too\n",
        "\n",
        "        with tx_output:\n",
        "            clear_output()\n",
        "            console.print(\"\\n\\n[bold]Analyzing Transaction for Contracts[/bold]\", style=\"cyan3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "\n",
        "            # Determine transaction hash to use\n",
        "            current_tx_hash = tx_hash_override if tx_hash_override else tx_input.value.strip()\n",
        "\n",
        "            # Validate Tx Hash format\n",
        "            if not current_tx_hash or not re.match(r'^0x[0-9a-fA-F]{64}$', current_tx_hash):\n",
        "                console.print(\"[error]Invalid input: Please enter a valid 64-character transaction hash starting with 0x.\", style=\"error\")\n",
        "                return\n",
        "\n",
        "            # Update input field if hash was passed programmatically\n",
        "            if tx_hash_override: tx_input.value = tx_hash_override\n",
        "\n",
        "            selected_network = network_selector.value\n",
        "            # Fetch contracts involved in the transaction\n",
        "            contracts_in_tx = get_contracts_from_tx(current_tx_hash, selected_network)\n",
        "\n",
        "            if not contracts_in_tx:\n",
        "                console.print(f\"[warning]No contracts with bytecode found in transaction {shorten_address(current_tx_hash)} on {selected_network}, or an error occurred during lookup.\", style=\"warning\")\n",
        "                return # Exit if no contracts to analyze\n",
        "\n",
        "            # Prepare lists for analysis and comparison\n",
        "            contract_codes_list = []\n",
        "            contract_names_list = []\n",
        "            analyzed_contract_count = 0\n",
        "\n",
        "            console.print(f\"\\n\\n[bold cyan3]Analyzing {len(contracts_in_tx)} Contract(s) Found in Transaction[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "            # Analyze each contract found\n",
        "            for address, name in contracts_in_tx.items():\n",
        "                code = get_contract_code(address, network=selected_network)\n",
        "                if code:\n",
        "                    analysis = analyze_bytecode(code, name) # Name includes address\n",
        "                    if analysis:\n",
        "                        analysis_results[analysis[\"contract_name\"]] = analysis\n",
        "                        contract_codes_list.append(code)\n",
        "                        contract_names_list.append(analysis[\"contract_name\"])\n",
        "                        analyzed_contract_count += 1\n",
        "\n",
        "            # Perform comparison if multiple contracts were successfully analyzed\n",
        "            if analyzed_contract_count > 1:\n",
        "                 multi_comparison_data = compare_multiple_contracts(contract_codes_list, contract_names_list)\n",
        "            elif analyzed_contract_count == 1:\n",
        "                 console.print(\"[info]Only one contract was successfully analyzed from the transaction. Skipping comparison.\", style=\"info\")\n",
        "            else:\n",
        "                 console.print(\"[warning]Could not successfully analyze bytecode for any contracts found in the transaction.\", style=\"warning\")\n",
        "\n",
        "            # Display export options if results were generated\n",
        "            if analysis_results:\n",
        "                show_export_options(tx_output)\n",
        "\n",
        "    analyze_button.on_click(analyze_tx_action)\n",
        "\n",
        "    # Layout for the tab\n",
        "    tx_tab.children = [\n",
        "        widgets.HTML(\"<h3>Analyze Contracts from Transaction</h3>\"),\n",
        "        widgets.HTML(\"<p>Extracts contract addresses involved in a transaction (target, event emitters, created contracts), fetches their bytecode, analyzes them individually, and performs a multi-contract comparison if applicable.</p>\"),\n",
        "        widgets.HBox([tx_input, network_selector, analyze_button]),\n",
        "        tx_output\n",
        "    ]\n",
        "\n",
        "    console.print(\"\\n\\n[bold]üìÑ Advanced Bytecode Analysis via eth_getCode[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Automatically analyze TARGET_TX_HASH if defined globally and valid\n",
        "    if 'TARGET_TX_HASH' in globals() and TARGET_TX_HASH and re.match(r'^0x[0-9a-fA-F]{64}$', TARGET_TX_HASH):\n",
        "        console.print(f\"\\n\\n[info]‚û°Ô∏èAuto-analyzing Target transaction hash: {TARGET_TX_HASH}\", style=\"info\")\n",
        "        analyze_tx_action(None, TARGET_TX_HASH)\n",
        "\n",
        "    return tx_tab\n",
        "\n",
        "\n",
        "def analyze_custom_tab():\n",
        "    \"\"\"Creates the UI and logic for the Custom Contract analysis tab.\"\"\"\n",
        "    custom_tab = widgets.VBox()\n",
        "\n",
        "    # Example stablecoin addresses for comparison\n",
        "    example_addresses = [\n",
        "        \"0x6c3ea9036406852006290770BEdFcAbA0e23A0e8\",  # PYUSD Proxy\n",
        "        \"0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\",  # USDC Proxy\n",
        "        \"0xdac17f958d2ee523a2206206994597c13d831ec7\"   # USDT\n",
        "    ]\n",
        "    example_names = [\"PYUSD\", \"USDC\", \"USDT\"]\n",
        "\n",
        "    # Input fields for addresses and names\n",
        "    address_inputs = [widgets.Text(placeholder=f'e.g., {example_addresses[i]}',\n",
        "                                  description=f'Addr {i+1}:',\n",
        "                                  layout=widgets.Layout(width='60%')) for i in range(3)]\n",
        "    name_inputs = [widgets.Text(description=f'Name {i+1}:',\n",
        "                               layout=widgets.Layout(width='30%')) for i in range(3)]\n",
        "\n",
        "    # Set default names\n",
        "    for i in range(3):\n",
        "        name_inputs[i].value = f\"Contract {chr(65+i)}\"\n",
        "\n",
        "    # Network selector and buttons\n",
        "    network_selector = widgets.Dropdown(options=['mainnet', 'sepolia', 'holesky'], value='mainnet', description='Network:', layout=widgets.Layout(width='auto'))\n",
        "    analyze_button = widgets.Button(description='Analyze Custom Contracts', button_style='primary', icon='cogs', layout=widgets.Layout(width='auto'))\n",
        "    example_button = widgets.Button(description='Load Stablecoin Examples', button_style='info', icon='info', layout=widgets.Layout(width='auto'))\n",
        "\n",
        "    custom_output = widgets.Output()\n",
        "\n",
        "    def load_examples(b):\n",
        "        \"\"\"Loads example stablecoin addresses into the input fields.\"\"\"\n",
        "        for i in range(3):\n",
        "            address_inputs[i].value = example_addresses[i]\n",
        "            name_inputs[i].value = example_names[i]\n",
        "\n",
        "    example_button.on_click(load_examples)\n",
        "\n",
        "    def analyze_custom_action(b):\n",
        "        # Access and reset global result containers\n",
        "        global analysis_results, comparison_data, multi_comparison_data\n",
        "        analysis_results = {}\n",
        "        comparison_data = None\n",
        "        multi_comparison_data = None\n",
        "\n",
        "        with custom_output:\n",
        "            clear_output()\n",
        "            console.print(\"\\n\\n[bold]‚öôÔ∏è Analyzing Custom Contracts[/bold]\", style=\"cyan3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            # Collect valid addresses and corresponding names\n",
        "            addresses_to_analyze = []\n",
        "            names_to_analyze = []\n",
        "            for i in range(len(address_inputs)):\n",
        "                addr = address_inputs[i].value.strip()\n",
        "                if addr: # Only process if address field is not empty\n",
        "                    if re.match(r'^0x[0-9a-fA-F]{40}$', addr):\n",
        "                        addresses_to_analyze.append(addr)\n",
        "                        # Use provided name or default\n",
        "                        names_to_analyze.append(name_inputs[i].value.strip() or f\"Contract {chr(65+i)}\")\n",
        "                    else:\n",
        "                        console.print(f\"[warning]Skipping invalid address format entered for Contract {i+1}: '{addr}'\", style=\"warning\")\n",
        "\n",
        "            if not addresses_to_analyze:\n",
        "                console.print(\"[error]No valid contract addresses entered. Please enter at least one valid Ethereum address.\", style=\"error\")\n",
        "                return\n",
        "\n",
        "            selected_network = network_selector.value\n",
        "            contract_codes_list = []\n",
        "            contract_names_list = []\n",
        "            analyzed_contract_count = 0\n",
        "\n",
        "            # Analyze each valid contract\n",
        "            for i, address in enumerate(addresses_to_analyze):\n",
        "                contract_display_name = f\"{names_to_analyze[i]} ({shorten_address(address)})\"\n",
        "                code = get_contract_code(address, network=selected_network)\n",
        "                if code:\n",
        "                    analysis = analyze_bytecode(code, contract_display_name)\n",
        "                    if analysis:\n",
        "                        analysis_results[analysis[\"contract_name\"]] = analysis\n",
        "                        contract_codes_list.append(code)\n",
        "                        contract_names_list.append(analysis[\"contract_name\"])\n",
        "                        analyzed_contract_count += 1\n",
        "\n",
        "            # Perform comparisons based on the number of successfully analyzed contracts\n",
        "            if analyzed_contract_count == 2:\n",
        "                 # Assume the two might be a proxy/implementation pair\n",
        "                 comparison_data = compare_proxy_implementation(\n",
        "                     contract_codes_list[0], contract_codes_list[1],\n",
        "                     contract_names_list[0], contract_names_list[1]\n",
        "                 )\n",
        "            elif analyzed_contract_count > 2:\n",
        "                 # Perform multi-contract comparison\n",
        "                 multi_comparison_data = compare_multiple_contracts(contract_codes_list, contract_names_list)\n",
        "            elif analyzed_contract_count == 1:\n",
        "                 console.print(\"[info]Only one contract was analyzed successfully. Skipping comparison.\", style=\"info\")\n",
        "            else: # analyzed_contract_count == 0\n",
        "                 console.print(\"[warning]Could not successfully analyze bytecode for any of the provided contracts.\", style=\"warning\")\n",
        "\n",
        "            # Show export options if any results were generated\n",
        "            if analysis_results:\n",
        "                show_export_options(custom_output)\n",
        "\n",
        "    analyze_button.on_click(analyze_custom_action)\n",
        "\n",
        "    # Warning about addresses\n",
        "    address_note = widgets.HTML(\"\"\"\n",
        "    <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "        <strong>Important:</strong> Enter only smart contract addresses, not user wallet addresses (EOAs).\n",
        "        User wallet addresses will show \"No bytecode found\" error. Try the example stablecoin addresses for a demonstration.\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    # Layout for the tab using HBox for alignment\n",
        "    input_rows = [widgets.HBox([address_inputs[i], name_inputs[i]]) for i in range(3)]\n",
        "    custom_tab.children = [\n",
        "        widgets.HTML(\"<h3>Analyze Custom Contracts by Address</h3>\"),\n",
        "        widgets.HTML(\"<p>Enter up to three contract addresses and optional custom names. The tool will fetch bytecode, analyze each contract, and perform comparisons (Proxy vs. Impl for two, Multi-Contract for three).</p>\"),\n",
        "        address_note,\n",
        "        widgets.HBox([example_button], layout=widgets.Layout(margin='10px 0')),\n",
        "        *input_rows, # Unpack the list of HBox widgets\n",
        "        widgets.HBox([network_selector, analyze_button]),\n",
        "        custom_output\n",
        "    ]\n",
        "\n",
        "    return custom_tab\n",
        "\n",
        "\n",
        "# --- Main Execution: Assemble and Display Tabs ---\n",
        "\n",
        "# Create the tab instances\n",
        "tab1 = analyze_pyusd_tab()\n",
        "tab2 = analyze_tx_tab()\n",
        "tab3 = analyze_custom_tab()\n",
        "\n",
        "# Assign tabs to the Tab widget\n",
        "analysis_tabs.children = [tab1, tab2, tab3]\n",
        "\n",
        "# Set descriptive titles for each tab\n",
        "analysis_tabs.set_title(0, 'PYUSD Analysis')\n",
        "analysis_tabs.set_title(1, 'From Transaction')\n",
        "analysis_tabs.set_title(2, 'Custom Contracts')\n",
        "\n",
        "# Display the main title and the tab interface\n",
        "console.print(\"\\n\\nSelect an analysis mode below to fetch and examine contract bytecode:\\n\\n\")\n",
        "display(analysis_tabs)"
      ],
      "metadata": {
        "id": "IikOrrEzIvKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 üß± `trace_block`: Analyzing All Transactions in a Block\n",
        "---\n",
        "\n",
        "This section utilizes the `trace_block` RPC method to retrieve summary traces for **all transactions** executed within a single target block (`TARGET_BLOCK_IDENTIFIER`). This provides a high-level overview of the block's activity, allowing us to understand the context surrounding specific PYUSD transactions and identify broader patterns.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `trace_block`\n",
        "> *   **Multiplier:** `50x` (Available on Mainnet via GCP)\n",
        "> *   **GCP Advantage:** Tracing an entire block is computationally demanding. GCP provides this capability on Mainnet, often restricted or unavailable elsewhere, allowing for comprehensive block-level analysis without needing to trace each transaction individually first.\n",
        "> *   **PYUSD Insight:** `trace_block` helps us:\n",
        ">     *   Quickly identify **all transactions interacting with PYUSD** within a specific block.\n",
        ">     *   Analyze the **gas consumption patterns** across different transaction types (PYUSD transfers, DeFi interactions, contract creations) within the block.\n",
        ">     *   Understand the immediate **on-chain environment** surrounding significant PYUSD events.\n",
        ">     *   Detect **potential indicators** of MEV activity or unusual transaction sequences involving PYUSD by examining the full block context (transaction order, gas usage, specific calls).\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Block Trace:** Calls `trace_block` using the target block identifier.\n",
        "2.  **Process Traces:** Iterates through the list of transaction traces returned for the block.\n",
        "3.  **Categorize & Analyze (within `analyze_block_trace`):**\n",
        "    *   Each transaction trace is categorized (e.g., ETH Transfer, Contract Call, PYUSD Transfer, PYUSD Approval) using `categorize_transaction`.\n",
        "    *   PYUSD-specific details (function calls, parameters, events) are extracted using `extract_pyusd_details`.\n",
        "    *   Gas usage is aggregated by transaction type (`analyze_gas_distribution`).\n",
        "    *   PYUSD token flow within the block is analyzed (`analyze_pyusd_flow`).\n",
        "4.  **Visualize & Summarize:**\n",
        "    *   **Block Summary Panel:** Displays key statistics (total transactions, gas, errors, PYUSD interactions) using `rich`.\n",
        "    *   **Gas Analysis:** Shows tables (`rich`) and plots (`plotly`) of gas usage distribution by transaction type.\n",
        "    *   **PYUSD Activity:** Tables (`rich`) detailing PYUSD interactions, function calls, and token flow graphs (`graphviz`).\n",
        "    *   **Transaction Table:** An interactive table (`pandas`, `ipywidgets`) summarizing all transactions in the block, with options to filter for PYUSD interactions.\n",
        "    *   **Export Options:** Download block transaction summaries.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **PYUSD Transaction Density:** How many transactions in the block interact with PYUSD?\n",
        "*   **Gas Usage Patterns:** Which types of transactions consume the most gas in this block? Are PYUSD interactions relatively efficient or expensive compared to others?\n",
        "*   **PYUSD Flow:** Observe the primary PYUSD movements within the block using the flow diagram.\n",
        "*   **Context:** Examine the transactions immediately before and after significant PYUSD events **using the full transaction table**."
      ],
      "metadata": {
        "id": "-LNSmB5aUaoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üß± Block Tracing and Analysis using trace_block (Google Cost-Efficient API)\n",
        "# =============================================================================================\n",
        "# This cell utilizes the trace_block RPC method to analyze all transactions within a specific block.\n",
        "# Functionality includes:\n",
        "# - Fetching summary traces for every transaction in the target block via trace_block.\n",
        "# - Categorizing each transaction (e.g., ETH Transfer, Contract Call, PYUSD Transfer, PYUSD Approval).\n",
        "# - Extracting detailed information for PYUSD-related transactions (function calls, parameters, amounts, events).\n",
        "# - Analyzing and visualizing gas consumption patterns across different transaction types within the block.\n",
        "# - Analyzing and visualizing the flow of PYUSD tokens (transfers, approvals) within the block context using Graphviz.\n",
        "# - Displaying comprehensive summary statistics and detailed tables using rich console formatting.\n",
        "# - Providing an interactive table of all block transactions with filtering for PYUSD interactions.\n",
        "# - Offering direct export options for the analysis results to CSV, JSON, and Google Sheets.\n",
        "# - Leveraging GCP's premium RPC capabilities for the compute-intensive trace_block method on Mainnet.\n",
        "\n",
        "def categorize_transaction(trace_item):\n",
        "    \"\"\"Categorizes a transaction trace based on its characteristics.\"\"\"\n",
        "    action = trace_item.get('action', {})\n",
        "    to_addr = action.get('to', action.get('address', ''))\n",
        "    input_data = action.get('input', '0x')\n",
        "\n",
        "    # Initialize category data\n",
        "    category = {\n",
        "        'type': 'other',\n",
        "        'subtype': 'unknown',\n",
        "        'description': 'Other transaction',\n",
        "        'is_pyusd': False,\n",
        "        'function_name': None,\n",
        "        'function_category': None\n",
        "    }\n",
        "\n",
        "    # Check contract creation\n",
        "    if action.get('init') and not action.get('to'):\n",
        "        category.update({\n",
        "            'type': 'contract_creation',\n",
        "            'subtype': 'deployment',\n",
        "            'description': 'Contract Deployment'\n",
        "        })\n",
        "        return category\n",
        "\n",
        "    # Check if address is any of the PYUSD contracts\n",
        "    is_pyusd_contract = False\n",
        "    if to_addr:\n",
        "        to_addr_lower = to_addr.lower()\n",
        "        for contract_addr in PYUSD_CONTRACTS:\n",
        "            if to_addr_lower == contract_addr:\n",
        "                is_pyusd_contract = True\n",
        "                category.update({\n",
        "                    'type': 'token',\n",
        "                    'subtype': 'pyusd',\n",
        "                    'description': f'PYUSD: {PYUSD_CONTRACTS[contract_addr]}',\n",
        "                    'is_pyusd': True,\n",
        "                    'contract_name': PYUSD_CONTRACTS[contract_addr]\n",
        "                })\n",
        "                break\n",
        "\n",
        "    # If it's a PYUSD contract, try to decode function\n",
        "    if is_pyusd_contract and input_data and len(input_data) >= 10:\n",
        "        function_name = decode_pyusd_function(input_data)\n",
        "        function_category = get_function_category(input_data)\n",
        "        category.update({\n",
        "            'function_name': function_name,\n",
        "            'function_category': function_category,\n",
        "            'description': f'PYUSD: {function_name}'\n",
        "        })\n",
        "\n",
        "        # Further refine subtype based on function category\n",
        "        if function_category == 'token_movement':\n",
        "            category['subtype'] = 'transfer'\n",
        "        elif function_category == 'allowance':\n",
        "            category['subtype'] = 'approval'\n",
        "        elif function_category == 'supply_change':\n",
        "            category['subtype'] = 'supply_change'\n",
        "        elif function_category == 'control':\n",
        "            category['subtype'] = 'control'\n",
        "\n",
        "    # Check for ETH transfers (no input data)\n",
        "    elif input_data == '0x' or len(input_data) <= 2:\n",
        "        value = int(action.get('value', '0x0'), 16)\n",
        "        if value > 0:\n",
        "            category.update({\n",
        "                'type': 'eth_transfer',\n",
        "                'subtype': 'transfer',\n",
        "                'description': 'ETH Transfer'\n",
        "            })\n",
        "\n",
        "    # Other contract interactions\n",
        "    elif to_addr and len(input_data) >= 10:\n",
        "        # This is a contract interaction, but not with PYUSD\n",
        "        category.update({\n",
        "            'type': 'contract_interaction',\n",
        "            'subtype': 'call',\n",
        "            'description': 'Contract Interaction',\n",
        "            'function_selector': input_data[:10]\n",
        "        })\n",
        "\n",
        "    return category\n",
        "\n",
        "def extract_pyusd_details(trace_item):\n",
        "    \"\"\"Extracts PYUSD-specific details from a trace item if present.\"\"\"\n",
        "    action = trace_item.get('action', {})\n",
        "    result = trace_item.get('result', {})\n",
        "    input_data = action.get('input', '0x')\n",
        "    to_addr = action.get('to', '')\n",
        "\n",
        "    details = {\n",
        "        'is_pyusd_tx': False,\n",
        "        'function': None,\n",
        "        'function_category': None,\n",
        "        'params': {},\n",
        "        'events': [],\n",
        "        'amount': None,\n",
        "        'from_addr': None,\n",
        "        'to_addr': None,\n",
        "        'decoded': {}\n",
        "    }\n",
        "\n",
        "    # Check if this is a PYUSD contract\n",
        "    is_pyusd_contract = False\n",
        "    if to_addr:\n",
        "        to_addr_lower = to_addr.lower()\n",
        "        for contract_addr in PYUSD_CONTRACTS:\n",
        "            if to_addr_lower == contract_addr:\n",
        "                is_pyusd_contract = True\n",
        "                details['contract_name'] = PYUSD_CONTRACTS[contract_addr]\n",
        "                break\n",
        "\n",
        "    if not is_pyusd_contract:\n",
        "        return details\n",
        "\n",
        "    # It's a PYUSD transaction\n",
        "    details['is_pyusd_tx'] = True\n",
        "\n",
        "    # Try to decode function call\n",
        "    if len(input_data) >= 10:\n",
        "        method_sig = input_data[:10]\n",
        "        details['function'] = decode_pyusd_function(input_data)\n",
        "        details['function_category'] = get_function_category(input_data)\n",
        "\n",
        "        # Attempt basic parameter decoding for common functions\n",
        "        if method_sig == '0xa9059cbb':  # transfer(address,uint256)\n",
        "            try:\n",
        "                to_address_hex = '0x' + input_data[10:74].lstrip('0')\n",
        "                amount_hex = '0x' + input_data[74:138].lstrip('0')\n",
        "                details['params']['to'] = Web3.to_checksum_address(to_address_hex)\n",
        "                amount_raw = int(amount_hex, 16)\n",
        "                details['amount'] = amount_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                details['to_addr'] = details['params']['to']\n",
        "                details['from_addr'] = action.get('from')\n",
        "\n",
        "                details['decoded'] = {\n",
        "                    'operation': 'transfer',\n",
        "                    'from': action.get('from'),\n",
        "                    'to': details['params']['to'],\n",
        "                    'amount': f\"{details['amount']} PYUSD\"\n",
        "                }\n",
        "            except Exception as e:\n",
        "                details['decode_error'] = str(e)\n",
        "\n",
        "        elif method_sig == '0x095ea7b3':  # approve(address,uint256)\n",
        "            try:\n",
        "                spender_hex = '0x' + input_data[10:74].lstrip('0')\n",
        "                amount_hex = '0x' + input_data[74:138].lstrip('0')\n",
        "                details['params']['spender'] = Web3.to_checksum_address(spender_hex)\n",
        "                amount_raw = int(amount_hex, 16)\n",
        "                details['amount'] = amount_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                details['decoded'] = {\n",
        "                    'operation': 'approve',\n",
        "                    'owner': action.get('from'),\n",
        "                    'spender': details['params']['spender'],\n",
        "                    'amount': f\"{details['amount']} PYUSD\"\n",
        "                }\n",
        "            except Exception as e:\n",
        "                details['decode_error'] = str(e)\n",
        "\n",
        "    # Extract any logs (events) from the result\n",
        "    if 'logs' in result and isinstance(result['logs'], list):\n",
        "        for log in result['logs']:\n",
        "            if log.get('address', '').lower() == PYUSD_ADDRESS_LOWER_ETH and log.get('topics'):\n",
        "                topic0 = log['topics'][0]\n",
        "\n",
        "                if topic0 in PYUSD_EVENTS:\n",
        "                    event_data = log.get('data', '0x')\n",
        "                    decoded_event = decode_pyusd_event(topic0, log['topics'], event_data)\n",
        "                    details['events'].append(decoded_event)\n",
        "\n",
        "                    # For Transfer events, extract additional information\n",
        "                    if topic0 == TRANSFER_EVENT_TOPIC and 'decoded' in decoded_event:\n",
        "                        event_from = decoded_event['decoded'].get('from')\n",
        "                        event_to = decoded_event['decoded'].get('to')\n",
        "                        event_value = decoded_event['decoded'].get('value')\n",
        "\n",
        "                        if not details['amount'] and event_value is not None:\n",
        "                            details['amount'] = event_value / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                        if not details['from_addr'] and event_from:\n",
        "                            details['from_addr'] = event_from\n",
        "                        if not details['to_addr'] and event_to:\n",
        "                            details['to_addr'] = event_to\n",
        "\n",
        "    return details\n",
        "\n",
        "def analyze_gas_distribution(traces_with_categories):\n",
        "    \"\"\"Analyzes gas distribution across different transaction types.\"\"\"\n",
        "    gas_by_category = {}\n",
        "    gas_by_function = {}\n",
        "    pyusd_vs_other = {\n",
        "        'pyusd': {'count': 0, 'gas': 0},\n",
        "        'other': {'count': 0, 'gas': 0}\n",
        "    }\n",
        "\n",
        "    for trace in traces_with_categories:\n",
        "        category = trace.get('category', {})\n",
        "        gas_used = trace.get('gas_used', 0)\n",
        "\n",
        "        # By main category\n",
        "        cat_type = category.get('type', 'other')\n",
        "        if cat_type not in gas_by_category:\n",
        "            gas_by_category[cat_type] = {'count': 0, 'gas': 0}\n",
        "        gas_by_category[cat_type]['count'] += 1\n",
        "        gas_by_category[cat_type]['gas'] += gas_used\n",
        "\n",
        "        # PYUSD vs other\n",
        "        if category.get('is_pyusd', False):\n",
        "            pyusd_vs_other['pyusd']['count'] += 1\n",
        "            pyusd_vs_other['pyusd']['gas'] += gas_used\n",
        "\n",
        "            # By PYUSD function\n",
        "            function_name = category.get('function_name', 'unknown')\n",
        "            if function_name not in gas_by_function:\n",
        "                gas_by_function[function_name] = {'count': 0, 'gas': 0}\n",
        "            gas_by_function[function_name]['count'] += 1\n",
        "            gas_by_function[function_name]['gas'] += gas_used\n",
        "        else:\n",
        "            pyusd_vs_other['other']['count'] += 1\n",
        "            pyusd_vs_other['other']['gas'] += gas_used\n",
        "\n",
        "    return {\n",
        "        'by_category': gas_by_category,\n",
        "        'by_function': gas_by_function,\n",
        "        'pyusd_vs_other': pyusd_vs_other\n",
        "    }\n",
        "\n",
        "def visualize_gas_distribution(gas_analysis, title=\"Gas Usage Distribution in Block\"):\n",
        "    \"\"\"Creates visualization for gas distribution across transaction types.\"\"\"\n",
        "    # Prepare data for visualization\n",
        "    categories = []\n",
        "    gas_values = []\n",
        "    counts = []\n",
        "\n",
        "    for category, data in gas_analysis['by_category'].items():\n",
        "        if data['gas'] > 0:  # Only include categories with gas usage\n",
        "            categories.append(category)\n",
        "            gas_values.append(data['gas'])\n",
        "            counts.append(data['count'])\n",
        "\n",
        "    # Create figure with subplots in a container div\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        subplot_titles=(\"\", \"\"),  # Empty subplot titles, we'll add custom ones\n",
        "        specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}]],\n",
        "        horizontal_spacing=0.05  # Reduce spacing between charts\n",
        "    )\n",
        "\n",
        "    # Add gas usage pie chart\n",
        "    fig.add_trace(\n",
        "        go.Pie(\n",
        "            labels=categories,\n",
        "            values=gas_values,\n",
        "            textinfo='percent+label',\n",
        "            hole=.3,\n",
        "            marker_colors=px.colors.qualitative.Pastel\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Add transaction count pie chart\n",
        "    fig.add_trace(\n",
        "        go.Pie(\n",
        "            labels=categories,\n",
        "            values=counts,\n",
        "            textinfo='percent+label',\n",
        "            hole=.3,\n",
        "            marker_colors=px.colors.qualitative.Pastel\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # Create a container-like layout with proper spacing\n",
        "    fig.update_layout(\n",
        "        # Main title with padding\n",
        "        title={\n",
        "            'text': f\"<b>{title}</b>\",  # Bold with HTML\n",
        "            'y': 0.98,                  # Position higher\n",
        "            'x': 0.5,                   # Center align\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top',\n",
        "            'font': {\n",
        "                'size': 24,             # Larger font\n",
        "                'family': 'Arial, sans-serif'\n",
        "            },\n",
        "            'pad': {'b': 30}            # Add bottom padding to title\n",
        "        },\n",
        "\n",
        "        # Chart container with padding\n",
        "        margin=dict(t=120, b=120, l=40, r=40),  # Extra top and bottom margin\n",
        "        height=650,  # Increased height for better spacing\n",
        "\n",
        "        # Add chart subtitles directly under each chart\n",
        "        annotations=[\n",
        "            dict(\n",
        "                text=\"<b>Gas Usage by Transaction Type</b>\",\n",
        "                x=0.1,\n",
        "                y=-0.10,        # Position directly under first chart\n",
        "                xref=\"paper\",\n",
        "                yref=\"paper\",\n",
        "                showarrow=False,\n",
        "                font=dict(size=14)\n",
        "            ),\n",
        "            dict(\n",
        "                text=\"<b>Transaction Count by Type</b>\",\n",
        "                x=0.9,\n",
        "                y=-0.10,        # Position directly under second chart\n",
        "                xref=\"paper\",\n",
        "                yref=\"paper\",\n",
        "                showarrow=False,\n",
        "                font=dict(size=14)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def analyze_pyusd_flow(traces_with_details, block_number):\n",
        "    \"\"\"Analyzes PYUSD token flow within the block.\"\"\"\n",
        "    # Initialize flow data\n",
        "    flow_data = {\n",
        "        'total_transferred': 0,\n",
        "        'unique_senders': set(),\n",
        "        'unique_receivers': set(),\n",
        "        'transfers': [],\n",
        "        'approvals': [],\n",
        "        'other_operations': []\n",
        "    }\n",
        "\n",
        "    for trace in traces_with_details:\n",
        "        # Get PYUSD details safely\n",
        "        pyusd_details = trace.get('pyusd_details')\n",
        "\n",
        "        # Skip if no PYUSD details or not a PYUSD transaction\n",
        "        if not pyusd_details or not pyusd_details.get('is_pyusd_tx'):\n",
        "            continue\n",
        "\n",
        "        function = pyusd_details.get('function', '')\n",
        "\n",
        "        if function and 'transfer' in function.lower() and pyusd_details.get('amount') and pyusd_details.get('from_addr') and pyusd_details.get('to_addr'):\n",
        "            # This is a transfer\n",
        "            flow_data['total_transferred'] += pyusd_details['amount']\n",
        "            flow_data['unique_senders'].add(pyusd_details['from_addr'])\n",
        "            flow_data['unique_receivers'].add(pyusd_details['to_addr'])\n",
        "\n",
        "            flow_data['transfers'].append({\n",
        "                'tx_hash': trace.get('tx_hash'),\n",
        "                'from': pyusd_details['from_addr'],\n",
        "                'to': pyusd_details['to_addr'],\n",
        "                'amount': pyusd_details['amount'],\n",
        "                'failed': trace.get('failed', False)\n",
        "            })\n",
        "\n",
        "        elif function and 'approve' in function.lower() and pyusd_details.get('amount'):\n",
        "            # This is an approval\n",
        "            flow_data['approvals'].append({\n",
        "                'tx_hash': trace.get('tx_hash'),\n",
        "                'owner': pyusd_details.get('from_addr') or trace.get('from'),\n",
        "                'spender': pyusd_details.get('params', {}).get('spender'),\n",
        "                'amount': pyusd_details['amount'],\n",
        "                'failed': trace.get('failed', False)\n",
        "            })\n",
        "\n",
        "        else:\n",
        "            # Other PYUSD operations\n",
        "            flow_data['other_operations'].append({\n",
        "                'tx_hash': trace.get('tx_hash'),\n",
        "                'function': function,\n",
        "                'from': trace.get('from'),\n",
        "                'failed': trace.get('failed', False)\n",
        "            })\n",
        "\n",
        "    # Calculate statistics\n",
        "    flow_data['unique_senders_count'] = len(flow_data['unique_senders'])\n",
        "    flow_data['unique_receivers_count'] = len(flow_data['unique_receivers'])\n",
        "    flow_data['transfer_count'] = len(flow_data['transfers'])\n",
        "    flow_data['approval_count'] = len(flow_data['approvals'])\n",
        "    flow_data['other_count'] = len(flow_data['other_operations'])\n",
        "\n",
        "    return flow_data\n",
        "\n",
        "def create_pyusd_flow_diagram(flow_data, max_flows=10):\n",
        "    \"\"\"Creates a visualization of PYUSD token flows.\"\"\"\n",
        "    if not flow_data['transfers']:\n",
        "        return None\n",
        "\n",
        "    # Sort transfers by amount\n",
        "    sorted_transfers = sorted(flow_data['transfers'], key=lambda x: x['amount'], reverse=True)\n",
        "\n",
        "    # Take top flows based on amount\n",
        "    top_flows = sorted_transfers[:max_flows]\n",
        "\n",
        "    # Create flow diagram\n",
        "    dot = Digraph(comment='PYUSD Token Flow', format='png')\n",
        "    dot.attr(rankdir='LR', overlap='false')\n",
        "    dot.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "\n",
        "    # Add nodes and edges\n",
        "    added_nodes = set()\n",
        "\n",
        "    for transfer in top_flows:\n",
        "        from_addr = transfer['from']\n",
        "        from_addr_short = from_addr[:6] + '...' + from_addr[-4:]\n",
        "        to_addr = transfer['to']\n",
        "        to_addr_short = to_addr[:6] + '...' + to_addr[-4:]\n",
        "        amount = f\"{transfer['amount']:.2f} PYUSD\"\n",
        "\n",
        "        # Add sender node if not already added\n",
        "        node_id_from = from_addr\n",
        "        if node_id_from not in added_nodes:\n",
        "            dot.node(node_id_from, from_addr_short, fillcolor='lightblue', tooltip=from_addr)\n",
        "            added_nodes.add(node_id_from)\n",
        "\n",
        "        # Add receiver node if not already added\n",
        "        node_id_to = to_addr\n",
        "        if node_id_to not in added_nodes:\n",
        "            dot.node(node_id_to, to_addr_short, fillcolor='palegreen', tooltip=to_addr)\n",
        "            added_nodes.add(node_id_to)\n",
        "\n",
        "        # Add edge for the transfer\n",
        "        edge_style = 'dashed' if transfer.get('failed') else 'solid'\n",
        "        dot.edge(node_id_from, node_id_to, label=amount, style=edge_style)\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Dedicated Export Functions\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets_direct(df, sheet_name=None):\n",
        "    \"\"\"Exports DataFrame directly to Google Sheets using authenticated session.\"\"\"\n",
        "    if sheet_name is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_name = f\"PYUSD Analysis {timestamp}\"\n",
        "\n",
        "    # Use Google Colab integration for direct export\n",
        "    html = f'''\n",
        "    <script src=\"https://apis.google.com/js/platform.js\" async defer></script>\n",
        "    <script>\n",
        "    function createSheet() {{\n",
        "        const csv = `{df.to_csv(index=False).replace('\"', '\"\"')}`;\n",
        "\n",
        "        // Create sheet using Google Colab API\n",
        "        google.colab.kernel.invokeFunction('notebook.createSheet', [csv, '{sheet_name}'], {{}});\n",
        "    }}\n",
        "\n",
        "    // Execute immediately\n",
        "    setTimeout(createSheet, 100);\n",
        "    </script>\n",
        "    <div>Creating Google Sheet \"{sheet_name}\"...</div>\n",
        "    '''\n",
        "\n",
        "    # Register the Python callback that the JavaScript will call\n",
        "    from google.colab import output\n",
        "\n",
        "    @output.register_callback('notebook.createSheet')\n",
        "    def create_sheet_callback(csv_data, name):\n",
        "        try:\n",
        "            from google.colab import auth\n",
        "            from googleapiclient.discovery import build\n",
        "            from googleapiclient.http import MediaInMemoryUpload\n",
        "            import io\n",
        "\n",
        "            # Ensure authentication\n",
        "            auth.authenticate_user()\n",
        "\n",
        "            # Create Drive API client\n",
        "            drive_service = build('drive', 'v3')\n",
        "\n",
        "            # File metadata\n",
        "            file_metadata = {\n",
        "                'name': name,\n",
        "                'mimeType': 'application/vnd.google-apps.spreadsheet'\n",
        "            }\n",
        "\n",
        "            # Create CSV upload\n",
        "            media = MediaInMemoryUpload(\n",
        "                io.BytesIO(csv_data.encode('utf-8')),\n",
        "                mimetype='text/csv',\n",
        "                resumable=True\n",
        "            )\n",
        "\n",
        "            # Create the Sheet\n",
        "            file = drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id,webViewLink'\n",
        "            ).execute()\n",
        "\n",
        "            # Return success with link\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'file_id': file.get('id'),\n",
        "                'link': file.get('webViewLink')\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': str(e)\n",
        "            }\n",
        "\n",
        "    return HTML(html)\n",
        "\n",
        "def analyze_block_trace(block_trace_results_list, block_identifier):\n",
        "    \"\"\"Analyzes the output list from trace_block with PYUSD-focused analysis.\"\"\"\n",
        "    if not isinstance(block_trace_results_list, list): # trace_block should return a list\n",
        "        console.print(f\"[error]Expected a list from trace_block for block {block_identifier}, got {type(block_trace_results_list)}.\", style=\"error\")\n",
        "        display_json(block_trace_results_list, \"Unexpected Result Structure\")\n",
        "        return None\n",
        "    if not block_trace_results_list:\n",
        "        console.print(f\"[warning]No block trace results (empty list) provided for block {block_identifier}.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]üß± Analysis of {len(block_trace_results_list)} Traces for Block {block_identifier}[/bold cyan3]\")\n",
        "    console.print(\"[info]Extracting and categorizing transaction data...\", style=\"info\")\n",
        "\n",
        "    # Initialize counters and trackers\n",
        "    pyusd_interactions_count = 0\n",
        "    total_gas_used_in_traces = 0\n",
        "    failed_traces_count = 0\n",
        "    pyusd_transfer_volume = 0\n",
        "    traces_with_categories = []  # Store traces with their categories\n",
        "\n",
        "    # Process each trace\n",
        "    for i, trace in enumerate(block_trace_results_list):\n",
        "        # Default values\n",
        "        tx_hash = 'N/A'\n",
        "        from_addr = 'N/A'\n",
        "        to_addr = 'N/A'\n",
        "        value_eth = 0\n",
        "        value_eth_str = '0 ETH'\n",
        "        input_data = '0x'\n",
        "        gas_used = 0\n",
        "        error = None\n",
        "        tx_pos = i # Fallback index\n",
        "\n",
        "        try:\n",
        "            # Extract basic trace info\n",
        "            action = trace.get('action', {})\n",
        "            result = trace.get('result', {})\n",
        "            tx_hash = trace.get('transactionHash', action.get('transactionHash', f'trace_{i}'))\n",
        "            tx_pos = trace.get('transactionPosition', tx_pos)\n",
        "\n",
        "            from_addr = action.get('from', 'N/A')\n",
        "            # Handle contract creation ('address') vs. call ('to')\n",
        "            to_addr = action.get('to', action.get('address', 'N/A'))\n",
        "            value_wei_hex = action.get('value', '0x0')\n",
        "            input_data = action.get('input', '0x')\n",
        "\n",
        "            # Check both top-level and result for gasUsed and error\n",
        "            gas_used_hex = result.get('gasUsed', trace.get('gasUsed', '0x0'))\n",
        "            error = trace.get('error', result.get('error', None))\n",
        "\n",
        "            gas_used = int(gas_used_hex, 16) if gas_used_hex and isinstance(gas_used_hex, str) else gas_used_hex or 0\n",
        "\n",
        "            # Convert value from Wei to ETH\n",
        "            if isinstance(value_wei_hex, str) and value_wei_hex.startswith('0x'):\n",
        "                value_eth = int(value_wei_hex, 16) / 1e18\n",
        "            else:\n",
        "                value_eth = (value_wei_hex or 0) / 1e18\n",
        "\n",
        "            value_eth_str = format_value_eth(value_wei_hex)\n",
        "\n",
        "            # Categorize the transaction\n",
        "            category = categorize_transaction(trace)\n",
        "\n",
        "            # Extract PYUSD-specific details if relevant\n",
        "            pyusd_details = extract_pyusd_details(trace) if category.get('is_pyusd') else None\n",
        "\n",
        "            # Update PYUSD transfer volume if this is a PYUSD transfer\n",
        "            if pyusd_details and pyusd_details.get('amount') and 'transfer' in (pyusd_details.get('function') or '').lower():\n",
        "                pyusd_transfer_volume += pyusd_details['amount']\n",
        "\n",
        "        except Exception as parse_err:\n",
        "            console.print(f\"[warning]Could not fully parse trace item {i} in block {block_identifier}: {parse_err}\", style=\"warning\")\n",
        "            error = f\"Parse Error: {parse_err}\" # Mark as failed due to parsing\n",
        "            category = {'type': 'unknown', 'description': 'Parse Error', 'is_pyusd': False}\n",
        "            pyusd_details = None\n",
        "\n",
        "        # Update counters\n",
        "        if category.get('is_pyusd'):\n",
        "            pyusd_interactions_count += 1\n",
        "        if error:\n",
        "            failed_traces_count += 1\n",
        "        total_gas_used_in_traces += gas_used\n",
        "\n",
        "        # Store trace with category and details\n",
        "        trace_summary = {\n",
        "            'tx_index': tx_pos,\n",
        "            'tx_hash': tx_hash,\n",
        "            'from': from_addr,\n",
        "            'to': to_addr,\n",
        "            'value_eth': value_eth,\n",
        "            'value_eth_str': value_eth_str,\n",
        "            'gas_used': gas_used,\n",
        "            'failed': error is not None,\n",
        "            'error': error,\n",
        "            'category': category,\n",
        "            'pyusd_details': pyusd_details,\n",
        "            'input_preview': input_data[:10] + ('...' if len(input_data)>10 else ''),\n",
        "        }\n",
        "\n",
        "        traces_with_categories.append(trace_summary)\n",
        "\n",
        "    # Sort traces by transaction index\n",
        "    traces_with_categories.sort(key=lambda x: x['tx_index'] if isinstance(x['tx_index'], int) else float('inf'))\n",
        "\n",
        "    # Create DataFrame for display - include full addresses for proper data analysis\n",
        "    # Use only one index (not creating an extra 'index' column)\n",
        "    summary_df = pd.DataFrame([{\n",
        "        'tx_index': t['tx_index'],\n",
        "        'tx_hash': t['tx_hash'],\n",
        "        'from': t['from'],  # Full address\n",
        "        'to': t['to'],      # Full address\n",
        "        'value': t['value_eth_str'],\n",
        "        'gas_used': t['gas_used'],\n",
        "        'type': t['category']['description'],\n",
        "        'failed': t['failed'],\n",
        "        'pyusd': t['category'].get('is_pyusd', False)\n",
        "    } for t in traces_with_categories])\n",
        "\n",
        "    # Display Block Summary Panel\n",
        "    block_num = block_identifier\n",
        "    if isinstance(block_identifier, str) and block_identifier.startswith('0x'):\n",
        "        try:\n",
        "            block_num = int(block_identifier, 16)\n",
        "        except:\n",
        "            block_num = block_identifier\n",
        "\n",
        "    # Add more spacing before summary panel\n",
        "    console.print(\"\\n\")\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold]Block Trace Analysis (Block {block_num})[/bold]\n",
        "Transactions Traced: {len(block_trace_results_list)}\n",
        "Total Gas Used (Sum): {total_gas_used_in_traces:,}\n",
        "Traces with Errors: {failed_traces_count}\n",
        "PYUSD Interactions: {pyusd_interactions_count}\n",
        "PYUSD Transfer Volume: {pyusd_transfer_volume:.2f} PYUSD\"\"\",\n",
        "        title=\"üß± trace_block Analysis\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # Analyze gas distribution\n",
        "    console.print(\"\\n\\n[bold chartreuse1]ANALYZING GAS USAGE PATTERNS ACROSS TRANSACTION TYPES[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "    gas_analysis = analyze_gas_distribution(traces_with_categories)\n",
        "\n",
        "    # Add spacing before gas analysis\n",
        "    console.print(\"\\n\\n[bold chartreuse1]üìä Gas Usage Analysis by Transaction Type[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    # Create and display gas usage tables\n",
        "    gas_table = Table(title=\"\", title_style=\"bold chartreuse1\")\n",
        "    gas_table.add_column(\"Transaction Type\", style=\"chartreuse1\")\n",
        "    gas_table.add_column(\"Count\", justify=\"right\")\n",
        "    gas_table.add_column(\"Total Gas\", justify=\"right\")\n",
        "    gas_table.add_column(\"Avg Gas/Tx\", justify=\"right\")\n",
        "    gas_table.add_column(\"% of Total\", justify=\"right\")\n",
        "\n",
        "    for category, data in sorted(gas_analysis['by_category'].items(), key=lambda x: x[1]['gas'], reverse=True):\n",
        "        if data['gas'] > 0:  # Only include categories with gas usage\n",
        "            avg_gas = data['gas'] // data['count'] if data['count'] > 0 else 0\n",
        "            pct_total = (data['gas'] / total_gas_used_in_traces * 100) if total_gas_used_in_traces > 0 else 0\n",
        "            gas_table.add_row(\n",
        "                category.replace('_', ' ').title(),\n",
        "                f\"{data['count']:,}\",\n",
        "                f\"{data['gas']:,}\",\n",
        "                f\"{avg_gas:,}\",\n",
        "                f\"{pct_total:.1f}%\"\n",
        "            )\n",
        "\n",
        "    console.print(gas_table)\n",
        "\n",
        "    # PYUSD specific analysis - only if there are PYUSD interactions\n",
        "    if pyusd_interactions_count > 0:\n",
        "        console.print(\"\\n\\n[bold chartreuse1]ü™ô PYUSD Transactions Analysis in Block[/bold chartreuse1]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "        # Create PYUSD-specific table\n",
        "        pyusd_table = Table(title=\"\", title_style=\"bold chartreuse1\")\n",
        "        pyusd_table.add_column(\"Tx Hash\", style=\"dim\")\n",
        "        pyusd_table.add_column(\"Function\")\n",
        "        pyusd_table.add_column(\"From\")\n",
        "        pyusd_table.add_column(\"To\")\n",
        "        pyusd_table.add_column(\"Amount\")\n",
        "        pyusd_table.add_column(\"Gas Used\")\n",
        "        pyusd_table.add_column(\"Status\")\n",
        "\n",
        "        # Get all PYUSD transactions\n",
        "        pyusd_txs = [t for t in traces_with_categories if t['category'].get('is_pyusd')]\n",
        "\n",
        "        # Sort by gas used (descending)\n",
        "        pyusd_txs.sort(key=lambda x: x['gas_used'], reverse=True)\n",
        "\n",
        "        # Add rows for PYUSD transactions (limit to first 15 to avoid huge output)\n",
        "        for tx in pyusd_txs[:15]:\n",
        "            details = tx['pyusd_details'] or {}\n",
        "            function = tx['category'].get('function_name', 'Unknown')\n",
        "\n",
        "            # Format from/to addresses - showing full addresses on hover\n",
        "            from_full = details.get('from_addr') or tx['from']\n",
        "            from_addr = f\"{from_full[:6]}...{from_full[-4:]}\" if from_full and len(from_full) > 10 else from_full\n",
        "\n",
        "            to_full = None\n",
        "            if details.get('to_addr'):\n",
        "                to_full = details['to_addr']\n",
        "            elif 'approve' in function.lower() and details.get('params', {}).get('spender'):\n",
        "                to_full = details['params']['spender']\n",
        "\n",
        "            to_addr = f\"{to_full[:6]}...{to_full[-4:]}\" if to_full and len(to_full) > 10 else \"N/A\"\n",
        "\n",
        "            # Format amount\n",
        "            amount = \"N/A\"\n",
        "            if details.get('amount') is not None:\n",
        "                amount = f\"{details['amount']:.2f} PYUSD\"\n",
        "\n",
        "            # Format status\n",
        "            status_color = \"red\" if tx['failed'] else \"green\"\n",
        "            status_text = \"Failed\" if tx['failed'] else \"Success\"\n",
        "\n",
        "            # Format transaction hash\n",
        "            tx_hash = tx['tx_hash']\n",
        "            tx_hash_display = f\"{tx_hash[:10]}...\" if len(tx_hash) > 12 else tx_hash\n",
        "\n",
        "            # Add row with full data in title attributes\n",
        "            pyusd_table.add_row(\n",
        "                tx_hash_display,\n",
        "                function,\n",
        "                from_addr,\n",
        "                to_addr,\n",
        "                amount,\n",
        "                f\"{tx['gas_used']:,}\",\n",
        "                f\"[{status_color}]{status_text}[/{status_color}]\"\n",
        "            )\n",
        "\n",
        "        if len(pyusd_txs) > 15:\n",
        "            pyusd_table.add_row(\n",
        "                \"...\",\n",
        "                f\"+ {len(pyusd_txs) - 15} more\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        console.print(pyusd_table)\n",
        "\n",
        "        # Analyze PYUSD token flow\n",
        "        console.print(\"\\n\\n[bold yellow3]ANALYZING PYUSD TOKEN FLOW WITHIN THE BLOCK[/bold yellow3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "        flow_analysis = analyze_pyusd_flow(traces_with_categories, block_num)\n",
        "\n",
        "        # Display flow summary\n",
        "        flow_panel = Panel(f\"\"\"\n",
        "[bold]PYUSD Token Flow in Block {block_num}[/bold]\n",
        "Total PYUSD Transferred: {flow_analysis['total_transferred']:.2f} PYUSD\n",
        "Transfer Transactions: {flow_analysis['transfer_count']}\n",
        "Approval Transactions: {flow_analysis['approval_count']}\n",
        "Other PYUSD Transactions: {flow_analysis['other_count']}\n",
        "Unique Senders: {flow_analysis['unique_senders_count']}\n",
        "Unique Receivers: {flow_analysis['unique_receivers_count']}\"\"\",\n",
        "            title=\"üîÑ PYUSD Flow Analysis\", border_style=\"yellow3\", expand=False)\n",
        "\n",
        "        console.print(flow_panel)\n",
        "\n",
        "        # Create and display flow diagram if there are transfers\n",
        "        if flow_analysis['transfers']:\n",
        "            console.print(\"\\n\\n[bold magenta3]PYUSD Token Flow Fiagram (Top Transfers)[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "            try:\n",
        "                flow_diagram = create_pyusd_flow_diagram(flow_analysis)\n",
        "                if flow_diagram:\n",
        "                    display(flow_diagram)\n",
        "            except Exception as viz_err:\n",
        "                console.print(f\"[warning]Could not create flow visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Visualize gas distribution with better spacing\n",
        "    console.print(\"\\n\\n[bold magenta3]Gas Usage Distribution in Block[/bold magenta3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "    try:\n",
        "        gas_viz = visualize_gas_distribution(gas_analysis)\n",
        "        display(gas_viz)\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create gas visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Show filter options first\n",
        "    console.print(\"\\n\\n[bold cyan3]üìã Block Transaction Summary[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create filter controls and PYUSD-focused display\n",
        "    if not summary_df.empty:\n",
        "        # Create PYUSD-only and All transactions dataframes\n",
        "        pyusd_df = summary_df[summary_df['pyusd'] == True].copy()\n",
        "\n",
        "        # Filter options above the table\n",
        "        display(widgets.HTML(\"<h4>Filter Options:</h4>\"))\n",
        "\n",
        "        # Keep both buttons - arranged in an HBox for better layout\n",
        "        filter_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Show PYUSD Only',\n",
        "                button_style='success',\n",
        "                layout=widgets.Layout(width='180px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Show All Transactions',\n",
        "                button_style='info',\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        display(filter_buttons)\n",
        "\n",
        "        # Output area for transactions\n",
        "        transaction_output = widgets.Output()\n",
        "\n",
        "        # Export buttons below the table with better styling\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Export to CSV',\n",
        "                button_style='primary',  # Green\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export as JSON',\n",
        "                button_style='warning',  # Orange\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export to Google Sheets',\n",
        "                button_style='info',     # Blue\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        export_output = widgets.Output()\n",
        "\n",
        "        def show_all_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                display(summary_df)\n",
        "\n",
        "        def show_pyusd_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                display(pyusd_df)\n",
        "\n",
        "        # Export handlers\n",
        "        def export_csv(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame\n",
        "                current_df = summary_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) > len(str(pyusd_df)) else pyusd_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_num}_transactions_{timestamp}.csv\"\n",
        "                display(download_csv_direct(current_df, filename))\n",
        "\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame\n",
        "                current_df = summary_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) > len(str(pyusd_df)) else pyusd_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_num}_transactions_{timestamp}.json\"\n",
        "                records = current_df.to_dict('records')\n",
        "                display(download_json_direct(records, filename))\n",
        "\n",
        "        def export_to_sheets(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame\n",
        "                current_df = summary_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) > len(str(pyusd_df)) else pyusd_df\n",
        "                sheet_name = f\"Block {block_num} Transactions {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "                display(export_to_google_sheets_direct(current_df, sheet_name))\n",
        "\n",
        "        # Connect callbacks\n",
        "        filter_buttons.children[0].on_click(show_pyusd_txs)   # PYUSD Only button\n",
        "        filter_buttons.children[1].on_click(show_all_txs)     # Show All button\n",
        "        export_buttons.children[0].on_click(export_csv)\n",
        "        export_buttons.children[1].on_click(export_json)\n",
        "        export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "        # Display transaction table area\n",
        "        display(transaction_output)\n",
        "\n",
        "        # Show PYUSD transactions by default\n",
        "        show_pyusd_txs(None)\n",
        "\n",
        "        # Export section below the table\n",
        "        console.print(\"\\n\\n[bold]Export Options:[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        display(export_buttons)\n",
        "        display(export_output)\n",
        "\n",
        "    # Return both the basic DataFrame and the enhanced data\n",
        "    return {\n",
        "        'summary_df': summary_df,\n",
        "        'traces_with_categories': traces_with_categories,\n",
        "        'gas_analysis': gas_analysis,\n",
        "        'pyusd_interactions': pyusd_interactions_count,\n",
        "        'total_gas_used': total_gas_used_in_traces,\n",
        "        'pyusd_transfer_volume': pyusd_transfer_volume\n",
        "    }\n",
        "\n",
        "# --- Execute Block Tracing ---\n",
        "# WARNING: Tracing a full block can be slow. Default to False.\n",
        "RUN_TRACE_BLOCK = True # <<< SET TO TRUE TO RUN THIS EXPENSIVE TRACE\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_trace_block = TARGET_BLOCK_IDENTIFIER\n",
        "    block_id_for_rpc = None\n",
        "\n",
        "    # Format block identifier for trace_block (requires hex string or tag)\n",
        "    if isinstance(block_id_trace_block, int):\n",
        "        block_id_for_rpc = hex(block_id_trace_block)\n",
        "    elif isinstance(block_id_trace_block, str):\n",
        "        if block_id_trace_block.startswith(\"0x\"):\n",
        "            block_id_for_rpc = block_id_trace_block # Hash or Hex Number\n",
        "        elif block_id_trace_block in [\"latest\", \"pending\", \"earliest\"]:\n",
        "            block_id_for_rpc = block_id_trace_block\n",
        "        else: # Try converting string int\n",
        "             try:\n",
        "                 block_id_for_rpc = hex(int(block_id_trace_block))\n",
        "             except ValueError:\n",
        "                 console.print(f\"[error]Invalid TARGET_BLOCK_IDENTIFIER '{block_id_trace_block}' for trace_block. Needs hex string, int, or tag.\", style=\"error\")\n",
        "\n",
        "    if RUN_TRACE_BLOCK and block_id_for_rpc:\n",
        "        console.print(\"\\n\\n[bold]üß± Tracing & Analyis via trace_block[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        console.print(f\"\\n\\n[warning]Attempting 'trace_block' for {block_id_for_rpc} on Mainnet (Can be SLOW!)...[/warning]\", style=\"warning\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        block_trace_results = make_rpc_request(\"trace_block\", [block_id_for_rpc], network='mainnet')\n",
        "        end_time = time.time()\n",
        "\n",
        "        trace_time = end_time - start_time\n",
        "        console.print(f\"[info]trace_block API call completed in {trace_time:.2f} seconds\", style=\"info\")\n",
        "\n",
        "        if block_trace_results is not None: # Check for None explicitly, as empty list is valid\n",
        "            console.print(\"[success]Successfully retrieved block trace data.\", style=\"success\")\n",
        "            analysis_results = analyze_block_trace(block_trace_results, block_id_for_rpc)\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to get block trace for {block_id_for_rpc} using 'trace_block'. RPC call failed, timed out, or returned null.\", style=\"error\")\n",
        "\n",
        "    elif not RUN_TRACE_BLOCK:\n",
        "        console.print(f\"\\n[info]Skipping 'trace_block' as RUN_TRACE_BLOCK is False.\", style=\"info\")\n",
        "        console.print(f\"[info]Set RUN_TRACE_BLOCK = True to execute this cell with the target block {block_id_trace_block}.\", style=\"info\")\n",
        "    elif not block_id_for_rpc:\n",
        "         pass # Error already printed\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping trace_block analysis.\", style=\"warning\")\n",
        "    console.print(\"[info]Set TARGET_BLOCK_IDENTIFIER to a block number or hash to use this cell.\", style=\"info\")"
      ],
      "metadata": {
        "id": "Lt34TjimUeF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 üß± `debug_traceBlockByNumber` and `debug_traceBlockByHash`: Detailed Block Tracing\n",
        "---\n",
        "\n",
        "This section explores tracing all transactions within a block using methods from the `debug` namespace: `debug_traceBlockByNumber` (which takes a block number) **and** `debug_traceBlockByHash` (which takes a block hash).\n",
        "\n",
        "Unlike `trace_block` (from the `trace` namespace), these `debug_` methods often provide **more detailed trace outputs for *each* transaction** within the block, typically defaulting to a format similar to `debug_traceTransaction`'s `callTracer` on GCP. This allows for a deeper analysis of the internal execution flow of every transaction in the target block.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Methods:** `debug_traceBlockByNumber`, `debug_traceBlockByHash`\n",
        "> *   **Multiplier:** `50x` (Each method call)\n",
        "> *   **GCP Advantage:** Tracing full blocks with this level of detail per transaction is highly resource-intensive. GCP's infrastructure and free quotas make it feasible to retrieve and process these potentially very large and numerous trace results efficiently.\n",
        "> *   **PYUSD Insight:** These methods enable:\n",
        ">     *   Detailed analysis of **internal calls** for *all* transactions interacting with PYUSD in a block, not just a single target transaction.\n",
        ">     *   Identifying **indirect PYUSD interactions** where a contract called by the main transaction subsequently interacts with PYUSD.\n",
        ">     *   Comparing gas efficiency and execution paths of multiple PYUSD transactions within the same block context.\n",
        ">     *   Analyzing block-level **MEV patterns** (like sandwich attacks) by examining the detailed traces of surrounding transactions.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Detailed Block Trace:**\n",
        "    *   The first part calls `debug_traceBlockByNumber` using the target block identifier (converted to a hex number or tag) and a tracer configuration (typically `callTracer`).\n",
        "    *   The second part retrieves the corresponding block hash and then calls `debug_traceBlockByHash` with the hash and the tracer configuration.\n",
        "2.  **Process Individual Traces:** The `analyze_debug_block_trace` function is reused for the output list from *both* methods. It iterates through the list, where each item usually contains the detailed trace result for one transaction.\n",
        "3.  **Categorize & Analyze:**\n",
        "    *   Extracts details (gas, status, function calls) for each transaction's trace.\n",
        "    *   Specifically identifies PYUSD function calls and categories.\n",
        "    *   Detects internal transactions involving PYUSD (`detect_pyusd_internal_transactions`).\n",
        "4.  **Visualize & Summarize:** (Outputs are generated for results from both methods if run)\n",
        "    *   **Enhanced Block Summary:** Includes counts for PYUSD transfers, mints, burns, and total volume within the block.\n",
        "    *   **PYUSD Function Analysis:** Shows distribution and visualization of PYUSD functions called across the block.\n",
        "    *   **Internal Call Table:** Lists detected internal calls to PYUSD contracts.\n",
        "    *   **Gas & Transfer Visualizations:** Plots gas distribution and PYUSD transfer networks for the block.\n",
        "    *   **Transaction Table:** Interactive summary table for all transactions.\n",
        "    *   **Export Options:** Download block summary data.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   Compare the outputs/analyses from `debug_traceBlockByNumber` and `debug_traceBlockByHash` for consistency (they should generally be the same if targeting the same block).\n",
        "*   **PYUSD Function Distribution:** Which PYUSD functions were most commonly called in this block?\n",
        "*   **Internal PYUSD Calls:** Did contracts *other than* the main target interact with PYUSD?\n",
        "*   **Gas Comparison:** Compare the gas usage of similar PYUSD operations within the same block.\n",
        "*   **Correlated Activity:** Examine traces of transactions near PYUSD interactions for related DeFi or MEV activity."
      ],
      "metadata": {
        "id": "2VAJLLSVVxC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üß± Trace Block using debug_traceBlockByNumber / debug_traceBlockByHash\n",
        "# =============================================================================================\n",
        "# Note: Output format can be complex and node-dependent. Often returns a list of objects,\n",
        "# each containing a 'result' which holds the trace (e.g., callTracer format).\n",
        "# This cell performs detailed tracing and analysis of all transactions within a specific block\n",
        "# using the `debug_traceBlockByNumber` and `debug_traceBlockByHash` RPC methods, providing\n",
        "# deep insights into block activity with a focus on PYUSD interactions.\n",
        "#\n",
        "# Functionality includes:\n",
        "# - Fetching detailed execution traces (e.g., callTracer output) for every transaction\n",
        "#   in the target block via both debug methods.\n",
        "# - Processing each transaction's trace to extract key information (from, to, gas, status, calls).\n",
        "# - Analyzing PYUSD-specific interactions: function decoding, volume calculation, internal call detection.\n",
        "# - Generating comprehensive analysis outputs: summary panel, function category table/pie chart,\n",
        "#   direct PYUSD interactions table, internal calls table.\n",
        "# - Visualizing block-level data: PYUSD transfer network graph (Graphviz), gas usage distribution histogram (Plotly).\n",
        "# - Providing an interactive table (ipywidgets/pandas) for all block transactions with PYUSD filtering.\n",
        "# - Offering direct export options for the analysis results to CSV, JSON, and Google Sheets.\n",
        "# - Leveraging GCP's premium RPC capabilities for these resource-intensive debug methods on Mainnet.\n",
        "\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, clear_output\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Dedicated Export Functions\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets_direct(df, sheet_name=None):\n",
        "    \"\"\"Exports DataFrame directly to Google Sheets using authenticated session.\"\"\"\n",
        "    if sheet_name is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_name = f\"PYUSD Analysis {timestamp}\"\n",
        "\n",
        "    # Use Google Colab integration for direct export\n",
        "    html = f'''\n",
        "    <script src=\"https://apis.google.com/js/platform.js\" async defer></script>\n",
        "    <script>\n",
        "    function createSheet() {{\n",
        "        const csv = `{df.to_csv(index=False).replace('\"', '\"\"')}`;\n",
        "\n",
        "        // Create sheet using Google Colab API\n",
        "        google.colab.kernel.invokeFunction('notebook.createSheet', [csv, '{sheet_name}'], {{}});\n",
        "    }}\n",
        "\n",
        "    // Execute immediately\n",
        "    setTimeout(createSheet, 100);\n",
        "    </script>\n",
        "    <div>Creating Google Sheet \"{sheet_name}\"...</div>\n",
        "    '''\n",
        "\n",
        "    # Register the Python callback that the JavaScript will call\n",
        "    from google.colab import output\n",
        "\n",
        "    @output.register_callback('notebook.createSheet')\n",
        "    def create_sheet_callback(csv_data, name):\n",
        "        try:\n",
        "            from google.colab import auth\n",
        "            from googleapiclient.discovery import build\n",
        "            from googleapiclient.http import MediaInMemoryUpload\n",
        "            import io\n",
        "\n",
        "            # Ensure authentication\n",
        "            auth.authenticate_user()\n",
        "\n",
        "            # Create Drive API client\n",
        "            drive_service = build('drive', 'v3')\n",
        "\n",
        "            # File metadata\n",
        "            file_metadata = {\n",
        "                'name': name,\n",
        "                'mimeType': 'application/vnd.google-apps.spreadsheet'\n",
        "            }\n",
        "\n",
        "            # Create CSV upload\n",
        "            media = MediaInMemoryUpload(\n",
        "                io.BytesIO(csv_data.encode('utf-8')),\n",
        "                mimetype='text/csv',\n",
        "                resumable=True\n",
        "            )\n",
        "\n",
        "            # Create the Sheet\n",
        "            file = drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id,webViewLink'\n",
        "            ).execute()\n",
        "\n",
        "            # Return success with link\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'file_id': file.get('id'),\n",
        "                'link': file.get('webViewLink')\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': str(e)\n",
        "            }\n",
        "\n",
        "    return HTML(html)\n",
        "\n",
        "def detect_pyusd_internal_transactions(debug_trace_list):\n",
        "    \"\"\"Analyze traces for PYUSD internal transactions (contracts calling PYUSD).\"\"\"\n",
        "    internal_txs = []\n",
        "\n",
        "    for i, trace_item in enumerate(debug_trace_list):\n",
        "        tx_hash = trace_item.get('txHash', f'tx_{i}')\n",
        "        trace_result = trace_item.get('result', {})\n",
        "\n",
        "        # Skip if there are no calls\n",
        "        if not isinstance(trace_result.get('calls'), list):\n",
        "            continue\n",
        "\n",
        "        # Function to recursively process calls\n",
        "        def process_calls(calls, depth=0, parent_from=None, parent_to=None):\n",
        "            for call in calls:\n",
        "                call_to = call.get('to', '')\n",
        "                call_from = call.get('from', parent_from if parent_from else '')\n",
        "                call_type = call.get('type', 'CALL')\n",
        "                call_input = call.get('input', '0x')\n",
        "                call_gas_used = call.get('gasUsed', '0x0')\n",
        "\n",
        "                # Check if this call is to a PYUSD contract\n",
        "                if call_to and call_to.lower() in PYUSD_CONTRACTS:\n",
        "                    # Try to decode the function\n",
        "                    function_name = \"Unknown\"\n",
        "                    if call_input and len(call_input) >= 10:\n",
        "                        method_sig = call_input[:10]\n",
        "                        if method_sig in PYUSD_SIGNATURES:\n",
        "                            function_name = PYUSD_SIGNATURES[method_sig][\"name\"]\n",
        "\n",
        "                    # Record this internal transaction\n",
        "                    internal_txs.append({\n",
        "                        'tx_hash': tx_hash,\n",
        "                        'from': call_from,\n",
        "                        'to': call_to,\n",
        "                        'to_contract': get_contract_name(call_to),\n",
        "                        'function': function_name,\n",
        "                        'call_type': call_type,\n",
        "                        'gas_used': int(call_gas_used, 16) if isinstance(call_gas_used, str) else call_gas_used,\n",
        "                        'depth': depth\n",
        "                    })\n",
        "\n",
        "                # Process nested calls recursively\n",
        "                if isinstance(call.get('calls'), list):\n",
        "                    process_calls(call['calls'], depth + 1, call_from, call_to)\n",
        "\n",
        "        # Start processing from the top level calls\n",
        "        if isinstance(trace_result.get('calls'), list):\n",
        "            process_calls(trace_result['calls'])\n",
        "\n",
        "    return internal_txs\n",
        "\n",
        "def analyze_debug_block_trace(debug_trace_list, block_identifier):\n",
        "    \"\"\"Analyzes the output list from debug_traceBlockByNumber/Hash with PYUSD focus.\"\"\"\n",
        "    if not isinstance(debug_trace_list, list):\n",
        "        console.print(f\"[error]Expected a list from debug_traceBlock for {block_identifier}, got {type(debug_trace_list)}.\", style=\"error\")\n",
        "        display_json(debug_trace_list, \"Unexpected Result Structure\")\n",
        "        return None\n",
        "    if not debug_trace_list:\n",
        "        console.print(f\"[warning]No trace results (empty list) from debug_traceBlock for {block_identifier}.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]Analyzing {len(debug_trace_list)} Traces from debug_traceBlock for {block_identifier}[/bold cyan3]\")\n",
        "\n",
        "    # Counters and aggregators\n",
        "    pyusd_interactions_count = 0\n",
        "    pyusd_transfer_count = 0\n",
        "    pyusd_mint_count = 0\n",
        "    pyusd_burn_count = 0\n",
        "    total_gas_used = 0\n",
        "    failed_traces_count = 0\n",
        "\n",
        "    # Track PYUSD transfers within block\n",
        "    pyusd_transfers = []\n",
        "    pyusd_volume = 0\n",
        "\n",
        "    # Track function categories\n",
        "    function_categories = {\n",
        "        \"token_movement\": 0,\n",
        "        \"supply_change\": 0,\n",
        "        \"allowance\": 0,\n",
        "        \"control\": 0,\n",
        "        \"admin\": 0,\n",
        "        \"view\": 0,\n",
        "        \"other\": 0\n",
        "    }\n",
        "\n",
        "    trace_summary_list = []\n",
        "\n",
        "    for i, trace_item in enumerate(debug_trace_list):\n",
        "        # Default values\n",
        "        tx_hash = 'N/A'\n",
        "        from_addr = 'N/A'\n",
        "        to_addr = 'N/A'\n",
        "        value_eth_str = '0 ETH'\n",
        "        gas_used = 0\n",
        "        error = None\n",
        "        interacted_with_pyusd = False\n",
        "        tx_pos = i  # Fallback index\n",
        "        pyusd_function = None\n",
        "        pyusd_function_category = \"other\"\n",
        "        is_pyusd_transfer = False\n",
        "        is_pyusd_mint = False\n",
        "        is_pyusd_burn = False\n",
        "        transfer_value = 0\n",
        "\n",
        "        try:\n",
        "            # debug_traceBlock* often nests the main trace info under 'result'\n",
        "            trace_result = trace_item.get('result', {})  # Get the nested trace\n",
        "            tx_hash = trace_item.get('txHash', f'tx_{i}')  # Hash might be at top level\n",
        "\n",
        "            # Parse fields from the nested 'result' if it exists\n",
        "            if trace_result:\n",
        "                from_addr = trace_result.get('from', 'N/A')\n",
        "                to_addr = trace_result.get('to', 'N/A')\n",
        "                value_wei_hex = trace_result.get('value', '0x0')\n",
        "                gas_used_hex = trace_result.get('gasUsed', '0x0')\n",
        "                error = trace_result.get('error')  # Error within the execution\n",
        "                input_data = trace_result.get('input', '0x')\n",
        "\n",
        "                gas_used = int(gas_used_hex, 16) if gas_used_hex else 0\n",
        "                value_eth_str = format_value_eth(value_wei_hex)\n",
        "\n",
        "                # Check for PYUSD contract interactions\n",
        "                interacted_with_pyusd = to_addr and to_addr.lower() in PYUSD_CONTRACTS\n",
        "\n",
        "                # If this is a PYUSD interaction, analyze the function being called\n",
        "                if interacted_with_pyusd and input_data and input_data != '0x':\n",
        "                    method_sig = input_data[:10]\n",
        "\n",
        "                    if method_sig in PYUSD_SIGNATURES:\n",
        "                        sig_info = PYUSD_SIGNATURES[method_sig]\n",
        "                        pyusd_function = sig_info[\"name\"]\n",
        "                        pyusd_function_category = sig_info[\"category\"]\n",
        "\n",
        "                        # Track function category\n",
        "                        function_categories[pyusd_function_category] += 1\n",
        "\n",
        "                        # Check for specific functions\n",
        "                        if method_sig == '0xa9059cbb':  # transfer\n",
        "                            is_pyusd_transfer = True\n",
        "                            pyusd_transfer_count += 1\n",
        "\n",
        "                            # Try to decode transfer parameters\n",
        "                            try:\n",
        "                                to_offset = 10\n",
        "                                to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                                amount_offset = 74\n",
        "                                amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                                transfer_value = amount\n",
        "                                pyusd_volume += amount\n",
        "\n",
        "                                # Track transfer for visualization\n",
        "                                pyusd_transfers.append({\n",
        "                                    'from': from_addr,\n",
        "                                    'to': to_param,\n",
        "                                    'value': amount,\n",
        "                                    'tx_hash': tx_hash\n",
        "                                })\n",
        "                            except Exception:\n",
        "                                pass\n",
        "\n",
        "                        elif method_sig == '0x40c10f19':  # mint\n",
        "                            is_pyusd_mint = True\n",
        "                            pyusd_mint_count += 1\n",
        "\n",
        "                            # Try to decode mint amount\n",
        "                            try:\n",
        "                                amount_offset = 74\n",
        "                                amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                                transfer_value = amount\n",
        "                                pyusd_volume += amount\n",
        "                            except Exception:\n",
        "                                pass\n",
        "\n",
        "                        elif method_sig == '0x42966c68':  # burn\n",
        "                            is_pyusd_burn = True\n",
        "                            pyusd_burn_count += 1\n",
        "\n",
        "                            # Try to decode burn amount\n",
        "                            try:\n",
        "                                amount_offset = 10\n",
        "                                amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                                transfer_value = amount\n",
        "                                pyusd_volume += amount\n",
        "                            except Exception:\n",
        "                                pass\n",
        "\n",
        "                # Check for sub-calls that might interact with PYUSD\n",
        "                if 'calls' in trace_result and isinstance(trace_result['calls'], list):\n",
        "                    for call in trace_result['calls']:\n",
        "                        if call.get('to', '').lower() in PYUSD_CONTRACTS:\n",
        "                            interacted_with_pyusd = True\n",
        "                            break\n",
        "            else:\n",
        "                # Handle cases where 'result' is missing - trace might have failed earlier\n",
        "                error = trace_item.get('error', 'Missing trace result')  # Check top level error\n",
        "\n",
        "        except Exception as parse_err:\n",
        "            console.print(f\"[warning]Could not fully parse trace item {i} in debug block trace {block_identifier}: {parse_err}\", style=\"warning\")\n",
        "            error = f\"Parse Error: {parse_err}\"\n",
        "\n",
        "        if error:\n",
        "            failed_traces_count += 1\n",
        "        if interacted_with_pyusd:\n",
        "            pyusd_interactions_count += 1\n",
        "        total_gas_used += gas_used\n",
        "\n",
        "        trace_summary_list.append({\n",
        "            'tx_index': tx_pos,  # Using list index as fallback for tx position\n",
        "            'tx_hash': tx_hash,\n",
        "            'from': from_addr,\n",
        "            'to': to_addr,\n",
        "            'value_eth': value_eth_str,\n",
        "            'gas_used': gas_used,\n",
        "            'failed': error is not None,\n",
        "            'pyusd_interaction': interacted_with_pyusd,\n",
        "            'pyusd_function': pyusd_function,\n",
        "            'pyusd_function_category': pyusd_function_category,\n",
        "            'is_pyusd_transfer': is_pyusd_transfer,\n",
        "            'is_pyusd_mint': is_pyusd_mint,\n",
        "            'is_pyusd_burn': is_pyusd_burn,\n",
        "            'transfer_value': transfer_value\n",
        "        })\n",
        "\n",
        "    summary_df = pd.DataFrame(trace_summary_list)\n",
        "\n",
        "    # Calculate key metrics\n",
        "    pyusd_volume_formatted = format_value_pyusd(pyusd_volume) if pyusd_volume > 0 else \"0 PYUSD\"\n",
        "    pyusd_pct = (pyusd_interactions_count / len(debug_trace_list) * 100) if debug_trace_list else 0\n",
        "\n",
        "    # Display Enhanced Summary Stats\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold cyan3]Enhanced debug_traceBlock Summary ({block_identifier})[/bold cyan3]\n",
        "[bold cyan3]Transactions Traced:[/bold cyan3] {len(debug_trace_list)}\n",
        "[bold cyan3]Total Gas Used:[/bold cyan3] {total_gas_used:,}\n",
        "[bold cyan3]Traces with Errors:[/bold cyan3] {failed_traces_count}\n",
        "\n",
        "[bold green3]PYUSD Activity[/bold green3]\n",
        "[bold green3]PYUSD Interactions:[/bold green3] {pyusd_interactions_count} ({pyusd_pct:.1f}% of transactions)\n",
        "[bold green3]PYUSD Transfers:[/bold green3] {pyusd_transfer_count}\n",
        "[bold green3]PYUSD Mints:[/bold green3] {pyusd_mint_count}\n",
        "[bold green3]PYUSD Burns:[/bold green3] {pyusd_burn_count}\n",
        "[bold green3]PYUSD Volume:[/bold green3] {pyusd_volume_formatted}\"\"\",\n",
        "        title=\"debug_traceBlock Analysis\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # Display function category breakdown if any PYUSD activity\n",
        "    console.print(\"\\n\\n[bold]PYUSD Function Categories[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    if pyusd_interactions_count > 0:\n",
        "        category_table = Table(title=\"\", show_header=True, header_style=\"bold green3\")\n",
        "        category_table.add_column(\"Category\")\n",
        "        category_table.add_column(\"Count\", justify=\"right\")\n",
        "        category_table.add_column(\"Percentage\", justify=\"right\")\n",
        "\n",
        "        for category, count in function_categories.items():\n",
        "            if count > 0:\n",
        "                percentage = (count / pyusd_interactions_count * 100)\n",
        "                category_table.add_row(\n",
        "                    category.replace('_', ' ').title(),\n",
        "                    str(count),\n",
        "                    f\"{percentage:.1f}%\"\n",
        "                )\n",
        "\n",
        "        console.print(category_table)\n",
        "\n",
        "        # Create visualization of function categories\n",
        "        try:\n",
        "            console.print(f\"\\n\\n[bold]PYUSD Function Categories in Block Visualization: [cyan3]{block_identifier}[/cyan3][/bold]\", style=\"magenta3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            category_data = pd.DataFrame([\n",
        "                {\"category\": cat.replace('_', ' ').title(), \"count\": count}\n",
        "                for cat, count in function_categories.items() if count > 0\n",
        "            ])\n",
        "\n",
        "            if not category_data.empty:\n",
        "                fig_categories = px.pie(\n",
        "                    category_data, values='count', names='category',\n",
        "                    title=f'PYUSD Function Categories in Block {block_identifier}'\n",
        "                )\n",
        "                fig_categories.update_layout(template=\"plotly_white\")\n",
        "                fig_categories.show()\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create function category visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Display PYUSD-specific transactions\n",
        "    if pyusd_interactions_count > 0 and not summary_df.empty:\n",
        "        console.print(\"\\n\\n[bold green3]üìä PYUSD Interactions in Block[/bold green3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "\n",
        "        pyusd_txs = summary_df[summary_df['pyusd_interaction']].copy()\n",
        "\n",
        "        if not pyusd_txs.empty:\n",
        "            # Add readable addresses\n",
        "            pyusd_txs['from_short'] = pyusd_txs['from'].apply(shorten_address)\n",
        "            pyusd_txs['to_short'] = pyusd_txs['to'].apply(shorten_address)\n",
        "\n",
        "            # Add transfer value formatting\n",
        "            if 'transfer_value' in pyusd_txs.columns:\n",
        "                pyusd_txs['value_pyusd'] = pyusd_txs['transfer_value'].apply(\n",
        "                    lambda x: format_value_pyusd(x) if x > 0 else \"\"\n",
        "                )\n",
        "\n",
        "            # Display streamlined view\n",
        "            display_cols = [\n",
        "                'tx_index', 'from', 'to', 'pyusd_function',\n",
        "                'value_pyusd', 'gas_used', 'failed'\n",
        "            ]\n",
        "\n",
        "            # Filter columns that exist\n",
        "            display_cols = [col for col in display_cols if col in pyusd_txs.columns]\n",
        "\n",
        "            # Create a table to display this data\n",
        "            console.print(\"\\n\\n[bold]PYUSD Transactions in Block[/bold]\", style=\"cyan3\")\n",
        "            pyusd_table = Table(title=\"\", title_style=\"\")\n",
        "            pyusd_table.add_column(\"Tx Index\")\n",
        "            pyusd_table.add_column(\"From\")\n",
        "            pyusd_table.add_column(\"To\")\n",
        "            pyusd_table.add_column(\"Function\")\n",
        "            pyusd_table.add_column(\"Amount\")\n",
        "            pyusd_table.add_column(\"Gas Used\")\n",
        "            pyusd_table.add_column(\"Status\")\n",
        "\n",
        "            # Add rows (limit to first 15 to avoid huge output)\n",
        "            for idx, row in pyusd_txs.head(15).iterrows():\n",
        "                status_color = \"red\" if row['failed'] else \"green\"\n",
        "                status_text = \"Failed\" if row['failed'] else \"Success\"\n",
        "\n",
        "                pyusd_table.add_row(\n",
        "                    str(row['tx_index']),\n",
        "                    row['from'],\n",
        "                    row['to'],\n",
        "                    str(row['pyusd_function'] or \"\"),\n",
        "                    row.get('value_pyusd', \"\"),\n",
        "                    f\"{row['gas_used']:,}\",\n",
        "                    f\"[{status_color}]{status_text}[/{status_color}]\"\n",
        "                )\n",
        "\n",
        "            if len(pyusd_txs) > 15:\n",
        "                pyusd_table.add_row(\n",
        "                    \"...\",\n",
        "                    f\"+ {len(pyusd_txs) - 15} more\",\n",
        "                    \"\", \"\", \"\", \"\", \"\"\n",
        "                )\n",
        "\n",
        "            console.print(pyusd_table)\n",
        "        else:\n",
        "            console.print(\"[info]No direct PYUSD interactions found.\", style=\"info\")\n",
        "\n",
        "    # Visualize PYUSD transfer network if transfers exist\n",
        "    if pyusd_transfers:\n",
        "        console.print(\"\\n\\n[bold magenta3]üîÑ PYUSD Transfer Network in Block[/bold magenta3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        try:\n",
        "            # Create transfer network visualization\n",
        "            flow_graph = Digraph(comment=f\"PYUSD Transfers in Block {block_identifier}\", format='png')\n",
        "            flow_graph.attr(rankdir='TB', bgcolor='transparent')\n",
        "            flow_graph.attr('node', shape='box', style='filled', fontname='helvetica',\n",
        "                           fontcolor='black', fillcolor='palegreen')\n",
        "\n",
        "            # Track nodes we've added\n",
        "            added_nodes = set()\n",
        "\n",
        "            # Aggregate transfers between same addresses\n",
        "            transfer_map = {}\n",
        "\n",
        "            for transfer in pyusd_transfers:\n",
        "                from_addr = transfer['from']\n",
        "                to_addr = transfer['to']\n",
        "                value = transfer['value']\n",
        "\n",
        "                key = (from_addr, to_addr)\n",
        "                if key in transfer_map:\n",
        "                    transfer_map[key] += value\n",
        "                else:\n",
        "                    transfer_map[key] = value\n",
        "\n",
        "            # Add nodes and edges\n",
        "            for (from_addr, to_addr), total_value in transfer_map.items():\n",
        "\n",
        "                if from_addr not in added_nodes:\n",
        "                    flow_graph.node(from_addr, label=from_addr)\n",
        "                    added_nodes.add(from_addr)\n",
        "\n",
        "                if to_addr not in added_nodes:\n",
        "                    flow_graph.node(to_addr, label=to_addr)\n",
        "                    added_nodes.add(to_addr)\n",
        "\n",
        "                value_str = format_value_pyusd(total_value)\n",
        "                flow_graph.edge(from_addr, to_addr, label=value_str)\n",
        "\n",
        "            display(flow_graph)\n",
        "            console.print(\"[info]This graph shows PYUSD transfers within the block.\", style=\"info\")\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create PYUSD transfer network visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Analyze internal transactions\n",
        "    internal_txs = detect_pyusd_internal_transactions(debug_trace_list)\n",
        "    if internal_txs:\n",
        "        console.print(\"\\n\\n[bold green3]üîÑ PYUSD Internal Transactions[/bold green3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "        console.print(f\"[info]Found {len(internal_txs)} internal transactions involving PYUSD contracts.\", style=\"info\")\n",
        "\n",
        "        # Create a table of internal transactions\n",
        "        console.print(\"\\n\\n[bold cyan3]Internal PYUSD Calls[/bold cyan3]\")\n",
        "\n",
        "        internal_table = Table(title=\"\", title_style=\"bold cyan\")\n",
        "        internal_table.add_column(\"From\", style=\"dim\")\n",
        "        internal_table.add_column(\"To Contract\", style=\"cyan\")\n",
        "        internal_table.add_column(\"Function\")\n",
        "        internal_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "        internal_table.add_column(\"Depth\", justify=\"right\")\n",
        "\n",
        "        # Show a subset if there are many\n",
        "        display_limit = min(10, len(internal_txs))\n",
        "        for i in range(display_limit):\n",
        "            tx = internal_txs[i]\n",
        "            internal_table.add_row(\n",
        "                tx['from'],\n",
        "                tx['to_contract'],\n",
        "                tx['function'],\n",
        "                f\"{tx['gas_used']:,}\",\n",
        "                str(tx['depth'])\n",
        "            )\n",
        "\n",
        "        if len(internal_txs) > display_limit:\n",
        "            internal_table.add_row(\n",
        "                f\"+ {len(internal_txs) - display_limit} more...\",\n",
        "                \"\", \"\", \"\", \"\"\n",
        "            )\n",
        "\n",
        "        console.print(internal_table)\n",
        "\n",
        "    # Display summary table for all transactions with enhanced interactive features\n",
        "    if not summary_df.empty:\n",
        "        console.print(\"\\n[bold chartreuse1]üìã Block Transaction Summary[/bold chartreuse1]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "        # Create filter controls and PYUSD-focused display\n",
        "        # Create PYUSD-only dataframe\n",
        "        pyusd_df = summary_df[summary_df['pyusd_interaction'] == True].copy()\n",
        "\n",
        "        # Filter options above the table\n",
        "        display(widgets.HTML(\"<h4>Filter Options:</h4>\"))\n",
        "\n",
        "        # Keep both buttons - arranged in an HBox for better layout\n",
        "        filter_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Show PYUSD Only',\n",
        "                button_style='success',\n",
        "                layout=widgets.Layout(width='180px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Show All Transactions',\n",
        "                button_style='info',\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        display(filter_buttons)\n",
        "\n",
        "        # Output area for transactions\n",
        "        transaction_output = widgets.Output()\n",
        "\n",
        "        # Export buttons with better styling\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Export to CSV',\n",
        "                button_style='primary',  # Green\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export as JSON',\n",
        "                button_style='warning',  # Orange\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export to Google Sheets',\n",
        "                button_style='info',     # Blue\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        export_output = widgets.Output()\n",
        "\n",
        "        # Display columns for better view\n",
        "        display_cols = [\n",
        "            'tx_index', 'from', 'to', 'gas_used',\n",
        "            'pyusd_interaction', 'pyusd_function', 'failed'\n",
        "        ]\n",
        "\n",
        "        # Filter columns that exist\n",
        "        display_cols = [col for col in display_cols if col in summary_df.columns]\n",
        "\n",
        "        def show_all_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                display(summary_df[display_cols])\n",
        "\n",
        "        def show_pyusd_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                if len(pyusd_df) > 0:\n",
        "                    display(pyusd_df[display_cols])\n",
        "                else:\n",
        "                    display(widgets.HTML(\"<p>No PYUSD transactions in this block.</p>\"))\n",
        "\n",
        "        # Export handlers\n",
        "        def export_csv(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame based on which filter is active\n",
        "                current_df = pyusd_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) <= len(str(pyusd_df)) else summary_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_identifier}_transactions_{timestamp}.csv\"\n",
        "                display(download_csv_direct(current_df, filename))\n",
        "\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame based on which filter is active\n",
        "                current_df = pyusd_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) <= len(str(pyusd_df)) else summary_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_identifier}_transactions_{timestamp}.json\"\n",
        "                records = current_df.to_dict('records')\n",
        "                display(download_json_direct(records, filename))\n",
        "\n",
        "        def export_to_sheets(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame based on which filter is active\n",
        "                current_df = pyusd_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) <= len(str(pyusd_df)) else summary_df\n",
        "                sheet_name = f\"Block {block_identifier} Transactions {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "                display(export_to_google_sheets_direct(current_df, sheet_name))\n",
        "\n",
        "        # Connect callbacks\n",
        "        filter_buttons.children[0].on_click(show_pyusd_txs)   # PYUSD Only button\n",
        "        filter_buttons.children[1].on_click(show_all_txs)     # Show All button\n",
        "        export_buttons.children[0].on_click(export_csv)\n",
        "        export_buttons.children[1].on_click(export_json)\n",
        "        export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "        # Display transaction table area\n",
        "        display(transaction_output)\n",
        "\n",
        "        # Show PYUSD transactions by default\n",
        "        show_pyusd_txs(None)\n",
        "\n",
        "        # Export section below the table\n",
        "        console.print(\"\\n\\n[bold]Export Options:[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        display(export_buttons)\n",
        "        display(export_output)\n",
        "\n",
        "    # Return the DataFrame for further analysis\n",
        "    return summary_df\n",
        "\n",
        "# --- Execute debug_traceBlockByNumber with enhanced config ---\n",
        "# WARNING: Can be slow. Default to False.\n",
        "RUN_DEBUG_TRACE_BLOCK_NUM = True # <<< SET TO TRUE TO RUN THIS\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_debug_trace_num = TARGET_BLOCK_IDENTIFIER\n",
        "    block_param_num = None\n",
        "\n",
        "    # Format block identifier for debug_traceBlockByNumber (requires hex number string or tag)\n",
        "    if isinstance(block_id_debug_trace_num, int):\n",
        "        block_param_num = hex(block_id_debug_trace_num)\n",
        "    elif isinstance(block_id_debug_trace_num, str):\n",
        "        if block_id_debug_trace_num.startswith(\"0x\") and len(block_id_debug_trace_num) != 66: # Is hex number\n",
        "             block_param_num = block_id_debug_trace_num\n",
        "        elif block_id_debug_trace_num in [\"latest\", \"pending\", \"earliest\"]:\n",
        "            block_param_num = block_id_debug_trace_num\n",
        "        else: # Try converting string int\n",
        "             try:\n",
        "                 block_param_num = hex(int(block_id_debug_trace_num))\n",
        "             except ValueError:\n",
        "                 console.print(f\"[error]Invalid TARGET_BLOCK_IDENTIFIER '{block_id_debug_trace_num}' for debug_traceBlockByNumber. Needs hex number string or tag.\", style=\"error\")\n",
        "\n",
        "    if RUN_DEBUG_TRACE_BLOCK_NUM and block_param_num:\n",
        "        console.print(\"[bold cyan3]üß± Tracing & Analyis via debug_traceBlockByNumber[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        console.print(f\"\\n\\n[warning]Attempting 'debug_traceBlockByNumber' for {block_param_num} on Mainnet (Can be SLOW!)...[/warning]\", style=\"warning\")\n",
        "\n",
        "        # Use the enhanced tracer config for better insights\n",
        "        enhanced_config = {\n",
        "            \"tracer\": \"callTracer\",\n",
        "            \"tracerConfig\": TRACE_CONFIGS[\"callTracer\"]\n",
        "        }\n",
        "\n",
        "        debug_block_num_trace_results = make_rpc_request(\n",
        "            \"debug_traceBlockByNumber\",\n",
        "            [block_param_num, enhanced_config],\n",
        "            network='mainnet'\n",
        "        )\n",
        "\n",
        "        if debug_block_num_trace_results is not None:\n",
        "            block_analysis = analyze_debug_block_trace(debug_block_num_trace_results, block_param_num)\n",
        "\n",
        "            # Add any post-analysis insights here\n",
        "            if block_analysis is not None and 'pyusd_interaction' in block_analysis.columns:\n",
        "                pyusd_txs = block_analysis[block_analysis['pyusd_interaction']]\n",
        "                if not pyusd_txs.empty:\n",
        "                    # Create a histogram of gas usage for PYUSD vs non-PYUSD transactions\n",
        "                    try:\n",
        "                        # Add interaction type column\n",
        "                        block_analysis['interaction_type'] = block_analysis['pyusd_interaction'].apply(\n",
        "                            lambda x: 'PYUSD Transaction' if x else 'Other Transaction'\n",
        "                        )\n",
        "\n",
        "                        console.print(f\"\\n\\n[bold]Gas Usage Distribution in Block: [cyan3]{block_param_num}[/cyan3][/bold]\", style=\"magenta3\")\n",
        "                        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                        # Create histogram\n",
        "                        fig_gas = px.histogram(\n",
        "                            block_analysis, x='gas_used', color='interaction_type',\n",
        "                            title=f'Gas Usage Distribution in Block {block_param_num}',\n",
        "                            labels={'gas_used': 'Gas Used', 'count': 'Number of Transactions'},\n",
        "                            log_y=True  # Log scale for better visibility of distribution\n",
        "                        )\n",
        "                        fig_gas.update_layout(template=\"plotly_white\")\n",
        "                        fig_gas.show()\n",
        "                    except Exception as viz_err:\n",
        "                        console.print(f\"[warning]Could not create gas usage histogram: {viz_err}\", style=\"warning\")\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to get block trace for {block_param_num} using 'debug_traceBlockByNumber'.\", style=\"error\")\n",
        "\n",
        "    elif not RUN_DEBUG_TRACE_BLOCK_NUM:\n",
        "        console.print(f\"\\n[info]Skipping 'debug_traceBlockByNumber' as RUN_DEBUG_TRACE_BLOCK_NUM is False.\", style=\"info\")\n",
        "    elif not block_param_num:\n",
        "         pass # Error already printed by validation logic\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping debug_traceBlockByNumber analysis.\", style=\"warning\")\n",
        "\n",
        "\n",
        "# --- Execute debug_traceBlockByHash with enhanced config ---\n",
        "# WARNING: Can be slow. Default to False.\n",
        "RUN_DEBUG_TRACE_BLOCK_HASH = True # <<< SET TO TRUE TO RUN THIS\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_debug_trace_hash = TARGET_BLOCK_IDENTIFIER\n",
        "    block_hash_param = None\n",
        "\n",
        "    # Need to get the block HASH for this method\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]üß± Tracing & Analyis via debug_traceBlockByHash[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        console.print(f\"\\n\\n[bold cyan3]üì° Querying block info for identifier '{block_id_debug_trace_hash}' to get hash...[bold cyan3]\")\n",
        "        # Use the mainnet client to get block info\n",
        "        if w3_mainnet:\n",
        "            block_info = w3_mainnet.eth.get_block(block_id_debug_trace_hash)\n",
        "            if block_info and 'hash' in block_info:\n",
        "                block_hash_param = block_info['hash'].hex()\n",
        "                console.print(f\"\\n\\n[info]Found block hash: {block_hash_param}\", style=\"info\")\n",
        "            else:\n",
        "                console.print(f\"[error]Could not retrieve block info or hash for identifier '{block_id_debug_trace_hash}'. Block might not exist.\", style=\"error\")\n",
        "        else:\n",
        "             console.print(\"[error]Mainnet client not available to fetch block hash.\", style=\"error\")\n",
        "\n",
        "    except Exception as e:\n",
        "         console.print(f\"[error]Error retrieving block hash for '{block_id_debug_trace_hash}': {e}\", style=\"error\")\n",
        "\n",
        "\n",
        "    if RUN_DEBUG_TRACE_BLOCK_HASH and block_hash_param:\n",
        "        console.print(f\"\\n[warning]Attempting 'debug_traceBlockByHash' for {block_hash_param} on Mainnet (Can be SLOW!)...[/warning]\", style=\"warning\")\n",
        "\n",
        "        # Use the enhanced tracer config\n",
        "        enhanced_config = {\n",
        "            \"tracer\": \"callTracer\",\n",
        "            \"tracerConfig\": TRACE_CONFIGS[\"callTracer\"]\n",
        "        }\n",
        "\n",
        "        debug_block_hash_trace_results = make_rpc_request(\n",
        "            \"debug_traceBlockByHash\",\n",
        "            [block_hash_param, enhanced_config],\n",
        "            network='mainnet'\n",
        "        )\n",
        "\n",
        "        if debug_block_hash_trace_results is not None:\n",
        "            # Analyze with the same function as debug_traceBlockByNumber\n",
        "            block_analysis = analyze_debug_block_trace(debug_block_hash_trace_results, block_hash_param)\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to get block trace for hash {block_hash_param} using 'debug_traceBlockByHash'.\", style=\"error\")\n",
        "\n",
        "    elif not RUN_DEBUG_TRACE_BLOCK_HASH:\n",
        "        console.print(f\"\\n[info]Skipping 'debug_traceBlockByHash' as RUN_DEBUG_TRACE_BLOCK_HASH is False.\", style=\"info\")\n",
        "    elif not block_hash_param:\n",
        "        pass # Error already printed by validation logic\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping debug_traceBlockByHash analysis.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "TYUZoQwtVzrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 üß™ `debug_traceCall`, `eth.call`, `eth.estimate_gas`: Advanced Simulation of PYUSD Transactions\n",
        "---\n",
        "\n",
        "This section utilizes a **multi-stage simulation approach** to analyze potential PYUSD transactions *without* broadcasting them or requiring real gas/ETH. It intelligently combines standard and advanced RPC methods (`eth.call`, `eth.estimate_gas`, and optionally `debug_traceCall`/`trace_call`) to provide comprehensive insights based on a specific block state.\n",
        "\n",
        "This hybrid strategy is incredibly useful for:\n",
        "\n",
        "*   **Pre-flight Validation (`eth.call`):** Quickly checking if a transaction would likely revert due to basic errors (invalid parameters, immediate contract logic failure).\n",
        "*   **Gas Estimation (`eth.estimate_gas`):** Predicting the gas cost *before* sending, allowing for optimization and budget planning. The code uses this as the primary gas source unless a trace provides a more accurate figure.\n",
        "*   **Revert Debugging (`eth.call` Error + Trace):** Understanding *why* a potential transaction might fail by analyzing the initial revert reason or, if tracing is enabled, examining the detailed execution path and internal calls.\n",
        "*   **State Change Analysis (Trace Events):** Observing the potential impact of operations like `transfer` or `approve` by decoding specific events (e.g., `Transfer` event) emitted during the simulated trace.\n",
        "*   **\"What-If\" Analysis & Comparison:** Testing different parameters for PYUSD functions to compare outcomes, gas costs (`eth.estimate_gas`), and execution details (trace).\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Methods:** `eth.call`, `eth.estimate_gas`, `debug_traceCall` (preferred for tracing), `trace_call` (fallback)\n",
        "> *   **Multiplier for `debug_traceCall`/`trace_call`:** `50x` (Available on Mainnet via GCP)\n",
        "> *   **GCP Advantage:** Simulating complex transactions and obtaining detailed execution traces via `debug_traceCall` (especially those interacting with multiple contracts) is resource-intensive. GCP allows these detailed simulations efficiently on Mainnet.\n",
        "> *   **PYUSD Insight:** This advanced simulation enables:\n",
        ">     *   Robust **pre-flight checks** for PYUSD transfers, approvals, mints, burns.\n",
        ">     *   Comparing the gas cost (`eth.estimate_gas`) of different PYUSD transfer amounts or approval values.\n",
        ">     *   Debugging potential integration issues by simulating calls *from* other contracts *to* the PYUSD contract and analyzing the trace.\n",
        "\n",
        "**Analysis Workflow (as implemented in the code):**\n",
        "\n",
        "1.  **Define Call & Pre-Check:**\n",
        "    *   Constructs the transaction call dictionary (`from`, `to`, `data`, etc.).\n",
        "    *   Performs an optional, preliminary PYUSD balance check (`estimate_pyusd_balance` using `eth.call`) for relevant operations to provide immediate context.\n",
        "2.  **Stage 1: Basic Simulation (`eth.call`):**\n",
        "    *   *Always* executes `eth.call` first to get an immediate success/fail status and potential revert data.\n",
        "3.  **Stage 2: Gas Estimation (`eth.estimate_gas`):**\n",
        "    *   If `eth.call` succeeded OR failed *only* due to insufficient balance (indicating the logic is otherwise sound), it attempts `eth.estimate_gas` to get the predicted gas cost. This value is stored as the primary `gas_used`.\n",
        "4.  **Stage 3: Detailed Tracing (Optional - `debug_traceCall`/`trace_call`):**\n",
        "    *   If `use_trace=True` and the simulation is plausible (success or hypothetical success from Stage 2), it attempts detailed tracing.\n",
        "    *   It prioritizes `debug_traceCall`, using the `make_rpc_request` helper to try multiple parameter formats for maximum compatibility (essential for providers like GCP).\n",
        "    *   If `debug_traceCall` fails across formats, it attempts `trace_call` as a fallback.\n",
        "5.  **Analyze & Assemble Results:**\n",
        "    *   The `simulate_pyusd_transaction` function gathers results into an `analysis` dictionary.\n",
        "    *   It decodes known ERC-20/PYUSD errors from `eth.call` failures.\n",
        "    *   It categorizes gas usage based on the estimated gas and function type.\n",
        "    *   **If a trace was successful:** It parses the `trace_result` to potentially refine `gas_used` (if available in trace), extract internal calls, and identify `state_changes` by decoding specific emitted events (like PYUSD `Transfer` logs) found within the trace.\n",
        "    *   It decodes the return `output` for view functions (like `balanceOf`).\n",
        "6.  **Visualize & Export:**\n",
        "    *   Uses `display_simulation_analysis` to present a structured summary: function details, execution results (status, gas, errors, decoded output), state changes (from trace events), and transaction flow diagrams.\n",
        "    *   Leverages `compare_pyusd_transactions` and `batch_simulate_pyusd_transactions` for multi-run analysis with comparison tables and charts.\n",
        "    *   Provides export options (CSV, JSON, Google Sheets) via helper functions.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "\n",
        "*   **Status:** Did `eth.call` succeed? If not, what was the decoded error? Is it a \"Hypothetical Success\" (meaning `eth.estimate_gas` worked even if the initial balance was too low)?\n",
        "*   **Gas Used:** What is the `eth.estimate_gas` value? Was it refined by a value from the trace? How does it compare across different parameters (in comparison mode)?\n",
        "*   **Gas Profile:** How does the gas usage categorize (Efficient, Medium, High) for this type of operation?\n",
        "*   **Decoded Output:** For view functions (`balanceOf`, `allowance`), what is the simulated return value?\n",
        "*   **State Changes (from Trace):** If tracing was enabled, were any key events (like `Transfer`) detected in the execution trace, indicating simulated state modifications?\n",
        "*   **Internal Calls (from Trace):** Does the trace reveal calls made by the PYUSD contract to other contracts?"
      ],
      "metadata": {
        "id": "MJEWElUzqMwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üß™ Advanced PYUSD Transaction Simulation with Trace Analysis\n",
        "# =============================================================================================\n",
        "# This cell provides comprehensive simulation and analysis for PYUSD transactions on Ethereum.\n",
        "# Features:\n",
        "# - Hybrid simulation approach using eth.call and trace_call for reliability\n",
        "# - Transaction parameter optimization and gas estimation\n",
        "# - Rich visual analysis of transaction effects and gas usage\n",
        "# - Multi-format export capabilities (CSV, JSON, Google Sheets)\n",
        "# - Advanced error decoding and meaningful diagnostics\n",
        "# - Support for multiple transaction types and batched operations\n",
        "\n",
        "from web3 import Web3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "from rich.layout import Layout\n",
        "from rich.console import Group\n",
        "from rich.rule import Rule\n",
        "from rich import box\n",
        "from graphviz import Digraph\n",
        "import matplotlib.pyplot as plt\n",
        "from rich.theme import Theme\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",\n",
        "    \"success\": \"spring_green3\",\n",
        "    \"warning\": \"gold3\",\n",
        "    \"error\": \"red3\",\n",
        "    \"highlight\": \"royal_blue1\"\n",
        "})\n",
        "\n",
        "# Initialize Rich console with the theme\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# =============================================================================================\n",
        "# üìä Visualization Functions\n",
        "# =============================================================================================\n",
        "\n",
        "def create_gas_comparison_chart(results, function_name):\n",
        "    \"\"\"Create a matplotlib bar chart comparing gas usage.\n",
        "\n",
        "    Args:\n",
        "        results: List of simulation results\n",
        "        function_name: Name of the function being compared\n",
        "\n",
        "    Returns:\n",
        "        Success status boolean\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Prepare data for visualization\n",
        "        gas_data = []\n",
        "        for result in results:\n",
        "            if result[\"success\"] or result.get(\"hypothetical_success\", False):\n",
        "                gas_data.append({\n",
        "                    \"variant\": result[\"variant\"],\n",
        "                    \"gas_used\": result[\"gas_used\"],\n",
        "                    \"category\": result.get(\"gas_category\", \"Unknown\")\n",
        "                })\n",
        "\n",
        "        if not gas_data:\n",
        "            return False\n",
        "\n",
        "        # Create dataframe\n",
        "        gas_df = pd.DataFrame(gas_data)\n",
        "\n",
        "        # Print header\n",
        "        console.print(\"\\n\\n[bold]‚õΩ Gas Usage Comparison Chart:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create figure and axis\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        # Plot the bars\n",
        "        bars = ax.bar(gas_df['variant'], gas_df['gas_used'], color='steelblue')\n",
        "\n",
        "        # Add value labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{int(height):,}',\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "        # Add chart styling\n",
        "        ax.set_title(f'Gas Usage Comparison - {function_name}()', fontsize=14, pad=20)\n",
        "        ax.set_xlabel('Variant(s)', fontsize=12)\n",
        "        ax.set_ylabel('Gas Used', fontsize=12)\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the chart\n",
        "        plt.show()\n",
        "\n",
        "        # If we have multiple results, also create a relative cost comparison\n",
        "        if len(gas_data) > 1:\n",
        "            # Find minimum gas cost as baseline\n",
        "            min_gas = min(item[\"gas_used\"] for item in gas_data)\n",
        "            rel_data = []\n",
        "            for item in gas_data:\n",
        "                rel_data.append({\n",
        "                    \"variant\": item[\"variant\"],\n",
        "                    \"relative_cost\": item[\"gas_used\"] / min_gas\n",
        "                })\n",
        "\n",
        "            rel_df = pd.DataFrame(rel_data)\n",
        "\n",
        "            # Create a new figure for relative comparison\n",
        "            console.print(\"\\n\\n[bold]‚õΩ Relative Gas Cost Comparison:[/bold]\", style=\"magenta3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "            # Plot the relative bars\n",
        "            rel_bars = ax2.bar(rel_df['variant'], rel_df['relative_cost'], color='lightcoral')\n",
        "\n",
        "            # Add value labels\n",
        "            for bar in rel_bars:\n",
        "                height = bar.get_height()\n",
        "                ax2.annotate(f'{height:.2f}x',\n",
        "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                            xytext=(0, 3),  # 3 points vertical offset\n",
        "                            textcoords=\"offset points\",\n",
        "                            ha='center', va='bottom')\n",
        "\n",
        "            # Add chart styling\n",
        "            ax2.set_title('Relative Gas Cost Comparison', fontsize=14, pad=20)\n",
        "            ax2.set_xlabel('Variant', fontsize=12)\n",
        "            ax2.set_ylabel('Relative Cost (1.0 = Cheapest)', fontsize=12)\n",
        "            ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "            # Adjust layout\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Display the chart\n",
        "            plt.show()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create gas comparison chart: {viz_err}\", style=\"warning\")\n",
        "        import traceback\n",
        "        console.print(f\"[dim]{traceback.format_exc()}[/dim]\")\n",
        "        return False\n",
        "\n",
        "def create_batch_gas_chart(results, total_gas):\n",
        "    \"\"\"Create a matplotlib bar chart for batch operations gas usage.\n",
        "\n",
        "    Args:\n",
        "        results: List of simulation results\n",
        "        total_gas: Total gas used by the batch\n",
        "\n",
        "    Returns:\n",
        "        Success status boolean\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if len(results) <= 1:\n",
        "            return False\n",
        "\n",
        "        # Prepare data\n",
        "        gas_data = []\n",
        "        for i, result in enumerate(results):\n",
        "            op_name = f\"{i+1}. {result['function']}\"\n",
        "            gas_data.append({\n",
        "                \"operation\": op_name,\n",
        "                \"gas_used\": result['gas_used']\n",
        "            })\n",
        "\n",
        "        # Create dataframe\n",
        "        gas_df = pd.DataFrame(gas_data)\n",
        "\n",
        "        # Print header\n",
        "        console.print(\"\\n\\n[bold]‚õΩ Batch Operations Gas Usage:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create figure and axis\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "        # Plot the bars\n",
        "        bars = ax.bar(gas_df['operation'], gas_df['gas_used'], color='steelblue')\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{int(height):,}',\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "        # Add total gas line\n",
        "        ax.axhline(y=total_gas, color='r', linestyle='--', linewidth=2)\n",
        "\n",
        "        # Add total gas annotation\n",
        "        ax.annotate(f'Total Gas: {total_gas:,}',\n",
        "                    xy=(len(results)/2 - 0.5, total_gas),\n",
        "                    xytext=(0, 10),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom',\n",
        "                    color='red', fontsize=12,\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"red\", alpha=0.8))\n",
        "\n",
        "        # Add chart styling\n",
        "        ax.set_title('Batch Operations Gas Usage', fontsize=14, pad=20)\n",
        "        ax.set_xlabel('Operation', fontsize=12)\n",
        "        ax.set_ylabel('Gas Used', fontsize=12)\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Rotate x-axis labels for better readability\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the chart\n",
        "        plt.show()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create batch gas chart: {viz_err}\", style=\"warning\")\n",
        "        import traceback\n",
        "        console.print(f\"[dim]{traceback.format_exc()}[/dim]\")\n",
        "        return False\n",
        "\n",
        "# =============================================================================================\n",
        "# üìã Export Functions\n",
        "# =============================================================================================\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_simulation_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_simulation_{timestamp}.json\"\n",
        "\n",
        "    # Custom JSON encoder that handles NumPy types\n",
        "    class NumpyEncoder(json.JSONEncoder):\n",
        "        def default(self, obj):\n",
        "            if isinstance(obj, np.ndarray):\n",
        "                return obj.tolist()\n",
        "            if isinstance(obj, np.integer):\n",
        "                return int(obj)\n",
        "            if isinstance(obj, np.floating):\n",
        "                return float(obj)\n",
        "            if isinstance(obj, (np.bool_)):\n",
        "                return bool(obj)\n",
        "            return super().default(obj)\n",
        "\n",
        "    # Convert to JSON string with custom encoder\n",
        "    json_str = json.dumps(data, default=str, indent=2, cls=NumpyEncoder)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, simulation_title):\n",
        "    \"\"\"Export simulation data to Google Sheets with rich formatting.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[info]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD Simulation {simulation_title} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Simulation Results\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transaction Simulation Analysis\"],\n",
        "            [f\"Simulation: {simulation_title}\"],\n",
        "            [f\"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # Add transaction stats summary\n",
        "        if \"summary\" in data_dict:\n",
        "            stats = data_dict[\"summary\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Summary\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "\n",
        "                # Try to format numerical values with commas\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        formatted_value = f\"{value:,}\"\n",
        "                    else:\n",
        "                        formatted_value = str(value)\n",
        "                except:\n",
        "                    formatted_value = str(value)\n",
        "\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 2  # Add extra space after table\n",
        "\n",
        "        # Add gas analysis reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Gas usage visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add main DataFrame data\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Simulation Data\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # For simulation data, select most important columns for readability\n",
        "            if len(df.columns) > 10:\n",
        "                key_cols = [\"variant\", \"function\", \"from\", \"to\", \"amount\", \"gas_used\", \"status\", \"error\"]\n",
        "                display_cols = [col for col in key_cols if col in df.columns]\n",
        "\n",
        "                # Add any custom columns that might contain analysis results\n",
        "                other_important_cols = []\n",
        "                for col in df.columns:\n",
        "                    if col not in display_cols and any(x in col.lower() for x in [\"pyusd\", \"token\", \"note\", \"category\"]):\n",
        "                        other_important_cols.append(col)\n",
        "\n",
        "                display_cols.extend(other_important_cols)\n",
        "                display_df = df[display_cols]\n",
        "            else:\n",
        "                display_df = df\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [display_df.columns.tolist()] + display_df.values.tolist()\n",
        "\n",
        "            # Format values for better readability\n",
        "            for i in range(1, len(df_values)):\n",
        "                for j, col in enumerate(display_df.columns):\n",
        "                    val = df_values[i][j]\n",
        "\n",
        "                    # Format different column types appropriately\n",
        "                    if pd.isnull(val):\n",
        "                        df_values[i][j] = \"\"\n",
        "                    elif col in [\"gas_used\", \"amount\"] and isinstance(val, (int, float)):\n",
        "                        df_values[i][j] = f\"{val:,}\"\n",
        "                    else:\n",
        "                        df_values[i][j] = str(val)\n",
        "\n",
        "            worksheet.update(f\"A{current_row}\", df_values)\n",
        "\n",
        "            # Format the DataFrame header\n",
        "            worksheet.format(f\"A{current_row}:{chr(65+len(display_df.columns)-1)}{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            # Add alternating row colors for readability\n",
        "            data_rows = len(df_values)\n",
        "            for i in range(2, data_rows + 1, 2):\n",
        "                row_num = current_row + i - 1\n",
        "                worksheet.format(f\"A{row_num}:{chr(65+len(display_df.columns)-1)}{row_num}\", {\n",
        "                    \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Clear loading message and show success message\n",
        "        clear_output()\n",
        "        console.print(\"‚úì Successfully exported to Google Sheets\", style=\"success\")\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clear loading message and show error\n",
        "        clear_output()\n",
        "        console.print(f\"‚ùå Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "def create_comparison_export(results, function_name, from_addr):\n",
        "    \"\"\"Creates export options for comparison results.\"\"\"\n",
        "    # Create a DataFrame from results\n",
        "    comp_df = pd.DataFrame(results)\n",
        "\n",
        "    # Format params for better readability\n",
        "    comp_df['formatted_params'] = comp_df['params'].apply(lambda x: ', '.join([str(p) for p in x]))\n",
        "\n",
        "    # Create export output area\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Create export buttons with styling\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Define export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_comparison_{function_name}_{timestamp}.csv\"\n",
        "            # Create a clean export DataFrame\n",
        "            export_cols = ['variant', 'formatted_params', 'success', 'hypothetical_success', 'gas_used', 'gas_category', 'error']\n",
        "            export_df = comp_df[export_cols]\n",
        "            # Rename columns for clarity\n",
        "            export_df.columns = ['Variant', 'Parameters', 'Success', 'Hypothetical Success', 'Gas Used', 'Gas Profile', 'Error']\n",
        "            display(download_csv_direct(export_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_comparison_{function_name}_{timestamp}.json\"\n",
        "\n",
        "            # Create a clean export data structure\n",
        "            export_data = {\n",
        "                \"comparison_type\": \"PYUSD Transaction Comparison\",\n",
        "                \"function\": function_name,\n",
        "                \"from_address\": from_addr,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"variants\": []\n",
        "            }\n",
        "\n",
        "            # Format each variant result\n",
        "            for result in results:\n",
        "                variant_data = {\n",
        "                    \"variant\": result[\"variant\"],\n",
        "                    \"parameters\": [str(p) for p in result[\"params\"]],\n",
        "                    \"success\": result[\"success\"],\n",
        "                    \"hypothetical_success\": result.get(\"hypothetical_success\", False),\n",
        "                    \"gas_used\": result[\"gas_used\"],\n",
        "                    \"gas_category\": result.get(\"gas_category\", \"Unknown\")\n",
        "                }\n",
        "\n",
        "                if result[\"error\"]:\n",
        "                    variant_data[\"error\"] = result[\"error\"]\n",
        "\n",
        "                export_data[\"variants\"].append(variant_data)\n",
        "\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                # Create a clean export DataFrame\n",
        "                export_cols = ['variant', 'formatted_params', 'success', 'hypothetical_success', 'gas_used', 'gas_category', 'error']\n",
        "                export_df = comp_df[export_cols]\n",
        "                # Rename columns for clarity\n",
        "                export_df.columns = ['Variant', 'Parameters', 'Success', 'Hypothetical Success', 'Gas Used', 'Gas Profile', 'Error']\n",
        "\n",
        "                # Create summary data\n",
        "                summary_data = {\n",
        "                    \"summary\": {\n",
        "                        \"function\": function_name,\n",
        "                        \"from_address\": from_addr,\n",
        "                        \"timestamp\": datetime.now().isoformat(),\n",
        "                        \"variants_compared\": len(results),\n",
        "                        \"successful_variants\": sum(1 for r in results if r[\"success\"] or r.get(\"hypothetical_success\", False))\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                display(export_to_google_sheets(export_df, summary_data, f\"Comparison {function_name}()\"))\n",
        "            except Exception as e:\n",
        "                console.print(f\"[error]Error exporting to Google Sheets: {e}\", style=\"error\")\n",
        "                # Fallback to CSV export\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"pyusd_comparison_{function_name}_{timestamp}.csv\"\n",
        "                export_cols = ['variant', 'formatted_params', 'success', 'hypothetical_success', 'gas_used', 'gas_category', 'error']\n",
        "                export_df = comp_df[export_cols]\n",
        "                export_df.columns = ['Variant', 'Parameters', 'Success', 'Hypothetical Success', 'Gas Used', 'Gas Profile', 'Error']\n",
        "                display(download_csv_direct(export_df, filename))\n",
        "                display(HTML(f\"<div style='color:orange'>Falling back to CSV download due to Google Sheets error: {str(e)}</div>\"))\n",
        "\n",
        "    # Connect handlers to buttons\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    # Display export section\n",
        "    console.print(\"\\n\\n[bold]üì§ Export Options:[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "def create_batch_export(results, from_addr):\n",
        "    \"\"\"Creates export options for batch simulation results.\"\"\"\n",
        "    # Create a DataFrame from results\n",
        "    batch_data = []\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        # Create a row for each operation\n",
        "        batch_data.append({\n",
        "            \"operation\": i+1,\n",
        "            \"function\": result['function'],\n",
        "            \"params\": str(result['params']),\n",
        "            \"status\": \"Success\" if result['success'] else \"Hypothetical\" if result.get('hypothetical_success', False) else \"Failed\",\n",
        "            \"gas_used\": result['gas_used'],\n",
        "            \"gas_category\": result.get('gas_category', 'Unknown'),\n",
        "            \"error\": result['error'] if result['error'] else \"None\"\n",
        "        })\n",
        "\n",
        "    batch_df = pd.DataFrame(batch_data)\n",
        "\n",
        "    # Create export output area\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Create export buttons with styling\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export Batch to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export Batch as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='190px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Define export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_batch_simulation_{timestamp}.csv\"\n",
        "            display(download_csv_direct(batch_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_batch_simulation_{timestamp}.json\"\n",
        "\n",
        "            # Calculate batch statistics\n",
        "            batch_size = len(results)\n",
        "            successful_ops = sum(1 for r in results if r['success'] or r.get('hypothetical_success', False))\n",
        "            total_gas = sum(r['gas_used'] for r in results)\n",
        "\n",
        "            # Create a clean export data structure\n",
        "            export_data = {\n",
        "                \"simulation_type\": \"PYUSD Batch Transaction\",\n",
        "                \"from_address\": from_addr,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"summary\": {\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"successful_operations\": successful_ops,\n",
        "                    \"success_rate\": f\"{(successful_ops/batch_size)*100:.1f}%\",\n",
        "                    \"total_gas\": total_gas\n",
        "                },\n",
        "                \"operations\": []\n",
        "            }\n",
        "\n",
        "            # Format each operation result\n",
        "            for i, result in enumerate(results):\n",
        "                op_data = {\n",
        "                    \"index\": i+1,\n",
        "                    \"function\": result[\"function\"],\n",
        "                    \"parameters\": [str(p) for p in result[\"params\"]],\n",
        "                    \"success\": result[\"success\"],\n",
        "                    \"hypothetical_success\": result.get(\"hypothetical_success\", False),\n",
        "                    \"gas_used\": result[\"gas_used\"],\n",
        "                    \"gas_category\": result.get(\"gas_category\", \"Unknown\")\n",
        "                }\n",
        "\n",
        "                if result[\"error\"]:\n",
        "                    op_data[\"error\"] = result[\"error\"]\n",
        "\n",
        "                export_data[\"operations\"].append(op_data)\n",
        "\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                # Calculate batch statistics\n",
        "                batch_size = len(results)\n",
        "                successful_ops = sum(1 for r in results if r['success'] or r.get('hypothetical_success', False))\n",
        "                total_gas = sum(r['gas_used'] for r in results)\n",
        "\n",
        "                # Prepare export data\n",
        "                simulation_title = f\"Batch {batch_size} operations\"\n",
        "\n",
        "                # Create summary data\n",
        "                summary_data = {\n",
        "                    \"summary\": {\n",
        "                        \"from_address\": from_addr,\n",
        "                        \"timestamp\": datetime.now().isoformat(),\n",
        "                        \"batch_size\": batch_size,\n",
        "                        \"successful_operations\": successful_ops,\n",
        "                        \"success_rate\": f\"{(successful_ops/batch_size)*100:.1f}%\",\n",
        "                        \"total_gas\": total_gas\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                display(export_to_google_sheets(batch_df, summary_data, simulation_title))\n",
        "            except Exception as e:\n",
        "                console.print(f\"[error]Error exporting to Google Sheets: {e}\", style=\"error\")\n",
        "                # Fallback to CSV export\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"pyusd_batch_simulation_{timestamp}.csv\"\n",
        "                display(download_csv_direct(batch_df, filename))\n",
        "                display(HTML(f\"<div style='color:orange'>Falling back to CSV download due to Google Sheets error: {str(e)}</div>\"))\n",
        "\n",
        "    # Connect handlers to buttons\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    # Display export section\n",
        "    console.print(\"\\n\\n[bold]üì§ Batch Export Options:[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "# =============================================================================================\n",
        "# üìã Simulation Helpers\n",
        "# =============================================================================================\n",
        "\n",
        "def decode_erc20_error(error_code):\n",
        "    \"\"\"Decodes common ERC-20 error codes into human-readable messages.\"\"\"\n",
        "    known_errors = {\n",
        "        # Common ERC-20 error selectors\n",
        "        \"0x08c379a0\": \"Error string\",\n",
        "        \"0x356680b7\": \"ERC20: transfer amount exceeds balance\",\n",
        "        \"0x4e487b71\": \"Panic/Arithmetic error\",\n",
        "        \"0x01336cea\": \"ERC20: transfer from the zero address\",\n",
        "        \"0xbbc67f8f\": \"ERC20: transfer to the zero address\",\n",
        "        \"0x7939f424\": \"ERC20: approve from the zero address\",\n",
        "        \"0xd505accf\": \"ERC20: permit expired\",\n",
        "        \"0xdab70cb7\": \"ERC20: insufficient allowance\",\n",
        "        \"0xd1bebf0c\": \"ERC20: transfer to the zero address\",\n",
        "        \"0x8baa579f\": \"ERC20: invalid signature\",\n",
        "        \"0x0827a183\": \"ERC20Permit: expired deadline\",\n",
        "        \"0x8f4eb604\": \"ERC20Permit: invalid signature\",\n",
        "        \"0x3b8da488\": \"AccessControl: account is missing role\",\n",
        "        \"0x219f5d17\": \"Token operation is paused\",\n",
        "        \"0xf0019fe6\": \"Address is blacklisted\",\n",
        "        \"0x1bb2a6b6\": \"ERC20: cannot approve from the zero address\",\n",
        "        \"0x710086b0\": \"ERC20: cannot approve to the zero address\"\n",
        "    }\n",
        "\n",
        "    if error_code in known_errors:\n",
        "        return known_errors[error_code]\n",
        "    return f\"Unknown error code: {error_code}\"\n",
        "\n",
        "def categorize_gas_usage(function_name, gas_used):\n",
        "    \"\"\"Categorizes gas usage based on function type for better analysis.\"\"\"\n",
        "    # Define gas usage categories\n",
        "    gas_categories = {\n",
        "        \"Basic Transfer\": [\"transfer\"],\n",
        "        \"Authorization\": [\"approve\", \"increaseAllowance\", \"decreaseAllowance\", \"permit\", \"transferWithAuthorization\"],\n",
        "        \"Advanced Transfer\": [\"transferFrom\"],\n",
        "        \"Supply Management\": [\"mint\", \"burn\"],\n",
        "        \"Administrative\": [\"pause\", \"unpause\", \"transferOwnership\", \"renounceOwnership\"],\n",
        "        \"Query\": [\"balanceOf\", \"allowance\", \"totalSupply\", \"decimals\", \"name\", \"symbol\", \"paused\", \"owner\"]\n",
        "    }\n",
        "\n",
        "    for category, functions in gas_categories.items():\n",
        "        if function_name in functions:\n",
        "            # Add context based on gas amount\n",
        "            if gas_used > 80000:\n",
        "                return f\"{category} (High Gas)\"\n",
        "            elif gas_used > 40000:\n",
        "                return f\"{category} (Medium Gas)\"\n",
        "            else:\n",
        "                return f\"{category} (Efficient)\"\n",
        "\n",
        "    return \"Other Operation\"\n",
        "\n",
        "def make_rpc_request(method, params, network='mainnet'):\n",
        "    \"\"\"Helper function to make raw RPC requests via the specified network's provider.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "    try:\n",
        "        response = w3_client.provider.make_request(method, params)\n",
        "        if 'error' in response:\n",
        "            console.print(f\"[error]RPC Error ({method} on {network}): {response['error']['message']} (Code: {response['error']['code']})\", style=\"error\")\n",
        "            # console.print(response['error']) # Uncomment for full error details\n",
        "            return None\n",
        "        return response.get('result') # Return None if 'result' key is missing\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Exception during RPC call ({method} on {network}): {str(e)}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================================\n",
        "# üîÑ Core Simulation Functions\n",
        "# =============================================================================================\n",
        "\n",
        "def create_pyusd_call_data(function_name, *params):\n",
        "    \"\"\"Creates encoded call data for PYUSD contract functions.\"\"\"\n",
        "    # Use PYUSD_SIGNATURES from the configuration cell\n",
        "    signatures = {}\n",
        "    for selector, sig_info in PYUSD_SIGNATURES.items():\n",
        "        name = sig_info[\"name\"].split(\"(\")[0]  # Extract function name\n",
        "        param_types = []\n",
        "        param_section = sig_info[\"name\"].split(\"(\")[1].rstrip(\")\")\n",
        "        if param_section:\n",
        "            param_types = param_section.split(\",\")\n",
        "        signatures[name] = {\n",
        "            'selector': selector[2:] if selector.startswith(\"0x\") else selector,\n",
        "            'params': param_types\n",
        "        }\n",
        "\n",
        "    if function_name not in signatures:\n",
        "        raise ValueError(f\"Unsupported function: {function_name}\")\n",
        "\n",
        "    sig = signatures[function_name]\n",
        "    if len(params) != len(sig['params']):\n",
        "        raise ValueError(f\"Expected {len(sig['params'])} parameters for {function_name}, got {len(params)}\")\n",
        "\n",
        "    # Start with function selector\n",
        "    call_data = sig['selector']\n",
        "\n",
        "    # Add encoded parameters\n",
        "    for i, param_type in enumerate(sig['params']):\n",
        "        param_value = params[i]\n",
        "\n",
        "        if param_type == 'address':\n",
        "            # Ensure it's a valid address\n",
        "            addr = Web3.to_checksum_address(param_value)\n",
        "            # Remove 0x prefix and pad to 32 bytes\n",
        "            encoded_param = addr[2:].lower().zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "        elif param_type == 'uint256':\n",
        "            # Convert to raw integer value\n",
        "            if isinstance(param_value, float) and function_name in ['transfer', 'approve', 'transferFrom', 'mint', 'burn']:\n",
        "                # For amounts, convert from PYUSD to raw value\n",
        "                decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "                raw_value = int(param_value * (10**decimals))\n",
        "            else:\n",
        "                raw_value = int(param_value)\n",
        "\n",
        "            # Convert to hex without 0x prefix and pad to 32 bytes\n",
        "            encoded_param = hex(raw_value)[2:].zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "        elif param_type == 'bool':\n",
        "            # Encode boolean as 0 or 1 padded to 32 bytes\n",
        "            encoded_param = (1 if param_value else 0)\n",
        "            encoded_param = hex(encoded_param)[2:].zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "        elif param_type == 'bytes32':\n",
        "            # Ensure bytes32 is properly formatted\n",
        "            if isinstance(param_value, str):\n",
        "                if param_value.startswith('0x'):\n",
        "                    param_value = param_value[2:]\n",
        "                encoded_param = param_value.zfill(64)\n",
        "            else:\n",
        "                encoded_param = hex(param_value)[2:].zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "    return '0x' + call_data\n",
        "\n",
        "def estimate_pyusd_balance(address, block=\"latest\", network='mainnet'):\n",
        "    \"\"\"Estimates PYUSD balance for an address using eth.call.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        address = Web3.to_checksum_address(address)\n",
        "        pyusd_address = PYUSD_CONFIG['ethereum']['address']\n",
        "\n",
        "        # Create call data for balanceOf(address)\n",
        "        call_data = create_pyusd_call_data('balanceOf', address)\n",
        "\n",
        "        # Prepare call parameters\n",
        "        call_params = {\n",
        "            \"to\": pyusd_address,\n",
        "            \"data\": call_data\n",
        "        }\n",
        "\n",
        "        # Execute call\n",
        "        result = w3_client.eth.call(call_params, block_identifier=block)\n",
        "\n",
        "        if result:\n",
        "            # Decode uint256 result\n",
        "            balance_raw = int(result.hex(), 16)\n",
        "            balance_pyusd = balance_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "            return balance_pyusd\n",
        "\n",
        "        return 0\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Error estimating PYUSD balance for {address}: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "def simulate_pyusd_transaction(function_name, from_addr, *params, gas_limit=None, gas_price=None, value=0, block=\"latest\", use_trace=True, network='mainnet'):\n",
        "    \"\"\"Simulates PYUSD transactions with an efficient hybrid approach.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None, None\n",
        "\n",
        "    # Track operation category for better analysis\n",
        "    operation_category = None\n",
        "    for category, functions in GAS_CATEGORIES.items():\n",
        "        if function_name in functions:\n",
        "            operation_category = category\n",
        "            break\n",
        "\n",
        "    if not operation_category:\n",
        "        operation_category = \"other\"\n",
        "\n",
        "    try:\n",
        "        # Validate addresses and create call data\n",
        "        from_checksum_addr = Web3.to_checksum_address(from_addr)\n",
        "        pyusd_checksum_address = PYUSD_CONFIG['ethereum']['address']\n",
        "        call_data = create_pyusd_call_data(function_name, *params)\n",
        "    except ValueError as e:\n",
        "         console.print(f\"[error]Invalid parameters for simulation: {e}\", style=\"error\")\n",
        "         return None, None\n",
        "\n",
        "    # Create a panel for transaction information\n",
        "    tx_panel_content = f\"[bold cyan3]Function:[/bold cyan3] [white]{function_name}()[/white]\\n\"\n",
        "    tx_panel_content += f\"[bold cyan3]From:[/bold cyan3] [white]{from_checksum_addr}[/white]\\n\"\n",
        "    tx_panel_content += f\"[bold cyan3]To:[/bold cyan3] [white]{pyusd_checksum_address}[/white]\\n\"\n",
        "    tx_panel_content += f\"[bold cyan3]Network:[/bold cyan3] [white]{network.capitalize()}[/white]\"\n",
        "\n",
        "    console.print(Panel(\n",
        "        tx_panel_content,\n",
        "        title=\"[bold]üîÑ Simulating PYUSD Transaction[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    # Check PYUSD balance for relevant operations\n",
        "    if function_name in ['transfer', 'transferFrom', 'burn', 'transferWithAuthorization', 'burnFrom']:\n",
        "        # For transfer and burn, check sender's balance\n",
        "        balance = None\n",
        "        check_address = from_addr\n",
        "\n",
        "        # For transferFrom and burnFrom, check the owner's balance (first param)\n",
        "        if function_name in ['transferFrom', 'burnFrom']:\n",
        "            check_address = params[0]\n",
        "\n",
        "        balance = estimate_pyusd_balance(check_address, block=block, network=network)\n",
        "\n",
        "        if balance is not None:\n",
        "            # Get amount from parameters based on function\n",
        "            amount_index = 1 if function_name in ['transfer', 'approve', 'transferWithAuthorization'] else 2 if function_name == 'transferFrom' else 0\n",
        "            if amount_index < len(params):\n",
        "                amount = params[amount_index]\n",
        "                if isinstance(amount, float):\n",
        "                    if balance < amount:\n",
        "                        console.print(Panel(\n",
        "                            f\"Address [bold]{shorten_address(check_address)}[/bold] has [bold red]insufficient[/bold red] PYUSD balance ([bold]{balance:.6f}[/bold]) for this operation ([bold]{amount:.6f}[/bold]).\",\n",
        "                            border_style=\"yellow\",\n",
        "                            box=box.ROUNDED\n",
        "                        ))\n",
        "                    else:\n",
        "                        console.print(Panel(\n",
        "                            f\"Address [bold]{shorten_address(check_address)}[/bold] has [bold green]sufficient[/bold green] PYUSD balance ([bold]{balance:.6f}[/bold]) for this operation ([bold]{amount:.6f}[/bold]).\",\n",
        "                            border_style=\"green\",\n",
        "                            box=box.ROUNDED\n",
        "                        ))\n",
        "\n",
        "    # Prepare transaction parameters\n",
        "    call_params = {\n",
        "        \"from\": from_checksum_addr,\n",
        "        \"to\": pyusd_checksum_address,\n",
        "        \"data\": call_data,\n",
        "    }\n",
        "\n",
        "    # Add optional parameters if provided\n",
        "    if value > 0:\n",
        "        call_params[\"value\"] = hex(value)\n",
        "    if gas_limit:\n",
        "        call_params[\"gas\"] = hex(gas_limit)\n",
        "    if gas_price:\n",
        "        call_params[\"gasPrice\"] = hex(gas_price)\n",
        "\n",
        "    # STEP 1: Always try eth.call first - guaranteed to work\n",
        "    console.print(\"\\n\\n[info]Running basic transaction simulation...\", style=\"info\")\n",
        "    try:\n",
        "        result = w3_client.eth.call(call_params, block_identifier=block)\n",
        "        success = True\n",
        "        output = result.hex() if result else '0x'\n",
        "    except Exception as e:\n",
        "        success = False\n",
        "        error_msg = str(e)\n",
        "        console.print(f\"[warning]Transaction simulation revealed error: {error_msg}\", style=\"warning\")\n",
        "        output = None\n",
        "\n",
        "    # STEP 2: Try to estimate gas if call succeeded, or even if it failed due to balance\n",
        "    gas_used = 0\n",
        "    hypothetical_success = False\n",
        "\n",
        "    if success or (not success and error_msg == \"0x356680b7\"):  # If successful or just a balance issue\n",
        "        try:\n",
        "            # Try to estimate gas usage\n",
        "            console.print(\"[info]Estimating gas usage...\", style=\"info\")\n",
        "            gas_estimated = w3_client.eth.estimate_gas({\n",
        "                **call_params,\n",
        "                \"value\": 0  # Ensure no ETH is sent\n",
        "            })\n",
        "            gas_used = gas_estimated\n",
        "\n",
        "            if not success and error_msg == \"0x356680b7\":\n",
        "                hypothetical_success = True\n",
        "                console.print(\"[info]Transaction would likely succeed with sufficient balance.\", style=\"info\")\n",
        "        except Exception as gas_err:\n",
        "            # Couldn't estimate gas\n",
        "            console.print(f\"[warning]Could not estimate gas: {gas_err}\", style=\"warning\")\n",
        "\n",
        "    # STEP 3: Advanced trace analysis if requested\n",
        "    trace_result = None\n",
        "    if use_trace and (success or hypothetical_success):\n",
        "        console.print(\"[info]Attempting detailed transaction trace analysis...\", style=\"info\")\n",
        "\n",
        "        # Configure trace parameters based on mode\n",
        "        tracer_config = TRACE_CONFIGS[\"callTracer\"]\n",
        "\n",
        "        # Try multiple trace call parameter formats to maximize compatibility\n",
        "        trace_formats = [\n",
        "            # Format 1: Simple params array\n",
        "            [call_params, block],\n",
        "\n",
        "            # Format 2: With tracer specified\n",
        "            [call_params, block, \"callTracer\"],\n",
        "\n",
        "            # Format 3: Full tracer config\n",
        "            [call_params, block, {\"tracer\": \"callTracer\", \"tracerConfig\": tracer_config}],\n",
        "\n",
        "            # Format 4: Object format for Google RPC\n",
        "            {\n",
        "                \"transaction\": call_params,\n",
        "                \"blockNumber\": block if block != \"latest\" else \"latest\",\n",
        "                \"tracer\": \"callTracer\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        for i, trace_params in enumerate(trace_formats):\n",
        "            try:\n",
        "                console.print(f\"[info]Trying trace format {i+1}...\", style=\"info\")\n",
        "                trace_result = make_rpc_request(\"debug_traceCall\", trace_params, network=network)\n",
        "                if trace_result:\n",
        "                    console.print(\"[success]Successfully obtained transaction trace.\", style=\"success\")\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                console.print(f\"[warning]Trace format {i+1} failed: {e}\", style=\"warning\")\n",
        "\n",
        "        if not trace_result:\n",
        "            # Try alternate RPC method as last resort\n",
        "            try:\n",
        "                console.print(\"[info]Trying alternate tracing method...\", style=\"info\")\n",
        "                trace_result = make_rpc_request(\"trace_call\", trace_formats[0], network=network)\n",
        "                if trace_result:\n",
        "                    console.print(\"[success]Successfully obtained transaction trace using alternate method.\", style=\"success\")\n",
        "            except Exception as e:\n",
        "                console.print(f\"[warning]All trace methods failed: {e}\", style=\"warning\")\n",
        "\n",
        "    # Create analysis from the available data\n",
        "    analysis = {\n",
        "        'function': function_name,\n",
        "        'params': params,\n",
        "        'success': success,\n",
        "        'hypothetical_success': hypothetical_success,\n",
        "        'gas_used': gas_used,\n",
        "        'operation_category': operation_category,\n",
        "        'gas_category': categorize_gas_usage(function_name, gas_used),\n",
        "        'error': None,\n",
        "        'state_changes': [],\n",
        "        'output': output,\n",
        "        'calls': [],\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Handle error decoding\n",
        "    if not success:\n",
        "        # Decode error if it looks like a hex code\n",
        "        if isinstance(error_msg, str) and error_msg.startswith(\"0x\"):\n",
        "            decoded_error = decode_erc20_error(error_msg)\n",
        "            analysis['error'] = decoded_error\n",
        "\n",
        "            # Special handling for balance errors\n",
        "            if error_msg == \"0x356680b7\":\n",
        "                analysis['note'] = \"This transaction would succeed if the address had sufficient PYUSD balance.\"\n",
        "        else:\n",
        "            analysis['error'] = error_msg\n",
        "\n",
        "    # Add trace data if available\n",
        "    if trace_result:\n",
        "        # Extract relevant data from trace if available\n",
        "        if isinstance(trace_result, dict):\n",
        "            # Extract gas usage from trace if available\n",
        "            if 'gasUsed' in trace_result:\n",
        "                gas_used_value = trace_result['gasUsed']\n",
        "                analysis['gas_used'] = int(gas_used_value, 16) if isinstance(gas_used_value, str) and gas_used_value.startswith('0x') else int(gas_used_value)\n",
        "\n",
        "            # Extract internal calls\n",
        "            if 'calls' in trace_result and isinstance(trace_result['calls'], list):\n",
        "                analysis['calls'] = trace_result['calls']\n",
        "\n",
        "                # Extract state changes from internal calls\n",
        "                for call in trace_result['calls']:\n",
        "                    # Look for events, logs, or storage changes\n",
        "                    if 'logs' in call and isinstance(call['logs'], list):\n",
        "                        for log in call['logs']:\n",
        "                            if 'address' in log and log['address'].lower() == PYUSD_CONFIG['ethereum']['address'].lower():\n",
        "                                # This is a PYUSD log\n",
        "                                if 'topics' in log and log['topics']:\n",
        "                                    # Check if it's a Transfer event\n",
        "                                    topic0 = log['topics'][0]\n",
        "                                    if topic0 == PYUSD_CONFIG['ethereum']['transfer_event_topic']:\n",
        "                                        try:\n",
        "                                            from_addr = Web3.to_checksum_address('0x' + log['topics'][1][-40:])\n",
        "                                            to_addr = Web3.to_checksum_address('0x' + log['topics'][2][-40:])\n",
        "                                            value_raw = int(log['data'], 16)\n",
        "                                            value_pyusd = value_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                            analysis['state_changes'].append({\n",
        "                                                'type': 'transfer',\n",
        "                                                'from': from_addr,\n",
        "                                                'to': to_addr,\n",
        "                                                'amount': value_pyusd\n",
        "                                            })\n",
        "                                        except Exception as e:\n",
        "                                            console.print(f\"[warning]Could not decode Transfer event: {e}\", style=\"warning\")\n",
        "\n",
        "    # Decode function outputs for view functions\n",
        "    if success and function_name in ['balanceOf', 'allowance', 'totalSupply', 'decimals']:\n",
        "        try:\n",
        "            if output and output != '0x':\n",
        "                output_raw = int(output, 16)\n",
        "                if function_name in ['balanceOf', 'allowance', 'totalSupply']:\n",
        "                    # Convert raw value to PYUSD\n",
        "                    decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "                    output_value = output_raw / (10**decimals)\n",
        "                    analysis['decoded_output'] = output_value\n",
        "                else:\n",
        "                    analysis['decoded_output'] = output_raw\n",
        "        except Exception as e:\n",
        "            analysis['output_error'] = str(e)\n",
        "\n",
        "    # Display analysis results\n",
        "    display_simulation_analysis(analysis, function_name, params, from_address=from_checksum_addr)\n",
        "\n",
        "    # Export simulation data if requested\n",
        "    if success or hypothetical_success:\n",
        "        # Create export options with detailed simulation data\n",
        "        create_comparison_export([analysis], function_name, from_checksum_addr)\n",
        "\n",
        "    return output, analysis\n",
        "\n",
        "def display_simulation_analysis(analysis, function_name, params, from_address=None):\n",
        "    \"\"\"Displays the results of the simulation analysis in a user-friendly format.\"\"\"\n",
        "    # Create a visual divider\n",
        "    console.print(\"\\n\\n[bold]üîç PYUSD Transaction Simulation Analysis[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create function information panel\n",
        "    function_info = []\n",
        "\n",
        "    # Function name with styling\n",
        "    function_info.append(f\"[bold cyan3]Function:[/bold cyan3] [bold white]{function_name}()[/bold white]\")\n",
        "\n",
        "    # Format parameters based on function\n",
        "    if function_name == 'transfer':\n",
        "        to_addr = params[0]\n",
        "        amount = params[1]\n",
        "        function_info.append(f\"[bold cyan3]From:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'approve':\n",
        "        spender = params[0]\n",
        "        amount = params[1]\n",
        "        function_info.append(f\"[bold cyan3]Owner:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{spender}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'transferFrom':\n",
        "        from_addr = params[0]\n",
        "        to_addr = params[1]\n",
        "        amount = params[2]\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]From:[/bold cyan3] [white]{from_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'balanceOf':\n",
        "        address = params[0]\n",
        "        function_info.append(f\"[bold cyan3]Address:[/bold cyan3] [white]{address}[/white]\")\n",
        "    elif function_name == 'allowance':\n",
        "        owner = params[0]\n",
        "        spender = params[1]\n",
        "        function_info.append(f\"[bold cyan3]Owner:[/bold cyan3] [white]{owner}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{spender}[/white]\")\n",
        "    elif function_name == 'mint':\n",
        "        to_addr = params[0]\n",
        "        amount = params[1]\n",
        "        function_info.append(f\"[bold cyan3]Minter:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'burn':\n",
        "        amount = params[0]\n",
        "        function_info.append(f\"[bold cyan3]Burner:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'transferWithAuthorization':\n",
        "        to_addr = params[1]\n",
        "        amount = params[2]\n",
        "        function_info.append(f\"[bold cyan3]Authorized From:[/bold cyan3] [white]{params[0]}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Executor:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "    elif function_name == 'permit':\n",
        "        owner = params[1]\n",
        "        spender = params[1]\n",
        "        amount = params[2]\n",
        "        function_info.append(f\"[bold cyan3]Owner:[/bold cyan3] [white]{owner}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{spender}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Submitter:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "\n",
        "    # Create transaction result information\n",
        "    transaction_info = []\n",
        "\n",
        "    # Status with appropriate coloring\n",
        "    status_color = \"green3\" if analysis['success'] else \"yellow3\" if analysis['hypothetical_success'] else \"red3\"\n",
        "    status_text = \"Success\" if analysis['success'] else \"Hypothetical Success\" if analysis['hypothetical_success'] else \"Failed\"\n",
        "    transaction_info.append(f\"[bold cyan3]Status:[/bold cyan3] [{status_color}]{status_text}[/{status_color}]\")\n",
        "\n",
        "    # Operation category\n",
        "    transaction_info.append(f\"[bold cyan3]Category:[/bold cyan3] [white]{analysis['operation_category'].title()}[/white]\")\n",
        "\n",
        "    # Error message if any\n",
        "    if analysis['error']:\n",
        "        transaction_info.append(f\"[bold cyan3]Error:[/bold cyan3] [red3]{analysis['error']}[/red3]\")\n",
        "\n",
        "    # Additional notes if any\n",
        "    if 'note' in analysis:\n",
        "        transaction_info.append(f\"[bold cyan3]Note:[/bold cyan3] [yellow3]{analysis['note']}[/yellow3]\")\n",
        "\n",
        "    # Gas usage\n",
        "    transaction_info.append(f\"[bold cyan3]Gas Used:[/bold cyan3] [white]{analysis['gas_used']:,}[/white]\")\n",
        "    transaction_info.append(f\"[bold cyan3]Gas Profile:[/bold cyan3] [white]{analysis['gas_category']}[/white]\")\n",
        "\n",
        "    # Output data for view functions\n",
        "    if 'decoded_output' in analysis:\n",
        "        if function_name in ['balanceOf', 'allowance', 'totalSupply']:\n",
        "            transaction_info.append(f\"[bold cyan3]Result:[/bold cyan3] [green3]{analysis['decoded_output']:,.6f} PYUSD[/green3]\")\n",
        "        else:\n",
        "            transaction_info.append(f\"[bold cyan3]Result:[/bold cyan3] [green3]{analysis['decoded_output']}[/green3]\")\n",
        "    elif analysis['output']:\n",
        "        transaction_info.append(f\"[bold cyan3]Raw Output:[/bold cyan3] [dim white]{analysis['output']}[/dim white]\")\n",
        "\n",
        "    # Internal Calls Count if available\n",
        "    if 'calls' in analysis and analysis['calls']:\n",
        "        transaction_info.append(f\"[bold cyan3]Internal Calls:[/bold cyan3] [white]{len(analysis['calls'])}[/white]\")\n",
        "\n",
        "    # Create panels for better visual separation\n",
        "    function_panel = Panel(\n",
        "        \"\\n\".join(function_info),\n",
        "        title=\"[bold]Transaction Details[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    )\n",
        "\n",
        "    result_panel = Panel(\n",
        "        \"\\n\".join(transaction_info),\n",
        "        title=\"[bold]Execution Results[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    )\n",
        "\n",
        "    # Display panels side by side if possible, otherwise stacked\n",
        "    console.print(Group(function_panel, result_panel))\n",
        "\n",
        "    # Display state changes if any\n",
        "    if analysis['state_changes']:\n",
        "        console.print(\"\\n[bold cyan3]State Changes:[/bold cyan3]\")\n",
        "\n",
        "        state_table = Table(show_header=True, header_style=\"bold cyan3\", box=box.ROUNDED)\n",
        "        state_table.add_column(\"Type\", style=\"cyan3\")\n",
        "        state_table.add_column(\"Details\", style=\"white\")\n",
        "\n",
        "        for change in analysis['state_changes']:\n",
        "            if change['type'] == 'transfer':\n",
        "                from_addr = shorten_address(change['from'])\n",
        "                to_addr = shorten_address(change['to'])\n",
        "                amount = change['amount']\n",
        "                details = f\"{amount:,.2f} PYUSD from {from_addr} to {to_addr}\"\n",
        "                state_table.add_row(\"Transfer\", details)\n",
        "            else:\n",
        "                state_table.add_row(change['type'].title(), str(change))\n",
        "\n",
        "        console.print(Panel(state_table, title=\"[bold]State Changes[/bold]\", border_style=\"cyan\", box=box.ROUNDED))\n",
        "\n",
        "    # Create transaction flow diagram for transfers\n",
        "    if from_address and function_name in ['transfer', 'transferFrom', 'mint', 'burn', 'transferWithAuthorization', 'permit'] and (analysis['success'] or analysis['hypothetical_success']):\n",
        "        try:\n",
        "            console.print(\"\\n\\n[bold magenta3]Transaction Flow Visualization:[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            flow_graph = Digraph(comment=f\"PYUSD {function_name} Flow\", format='png')\n",
        "            flow_graph.attr(rankdir='TB', bgcolor='transparent')\n",
        "            flow_graph.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "\n",
        "            if function_name == 'transfer':\n",
        "                sender_addr = from_address\n",
        "                to_addr = params[0]\n",
        "                amount = params[1]\n",
        "\n",
        "                flow_graph.node('sender', f\"Sender\\n{sender_addr}\", fillcolor='lightblue')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{to_addr}\", fillcolor='palegreen')\n",
        "                flow_graph.edge('sender', 'receiver', label=f\"{amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'transferFrom':\n",
        "                owner_addr = params[0]\n",
        "                to_addr = params[1]\n",
        "                amount = params[2]\n",
        "                sender_addr = from_address\n",
        "\n",
        "                flow_graph.node('owner', f\"Owner\\n{owner_addr}\", fillcolor='lightblue')\n",
        "                flow_graph.node('spender', f\"Spender\\n{sender_addr}\", fillcolor='lightyellow')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{to_addr}\", fillcolor='palegreen')\n",
        "\n",
        "                flow_graph.edge('spender', 'owner', label=\"1. Has Allowance\")\n",
        "                flow_graph.edge('owner', 'receiver', label=f\"2. {amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'mint':\n",
        "                to_addr = params[0]\n",
        "                amount = params[1]\n",
        "\n",
        "                flow_graph.node('minter', f\"Minter\\n{shorten_address(from_address)}\", fillcolor='lightcoral')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{shorten_address(to_addr)}\", fillcolor='palegreen')\n",
        "                flow_graph.node('supply', \"PYUSD Supply\", fillcolor='lightcyan')\n",
        "\n",
        "                flow_graph.edge('minter', 'supply', label=f\"1. Increases by {amount:,.2f}\")\n",
        "                flow_graph.edge('supply', 'receiver', label=f\"2. {amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'burn':\n",
        "                amount = params[0]\n",
        "\n",
        "                flow_graph.node('burner', f\"Burner\\n{shorten_address(from_address)}\", fillcolor='lightcoral')\n",
        "                flow_graph.node('supply', \"PYUSD Supply\", fillcolor='lightcyan')\n",
        "\n",
        "                flow_graph.edge('burner', 'supply', label=f\"Burns {amount:,.2f} PYUSD\")\n",
        "                flow_graph.edge('supply', 'null', label=f\"Decreases by {amount:,.2f}\", style='dashed')\n",
        "\n",
        "            elif function_name == 'transferWithAuthorization':\n",
        "                from_addr = params[0]\n",
        "                to_addr = params[1]\n",
        "                amount = params[2]\n",
        "\n",
        "                flow_graph.node('owner', f\"Owner\\n{from_addr}\", fillcolor='lightblue')\n",
        "                flow_graph.node('executor', f\"Executor\\n{from_address}\", fillcolor='lightyellow')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{to_addr}\", fillcolor='palegreen')\n",
        "\n",
        "                flow_graph.edge('owner', 'executor', label=\"1. Authorization\")\n",
        "                flow_graph.edge('executor', 'receiver', label=f\"2. {amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'permit':\n",
        "                owner = params[0]\n",
        "                spender = params[1]\n",
        "                amount = params[2]\n",
        "\n",
        "                flow_graph.node('owner', f\"Owner\\n{owner}\", fillcolor='lightblue')\n",
        "                flow_graph.node('spender', f\"Spender\\n{spender}\", fillcolor='palegreen')\n",
        "                flow_graph.node('submitter', f\"Submitter\\n{from_address}\", fillcolor='lightyellow')\n",
        "\n",
        "                flow_graph.edge('owner', 'submitter', label=\"1. Signed Permit\")\n",
        "                flow_graph.edge('submitter', 'spender', label=f\"2. Approve {amount:,.2f} PYUSD\")\n",
        "\n",
        "            display(flow_graph)\n",
        "\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create flow visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "def compare_pyusd_transactions(function_name, from_addr, param_sets, network='mainnet'):\n",
        "    \"\"\"Compares multiple PYUSD transaction simulations with different parameters.\"\"\"\n",
        "    # Create a visual divider for the comparison section\n",
        "    console.print(\"\\n\\n[bold]üîÑ PYUSD Transaction Comparison[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Display function being compared\n",
        "    console.print(Panel(\n",
        "        f\"[bold white]Function:[/bold white] [cyan3]{function_name}()[/cyan3]\\n\"\n",
        "        f\"[bold white]From:[/bold white] [cyan3]{from_addr}[/cyan3]\\n\"\n",
        "        f\"[bold white]Network:[/bold white] [cyan3]{network.capitalize()}[/cyan3]\\n\"\n",
        "        f\"[bold white]Variants:[/bold white] [cyan3]{len(param_sets)}[/cyan3]\",\n",
        "        title=\"[bold]Comparison Parameters[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, params in enumerate(param_sets):\n",
        "        # Create visual separator between variants\n",
        "        console.print(f\"\\n\\n[bold cyan3]Variant {i+1}[/bold cyan3]: {params}\")\n",
        "        sim_result, analysis = simulate_pyusd_transaction(function_name, from_addr, *params, network=network)\n",
        "\n",
        "        if analysis:\n",
        "            # Store result for comparison\n",
        "            variant_name = f\"Variant {i+1}\"\n",
        "            results.append({\n",
        "                \"variant\": variant_name,\n",
        "                \"params\": params,\n",
        "                \"success\": analysis['success'],\n",
        "                \"hypothetical_success\": analysis.get('hypothetical_success', False),\n",
        "                \"gas_used\": analysis['gas_used'],\n",
        "                \"gas_category\": analysis.get('gas_category', 'Unknown'),\n",
        "                \"error\": analysis['error']\n",
        "            })\n",
        "\n",
        "    # Create comparison table\n",
        "    if results:\n",
        "        # Final comparison header\n",
        "        console.print(\"\\n\\n[bold]üìä Comparison Results[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        comp_table = Table(show_header=True, header_style=\"bold cyan3\", box=box.ROUNDED)\n",
        "        comp_table.add_column(\"Variant\", style=\"cyan3\")\n",
        "\n",
        "        # Add parameter columns based on function\n",
        "        if function_name == 'transfer' or function_name == 'approve':\n",
        "            comp_table.add_column(\"Recipient/Spender\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'transferFrom':\n",
        "            comp_table.add_column(\"From\", style=\"white\")\n",
        "            comp_table.add_column(\"To\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'mint':\n",
        "            comp_table.add_column(\"To\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'burn':\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'transferWithAuthorization':\n",
        "            comp_table.add_column(\"From\", style=\"white\")\n",
        "            comp_table.add_column(\"To\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'permit':\n",
        "            comp_table.add_column(\"Owner\", style=\"white\")\n",
        "            comp_table.add_column(\"Spender\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "\n",
        "        comp_table.add_column(\"Status\")\n",
        "        comp_table.add_column(\"Gas Used\", style=\"white\")\n",
        "        comp_table.add_column(\"Gas Profile\", style=\"white\")\n",
        "\n",
        "        for result in results:\n",
        "            row = [result[\"variant\"]]\n",
        "\n",
        "            # Add parameter values\n",
        "            params = result[\"params\"]\n",
        "            if function_name == 'transfer' or function_name == 'approve':\n",
        "                row.append(params[0])\n",
        "                row.append(f\"{params[1]:,.2f}\")\n",
        "            elif function_name == 'transferFrom':\n",
        "                row.append(params[0])\n",
        "                row.append(params[1])\n",
        "                row.append(f\"{params[2]:,.2f}\")\n",
        "            elif function_name == 'mint':\n",
        "                row.append(params[0])\n",
        "                row.append(f\"{params[1]:,.2f}\")\n",
        "            elif function_name == 'burn':\n",
        "                row.append(f\"{params[0]:,.2f}\")\n",
        "            elif function_name == 'transferWithAuthorization':\n",
        "                row.append(params[0])\n",
        "                row.append(params[1])\n",
        "                row.append(f\"{params[2]:,.2f}\")\n",
        "            elif function_name == 'permit':\n",
        "                row.append(params[0])\n",
        "                row.append(params[1])\n",
        "                row.append(f\"{params[2]:,.2f}\")\n",
        "\n",
        "            # Add status and gas\n",
        "            status_color = \"green3\" if result[\"success\"] else \"yellow3\" if result[\"hypothetical_success\"] else \"red3\"\n",
        "            status_text = \"Success\" if result[\"success\"] else \"Hypothetical Success\" if result[\"hypothetical_success\"] else \"Failed\"\n",
        "            row.append(f\"[{status_color}]{status_text}[/{status_color}]\")\n",
        "            row.append(f\"{result['gas_used']:,}\")\n",
        "            row.append(result[\"gas_category\"])\n",
        "\n",
        "            comp_table.add_row(*row)\n",
        "\n",
        "        console.print(Panel(comp_table, border_style=\"cyan3\", box=box.ROUNDED))\n",
        "\n",
        "        # Create gas comparison chart\n",
        "        create_gas_comparison_chart(results, function_name)\n",
        "\n",
        "        # Create export options for comparison results\n",
        "        create_comparison_export(results, function_name, from_addr)\n",
        "\n",
        "    return results\n",
        "\n",
        "def batch_simulate_pyusd_transactions(from_addr, batch_operations, network='mainnet'):\n",
        "    \"\"\"Simulates a batch of PYUSD transactions in sequence.\"\"\"\n",
        "    # Create a visual divider for the batch simulation\n",
        "    console.print(\"\\n\\n[bold]üîÑ PYUSD Batch Transaction Simulation[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Display batch information\n",
        "    console.print(Panel(\n",
        "        f\"[bold white]From Address:[/bold white] [cyan3]{from_addr}[/cyan3]\\n\"\n",
        "        f\"[bold white]Network:[/bold white] [cyan3]{network.capitalize()}[/cyan3]\\n\"\n",
        "        f\"[bold white]Batch Size:[/bold white] [cyan3]{len(batch_operations)}[/cyan3]\",\n",
        "        title=\"[bold]Batch Parameters[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    results = []\n",
        "    total_gas = 0\n",
        "    batch_success = True\n",
        "\n",
        "    # Run each simulation in the batch\n",
        "    for i, (function_name, params) in enumerate(batch_operations):\n",
        "        console.print(f\"\\n\\n[bold cyan3]Operation {i+1}/{len(batch_operations)}[/bold cyan3]: {function_name}{params}\")\n",
        "\n",
        "        # Convert params to a proper list if it's not already\n",
        "        params_list = list(params) if isinstance(params, (list, tuple)) else [params]\n",
        "\n",
        "        # Simulate this transaction\n",
        "        sim_result, analysis = simulate_pyusd_transaction(function_name, from_addr, *params_list, network=network)\n",
        "\n",
        "        # Store result\n",
        "        results.append(analysis)\n",
        "\n",
        "        # Update batch statistics\n",
        "        if analysis['success'] or analysis.get('hypothetical_success', False):\n",
        "            total_gas += analysis['gas_used']\n",
        "        else:\n",
        "            batch_success = False\n",
        "            # Stop batch if a transaction fails\n",
        "            console.print(Panel(\n",
        "                f\"[bold red]Batch simulation stopped at operation {i+1} due to failure[/bold red]\\n\"\n",
        "                f\"Function: {function_name}\\n\"\n",
        "                f\"Error: {analysis['error']}\",\n",
        "                title=\"[bold]Batch Failure[/bold]\",\n",
        "                border_style=\"red\",\n",
        "                box=box.ROUNDED\n",
        "            ))\n",
        "            break\n",
        "\n",
        "    # Display batch summary\n",
        "    status_color = \"green\" if batch_success else \"red\"\n",
        "    status_text = \"Success\" if batch_success else \"Failed\"\n",
        "\n",
        "    console.print(Panel(\n",
        "        f\"[bold white]Total Operations:[/bold white] [cyan]{len(results)}/{len(batch_operations)}[/cyan]\\n\"\n",
        "        f\"[bold white]Batch Status:[/bold white] [{status_color}]{status_text}[/{status_color}]\\n\"\n",
        "        f\"[bold white]Total Gas:[/bold white] [cyan]{total_gas:,}[/cyan]\",\n",
        "        title=\"[bold]Batch Summary[/bold]\",\n",
        "        border_style=\"cyan\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    # Create visualization for batch gas usage\n",
        "    create_batch_gas_chart(results, total_gas)\n",
        "\n",
        "    # Create export options for batch results\n",
        "    create_batch_export(results, from_addr)\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================================\n",
        "# üöÄ Interactive Demo Section\n",
        "# =============================================================================================\n",
        "\n",
        "def run_pyusd_simulations():\n",
        "    \"\"\"Run a series of PYUSD transaction simulations with enhanced UI display.\"\"\"\n",
        "    # Addresses with PYUSD balance (publicly available on blockchain)\n",
        "    PYUSD_HOLDER_ADDRESSES = [\n",
        "        \"0xf845a0A05Cbd91Ac15C3E59D126DE5dFbC2aAbb7\",  # Primary simulation address\n",
        "        \"0xad6452a9b8F10b0fE084C83c396ABAe96411C761\",\n",
        "        \"0x51C72848c68a965f66FA7a88855F9f7784502a7F\",\n",
        "        \"0x4bb41165A817628992ee40ea8e92F8800f143FbD\",\n",
        "        \"0x3519eE4d387150F230BaCa90f5C50E9d296164c6\"\n",
        "    ]\n",
        "\n",
        "    # Use first address with balance for simulations\n",
        "    SIM_FROM_ADDR = PYUSD_HOLDER_ADDRESSES[0]\n",
        "    SIM_TO_ADDR = \"0x5754284f345afc66a98fbB0a0Afe71e0F007B949\"  # Example recipient\n",
        "    SIM_AMOUNT = 100.0  # Amount of PYUSD\n",
        "\n",
        "    # Create a visually appealing header\n",
        "    console.print(\"\\n\\n[bold]üß™ Advanced PYUSD Transaction Simulator[/bold]\", style=\"chartreuse1\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"[bold chartreuse1]This Cell simulates PYUSD transactions against the Ethereum blockchain[/bold chartreuse1]\\n\"\n",
        "        \"[white]Test various ERC-20 operations without executing actual transactions[/white]\\n\\n\"\n",
        "        \"[bold yellow3]Features:[/bold yellow3]\\n\"\n",
        "        \"‚Ä¢ Reliable transaction simulation with advanced tracing\\n\"\n",
        "        \"‚Ä¢ Gas usage analysis and optimization recommendations\\n\"\n",
        "        \"‚Ä¢ Detailed state change tracking\\n\"\n",
        "        \"‚Ä¢ Multi-format data export options\\n\"\n",
        "        \"‚Ä¢ Batch transaction simulation\\n\"\n",
        "        \"‚Ä¢ Support for advanced PYUSD operations\",\n",
        "        title=\"[bold]Transaction Simulator Information[/bold]\",\n",
        "        subtitle=\"[dim]Powered by Google Blockchain RPC[/dim]\",\n",
        "        border_style=\"chartreuse1\",\n",
        "        box=box.ROUNDED,\n",
        "        padding=(1, 2)\n",
        "    ))\n",
        "\n",
        "    # Add disclaimer in a panel\n",
        "    console.print(\"\\n\\n[bold]‚ö†Ô∏è Disclaimer[/bold]\", style=\"yellow3\")\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"‚Ä¢ This is a [bold]read-only simulation tool[/bold]. No actual transactions are executed.\\n\"\n",
        "        \"‚Ä¢ The addresses used contain real PYUSD balances found on the public blockchain.\\n\"\n",
        "        \"‚Ä¢ This tool is for [bold]educational and testing purposes only[/bold].\\n\"\n",
        "        \"‚Ä¢ All simulations are performed against blockchain data without modifying any state.\\n\"\n",
        "        \"‚Ä¢ The trace_call API optimizations maximize Google's blockchain RPC capabilities.\",\n",
        "        title=\"[bold yellow3]DISCLAIMER[/bold yellow3]\",\n",
        "        border_style=\"yellow3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    console.print(\"\\n\")  # Add spacing\n",
        "\n",
        "    # 1. Transfer simulation\n",
        "    console.print(\"\\n\\n[bold chartreuse1]1. PYUSD Transfer Simulation[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    sim_result, sim_analysis = simulate_pyusd_transaction(\n",
        "        'transfer', SIM_FROM_ADDR, SIM_TO_ADDR, SIM_AMOUNT, network='mainnet'\n",
        "    )\n",
        "\n",
        "    # 2. PYUSD Balance check simulation\n",
        "    console.print(\"\\n\\n[bold chartreuse1]2. PYUSD Balance Check Simulation[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    sim_result_balance, sim_analysis_balance = simulate_pyusd_transaction(\n",
        "        'balanceOf', SIM_FROM_ADDR, SIM_FROM_ADDR, network='mainnet'\n",
        "    )\n",
        "\n",
        "    # 3. PYUSD Transfer Amount Comparison\n",
        "    console.print(\"\\n\\n[bold chartreuse1]3. PYUSD Transfer Amount Comparison[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    compare_results = compare_pyusd_transactions(\n",
        "        'transfer',\n",
        "        SIM_FROM_ADDR,\n",
        "        [\n",
        "            (SIM_TO_ADDR, 10000.0),\n",
        "            (SIM_TO_ADDR, 3000.0),\n",
        "            (SIM_TO_ADDR, 200.0)\n",
        "        ],\n",
        "        network='mainnet'\n",
        "    )\n",
        "\n",
        "    # 4. Batch Transaction Simulation\n",
        "    console.print(\"\\n\\n[bold chartreuse1]4. PYUSD Batch Transaction Simulation[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    batch_operations = [\n",
        "        ('balanceOf', [SIM_FROM_ADDR]),\n",
        "        ('transfer', [SIM_TO_ADDR, 50.0]),\n",
        "        ('approve', [SIM_TO_ADDR, 200.0]),\n",
        "    ]\n",
        "    batch_results = batch_simulate_pyusd_transactions(\n",
        "        SIM_FROM_ADDR,\n",
        "        batch_operations,\n",
        "        network='mainnet'\n",
        "    )\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"[cyan3]Simulation completed successfully![/cyan3]\\n\\n\"\n",
        "        \"[white]This cell demonstrates advanced PYUSD transaction simulation capabilities:[/white]\\n\"\n",
        "        \"‚Ä¢ [bold]Basic Transfer[/bold]: Simple PYUSD transfer with gas estimation\\n\"\n",
        "        \"‚Ä¢ [bold]Balance Check[/bold]: View operation with result decoding\\n\"\n",
        "        \"‚Ä¢ [bold]Transaction Comparison[/bold]: Gas usage analysis across different amounts\\n\"\n",
        "        \"‚Ä¢ [bold]Batch Operations[/bold]: Multiple operations simulated in sequence\\n\\n\"\n",
        "        \"[white]All results can be exported in CSV, JSON, or Google Sheets formats.[/white]\",\n",
        "        border_style=\"green3\",\n",
        "        box=box.ROUNDED,\n",
        "        title=\"[bold]üéâ Simulation Complete[/bold]\"\n",
        "    ))\n",
        "\n",
        "# Execute the simulations\n",
        "run_pyusd_simulations()"
      ],
      "metadata": {
        "id": "0ZBvghirsuew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.8 üìë `trace_transaction`: Alternative Transaction Trace Analysis\n",
        "\n",
        "This section explores `trace_transaction`, another RPC method for retrieving an execution trace for an *existing, already mined* transaction (`TARGET_TX_HASH`). While similar in purpose to `debug_traceTransaction`, its output format and the level of detail can differ depending on the node implementation. It often provides a list of \"actions\" or \"sub-traces\" representing the top-level call and internal calls.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `trace_transaction`\n",
        "> *   **Multiplier:** `50x` (Available on Mainnet via GCP)\n",
        "> *   **GCP Advantage:** Like other tracing methods, this can be resource-intensive. GCP ensures reliable retrieval of these traces for analysis. Comparing its output with `debug_traceTransaction` can sometimes reveal different perspectives on the execution.\n",
        "> *   **PYUSD Insight:** `trace_transaction` offers another way to:\n",
        ">     *   Visualize the call stack involving PYUSD interactions.\n",
        ">     *   Extract PYUSD function calls and **parameters** from the trace actions.\n",
        ">     *   Analyze gas usage breakdowns across the different actions within the trace.\n",
        ">     *   Identify common PYUSD transaction patterns (simple transfers, swaps, approvals).\n",
        ">     *   Detect potential MEV activity or security concerns based on the trace structure.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Trace:** Calls `trace_transaction` using the `TARGET_TX_HASH`.\n",
        "2.  **Process Actions:** The `analyze_trace_transaction` function iterates through the list of trace actions.\n",
        "3.  **Extract & Decode:** For each action, it extracts details like `from`, `to`, `value`, `gasUsed`, `input`, `output`, and `error`. It specifically decodes calls targeting PYUSD contracts.\n",
        "4.  **Analyze & Aggregate:**\n",
        "    *   Calculates overall gas usage, errors, and call depth.\n",
        "    *   Counts PYUSD interactions and categorizes PYUSD function calls.\n",
        "    *   Identifies PYUSD transfers and calculates volume.\n",
        "    *   Performs gas efficiency analysis against benchmarks.\n",
        "    *   Applies heuristics to identify transaction patterns (e.g., swap, simple transfer) and potential MEV/security flags.\n",
        "5.  **Visualize & Summarize:**\n",
        "    *   **Enhanced Summary Panel:** Displays aggregated metrics, complexity score, identified pattern, MEV/security flags.\n",
        "    *   **Security Concerns Table:** Lists any detected high-risk operations.\n",
        "    *   **PYUSD Function/Category Tables & Plots:** Shows the distribution and gas usage related to PYUSD calls.\n",
        "    *   **Transfer Table & Visualizations:** Details PYUSD token movements using tables and interactive **Plotly network graphs**.\n",
        "    *   **Call Tree Visualization:** Generates an interactive **Plotly graph** of the execution path (potentially using Graphviz for layout).\n",
        "    *   **Gas/Depth Plots:** Visualizes gas usage by contract type and call depth.\n",
        "    *   **Interactive Replay:** Provides a slider/play button to step through the execution sequence.\n",
        "    *   **Filtered Data Table:** Displays trace actions with interactive filtering.\n",
        "    *   **Export Options:** Download detailed trace analysis data.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Transaction Pattern:** What type of PYUSD activity does the analysis classify this as?\n",
        "*   **Security/MEV Flags:** Are there any warnings related to high-risk functions or potential MEV?\n",
        "*   **Gas Efficiency:** How does the gas usage for PYUSD calls compare to benchmarks?\n",
        "*   **Call Tree & Replay:** Follow the execution flow, paying attention to PYUSD interactions and any errors.\n",
        "*   **Token Flow:** Understand where PYUSD originated and ended up within this transaction.\n"
      ],
      "metadata": {
        "id": "LE0eRQe99ZvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üìë PYUSD Transaction Analysis with Interactive Visualization\n",
        "# =============================================================================================\n",
        "# This cell analyzes Ethereum transactions with a focus on PYUSD tokens, providing:\n",
        "# - Detailed execution trace analysis with step-by-step replay\n",
        "# - Visualization of contract interactions, call hierarchies, and token flows\n",
        "# - Security analysis identifying MEV potential and transaction patterns\n",
        "# - Gas usage optimization insights and export capabilities\n",
        "\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, clear_output, display, Javascript\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import networkx as nx\n",
        "import math\n",
        "from plotly.subplots import make_subplots\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "import time\n",
        "import re\n",
        "from eth_utils import decode_hex, to_hex, to_int\n",
        "\n",
        "# Transaction pattern definitions for classification\n",
        "PYUSD_TRANSACTION_PATTERNS = {\n",
        "    \"simple_transfer\": {\n",
        "        \"description\": \"Simple PYUSD transfer between addresses\",\n",
        "        \"signatures\": [\"transfer(address,uint256)\"],\n",
        "        \"contracts\": 1,\n",
        "        \"calls_min\": 1,\n",
        "        \"calls_max\": 3\n",
        "    },\n",
        "    \"swap_operation\": {\n",
        "        \"description\": \"PYUSD swap through DEX\",\n",
        "        \"signatures\": [\"transfer(address,uint256)\", \"swapExactTokensForTokens\", \"swapTokensForExactTokens\"],\n",
        "        \"contracts_min\": 2,\n",
        "        \"has_external_calls\": True\n",
        "    },\n",
        "    \"liquidity_provision\": {\n",
        "        \"description\": \"Adding/removing liquidity with PYUSD\",\n",
        "        \"signatures\": [\"transfer(address,uint256)\", \"mint\", \"addLiquidity\"],\n",
        "        \"contracts_min\": 2\n",
        "    },\n",
        "    \"bridge_operation\": {\n",
        "        \"description\": \"PYUSD bridge operation (cross-chain)\",\n",
        "        \"signatures\": [\"transfer(address,uint256)\", \"deposit\", \"lock\"],\n",
        "        \"gas_intensive\": True\n",
        "    },\n",
        "    \"multi_transfer\": {\n",
        "        \"description\": \"Multiple PYUSD transfers in one transaction\",\n",
        "        \"signatures\": [\"transfer(address,uint256)\"],\n",
        "        \"min_transfers\": 2\n",
        "    },\n",
        "    \"approval_flow\": {\n",
        "        \"description\": \"PYUSD approval for future spending\",\n",
        "        \"signatures\": [\"approve(address,uint256)\"],\n",
        "        \"calls_min\": 1,\n",
        "        \"calls_max\": 3\n",
        "    },\n",
        "    \"supply_change\": {\n",
        "        \"description\": \"Minting or burning of PYUSD supply\",\n",
        "        \"signatures\": [\"mint(address,uint256)\", \"burn(uint256)\"],\n",
        "        \"admin_operation\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "# MEV patterns to detect\n",
        "MEV_PATTERNS = {\n",
        "    \"sandwich_attack\": {\n",
        "        \"description\": \"Transaction sandwiched between two related transactions\",\n",
        "        \"indicators\": [\"swap before and after\", \"price impact\"]\n",
        "    },\n",
        "    \"arbitrage\": {\n",
        "        \"description\": \"Multi-step operation exploiting price differences\",\n",
        "        \"indicators\": [\"multiple DEX interactions\", \"circular flow\"]\n",
        "    },\n",
        "    \"front_running\": {\n",
        "        \"description\": \"Transaction potentially front-run by a MEV bot\",\n",
        "        \"indicators\": [\"unusual gas price\", \"similar operation before\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Security risk levels for different operations\n",
        "SECURITY_RISK_LEVELS = {\n",
        "    \"transferOwnership(address)\": \"high\",\n",
        "    \"pause()\": \"medium\",\n",
        "    \"unpause()\": \"medium\",\n",
        "    \"blacklist\": \"medium\",\n",
        "    \"upgrade\": \"high\",\n",
        "    \"initialize\": \"high\",\n",
        "    \"selfdestruct\": \"critical\",\n",
        "    \"mint(address,uint256)\": \"high\",\n",
        "    \"burn(uint256)\": \"medium\",\n",
        "    \"renounceOwnership()\": \"high\"\n",
        "}\n",
        "\n",
        "# Common gas costs for PYUSD operations for comparison - using full function names\n",
        "PYUSD_GAS_BENCHMARKS = {\n",
        "    \"transfer(address,uint256)\": {\n",
        "        \"median\": 65000,\n",
        "        \"p25\": 52000,\n",
        "        \"p75\": 78000\n",
        "    },\n",
        "    \"approve(address,uint256)\": {\n",
        "        \"median\": 46000,\n",
        "        \"p25\": 42000,\n",
        "        \"p75\": 58000\n",
        "    },\n",
        "    \"transferFrom(address,address,uint256)\": {\n",
        "        \"median\": 75000,\n",
        "        \"p25\": 65000,\n",
        "        \"p75\": 90000\n",
        "    },\n",
        "    \"mint(address,uint256)\": {\n",
        "        \"median\": 110000,\n",
        "        \"p25\": 95000,\n",
        "        \"p75\": 130000\n",
        "    },\n",
        "    \"burn(uint256)\": {\n",
        "        \"median\": 90000,\n",
        "        \"p25\": 80000,\n",
        "        \"p75\": 105000\n",
        "    }\n",
        "}\n",
        "\n",
        "# Export Functions\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets_direct(df, sheet_name=None):\n",
        "    \"\"\"Exports DataFrame directly to Google Sheets using authenticated session in Colab.\"\"\"\n",
        "    if sheet_name is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_name = f\"PYUSD Analysis {timestamp}\"\n",
        "\n",
        "    try:\n",
        "        from google.colab import auth\n",
        "        from googleapiclient.discovery import build\n",
        "        from googleapiclient.http import MediaInMemoryUpload\n",
        "        import io\n",
        "        from google.colab import output\n",
        "\n",
        "        @output.register_callback('notebook.createSheet')\n",
        "        def create_sheet_callback(csv_data, name):\n",
        "            try:\n",
        "                auth.authenticate_user()\n",
        "                drive_service = build('drive', 'v3')\n",
        "                file_metadata = {'name': name, 'mimeType': 'application/vnd.google-apps.spreadsheet'}\n",
        "                media = MediaInMemoryUpload(\n",
        "                    io.BytesIO(csv_data.encode('utf-8')),\n",
        "                    mimetype='text/csv',\n",
        "                    resumable=True\n",
        "                )\n",
        "                file = drive_service.files().create(\n",
        "                    body=file_metadata,\n",
        "                    media_body=media,\n",
        "                    fields='id,webViewLink'\n",
        "                ).execute()\n",
        "                return {\n",
        "                    'status': 'success',\n",
        "                    'file_id': file.get('id'),\n",
        "                    'link': file.get('webViewLink')\n",
        "                }\n",
        "            except Exception as e:\n",
        "                return {'status': 'error', 'message': str(e)}\n",
        "\n",
        "        csv_escaped = df.to_csv(index=False).replace('`', '\\\\`').replace('$', '\\\\$')\n",
        "\n",
        "        html = f'''\n",
        "        <script src=\"https://apis.google.com/js/platform.js\" async defer></script>\n",
        "        <script>\n",
        "        function createSheet() {{\n",
        "            const csv = `{csv_escaped}`;\n",
        "            google.colab.kernel.invokeFunction('notebook.createSheet', [csv, '{sheet_name}'], {{}})\n",
        "                .then(result => {{\n",
        "                    const outputDiv = document.getElementById('gsheet-output');\n",
        "                    if(result.data['application/json'].status === 'success') {{\n",
        "                        outputDiv.innerHTML = '<div>‚úÖ Google Sheet created: <a href=\"' + result.data['application/json'].link + '\" target=\"_blank\">{sheet_name}</a></div>';\n",
        "                    }} else {{\n",
        "                        outputDiv.innerHTML = '<div style=\"color:red\">‚ùå Error creating Google Sheet: ' + result.data['application/json'].message + '</div>';\n",
        "                    }}\n",
        "                }})\n",
        "                .catch(error => {{\n",
        "                     document.getElementById('gsheet-output').innerHTML = '<div style=\"color:red\">‚ùå Error invoking Google Sheet creation: ' + error + '</div>';\n",
        "                }});\n",
        "        }}\n",
        "        setTimeout(createSheet, 100);\n",
        "        </script>\n",
        "        <div id=\"gsheet-output\">Creating Google Sheet \"{sheet_name}\"...</div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except ImportError:\n",
        "         return HTML(\"<div style='color:red'>Google Colab specific export not available. Please run in Google Colab.</div>\")\n",
        "    except Exception as e:\n",
        "         return HTML(f\"<div style='color:red'>Error setting up Google Sheets export: {e}</div>\")\n",
        "\n",
        "\n",
        "# Plotly Visualization Functions\n",
        "def create_plotly_contract_interaction_graph(contract_interactions):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for contract interactions with directional arrows\"\"\"\n",
        "    if not contract_interactions:\n",
        "        return None\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    contracts_seen = set()\n",
        "    for src, dst in contract_interactions:\n",
        "        if not (isinstance(src, str) and src.startswith('0x') and len(src) == 42): continue\n",
        "        if not (isinstance(dst, str) and dst.startswith('0x') and len(dst) == 42): continue\n",
        "\n",
        "        if src not in contracts_seen:\n",
        "            src_name = PYUSD_CONTRACTS.get(src, \"External Contract\")\n",
        "            G.add_node(src, name=src_name, is_pyusd=(src in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(src)\n",
        "\n",
        "        if dst not in contracts_seen:\n",
        "            dst_name = PYUSD_CONTRACTS.get(dst, \"External Contract\")\n",
        "            G.add_node(dst, name=dst_name, is_pyusd=(dst in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(dst)\n",
        "\n",
        "        if src in G and dst in G:\n",
        "            G.add_edge(src, dst)\n",
        "\n",
        "    if not G.nodes():\n",
        "        console.print(\"[warning]No valid contract interactions found to generate graph.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        import pygraphviz as pgv\n",
        "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
        "    except ImportError:\n",
        "        console.print(\"[warning] pygraphviz import failed. Falling back to spring layout for contract interaction graph.\", style=\"warning\")\n",
        "        pos = nx.spring_layout(G, seed=42, k=1.5)\n",
        "    except Exception as layout_err:\n",
        "        console.print(f\"[warning] Hierarchical layout failed ({layout_err}). Falling back to spring layout.\", style=\"warning\")\n",
        "        pos = nx.spring_layout(G, seed=42, k=1.5)\n",
        "\n",
        "    edge_traces = []\n",
        "\n",
        "    for edge in G.edges():\n",
        "        src, dst = edge\n",
        "        if src not in pos or dst not in pos: continue\n",
        "\n",
        "        src_name = G.nodes[src].get('name', 'Unknown')\n",
        "        dst_name = G.nodes[dst].get('name', 'Unknown')\n",
        "\n",
        "        x0, y0 = pos[src]\n",
        "        x1, y1 = pos[dst]\n",
        "\n",
        "        dx = x1 - x0\n",
        "        dy = y1 - y0\n",
        "        length = math.sqrt(dx**2 + dy**2)\n",
        "        if length > 0: udx, udy = dx / length, dy / length\n",
        "        else: udx, udy = 0, 0\n",
        "\n",
        "        arrow_ratio = 0.8\n",
        "        arrow_x = x0 + arrow_ratio * dx\n",
        "        arrow_y = y0 + arrow_ratio * dy\n",
        "        angle = math.degrees(math.atan2(dy, dx))\n",
        "\n",
        "        edge_trace = go.Scatter(\n",
        "            x=[x0, x1], y=[y0, y1],\n",
        "            line=dict(width=1.5, color='rgba(50, 50, 50, 0.8)'),\n",
        "            hoverinfo='text',\n",
        "            text=f\"From: {src_name}<br>To: {dst_name}<br>From address: {src}<br>To address: {dst}\",\n",
        "            mode='lines', showlegend=False\n",
        "        )\n",
        "        arrow_trace = go.Scatter(\n",
        "            x=[arrow_x], y=[arrow_y], mode='markers',\n",
        "            marker=dict(symbol='triangle-right', size=12, color='rgba(50, 50, 50, 0.8)', angle=angle),\n",
        "            hoverinfo='none', showlegend=False\n",
        "        )\n",
        "        edge_traces.append(edge_trace)\n",
        "        edge_traces.append(arrow_trace)\n",
        "\n",
        "    node_x, node_y, node_colors, node_sizes, hover_texts, node_addresses = [], [], [], [], [], []\n",
        "    for node in G.nodes():\n",
        "        if node not in pos: continue\n",
        "        node_data = G.nodes[node]\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x); node_y.append(y)\n",
        "        is_pyusd = node_data.get('is_pyusd', False)\n",
        "        node_name = node_data.get('name', 'Unknown')\n",
        "        if is_pyusd:\n",
        "            if \"PYUSD Token\" in node_name: node_colors.append('rgba(144, 238, 144, 0.9)')\n",
        "            elif \"Supply Control\" in node_name: node_colors.append('rgba(135, 206, 250, 0.9)')\n",
        "            else: node_colors.append('rgba(224, 255, 255, 0.9)')\n",
        "        else: node_colors.append('rgba(211, 211, 211, 0.9)')\n",
        "        node_sizes.append(25 if is_pyusd else 18)\n",
        "        node_addresses.append(node)\n",
        "        hover_texts.append(f\"<b>{node_name}</b><br>Address: {node}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y, mode='markers+text', hoverinfo='text', text=node_addresses,\n",
        "        textposition=\"bottom center\", hovertext=hover_texts,\n",
        "        marker=dict(showscale=False, color=node_colors, size=node_sizes, line=dict(width=1, color='#000')),\n",
        "        textfont=dict(family=\"monospace\", size=10, color=\"black\")\n",
        "    )\n",
        "\n",
        "    legend_traces = [\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'), name='PYUSD Token', showlegend=True),\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'), name='Supply Control', showlegend=True),\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'), name='External Contract', showlegend=True)\n",
        "    ]\n",
        "\n",
        "    fig = go.Figure()\n",
        "    for trace in edge_traces: fig.add_trace(trace)\n",
        "    fig.add_trace(node_trace)\n",
        "    for trace in legend_traces: fig.add_trace(trace)\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='<b>Contract Interaction Overview</b>', titlefont=dict(size=16), showlegend=True,\n",
        "        legend=dict(title=\"Contract Types\", orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1, bgcolor=\"rgba(255, 255, 255, 0.8)\"),\n",
        "        hovermode='closest', margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\", height=600, paper_bgcolor='rgba(255,255,255,0.8)', plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def create_plotly_call_graph(call_data_list):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for the call trace hierarchy\"\"\"\n",
        "    if not call_data_list:\n",
        "        return None\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "    id_map = {}\n",
        "    node_list_for_graph = []\n",
        "\n",
        "    for i, call in enumerate(call_data_list):\n",
        "        trace_addr = call.get('trace_addr', [])\n",
        "        trace_addr_str = \"_\".join(map(str, trace_addr)) if trace_addr else \"root\"\n",
        "        node_id = f\"node_{trace_addr_str}\"\n",
        "        count = 0\n",
        "        original_node_id = node_id\n",
        "        while node_id in id_map.values():\n",
        "             count += 1\n",
        "             node_id = f\"{original_node_id}_{count}\"\n",
        "\n",
        "        call['id'] = node_id\n",
        "        id_map[tuple(trace_addr)] = node_id\n",
        "        node_list_for_graph.append(call)\n",
        "\n",
        "    for call in node_list_for_graph:\n",
        "        call_defaults = {\n",
        "            'type': 'CALL', 'depth': 0, 'from': 'N/A', 'to': 'N/A', 'value_eth': 0.0, 'gasUsed': 0,\n",
        "            'is_pyusd': False, 'contract': 'Other', 'function_category': 'other', 'error': None,\n",
        "            'input_preview': '0x', 'output_preview': '0x', 'function': 'N/A', 'trace_addr': []\n",
        "        }\n",
        "        node_data = {**call_defaults, **call}\n",
        "        G.add_node(call['id'], **node_data)\n",
        "\n",
        "    for call in node_list_for_graph:\n",
        "        trace_addr = call.get('trace_addr', [])\n",
        "        if trace_addr:\n",
        "            parent_trace_addr = tuple(trace_addr[:-1])\n",
        "            parent_id = id_map.get(parent_trace_addr)\n",
        "            if parent_id and parent_id in G and call['id'] in G:\n",
        "                G.add_edge(parent_id, call['id'])\n",
        "\n",
        "    if not G.nodes():\n",
        "         console.print(\"[warning]No nodes created for Plotly call graph.\", style=\"warning\")\n",
        "         return None\n",
        "\n",
        "    try:\n",
        "        import pygraphviz as pgv\n",
        "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
        "    except ImportError:\n",
        "        console.print(\"[warning]pygraphviz not found. Using spring layout for call graph.\", style=\"warning\")\n",
        "        pos = nx.spring_layout(G, seed=42, k=0.5)\n",
        "    except Exception as layout_err:\n",
        "         console.print(f\"[warning]Layout calculation failed ({layout_err}). Using random layout.\", style=\"warning\")\n",
        "         pos = nx.random_layout(G, seed=42)\n",
        "\n",
        "    edge_traces_by_type = {}\n",
        "    for edge in G.edges():\n",
        "        source, target = edge\n",
        "        if source not in G or target not in G or source not in pos or target not in pos: continue\n",
        "        source_data = G.nodes[source]; target_data = G.nodes[target]\n",
        "        call_type = target_data.get('type', 'CALL').upper()\n",
        "        if call_type not in edge_traces_by_type:\n",
        "            color, style, width = 'rgba(128, 128, 128, 0.7)', 'solid', 1\n",
        "            if call_type == 'DELEGATECALL': color, style, width = 'rgba(0, 0, 255, 0.7)', 'dash', 2\n",
        "            elif call_type == 'STATICCALL': color, style, width = 'rgba(0, 128, 0, 0.7)', 'dot', 1.5\n",
        "            elif call_type == 'CREATE': color, style, width = 'rgba(255, 165, 0, 0.8)', 'solid', 1.5\n",
        "            edge_traces_by_type[call_type] = {'x': [], 'y': [], 'text': [], 'color': color, 'style': style, 'width': width}\n",
        "\n",
        "        x0, y0 = pos[source]; x1, y1 = pos[target]\n",
        "        edge_traces_by_type[call_type]['x'].extend([x0, x1, None])\n",
        "        edge_traces_by_type[call_type]['y'].extend([y0, y1, None])\n",
        "        hover_text = f\"<b>{call_type}</b><br>From: {shorten_address(source_data.get('from', 'N/A'))}<br>To: {shorten_address(target_data.get('to', 'N/A'))}\"\n",
        "        edge_traces_by_type[call_type]['text'].append(hover_text)\n",
        "\n",
        "    edge_traces = []\n",
        "    for call_type, trace_data in edge_traces_by_type.items():\n",
        "        edge_traces.append(go.Scatter(x=trace_data['x'], y=trace_data['y'],\n",
        "                           line=dict(width=trace_data['width'], color=trace_data['color'], dash=trace_data['style']),\n",
        "                           hoverinfo='text', text=trace_data['text'], mode='lines', name=call_type))\n",
        "\n",
        "    node_x, node_y, node_colors, node_sizes, node_text, hover_texts = [], [], [], [], [], []\n",
        "    for node_id in G.nodes():\n",
        "        if node_id not in pos: continue\n",
        "        node_data = G.nodes[node_id]\n",
        "        x, y = pos[node_id]\n",
        "        node_x.append(x); node_y.append(y)\n",
        "\n",
        "        function_name = node_data.get('function', 'N/A')\n",
        "        if function_name == 'N/A':\n",
        "            function_name = get_function_description(\n",
        "                node_data.get('input_preview', '0x'), node_data.get('is_pyusd', False), node_data.get('contract', 'Other')\n",
        "            )\n",
        "\n",
        "        short_name = function_name.split('(')[0] if '(' in function_name else function_name\n",
        "        node_text.append(short_name[:10] + '...' if len(short_name) > 12 else short_name)\n",
        "\n",
        "        hover_text = f\"<b>{node_data.get('type', 'CALL').upper()} Call</b><br>\"\n",
        "        hover_text += f\"Depth: {node_data.get('depth','N/A')}, Gas: {node_data.get('gasUsed',0):,}<br>\"\n",
        "        hover_texts.append(hover_text)\n",
        "\n",
        "        error = node_data.get('error')\n",
        "        is_pyusd = node_data.get('is_pyusd', False)\n",
        "        contract_name = node_data.get('contract', 'Other')\n",
        "        color = 'rgba(211, 211, 211, 0.9)'\n",
        "        if error: color = 'rgba(255, 99, 71, 0.9)'\n",
        "        elif is_pyusd:\n",
        "            if \"PYUSD Token\" in contract_name: color = 'rgba(144, 238, 144, 0.9)'\n",
        "            elif \"Supply Control\" in contract_name: color = 'rgba(135, 206, 250, 0.9)'\n",
        "            else: color = 'rgba(224, 255, 255, 0.9)'\n",
        "        else:\n",
        "             depth = node_data.get('depth', 0)\n",
        "             intensity = min(95, max(70, 95 - depth * 5))\n",
        "             rgb_val = intensity / 100.0\n",
        "             color = f'rgba({int(rgb_val*255)}, {int(rgb_val*255)}, {int(rgb_val*255)}, 0.9)'\n",
        "        node_colors.append(color)\n",
        "\n",
        "        gas_used = node_data.get('gasUsed', 0)\n",
        "        node_sizes.append(max(15, min(40, 15 + (gas_used / 50000))))\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y, mode='markers+text', hoverinfo='text', text=node_text, textposition=\"top center\",\n",
        "        hovertext=hover_texts,\n",
        "        marker=dict(showscale=False, color=node_colors, size=node_sizes, line=dict(width=1, color='#000')),\n",
        "        textfont=dict(family=\"Arial\", size=9, color=\"#333\")\n",
        "    )\n",
        "\n",
        "    node_color_legend = [\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'), name='PYUSD Token', showlegend=True),\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'), name='Supply Control', showlegend=True),\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(224, 255, 255, 0.9)'), name='Other PYUSD Contract', showlegend=True),\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'), name='Other Contract', showlegend=True),\n",
        "        go.Scatter(x=[None], y=[None], mode='markers', marker=dict(size=15, color='rgba(255, 99, 71, 0.9)'), name='Error', showlegend=True)\n",
        "    ]\n",
        "\n",
        "    fig = go.Figure()\n",
        "    for trace in edge_traces: fig.add_trace(trace)\n",
        "    fig.add_trace(node_trace)\n",
        "    for trace in node_color_legend: fig.add_trace(trace)\n",
        "\n",
        "    fig.update_layout(\n",
        "        title='<b>Detailed Call Graph Visualization (trace_transaction)</b>', titlefont=dict(size=16), showlegend=True,\n",
        "        legend=dict(title=\"Legend\", orientation=\"v\", yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01, bgcolor=\"rgba(255, 255, 255, 0.8)\"),\n",
        "        hovermode='closest', margin=dict(b=40, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\", height=700, paper_bgcolor='rgba(255,255,255,0.8)', plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def create_plotly_flow_graph(transfers):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for PYUSD token flows\"\"\"\n",
        "    if not transfers:\n",
        "        return None\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "    transfer_totals = {}\n",
        "\n",
        "    for transfer in transfers:\n",
        "        from_addr = transfer.get('from')\n",
        "        to_addr = transfer.get('to')\n",
        "        amount_raw = transfer.get('amount', 0)\n",
        "        if not isinstance(amount_raw, (int, float)): continue\n",
        "        amount = int(amount_raw)\n",
        "        if not from_addr or not to_addr or amount <= 0: continue\n",
        "\n",
        "        edge_key = (from_addr.lower(), to_addr.lower())\n",
        "        transfer_totals[edge_key] = transfer_totals.get(edge_key, 0) + amount\n",
        "\n",
        "    nodes_added = set()\n",
        "    for (from_addr, to_addr), total_amount in transfer_totals.items():\n",
        "        if from_addr not in G:\n",
        "            G.add_node(from_addr, address=from_addr, label=shorten_address(from_addr))\n",
        "        if to_addr not in G:\n",
        "            G.add_node(to_addr, address=to_addr, label=shorten_address(to_addr))\n",
        "        G.add_edge(from_addr, to_addr, amount=total_amount, label=format_value_pyusd(total_amount))\n",
        "\n",
        "    if not G.nodes():\n",
        "        console.print(\"[warning]No valid transfer data found to create flow graph.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        pos = nx.spring_layout(G, k=1.0, seed=42)\n",
        "    except Exception as layout_err:\n",
        "        console.print(f\"[warning]Flow graph layout failed ({layout_err}). Using random layout.\", style=\"warning\")\n",
        "        pos = nx.random_layout(G, seed=42)\n",
        "\n",
        "    edge_x, edge_y, edge_text = [], [], []\n",
        "    label_x, label_y, label_text = [], [], []\n",
        "    arrow_x, arrow_y, arrow_angles = [], [], []\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "        if source not in pos or target not in pos: continue\n",
        "        x0, y0 = pos[source]; x1, y1 = pos[target]\n",
        "\n",
        "        edge_x.extend([x0, x1, None]); edge_y.extend([y0, y1, None])\n",
        "        amount_str = format_value_pyusd(data['amount'])\n",
        "        edge_text.append(f\"Transfer: {amount_str}<br>From: {shorten_address(source)}<br>To: {shorten_address(target)}\")\n",
        "\n",
        "        label_x.append((x0 + x1) / 2); label_y.append((y0 + y1) / 2); label_text.append(amount_str)\n",
        "\n",
        "        dx = x1 - x0; dy = y1 - y0\n",
        "        arrow_ratio = 0.95\n",
        "        arrow_x.append(x0 + dx * arrow_ratio); arrow_y.append(y0 + dy * arrow_ratio)\n",
        "        arrow_angles.append(math.degrees(math.atan2(dy, dx)))\n",
        "\n",
        "    edge_trace = go.Scatter(x=edge_x, y=edge_y, line=dict(width=2, color='rgba(50, 150, 50, 0.8)'),\n",
        "                           hoverinfo='text', text=edge_text, mode='lines', name='Transfer')\n",
        "    edge_label_trace = go.Scatter(x=label_x, y=label_y, text=label_text, mode='text', hoverinfo='none',\n",
        "                                 showlegend=False, textfont=dict(size=10, color='darkgreen'))\n",
        "    arrow_trace = go.Scatter(x=arrow_x, y=arrow_y, mode='markers', marker=dict(symbol='triangle-right', size=12,\n",
        "                           color='rgba(50, 150, 50, 0.8)', angle=arrow_angles), hoverinfo='none', showlegend=False)\n",
        "\n",
        "    node_x, node_y, node_text, node_hover = [], [], [], []\n",
        "    for node in G.nodes():\n",
        "        if node not in pos: continue\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x); node_y.append(y)\n",
        "        node_text.append(node)\n",
        "        node_hover.append(f\"<b>Address:</b> {node}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y, mode='markers+text', hoverinfo='text', text=node_text, textposition=\"bottom center\",\n",
        "        hovertext=node_hover,\n",
        "        marker=dict(color='rgba(144, 238, 144, 0.8)', size=25, line=dict(width=1, color='darkgreen'), symbol='circle'),\n",
        "        textfont=dict(family=\"monospace\", size=9, color=\"black\"), name='Address'\n",
        "    )\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(edge_trace); fig.add_trace(edge_label_trace); fig.add_trace(arrow_trace); fig.add_trace(node_trace)\n",
        "    fig.update_layout(\n",
        "        title='<b>PYUSD Token Flow Analysis</b>', titlefont=dict(size=16), showlegend=True,\n",
        "        legend=dict(title=\"Elements\", orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1, bgcolor=\"rgba(255, 255, 255, 0.8)\"),\n",
        "        hovermode='closest', margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\", height=600, paper_bgcolor='rgba(255,255,255,0.8)', plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "# Helper Functions for Enhanced Analysis\n",
        "def extract_params_from_input(input_data, method_sig, param_types):\n",
        "    \"\"\"Extract and decode parameters from input data based on function signature\"\"\"\n",
        "    try:\n",
        "        params_hex = input_data[10:]\n",
        "        decoded_params = []\n",
        "        pos = 0\n",
        "        for param_type in param_types:\n",
        "            if param_type == \"address\":\n",
        "                param_val = \"0x\" + params_hex[pos+24:pos+64]\n",
        "                decoded_params.append(param_val)\n",
        "            elif param_type.startswith(\"uint\"):\n",
        "                param_val = int(params_hex[pos:pos+64], 16)\n",
        "                decoded_params.append(param_val)\n",
        "            elif param_type == \"bool\":\n",
        "                param_val = int(params_hex[pos:pos+64], 16) != 0\n",
        "                decoded_params.append(param_val)\n",
        "            elif param_type == \"bytes32\":\n",
        "                param_val = \"0x\" + params_hex[pos:pos+64]\n",
        "                decoded_params.append(param_val)\n",
        "            pos += 64\n",
        "        return decoded_params\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "def decode_pyusd_function(input_data):\n",
        "    \"\"\"Enhanced function to decode PYUSD function calls with human-readable parameters\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return {\"name\": \"Unknown\", \"category\": \"other\", \"params\": {}}\n",
        "\n",
        "    method_sig = input_data[:10]\n",
        "\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        sig_info = PYUSD_SIGNATURES[method_sig]\n",
        "        function_name = sig_info[\"name\"]\n",
        "        function_category = sig_info[\"category\"]\n",
        "        params = {}\n",
        "\n",
        "        if method_sig == '0xa9059cbb':  # transfer(address,uint256)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"address\", \"uint256\"])\n",
        "                if len(decoded) == 2:\n",
        "                    params = {\n",
        "                        \"to\": decoded[0], \"to_address\": shorten_address(decoded[0]),\n",
        "                        \"amount\": decoded[1], \"amount_formatted\": format_value_pyusd(decoded[1])}\n",
        "            except Exception: pass\n",
        "        elif method_sig == '0x23b872dd':  # transferFrom(address,address,uint256)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"address\", \"address\", \"uint256\"])\n",
        "                if len(decoded) == 3:\n",
        "                    params = {\n",
        "                        \"from\": decoded[0], \"from_address\": shorten_address(decoded[0]),\n",
        "                        \"to\": decoded[1], \"to_address\": shorten_address(decoded[1]),\n",
        "                        \"amount\": decoded[2], \"amount_formatted\": format_value_pyusd(decoded[2])}\n",
        "            except Exception: pass\n",
        "        elif method_sig == '0x095ea7b3':  # approve(address,uint256)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"address\", \"uint256\"])\n",
        "                if len(decoded) == 2:\n",
        "                    params = {\n",
        "                        \"spender\": decoded[0], \"spender_address\": shorten_address(decoded[0]),\n",
        "                        \"amount\": decoded[1], \"amount_formatted\": format_value_pyusd(decoded[1])}\n",
        "            except Exception: pass\n",
        "        elif method_sig == '0x40c10f19':  # mint(address,uint256)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"address\", \"uint256\"])\n",
        "                if len(decoded) == 2:\n",
        "                    params = {\n",
        "                        \"to\": decoded[0], \"to_address\": shorten_address(decoded[0]),\n",
        "                        \"amount\": decoded[1], \"amount_formatted\": format_value_pyusd(decoded[1])}\n",
        "            except Exception: pass\n",
        "        elif method_sig == '0x42966c68':  # burn(uint256)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"uint256\"])\n",
        "                if len(decoded) == 1:\n",
        "                    params = {\"amount\": decoded[0], \"amount_formatted\": format_value_pyusd(decoded[0])}\n",
        "            except Exception: pass\n",
        "        elif method_sig == '0x70a08231':  # balanceOf(address)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"address\"])\n",
        "                if len(decoded) == 1:\n",
        "                    params = {\"account\": decoded[0], \"account_address\": shorten_address(decoded[0])}\n",
        "            except Exception: pass\n",
        "        elif method_sig == '0xdd62ed3e':  # allowance(address,address)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"address\", \"address\"])\n",
        "                if len(decoded) == 2:\n",
        "                    params = {\n",
        "                        \"owner\": decoded[0], \"owner_address\": shorten_address(decoded[0]),\n",
        "                        \"spender\": decoded[1], \"spender_address\": shorten_address(decoded[1])}\n",
        "            except Exception: pass\n",
        "        elif method_sig == '0xf2fde38b':  # transferOwnership(address)\n",
        "            try:\n",
        "                decoded = extract_params_from_input(input_data, method_sig, [\"address\"])\n",
        "                if len(decoded) == 1:\n",
        "                    params = {\"newOwner\": decoded[0], \"newOwner_address\": shorten_address(decoded[0])}\n",
        "            except Exception: pass\n",
        "\n",
        "        return {\"name\": function_name, \"category\": function_category, \"params\": params}\n",
        "    return {\"name\": \"Unknown\", \"category\": \"other\", \"params\": {}}\n",
        "\n",
        "\n",
        "def analyze_gas_efficiency(gas_used, function_name):\n",
        "    \"\"\"Analyze gas efficiency compared to benchmarks\"\"\"\n",
        "    if function_name in PYUSD_GAS_BENCHMARKS:\n",
        "        benchmark = PYUSD_GAS_BENCHMARKS[function_name]\n",
        "        median = benchmark[\"median\"]\n",
        "        p25 = benchmark[\"p25\"]\n",
        "        p75 = benchmark[\"p75\"]\n",
        "        pct_diff = ((gas_used - median) / median) * 100 if median > 0 else 0\n",
        "        if gas_used <= p25: efficiency, color = \"excellent\", \"green\"\n",
        "        elif gas_used <= median: efficiency, color = \"good\", \"blue\"\n",
        "        elif gas_used <= p75: efficiency, color = \"average\", \"yellow\"\n",
        "        else: efficiency, color = \"poor\", \"red\"\n",
        "        return {\"efficiency\": efficiency, \"color\": color, \"pct_diff\": pct_diff, \"compared_to_median\": gas_used - median}\n",
        "    return {\"efficiency\": \"unknown\", \"color\": \"gray\", \"pct_diff\": 0, \"compared_to_median\": 0}\n",
        "\n",
        "\n",
        "def identify_transaction_pattern(summary_df, pyusd_transfers):\n",
        "    \"\"\"Identify common transaction patterns for PYUSD\"\"\"\n",
        "    result = {\"pattern\": \"unknown\", \"confidence\": 0, \"description\": \"Unknown transaction pattern\", \"matches\": []}\n",
        "    if summary_df.empty: return result\n",
        "\n",
        "    pyusd_df = summary_df[summary_df['is_pyusd']] if 'is_pyusd' in summary_df.columns else pd.DataFrame()\n",
        "    contract_count = len(pyusd_df['to'].unique()) if not pyusd_df.empty and 'to' in pyusd_df.columns else 0\n",
        "    function_counts = pyusd_df['function'].value_counts().to_dict() if not pyusd_df.empty and 'function' in pyusd_df.columns else {}\n",
        "    transfer_count = len(pyusd_transfers)\n",
        "    matches = []\n",
        "\n",
        "    if transfer_count == 1 and contract_count <= 1 and \"transfer(address,uint256)\" in function_counts and function_counts.get(\"transfer(address,uint256)\",0) == 1:\n",
        "        matches.append((\"simple_transfer\", 0.9, \"Simple PYUSD transfer between addresses\"))\n",
        "    if transfer_count > 1 and \"transfer(address,uint256)\" in function_counts and function_counts.get(\"transfer(address,uint256)\",0) > 1:\n",
        "        matches.append((\"multi_transfer\", 0.8, \"Multiple PYUSD transfers in one transaction\"))\n",
        "    if \"approve(address,uint256)\" in function_counts and function_counts.get(\"approve(address,uint256)\",0) >= 1:\n",
        "        matches.append((\"approval_flow\", 0.85, \"PYUSD approval for future spending\"))\n",
        "    if (\"mint(address,uint256)\" in function_counts and function_counts.get(\"mint(address,uint256)\",0) >= 1) or (\"burn(uint256)\" in function_counts and function_counts.get(\"burn(uint256)\",0) >= 1):\n",
        "        matches.append((\"supply_change\", 0.95, \"Minting or burning of PYUSD supply\"))\n",
        "\n",
        "    external_contract_calls = summary_df[~summary_df['is_pyusd'] & (summary_df['type'].str.upper() == 'CALL')].shape[0] if 'is_pyusd' in summary_df.columns and 'type' in summary_df.columns else 0\n",
        "    if transfer_count >= 1 and external_contract_calls >= 3:\n",
        "        matches.append((\"swap_operation\", 0.7, \"PYUSD swap through DEX\"))\n",
        "    if transfer_count >= 1 and not pyusd_df.empty and 'function' in pyusd_df.columns and 'mint' in ' '.join(pyusd_df['function'].astype(str).values):\n",
        "        matches.append((\"liquidity_provision\", 0.6, \"Adding/removing liquidity with PYUSD\"))\n",
        "\n",
        "    if matches:\n",
        "        matches.sort(key=lambda x: x[1], reverse=True)\n",
        "        best_match = matches[0]\n",
        "        result = {\"pattern\": best_match[0], \"confidence\": best_match[1], \"description\": best_match[2], \"matches\": matches}\n",
        "    return result\n",
        "\n",
        "\n",
        "def detect_mev_potential(trace_list, summary_df, tx_hash):\n",
        "    \"\"\"Detect potential MEV activity in the transaction\"\"\"\n",
        "    results = {\"mev_detected\": False, \"type\": None, \"confidence\": 0, \"description\": None, \"indicators\": []}\n",
        "    if summary_df.empty: return results\n",
        "\n",
        "    token_movements = len(summary_df[summary_df['function'].str.contains('transfer', na=False)]) if 'function' in summary_df.columns else 0\n",
        "    unique_contracts = len(summary_df['to'].unique()) if 'to' in summary_df.columns else 0\n",
        "    indicators = []\n",
        "    has_swap = any(summary_df['function'].str.contains('swap', case=False, na=False)) if 'function' in summary_df.columns else False\n",
        "    external_calls = summary_df[~summary_df['is_pyusd']].shape[0] if 'is_pyusd' in summary_df.columns else 0\n",
        "\n",
        "    if has_swap and external_calls > 3:\n",
        "        indicators.append((\"potential_sandwich_target\", 0.6, \"Transaction contains swap with external calls\"))\n",
        "    if token_movements >= 3 and unique_contracts >= 3:\n",
        "        indicators.append((\"potential_arbitrage\", 0.7, \"Multiple token movements across different contracts\"))\n",
        "\n",
        "    if indicators:\n",
        "        indicators.sort(key=lambda x: x[1], reverse=True)\n",
        "        best_indicator = indicators[0]\n",
        "        results = {\"mev_detected\": True, \"type\": best_indicator[0], \"confidence\": best_indicator[1], \"description\": best_indicator[2], \"indicators\": indicators}\n",
        "    return results\n",
        "\n",
        "\n",
        "def detect_security_concerns(trace_list, summary_df):\n",
        "    \"\"\"Detect potential security concerns in the transaction\"\"\"\n",
        "    concerns = []\n",
        "    if summary_df.empty: return concerns\n",
        "\n",
        "    if 'function' in summary_df.columns:\n",
        "        for _, row in summary_df.iterrows():\n",
        "            function_name = row['function']\n",
        "            if function_name in SECURITY_RISK_LEVELS:\n",
        "                risk_level = SECURITY_RISK_LEVELS[function_name]\n",
        "                concerns.append({\n",
        "                    \"level\": risk_level,\n",
        "                    \"description\": f\"High-risk function '{function_name}' called\",\n",
        "                    \"contract\": row.get('contract', 'N/A'),\n",
        "                    \"from\": row.get('from', 'N/A')\n",
        "                })\n",
        "\n",
        "    if 'function' in summary_df.columns and 'approve(address,uint256)' in summary_df['function'].unique():\n",
        "         approval_rows = summary_df[summary_df['function'] == 'approve(address,uint256)']\n",
        "         approval_amount_cols = [col for col in summary_df.columns if 'param_amount' in col and col != 'param_amount_formatted']\n",
        "         if approval_amount_cols:\n",
        "             amount_col = approval_amount_cols[0]\n",
        "             for _, row in approval_rows.iterrows():\n",
        "                 if pd.notna(row[amount_col]) and isinstance(row[amount_col], (int, float)):\n",
        "                     amount_val = row[amount_col]\n",
        "                     max_uint_approx = (2**256) - (2**128)\n",
        "                     if amount_val >= max_uint_approx:\n",
        "                          concerns.append({\n",
        "                             \"level\": \"medium\",\n",
        "                             \"description\": f\"Potentially infinite approval granted\",\n",
        "                             \"contract\": row.get('contract', 'N/A'), \"from\": row.get('from', 'N/A')\n",
        "                          })\n",
        "                     elif amount_val >= (10**6) * 1000000:\n",
        "                         concerns.append({\n",
        "                             \"level\": \"low\",\n",
        "                             \"description\": f\"Large approval granted: {row.get('param_amount_formatted', format_value_pyusd(amount_val))}\",\n",
        "                             \"contract\": row.get('contract', 'N/A'), \"from\": row.get('from', 'N/A')\n",
        "                         })\n",
        "\n",
        "    if 'function' in summary_df.columns and any(summary_df['function'].str.contains('selfdestruct', case=False, na=False)):\n",
        "        concerns.append({\"level\": \"critical\", \"description\": \"Contract self-destruct called\", \"contract\": \"N/A\", \"from\": \"N/A\"})\n",
        "\n",
        "    return concerns\n",
        "\n",
        "# Main Analysis Function\n",
        "def analyze_trace_transaction(trace_list, tx_hash):\n",
        "    \"\"\"Analyzes the output list from trace_transaction with PYUSD focus.\"\"\"\n",
        "    if not isinstance(trace_list, list):\n",
        "        console.print(f\"[error]Expected a list from trace_transaction for {shorten_address(tx_hash)}, got {type(trace_list)}.\", style=\"error\")\n",
        "        return None\n",
        "    if not trace_list:\n",
        "        console.print(f\"[warning]No trace results (empty list) from trace_transaction for {shorten_address(tx_hash)}.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]Analyzing {len(trace_list)} Actions from trace_transaction for {shorten_address(tx_hash)}[/bold cyan3]\")\n",
        "\n",
        "    # Initialize tracking data\n",
        "    summary = []\n",
        "    total_gas_used = 0\n",
        "    errors = 0\n",
        "    pyusd_interactions = 0\n",
        "    pyusd_calls_by_function = {}\n",
        "    pyusd_calls_by_category = {cat: 0 for cat in [\"token_movement\", \"supply_change\", \"allowance\", \"control\", \"admin\", \"view\", \"other\"]}\n",
        "\n",
        "    # Data for Plotly graphs\n",
        "    call_data_list_for_plotly = []\n",
        "    contract_interactions_list = []\n",
        "    pyusd_transfers_for_plotly = []\n",
        "    pyusd_transfers_display = []\n",
        "\n",
        "    # Track call depth and sequence for replay visualization\n",
        "    call_sequence = []\n",
        "    max_depth = 0\n",
        "    gas_by_depth = {}\n",
        "    contract_interactions_agg = {}\n",
        "\n",
        "    # Enhanced token flow tracking\n",
        "    eth_flows = []\n",
        "\n",
        "    # Process each trace action\n",
        "    for i, trace_item in enumerate(trace_list):\n",
        "        if not isinstance(trace_item, dict): continue\n",
        "\n",
        "        action = trace_item.get('action', {})\n",
        "        result = trace_item.get('result', {})\n",
        "        trace_type = trace_item.get('type', 'N/A').upper()\n",
        "        trace_addr = trace_item.get('traceAddress', [])\n",
        "        error = trace_item.get('error')\n",
        "\n",
        "        current_depth = len(trace_addr)\n",
        "        max_depth = max(max_depth, current_depth)\n",
        "\n",
        "        from_addr = action.get('from')\n",
        "        from_addr_lower = from_addr.lower() if isinstance(from_addr, str) else None\n",
        "        to_addr = action.get('to', result.get('address') if trace_type == 'CREATE' else None)\n",
        "        to_addr_lower = to_addr.lower() if isinstance(to_addr, str) else None\n",
        "\n",
        "        value_raw_wei = to_int(hexstr=action.get('value', '0x0')) if action.get('value') else 0\n",
        "        value_eth = format_value_eth(value_raw_wei)\n",
        "        value_eth_float = float(w3_mainnet.from_wei(value_raw_wei, 'ether')) if w3_mainnet and value_raw_wei is not None else 0.0\n",
        "\n",
        "        gas_used_hex = result.get('gasUsed', trace_item.get('gasUsed', '0x0'))\n",
        "        gas_used = int(gas_used_hex, 16) if gas_used_hex else 0\n",
        "\n",
        "        depth_key = len(trace_addr)\n",
        "        gas_by_depth[depth_key] = gas_by_depth.get(depth_key, 0) + gas_used\n",
        "\n",
        "        call_data = action.get('input', '0x')\n",
        "        output_data = result.get('output', '0x')\n",
        "\n",
        "        # Check PYUSD based on address\n",
        "        is_pyusd_call = False\n",
        "        contract_name = \"Other Contract\"\n",
        "        check_addr_lower = None\n",
        "        if trace_type == 'CREATE':\n",
        "            created_addr_lower = result.get('address','').lower() if result else ''\n",
        "            if created_addr_lower in PYUSD_CONTRACTS:\n",
        "                is_pyusd_call = True\n",
        "                contract_name = PYUSD_CONTRACTS[created_addr_lower]\n",
        "                check_addr_lower = created_addr_lower\n",
        "            to_addr = result.get('address') if result else None\n",
        "            to_addr_lower = to_addr.lower() if isinstance(to_addr, str) else None\n",
        "        elif to_addr_lower:\n",
        "            if to_addr_lower in PYUSD_CONTRACTS:\n",
        "                is_pyusd_call = True\n",
        "                contract_name = PYUSD_CONTRACTS[to_addr_lower]\n",
        "                check_addr_lower = to_addr_lower\n",
        "\n",
        "        # Track contract interactions\n",
        "        if from_addr_lower and to_addr_lower:\n",
        "            contract_interactions_list.append((from_addr_lower, to_addr_lower))\n",
        "            interaction_key = f\"{from_addr_lower}:{to_addr_lower}\"\n",
        "            contract_interactions_agg[interaction_key] = contract_interactions_agg.get(interaction_key, {\"from\": from_addr, \"to\": to_addr, \"count\": 0, \"gas\": 0})\n",
        "            contract_interactions_agg[interaction_key][\"count\"] += 1\n",
        "            contract_interactions_agg[interaction_key][\"gas\"] += gas_used\n",
        "\n",
        "        if value_raw_wei > 0:\n",
        "            eth_flows.append({\"from\": from_addr, \"to\": to_addr, \"value\": value_raw_wei, \"value_formatted\": value_eth, \"trace_addr\": trace_addr})\n",
        "\n",
        "        # Function decoding\n",
        "        function_decoded = {\"name\": \"N/A\", \"category\": \"other\", \"params\": {}}\n",
        "        if trace_type in ['CALL', 'DELEGATECALL', 'STATICCALL'] and call_data and call_data != '0x':\n",
        "            if is_pyusd_call:\n",
        "                 function_decoded = decode_pyusd_function(call_data)\n",
        "            else:\n",
        "                 func_desc = get_function_description(call_data, is_pyusd_call, contract_name)\n",
        "                 function_decoded['name'] = func_desc\n",
        "        elif trace_type == 'CREATE':\n",
        "             function_decoded['name'] = 'Constructor'\n",
        "\n",
        "        function_name = function_decoded[\"name\"]\n",
        "        function_category = function_decoded[\"category\"]\n",
        "\n",
        "        if is_pyusd_call and function_name != \"N/A\" and function_name != \"Unknown\" and function_name != 'Constructor':\n",
        "            pyusd_calls_by_function[function_name] = pyusd_calls_by_function.get(function_name, 0) + 1\n",
        "            pyusd_calls_by_category[function_category] = pyusd_calls_by_category.get(function_category, 0) + 1\n",
        "\n",
        "            method_sig = call_data[:10]\n",
        "            if from_addr:\n",
        "                if method_sig == '0xa9059cbb': # transfer\n",
        "                    if 'amount' in function_decoded[\"params\"] and 'to' in function_decoded[\"params\"]:\n",
        "                        transfer_info_plotly = {'from': from_addr, 'to': function_decoded[\"params\"][\"to\"], 'amount': function_decoded[\"params\"][\"amount\"], 'trace_addr': trace_addr }\n",
        "                        pyusd_transfers_for_plotly.append(transfer_info_plotly)\n",
        "                        transfer_info_display = {**transfer_info_plotly, 'value': transfer_info_plotly['amount'] / (10**PYUSD_CONFIG['ethereum']['decimals'])}\n",
        "                        pyusd_transfers_display.append(transfer_info_display)\n",
        "                elif method_sig == '0x23b872dd': # transferFrom\n",
        "                    if all(k in function_decoded[\"params\"] for k in ['from', 'to', 'amount']):\n",
        "                        transfer_info_plotly = {'from': function_decoded[\"params\"][\"from\"], 'to': function_decoded[\"params\"][\"to\"], 'amount': function_decoded[\"params\"][\"amount\"], 'trace_addr': trace_addr}\n",
        "                        pyusd_transfers_for_plotly.append(transfer_info_plotly)\n",
        "                        transfer_info_display = {**transfer_info_plotly, 'value': transfer_info_plotly['amount'] / (10**PYUSD_CONFIG['ethereum']['decimals'])}\n",
        "                        pyusd_transfers_display.append(transfer_info_display)\n",
        "\n",
        "        # Data for Plotly Call Graph\n",
        "        call_info_plotly = {\n",
        "            'id': f\"node_{'_'.join(map(str, trace_addr)) if trace_addr else 'root'}\",\n",
        "            'trace_addr': trace_addr,\n",
        "            'type': trace_type,\n",
        "            'depth': current_depth,\n",
        "            'from': from_addr if from_addr else \"N/A\",\n",
        "            'to': to_addr if to_addr else (\"CREATE\" if trace_type == 'CREATE' else \"N/A\"),\n",
        "            'value_eth': value_eth_float,\n",
        "            'gasUsed': gas_used,\n",
        "            'is_pyusd': is_pyusd_call,\n",
        "            'contract': contract_name,\n",
        "            'function_category': function_decoded['category'],\n",
        "            'function': function_decoded['name'],\n",
        "            'error': error,\n",
        "            'input_preview': call_data[:10] + ('...' if len(call_data) > 10 else ''),\n",
        "            'output_preview': output_data[:10] + ('...' if len(output_data) > 10 else ''),\n",
        "        }\n",
        "        call_data_list_for_plotly.append(call_info_plotly)\n",
        "\n",
        "        if is_pyusd_call:\n",
        "            pyusd_interactions += 1\n",
        "\n",
        "        total_gas_used += gas_used\n",
        "        if error: errors += 1\n",
        "\n",
        "        call_sequence.append({\n",
        "            'index': i, 'trace_addr': trace_addr, 'depth': len(trace_addr), 'type': trace_type,\n",
        "            'from': from_addr, 'to': to_addr, 'is_pyusd': is_pyusd_call,\n",
        "            'function': function_decoded[\"name\"], 'params': function_decoded[\"params\"],\n",
        "            'gas_used': gas_used, 'value_eth': value_eth, 'error': error\n",
        "        })\n",
        "\n",
        "        # Prepare summary row\n",
        "        gas_efficiency = analyze_gas_efficiency(gas_used, function_decoded[\"name\"]) if is_pyusd_call and function_decoded[\"name\"] in PYUSD_GAS_BENCHMARKS else None\n",
        "        summary_row = {\n",
        "            'index': i, 'trace_address': str(trace_addr), 'type': trace_type,\n",
        "            'from': from_addr, 'to': to_addr if to_addr else (\"CREATE\" if trace_type == 'CREATE' else \"N/A\"),\n",
        "            'is_pyusd': is_pyusd_call, 'contract': contract_name,\n",
        "            'function': function_decoded[\"name\"], 'category': function_decoded[\"category\"],\n",
        "            'value_eth': value_eth, 'gas_used': gas_used, 'gas_str': format_gas(gas_used),\n",
        "            'gas_efficiency': gas_efficiency[\"efficiency\"] if gas_efficiency else \"N/A\",\n",
        "            'gas_pct_diff': gas_efficiency[\"pct_diff\"] if gas_efficiency else 0,\n",
        "            'error': error if error else \"None\", 'depth': len(trace_addr)\n",
        "        }\n",
        "        if function_decoded[\"params\"]:\n",
        "            for param_key, param_value in function_decoded[\"params\"].items():\n",
        "                if isinstance(param_value, (str, int, float, bool)) or param_value is None:\n",
        "                    if isinstance(param_value, str) and param_value.startswith(\"0x\"): continue\n",
        "                    if param_key not in ['from', 'to']:\n",
        "                        summary_row[f\"param_{param_key}\"] = param_value\n",
        "                elif isinstance(param_value, list):\n",
        "                    serializable_list = [str(item) if not isinstance(item, (str, int, float, bool)) else item for item in param_value]\n",
        "                    summary_row[f\"param_{param_key}\"] = json.dumps(serializable_list)\n",
        "                else:\n",
        "                    summary_row[f\"param_{param_key}\"] = str(param_value)\n",
        "\n",
        "        summary.append(summary_row)\n",
        "\n",
        "    summary_df = pd.DataFrame(summary)\n",
        "\n",
        "    pyusd_pct = (pyusd_interactions / len(trace_list) * 100) if trace_list else 0\n",
        "    pyusd_gas = summary_df[summary_df['is_pyusd']]['gas_used'].sum() if 'is_pyusd' in summary_df.columns and 'gas_used' in summary_df.columns else 0\n",
        "    pyusd_gas_pct = (pyusd_gas / total_gas_used * 100) if total_gas_used > 0 else 0\n",
        "\n",
        "    tx_pattern = identify_transaction_pattern(summary_df, pyusd_transfers_display)\n",
        "    mev_analysis = detect_mev_potential(trace_list, summary_df, tx_hash)\n",
        "    security_concerns = detect_security_concerns(trace_list, summary_df)\n",
        "\n",
        "    unique_contracts = len(summary_df['to'].unique()) if 'to' in summary_df.columns else 0\n",
        "    complexity_score = min(100, (\n",
        "        (len(trace_list) * 2) + (unique_contracts * 5) + (max_depth * 10) +\n",
        "        (len(pyusd_transfers_display) * 3) + (errors * 5)\n",
        "    ) / 3)\n",
        "\n",
        "    # Generate Plotly Graphs\n",
        "    contract_graph_plotly = None\n",
        "    if contract_interactions_list:\n",
        "        try:\n",
        "            interactions_no_loops = list(set([(f, t) for f, t in contract_interactions_list if f != t]))\n",
        "            if interactions_no_loops:\n",
        "                 contract_graph_plotly = create_plotly_contract_interaction_graph(interactions_no_loops)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create Plotly contract interaction graph: {viz_err}\", style=\"warning\")\n",
        "            print(traceback.format_exc())\n",
        "\n",
        "    call_graph_plotly = None\n",
        "    if call_data_list_for_plotly:\n",
        "        try:\n",
        "            call_graph_plotly = create_plotly_call_graph(call_data_list_for_plotly)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create Plotly call graph: {viz_err}\", style=\"warning\")\n",
        "    else:\n",
        "         console.print(\"[warning]No data collected for Plotly call graph.\", style=\"warning\")\n",
        "\n",
        "    flow_graph_plotly = None\n",
        "    if pyusd_transfers_for_plotly:\n",
        "        try:\n",
        "            flow_graph_plotly = create_plotly_flow_graph(pyusd_transfers_for_plotly)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create Plotly flow graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Display transaction summary panel\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold cyan3]PYUSD [green3]`trace_transaction`[/green3] Summary ({tx_hash})[/bold cyan3]\n",
        "[bold cyan3]Total Actions:[/bold cyan3] {len(trace_list)}\n",
        "[bold cyan3]Total Gas Used:[/bold cyan3] {total_gas_used:,}\n",
        "[bold cyan3]Actions with Errors:[/bold cyan3] {errors}\n",
        "[bold cyan3]Call Depth:[/bold cyan3] {max_depth} levels\n",
        "[bold cyan3]Unique Contracts:[/bold cyan3] {unique_contracts}\n",
        "[bold cyan3]Complexity Score:[/bold cyan3] {complexity_score:.1f}/100\n",
        "\n",
        "[bold green3]PYUSD Activity:[/bold green3]\n",
        "[bold cyan3]PYUSD Interactions:[/bold cyan3] {pyusd_interactions} ({pyusd_pct:.1f}% of actions)\n",
        "[bold cyan3]PYUSD Gas Usage:[/bold cyan3] {pyusd_gas:,} ({pyusd_gas_pct:.1f}% of total gas)\n",
        "[bold cyan3]PYUSD Transfers:[/bold cyan3] {len(pyusd_transfers_display)}\n",
        "\n",
        "[bold yellow3]Transaction Pattern:[/bold yellow3]\n",
        "[bold cyan3]Type:[/bold cyan3] {tx_pattern['pattern']}\n",
        "[bold cyan3]Description:[/bold cyan3] {tx_pattern['description']}\n",
        "[bold cyan3]Confidence:[/bold cyan3] {tx_pattern['confidence']:.0%}\n",
        "\n",
        "[bold red3]Security Analysis:[/bold red3]\n",
        "[bold cyan3]MEV Potential:[/bold cyan3] {\"Yes\" if mev_analysis[\"mev_detected\"] else \"No\"}\n",
        "{f\"[bold cyan3]MEV Type:[/bold cyan3] {mev_analysis['type']} ({mev_analysis['confidence']:.0%})\" if mev_analysis[\"mev_detected\"] else \"\"}\n",
        "[bold cyan3]Security Concerns:[/bold cyan3] {len(security_concerns)}\"\"\",\n",
        "        title=\"PYUSD Transaction Analysis\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # Display Plotly Graphs\n",
        "    if contract_graph_plotly:\n",
        "        console.print(\"\\n\\n[bold]üìä Contract Interaction Overview Chart:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        display(contract_graph_plotly)\n",
        "        console.print(\"[info]Interactive graph showing high-level contract interactions.\", style=\"info\")\n",
        "    else:\n",
        "        if not contract_interactions_list:\n",
        "            console.print(\"\\n[info]No contract interactions detected to generate graph.\", style=\"info\")\n",
        "\n",
        "    console.print(\"\\n\\n[bold magenta3]üìä Detailed Call Graph Visualization Chart:[/bold magenta3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "    if call_graph_plotly:\n",
        "        display(call_graph_plotly)\n",
        "        console.print(\"[info]Interactive visualization of the detailed call hierarchy.\", style=\"info\")\n",
        "    else:\n",
        "        if not call_data_list_for_plotly:\n",
        "             console.print(\"[warning]No call data available to generate call graph.\", style=\"warning\")\n",
        "\n",
        "    if flow_graph_plotly:\n",
        "        console.print(\"\\n\\n[bold magenta3]üîÑ PYUSD Token Flow Analysis Chart:[/bold magenta3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        display(flow_graph_plotly)\n",
        "        console.print(\"[info]Interactive graph showing the movement of PYUSD tokens.\", style=\"info\")\n",
        "    elif pyusd_transfers_display:\n",
        "         console.print(\"\\n\\n[warning]PYUSD transfers detected, but flow graph generation failed.\", style=\"warning\")\n",
        "\n",
        "    # Display security concerns if any\n",
        "    if security_concerns:\n",
        "        console.print(\"\\n[bold red]‚ö†Ô∏è Security Concerns[/bold red]\")\n",
        "        security_table = Table(show_header=True, header_style=\"bold red\")\n",
        "        security_table.add_column(\"Level\", style=\"dim\")\n",
        "        security_table.add_column(\"Description\", style=\"bold\")\n",
        "        security_table.add_column(\"Contract\")\n",
        "        for concern in security_concerns:\n",
        "            level_color = \"red\" if concern[\"level\"] in [\"high\", \"critical\"] else \"yellow\"\n",
        "            security_table.add_row(f\"[{level_color}]{concern['level'].upper()}[/{level_color}]\", concern[\"description\"], concern.get(\"contract\", \"N/A\"))\n",
        "        console.print(security_table)\n",
        "\n",
        "    # Display PYUSD function calls table if relevant\n",
        "    if pyusd_calls_by_function:\n",
        "        console.print(\"\\n\\n[bold green3]ü™ô PYUSD Function Calls[/bold green3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "\n",
        "        function_table = Table(show_header=True, header_style=\"bold green3\")\n",
        "        function_table.add_column(\"Function\")\n",
        "        function_table.add_column(\"Count\", justify=\"right\")\n",
        "        function_table.add_column(\"Category\", justify=\"center\")\n",
        "        function_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "        function_table.add_column(\"Gas Efficiency\", justify=\"center\")\n",
        "        gas_by_function = {}\n",
        "        if not summary_df.empty and 'function' in summary_df.columns and 'is_pyusd' in summary_df.columns and 'gas_used' in summary_df.columns:\n",
        "             pyusd_rows = summary_df[summary_df['is_pyusd']]\n",
        "             gas_by_function = pyusd_rows.groupby('function')['gas_used'].sum().to_dict()\n",
        "\n",
        "        for func, count in sorted(pyusd_calls_by_function.items(), key=lambda x: x[1], reverse=True):\n",
        "            category = next((info[\"category\"] for sig, info in PYUSD_SIGNATURES.items() if info[\"name\"] == func), \"other\")\n",
        "            gas_used_func = gas_by_function.get(func, 0)\n",
        "            efficiency, efficiency_color = \"N/A\", \"\"\n",
        "            if func in PYUSD_GAS_BENCHMARKS and count > 0:\n",
        "                eff_data = analyze_gas_efficiency(gas_used_func / count, func)\n",
        "                efficiency = eff_data[\"efficiency\"].title()\n",
        "                efficiency_color = eff_data[\"color\"]\n",
        "            function_table.add_row(func, str(count), category.replace('_', ' ').title(), f\"{gas_used_func:,}\", f\"[{efficiency_color}]{efficiency}[/{efficiency_color}]\" if efficiency_color else efficiency)\n",
        "        console.print(function_table)\n",
        "\n",
        "        console.print(\"\\n\\n[bold]PYUSD Function Categories in Transaction Chart:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "        try:\n",
        "            category_data = [{'category': cat.replace('_', ' ').title(), 'count': cnt} for cat, cnt in pyusd_calls_by_category.items() if cnt > 0]\n",
        "            if category_data:\n",
        "                category_df = pd.DataFrame(category_data)\n",
        "                color_map = {'Token Movement': 'lightgreen', 'Supply Change': 'coral', 'Allowance': 'skyblue', 'Control': 'gold', 'Admin': 'darkred', 'View': 'lightgray', 'Other': 'silver'}\n",
        "                fig_cat = px.pie(category_df, values='count', names='category', title=f'PYUSD Function Categories in Transaction {shorten_address(tx_hash)}', color='category', color_discrete_map=color_map)\n",
        "                fig_cat.update_layout(template=\"plotly_white\", legend_title_text='Function Category', legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
        "                fig_cat.update_traces(textposition='inside', textinfo='percent+label')\n",
        "                fig_cat.show()\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create function category chart: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Display PYUSD transfers table\n",
        "    if pyusd_transfers_display:\n",
        "        console.print(\"\\n\\n[bold yellow3]ü™ô PYUSD Token Transfers[/bold yellow3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "        transfer_table = Table(show_header=True, header_style=\"bold yellow3\")\n",
        "        transfer_table.add_column(\"From\")\n",
        "        transfer_table.add_column(\"To\")\n",
        "        transfer_table.add_column(\"Amount\", justify=\"right\")\n",
        "        transfer_table.add_column(\"Call Depth\", justify=\"center\")\n",
        "        total_transferred = 0\n",
        "        for transfer in pyusd_transfers_display:\n",
        "            from_addr, to_addr = transfer.get('from'), transfer.get('to')\n",
        "            amount = transfer.get('value',0.0)\n",
        "            total_transferred += amount\n",
        "            depth = len(transfer.get('trace_addr',[]))\n",
        "            amount_str = f\"{amount:,.6f} PYUSD\"\n",
        "            if amount >= 10000: amount_str = f\"[bold green]{amount_str}[/bold green]\"\n",
        "            elif amount >= 1000: amount_str = f\"[green]{amount_str}[/green]\"\n",
        "            transfer_table.add_row(from_addr, to_addr, amount_str, str(depth))\n",
        "        console.print(transfer_table)\n",
        "        console.print(f\"[info]Total PYUSD transferred: {total_transferred:,.6f} PYUSD\", style=\"info\")\n",
        "\n",
        "    # Display call stack depth visualization\n",
        "    if gas_by_depth:\n",
        "         console.print(\"\\n\\n[bold magenta3]Gas Usage by Call Depth Chart:[/bold magenta3]\")\n",
        "         console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "         try:\n",
        "            depth_df = pd.DataFrame([{\"depth\": depth, \"gas\": gas} for depth, gas in gas_by_depth.items()])\n",
        "            fig_depth = px.bar(depth_df, x='depth', y='gas', title=f'Gas Usage by Call Depth in {shorten_address(tx_hash)}', labels={'depth': 'Call Stack Depth', 'gas': 'Gas Used'}, color='gas', color_continuous_scale='Viridis')\n",
        "            fig_depth.update_layout(template=\"plotly_white\")\n",
        "            fig_depth.show()\n",
        "         except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not render call depth visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Display gas usage by category visualizations\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Gas Usage by Contract Chart:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        if not summary_df.empty and 'gas_used' in summary_df.columns and total_gas_used > 0:\n",
        "            contract_gas = summary_df.groupby('contract')['gas_used'].sum().reset_index()\n",
        "            contract_gas['percentage'] = contract_gas['gas_used'] / total_gas_used * 100\n",
        "            contract_colors = {\"PYUSD Token\": \"green\", \"PYUSD Implementation\": \"darkgreen\", \"Supply Control\": \"blue\", \"Supply Control Impl\": \"darkblue\", \"Other Contract\": \"gray\"}\n",
        "            fig_contract_gas = px.pie(contract_gas, values='gas_used', names='contract', title=f'Gas Usage by Contract in {shorten_address(tx_hash)}', hover_data=['percentage'], color='contract', color_discrete_map=contract_colors)\n",
        "            fig_contract_gas.update_layout(template=\"plotly_white\")\n",
        "            fig_contract_gas.show()\n",
        "\n",
        "            if pyusd_interactions > 0 and pyusd_gas > 0:\n",
        "                console.print(\"\\n\\n[bold]PYUSD Gas Usage by Function Category Chart:[/bold]\", style=\"magenta3\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                pyusd_gas_by_category = summary_df[summary_df['is_pyusd']].groupby('category')['gas_used'].sum().reset_index()\n",
        "                if not pyusd_gas_by_category.empty:\n",
        "                    pyusd_gas_by_category['percentage'] = pyusd_gas_by_category['gas_used'] / pyusd_gas * 100\n",
        "                    category_colors = {\"token_movement\": \"lightgreen\", \"supply_change\": \"coral\", \"allowance\": \"skyblue\", \"control\": \"gold\", \"admin\": \"darkred\", \"view\": \"lightgray\", \"other\": \"silver\"}\n",
        "                    pyusd_gas_by_category['category'] = pyusd_gas_by_category['category'].apply(lambda x: x.replace('_', ' ').title())\n",
        "                    fig_category_gas = px.pie(pyusd_gas_by_category, values='gas_used', names='category', title=f'PYUSD Gas Usage by Function Category in {shorten_address(tx_hash)}', hover_data=['percentage'], color='category', color_discrete_map={k.replace('_', ' ').title(): v for k, v in category_colors.items()})\n",
        "                    fig_category_gas.update_layout(template=\"plotly_white\")\n",
        "                    fig_category_gas.show()\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create gas usage visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Add gas efficiency analysis visualization\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Gas Efficiency by PYUSD Function Chart:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        if not summary_df.empty and 'gas_efficiency' in summary_df.columns and 'function' in summary_df.columns:\n",
        "            efficiency_df = summary_df[summary_df['gas_efficiency'] != 'N/A'].copy()\n",
        "            if not efficiency_df.empty:\n",
        "                efficiency_df['efficiency_level'] = pd.Categorical(efficiency_df['gas_efficiency'], categories=['excellent', 'good', 'average', 'poor'], ordered=True)\n",
        "                efficiency_colors = {'excellent': 'green', 'good': 'lightgreen', 'average': 'gold', 'poor': 'coral'}\n",
        "                fig_efficiency = px.bar(efficiency_df, x='function', y='gas_used', color='gas_efficiency', title=f'Gas Efficiency by PYUSD Function in {shorten_address(tx_hash)}', labels={'function': 'Function', 'gas_used': 'Gas Used', 'gas_efficiency': 'Efficiency'}, color_discrete_map=efficiency_colors)\n",
        "                fig_efficiency.update_layout(template=\"plotly_white\")\n",
        "                fig_efficiency.show()\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create gas efficiency visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Create interactive transaction replay component\n",
        "    if call_sequence:\n",
        "        console.print(\"\\n\\n[bold yellow3]üéÆ Interactive Transaction Replay[/bold yellow3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "        try:\n",
        "            # Create interactive replay controls\n",
        "            buttons_css = \"\"\"\n",
        "            <style>\n",
        "            /* Play/Pause Button (single toggle button in the Play widget) */\n",
        "            .widget-play .jupyter-button {\n",
        "                color: white !important;\n",
        "                background-color: #4285F4 !important; /* Blue */\n",
        "                border-color: #4285F4 !important;\n",
        "                font-weight: bold;\n",
        "                width: 80px !important;\n",
        "                height: 32px !important;\n",
        "                position: relative;\n",
        "            }\n",
        "\n",
        "            /* Add text for Play/Pause states */\n",
        "            .widget-play[playing=\"true\"] .jupyter-button::after {\n",
        "                content: \"Pause\";\n",
        "                position: absolute;\n",
        "                left: 10px;\n",
        "            }\n",
        "\n",
        "            .widget-play[playing=\"false\"] .jupyter-button::after {\n",
        "                content: \"Play\";\n",
        "                position: absolute;\n",
        "                left: 10px;\n",
        "            }\n",
        "\n",
        "            /* Hide the font-awesome icons that aren't showing */\n",
        "            .widget-play .jupyter-button i {\n",
        "                display: none !important;\n",
        "            }\n",
        "\n",
        "            /* Style for Next button */\n",
        "            .next-button .jupyter-button {\n",
        "                color: white !important;\n",
        "                background-color: #F4B400 !important; /* Yellow */\n",
        "                border-color: #F4B400 !important;\n",
        "                font-weight: bold;\n",
        "                width: 80px !important;\n",
        "            }\n",
        "\n",
        "            /* Style for Reset button */\n",
        "            .reset-button .jupyter-button {\n",
        "                color: white !important;\n",
        "                background-color: #DB4437 !important; /* Red */\n",
        "                border-color: #DB4437 !important;\n",
        "                font-weight: bold;\n",
        "                width: 80px !important;\n",
        "            }\n",
        "            </style>\n",
        "            \"\"\"\n",
        "            display(HTML(buttons_css))\n",
        "\n",
        "            # Create the controls with original functionality but with additional styling classes\n",
        "            replay_output = widgets.Output()\n",
        "            step_slider = widgets.IntSlider(value=0, min=0, max=len(call_sequence), step=1, description='Step:',\n",
        "                                          continuous_update=False, orientation='horizontal', readout=True,\n",
        "                                          readout_format='d', layout=widgets.Layout(width='500px'))\n",
        "\n",
        "            # Use the original Play widget\n",
        "            play_button = widgets.Play(value=0, min=0, max=len(call_sequence), step=1, interval=700)\n",
        "            widgets.jslink((play_button, 'value'), (step_slider, 'value'))\n",
        "\n",
        "            # Create custom buttons for Next and Reset with the specified class names\n",
        "            next_button = widgets.Button(description=\"Next\", layout=widgets.Layout(width='80px'),\n",
        "                                      button_style='warning')\n",
        "            next_button.add_class('next-button')  # Add class for CSS targeting\n",
        "\n",
        "            reset_button = widgets.Button(description=\"Reset\", layout=widgets.Layout(width='80px'),\n",
        "                                        button_style='danger')\n",
        "            reset_button.add_class('reset-button')  # Add class for CSS targeting\n",
        "\n",
        "            # Button handlers for Next and Reset\n",
        "            def next_clicked(b):\n",
        "                if step_slider.value < len(call_sequence):\n",
        "                    step_slider.value += 1\n",
        "\n",
        "            def reset_clicked(b):\n",
        "                play_button._playing = False  # Stop if playing\n",
        "                step_slider.value = 0\n",
        "\n",
        "            next_button.on_click(next_clicked)\n",
        "            reset_button.on_click(reset_clicked)\n",
        "\n",
        "            # Group controls together\n",
        "            controls = widgets.HBox([play_button, next_button, reset_button, step_slider])\n",
        "\n",
        "            def update_replay(change):\n",
        "                step = change['new']\n",
        "                with replay_output:\n",
        "                    clear_output(wait=True)\n",
        "                    if step == 0: display(HTML(f\"<h3>Transaction Start</h3><p>Hash: {tx_hash}</p>\"))\n",
        "                    elif step <= len(call_sequence):\n",
        "                        call = call_sequence[step-1]\n",
        "                        html = f\"<h3>Step {step} of {len(call_sequence)}</h3> <div style='display: flex; margin-bottom: 10px;'><div style='flex: 1;'><p><b>Call Type:</b> {call.get('type','N/A')}</p><p><b>From:</b> {call.get('from')}</p><p><b>To:</b> {call.get('to')}</p><p><b>Gas Used:</b> {call.get('gas_used',0):,}</p></div><div style='flex: 1;'><p><b>Call Depth:</b> {call.get('depth','N/A')}</p><p><b>PYUSD Call:</b> {'Yes' if call.get('is_pyusd') else 'No'}</p><p><b>Function:</b> {call.get('function') if call.get('function') else 'N/A'}</p><p><b>Status:</b> {'‚ùå Error: ' + call.get('error') if call.get('error') else '‚úÖ Success'}</p></div></div>\"\n",
        "                        if call.get('params'):\n",
        "                            html += \"<div style='background-color: #050505; color:white; padding: 5px; border-radius: 5px;'><h3 style='color:white;'>Parameters:</h3><ul>\"\n",
        "                            for pk, pv in call['params'].items():\n",
        "                                if pk in ['amount_formatted', 'to_address', 'from_address', 'spender_address']: html += f\"<li><b>{pk.replace('_', ' ').title()}:</b> {pv}</li>\"\n",
        "                            html += \"</ul></div>\"\n",
        "                        html += \"<div style='margin-top: 15px;'><h4>Call Stack:</h4><div style='display: flex; align-items: center;'>\"\n",
        "                        current_call_depth = call.get('depth',0)\n",
        "                        for i in range(current_call_depth + 1):\n",
        "                            is_current = i == current_call_depth\n",
        "                            is_pyusd_current = call.get('is_pyusd', False)\n",
        "                            color = 'palegreen' if is_pyusd_current and is_current else ('lightgray' if is_current else '#e0e0e0')\n",
        "                            border = f\"2px solid {'green' if is_pyusd_current and is_current else ('gray' if is_current else 'darkgray')}\"\n",
        "                            size = '30px' if is_current else '25px'\n",
        "                            html += f\"<div style='width: {size}; height: {size}; margin-right: 5px; background-color: {color}; border: {border}; border-radius: 5px; display: flex; justify-content: center; align-items: center; font-size: 12px; color: black;'>{i}</div>\"\n",
        "                            if not is_current: html += \"<div style='margin-right: 5px;'>‚Üí</div>\"\n",
        "                        html += \"</div></div>\"\n",
        "                        display(HTML(html))\n",
        "                        progress = step / len(call_sequence) * 100\n",
        "                        display(HTML(f\"\"\"<div style=\"width: 100%; background-color: #f0f0f0; border-radius: 5px; margin-top: 20px;\"><div style=\"width: {progress}%; height: 20px; background-color: #4CAF50; border-radius: 5px; text-align: center; color: white;\">{progress:.1f}%</div></div>\"\"\"))\n",
        "            step_slider.observe(update_replay, names='value')\n",
        "            display(controls); display(replay_output); update_replay({'new': 0})\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create transaction replay visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Display summary table with interactive filtering\n",
        "    if not summary_df.empty:\n",
        "        console.print(\"\\n\\n[bold cyan3]üìã trace_transaction Details[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        filter_output = widgets.Output(); table_output = widgets.Output()\n",
        "        function_types = ['All'] + sorted(summary_df['function'].dropna().astype(str).unique().tolist())\n",
        "        function_dropdown = widgets.Dropdown(options=function_types, value='All', description='Function:', layout=widgets.Layout(width='250px'))\n",
        "        contract_types = ['All'] + sorted(summary_df['contract'].dropna().unique().tolist())\n",
        "        contract_dropdown = widgets.Dropdown(options=contract_types, value='All', description='Contract:', layout=widgets.Layout(width='300px'))\n",
        "        pyusd_checkbox = widgets.Checkbox(value=False, description='PYUSD Only')\n",
        "        error_checkbox = widgets.Checkbox(value=False, description='Show Errors Only')\n",
        "        filter_box = widgets.HBox([function_dropdown, contract_dropdown, pyusd_checkbox, error_checkbox])\n",
        "        def update_table(change=None):\n",
        "            with table_output:\n",
        "                clear_output(wait=True)\n",
        "                filtered_df = summary_df.copy()\n",
        "                if function_dropdown.value != 'All': filtered_df = filtered_df[filtered_df['function'].astype(str) == function_dropdown.value]\n",
        "                if contract_dropdown.value != 'All': filtered_df = filtered_df[filtered_df['contract'] == contract_dropdown.value]\n",
        "                if pyusd_checkbox.value: filtered_df = filtered_df[filtered_df['is_pyusd']]\n",
        "                if error_checkbox.value: filtered_df = filtered_df[filtered_df['error'] != 'None']\n",
        "\n",
        "                def style_row(row):\n",
        "                    styles = [''] * len(row)\n",
        "                    if row['is_pyusd']:\n",
        "                        styles = ['background-color: #dff0d8; color: black'] * len(row)\n",
        "                    if row['error'] != 'None':\n",
        "                         styles = ['background-color: #f2dede; color: #a94442'] * len(row)\n",
        "                    return styles\n",
        "\n",
        "                def color_gas_efficiency(val):\n",
        "                    colors = {'excellent': 'green', 'good': 'darkgreen', 'average': 'orange', 'poor': 'red'}\n",
        "                    return f'color: {colors.get(val)}'\n",
        "\n",
        "                display_cols = ['type', 'from', 'to', 'is_pyusd', 'function', 'gas_str']\n",
        "                if 'gas_efficiency' in filtered_df.columns: display_cols.append('gas_efficiency')\n",
        "                display_cols.append('error')\n",
        "\n",
        "                styled_df = filtered_df[display_cols].style.apply(style_row, axis=1)\n",
        "                if 'gas_efficiency' in display_cols:\n",
        "                    styled_df = styled_df.map(color_gas_efficiency, subset=['gas_efficiency'])\n",
        "\n",
        "                display(HTML(f\"<p>Showing {len(filtered_df)} of {len(summary_df)} actions</p>\"))\n",
        "                display(styled_df)\n",
        "\n",
        "        function_dropdown.observe(update_table, names='value'); contract_dropdown.observe(update_table, names='value')\n",
        "        pyusd_checkbox.observe(update_table, names='value'); error_checkbox.observe(update_table, names='value')\n",
        "        display(widgets.HTML(\"<h4>Filter Options:</h4>\")); display(filter_box); display(table_output); update_table()\n",
        "\n",
        "        # Add export options\n",
        "        console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(description='Export to CSV', button_style='primary', layout=widgets.Layout(width='150px')),\n",
        "            widgets.Button(description='Export as JSON', button_style='warning', layout=widgets.Layout(width='150px')),\n",
        "            widgets.Button(description='Export to Google Sheets', button_style='info', layout=widgets.Layout(width='200px'))])\n",
        "        export_output = widgets.Output()\n",
        "        def export_csv(b):\n",
        "            with export_output: clear_output(); ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\"); fname = f\"transaction_{shorten_address(tx_hash)}_trace_{ts}.csv\"; display(download_csv_direct(summary_df, fname))\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output(); ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\"); fname = f\"transaction_{shorten_address(tx_hash)}_trace_{ts}.json\"\n",
        "                records = summary_df.astype(str).to_dict('records')\n",
        "                export_data = {\"transaction_hash\": tx_hash, \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                               \"summary\": {\"total_actions\": len(trace_list), \"total_gas_used\": total_gas_used, \"errors\": errors, \"pyusd_interactions\": pyusd_interactions, \"pyusd_transfers\": len(pyusd_transfers_display), \"complexity_score\": complexity_score, \"transaction_pattern\": tx_pattern['pattern'], \"pattern_confidence\": tx_pattern['confidence']},\n",
        "                               \"mev_analysis\": mev_analysis, \"security_concerns\": security_concerns, \"actions\": records}\n",
        "                display(download_json_direct(export_data, fname))\n",
        "        def export_to_sheets(b):\n",
        "            with export_output: clear_output(); sname = f\"Tx {shorten_address(tx_hash)} Trace {datetime.now().strftime('%y%m%d_%H%M')}\"; display(export_to_google_sheets_direct(summary_df, sname))\n",
        "        export_buttons.children[0].on_click(export_csv); export_buttons.children[1].on_click(export_json); export_buttons.children[2].on_click(export_to_sheets)\n",
        "        display(export_buttons); display(export_output)\n",
        "\n",
        "    # Return the enhanced DataFrame with additional analysis metadata\n",
        "    analysis_results = {\n",
        "        \"summary_df\": summary_df,\n",
        "        \"contract_graph\": contract_graph_plotly,\n",
        "        \"call_graph\": call_graph_plotly,\n",
        "        \"flow_graph\": flow_graph_plotly,\n",
        "        \"transaction_hash\": tx_hash,\n",
        "        \"transaction_pattern\": tx_pattern['pattern'],\n",
        "        \"complexity_score\": complexity_score,\n",
        "        \"mev_potential\": mev_analysis['mev_detected'],\n",
        "        \"security_concerns_count\": len(security_concerns)\n",
        "    }\n",
        "\n",
        "    return analysis_results\n",
        "\n",
        "# Execute trace_transaction with analysis\n",
        "if 'TARGET_TX_HASH' in locals() and validate_tx_hash:\n",
        "    console.print(\"\\n\\n[bold yellow3]üìë Tracing Transactions via 'trace_transaction'[/bold yellow3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "    console.print(f\"\\n\\n[info]Attempting enhanced 'trace_transaction' analysis for {TARGET_TX_HASH} on Mainnet...\", style=\"info\")\n",
        "\n",
        "    trace_transaction_results = make_rpc_request(\"trace_transaction\", [TARGET_TX_HASH], network='mainnet')\n",
        "\n",
        "    if trace_transaction_results is not None:\n",
        "        import traceback\n",
        "        analysis_output = analyze_trace_transaction(trace_transaction_results, TARGET_TX_HASH)\n",
        "\n",
        "        if analysis_output and isinstance(analysis_output, dict):\n",
        "            trace_analysis_df = analysis_output.get(\"summary_df\")\n",
        "\n",
        "            if trace_analysis_df is not None and not trace_analysis_df.empty:\n",
        "                 try:\n",
        "                    tx_details = w3_mainnet.eth.get_transaction(TARGET_TX_HASH)\n",
        "                    tx_receipt = w3_mainnet.eth.get_transaction_receipt(TARGET_TX_HASH)\n",
        "                    if tx_details and tx_receipt:\n",
        "                        console.print(\"\\n\\n[bold chartreuse1]üìë Transaction Context[/bold chartreuse1]\")\n",
        "                        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "                        tx_table = Table(show_header=False, box=None, padding=(0, 1))\n",
        "                        tx_table.add_column(\"Field\"); tx_table.add_column(\"Value\")\n",
        "                        tx_table.add_row(\"[bold chartreuse1]Transaction Hash:[/bold chartreuse1]\", TARGET_TX_HASH)\n",
        "                        tx_table.add_row(\"[bold chartreuse1]Block:[/bold chartreuse1]\", str(tx_receipt.blockNumber))\n",
        "                        tx_table.add_row(\"[bold chartreuse1]From:[/bold chartreuse1]\", shorten_address(tx_details['from']))\n",
        "                        tx_table.add_row(\"[bold chartreuse1]To:[/bold chartreuse1]\", shorten_address(tx_details.get('to')))\n",
        "                        tx_table.add_row(\"[bold chartreuse1]Value:[/bold chartreuse1]\", format_value_eth(tx_details['value']))\n",
        "                        tx_table.add_row(\"[bold chartreuse1]Gas Price:[/bold chartreuse1]\", f\"{w3_mainnet.from_wei(tx_details['gasPrice'], 'gwei'):.2f} Gwei\")\n",
        "                        tx_table.add_row(\"[bold chartreuse1]Gas Used:[/bold chartreuse1]\", f\"{tx_receipt['gasUsed']:,}\")\n",
        "                        tx_table.add_row(\"[bold chartreuse1]Status:[/bold chartreuse1]\", \"[green3]Success[/green3]\" if tx_receipt['status'] == 1 else \"[red3]Failed[/red3]\")\n",
        "                        tx_position = None\n",
        "                        try:\n",
        "                            block = w3_mainnet.eth.get_block(tx_receipt.blockNumber, full_transactions=True)\n",
        "                            for i, tx in enumerate(block.transactions):\n",
        "                                if tx.hash.hex() == TARGET_TX_HASH: tx_position = i; break\n",
        "                            if tx_position is not None:\n",
        "                                tx_table.add_row(\"[bold chartreuse1]Position in Block:[/bold chartreuse1]\", f\"{tx_position + 1} of {len(block.transactions)}\")\n",
        "                                mev_risk, mev_color = \"Low\", \"green3\"\n",
        "                                if 0 < tx_position < len(block.transactions) - 1: mev_risk, mev_color = \"Medium\", \"yellow3\"\n",
        "                                if len(block.transactions) > 10 and 1 < tx_position < len(block.transactions) - 2: mev_risk, mev_color = \"Higher\", \"red3\"\n",
        "                                tx_table.add_row(\"[bold chartreuse1]MEV Risk:[/bold chartreuse1]\", f\"[{mev_color}]{mev_risk}[/{mev_color}]\")\n",
        "                        except Exception as block_err:\n",
        "                            console.print(f\"[traceback]Could not get block details: {block_err}[/traceback]\")\n",
        "                        console.print(tx_table)\n",
        "                        etherscan_url = f\"https://etherscan.io/tx/{TARGET_TX_HASH}\"\n",
        "                        display(HTML(f'<p style=\"margin-top: 15px;\"><a href=\"{etherscan_url}\" target=\"_blank\" style=\"color: #1E90FF; font-weight: bold; text-decoration: none;\">üîó View Transaction on Etherscan</a></p>'))\n",
        "                 except Exception as tx_err:\n",
        "                    console.print(f\"[warning]Could not fetch additional transaction context: {tx_err}\", style=\"warning\")\n",
        "            else:\n",
        "                 console.print(\"[warning]Trace analysis failed or returned empty DataFrame, skipping context.\", style=\"warning\")\n",
        "        else:\n",
        "            console.print(\"[error]Analysis function failed to return expected results.\", style=\"error\")\n",
        "    else:\n",
        "        console.print(f\"[error]Failed to get trace for {TARGET_TX_HASH} using 'trace_transaction'.\", style=\"error\")\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_TX_HASH not set or invalid. Skipping trace_transaction analysis.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "Jhfmilm09iaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.9 üîÑ `trace_replayTransaction` and `trace_replayBlockTransactions`: State Replay Analysis (High Cost)\n",
        "---\n",
        "\n",
        "This section delves into the **most powerful (and computationally expensive)** tracing methods provided by GCP: `trace_replayTransaction` **and** `trace_replayBlockTransactions`. These allow re-executing a specific past transaction or all transactions in a past block *as if they were happening now* on the node, while enabling specific tracers to capture deep insights, most notably `stateDiff` for observing state changes.\n",
        "\n",
        "*   **`trace_replayTransaction`:** Replays a single transaction (`TARGET_TX_HASH`).\n",
        "*   **`trace_replayBlockTransactions`:** Replays all transactions in a block (`TARGET_BLOCK_IDENTIFIER`).\n",
        "\n",
        "**Key Tracers Used Here:**\n",
        "\n",
        "*   **`stateDiff`:** Records **every change** to account balances (ETH), nonces, code, and contract storage slots resulting from the execution. Essential for seeing the exact impact on PYUSD balances, allowances, supply, etc.\n",
        "*   **`trace`:** Provides a call trace similar to `trace_transaction`, useful for correlating state changes with specific internal calls.\n",
        "*   **`vmTrace`:** (Optional, can be selected) Offers an opcode-by-opcode execution trace like `structLog`, useful for extreme low-level debugging within the replay context.\n",
        "\n",
        "> **‚ö†Ô∏è Extreme Cost Factor & GCP Value**\n",
        ">\n",
        "> *   **Methods:** `trace_replayTransaction`, `trace_replayBlockTransactions`\n",
        "> *   **Multiplier:** `100x` (Each consumes 100x the quota/cost of a basic call)\n",
        "> *   **GCP Advantage:** These methods are **extremely resource-intensive**, especially with the `stateDiff` tracer which generates significant output. GCP's infrastructure and generous free quotas make it feasible to run these replays on Mainnet, where they are often entirely unavailable or prohibitively expensive elsewhere.\n",
        "> *   **PYUSD Insight:** Replay tracing enables:\n",
        ">     *   **Precise State Change Tracking:** Observing exactly how PYUSD balances, total supply, allowances, and other contract state variables (like paused status) were modified by a transaction or across a whole block.\n",
        ">     *   **Debugging Failed Transactions:** Understanding the exact state (balances, storage) that led to a revert, even if logs weren't emitted.\n",
        ">     *   **Auditing Complex Operations:** Verifying the exact outcome and side effects of intricate PYUSD interactions (e.g., multi-step DeFi processes, bridge operations).\n",
        ">     *   **Historical State Analysis:** Replaying transactions at different historical block heights to understand state evolution.\n",
        "\n",
        "**Analysis Workflow (`trace_replayTransaction`):**\n",
        "\n",
        "1.  **Request Replay:** Calls `trace_replayTransaction` with the `TARGET_TX_HASH` and selected tracers (controlled by `REPLAY_TRACERS`).\n",
        "2.  **Analyze Result:** The `analyze_replay_transaction` function processes the returned dictionary.\n",
        "3.  **Parse Tracers:**\n",
        "    *   Analyzes `trace` output (if requested) for PYUSD calls, transfers, gas, and security flags.\n",
        "    *   Analyzes `stateDiff` output (if requested) to identify and decode all state changes, specifically highlighting PYUSD contract modifications (balances, supply, storage).\n",
        "    *   Analyzes `vmTrace` output (if requested) for opcode-level gas statistics.\n",
        "4.  **Summarize & Visualize:** Presents findings through summary panels, tables detailing PYUSD interactions/transfers/state changes, security flag lists, and visualizations (token flow, gas usage). Includes export options.\n",
        "\n",
        "**Analysis Workflow (`trace_replayBlockTransactions`):**\n",
        "\n",
        "1.  **Request Block Replay:** Calls `trace_replayBlockTransactions` with the target block identifier (converted to hex) and selected tracers (controlled by `REPLAY_BLOCK_TRACERS`).\n",
        "2.  **Process Transaction Results:** The `analyze_replay_block` function iterates through the list of replay results (one per transaction).\n",
        "3.  **Aggregate & Analyze:** For each transaction's result, it extracts key PYUSD metrics (interactions, transfers, volume, state changes) and security flags by analyzing the chosen tracer outputs. It aggregates statistics across the entire block.\n",
        "4.  **Visualize & Summarize:** Shows block-wide summaries, state change distributions, security flags, interactive transaction tables, PYUSD volume/activity plots, and export options.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **`stateDiff` Output:** This is the unique value. Focus on changes related to PYUSD: `totalSupply`, user `balances`, `allowances`, `owner`, `paused` state slots. Compare the `from` and `to` values for each change.\n",
        "*   **Correlation:** Relate the state changes (`stateDiff`) back to the function calls observed in the `trace` output for the same transaction/block.\n",
        "*   **Security Flags:** Pay attention to critical changes like ownership transfers, code modifications, large supply changes, or admin function calls detected in either tracer.\n",
        "*   **(Block Replay):** Observe the *net effect* of the entire block on PYUSD state. Identify transactions with the largest impact on balances or supply."
      ],
      "metadata": {
        "id": "jAygisJkgIPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üîÑ PYUSD Replay Transaction using trace_replayTransaction and trace_replayBlockTransactions\n",
        "# =============================================================================================\n",
        "# These methods provide detailed execution tracing at significantly higher computational cost\n",
        "# but deliver unparalleled insights into PYUSD transactions and state changes.\n",
        "# This cell leverages high-cost replay methods (trace_replayTransaction, trace_replayBlockTransactions) for deep analysis:\n",
        "# - Detailed state change analysis (`stateDiff`) showing PYUSD balance, storage, and supply modifications.\n",
        "# - Execution tracing (`trace`) within the replay context to correlate calls with state changes.\n",
        "# - Token flow visualization derived from trace or state diff, illustrating transfer patterns.\n",
        "# - VM-level execution insights (if `vmTrace` option is used) for low-level debugging.\n",
        "# - Security analysis identifying admin functions or critical state modifications (e.g., ownership, code changes).\n",
        "# - Gas usage analysis within the replayed execution context.\n",
        "\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, clear_output, display\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from graphviz import Digraph\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "import time\n",
        "import re\n",
        "from eth_utils import decode_hex, to_hex, to_int\n",
        "from web3 import Web3\n",
        "\n",
        "\"\"\"\n",
        "IMPORTANT: Cost Warning ‚ö†Ô∏è\n",
        "\n",
        "trace_replayTransaction and trace_replayBlockTransactions are extremely computationally expensive\n",
        "operations (approximately 100x the cost of regular trace methods). These methods are only available\n",
        "for free through Google Cloud's Blockchain RPC service. On other providers, these would incur\n",
        "significant costs and may even be unavailable.\n",
        "\n",
        "Use these methods judiciously for detailed analysis rather than routine monitoring.\n",
        "\n",
        "Key Features:\n",
        "- Detailed execution tracing with different tracer options\n",
        "- State change analysis showing how PYUSD balances and storage are modified\n",
        "- Token flow visualization showing transfer patterns\n",
        "- VM-level execution insights (with vmTrace option)\n",
        "\n",
        "Available Tracers:\n",
        "- \"trace\": Similar to trace_transaction but with additional context\n",
        "- \"stateDiff\": Shows all state changes caused by the transaction (balances, storage, etc.)\n",
        "- \"vmTrace\": Provides detailed VM execution trace with opcode-level information\n",
        "\"\"\"\n",
        "\n",
        "# Constants for PYUSD ERC20 Storage Layout Analysis\n",
        "# These are the standard storage slots for PYUSD based on OpenZeppelin ERC20 implementation\n",
        "# Actual slots may vary based on inheritance and implementation details\n",
        "PYUSD_TOTAL_SUPPLY_SLOT = 0\n",
        "PYUSD_BALANCES_SLOT = 1  # Mapping base - actual slot needs keccak256 hash of address + position\n",
        "PYUSD_ALLOWANCES_SLOT = 2  # Mapping base - actual slot needs keccak256 hash\n",
        "PYUSD_OWNER_SLOT = 3\n",
        "PYUSD_PAUSED_SLOT = 4\n",
        "\n",
        "# Map of known PYUSD operations to their gas profiles\n",
        "PYUSD_GAS_PROFILE = {\n",
        "    \"transfer\": {\"low\": 45000, \"typical\": 65000, \"high\": 80000},\n",
        "    \"transferFrom\": {\"low\": 60000, \"typical\": 80000, \"high\": 100000},\n",
        "    \"mint\": {\"low\": 90000, \"typical\": 120000, \"high\": 150000},\n",
        "    \"burn\": {\"low\": 70000, \"typical\": 90000, \"high\": 120000},\n",
        "    \"approve\": {\"low\": 40000, \"typical\": 46000, \"high\": 60000}\n",
        "}\n",
        "\n",
        "# Security colors for better dark theme visibility\n",
        "SECURITY_COLORS = {\n",
        "    \"critical\": \"#ff5252\", # Lighter red for dark themes\n",
        "    \"high\": \"#ff7070\",     # Medium-light red\n",
        "    \"warning\": \"#ffd966\",  # Amber yellow\n",
        "    \"info\": \"#80d8ff\"      # Light blue\n",
        "}\n",
        "\n",
        "# DataTable pagination function for transaction displays\n",
        "def display_transaction_dataframe(df, title=\"Transaction Data\"):\n",
        "    \"\"\"\n",
        "    Display a transaction DataFrame with pagination controls\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to display\n",
        "        title: Title to show above the table\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        display(HTML(f\"<h3>{title}</h3><p>No data available.</p>\"))\n",
        "        return\n",
        "\n",
        "    # Create pagination controls\n",
        "    page_size = widgets.Dropdown(\n",
        "        options=[10, 20, 50, 100],\n",
        "        value=20,\n",
        "        description='No. of Rows:',\n",
        "        disabled=False,\n",
        "    )\n",
        "\n",
        "    current_page = widgets.IntText(\n",
        "        value=1,\n",
        "        description='Page:',\n",
        "        disabled=False,\n",
        "        layout=widgets.Layout(width='120px')\n",
        "    )\n",
        "\n",
        "    prev_button = widgets.Button(\n",
        "        description='Previous',\n",
        "        disabled=True,\n",
        "        button_style='info',\n",
        "        layout=widgets.Layout(width='100px')\n",
        "    )\n",
        "\n",
        "    next_button = widgets.Button(\n",
        "        description='Next',\n",
        "        disabled=False,\n",
        "        button_style='info',\n",
        "        layout=widgets.Layout(width='100px')\n",
        "    )\n",
        "\n",
        "    controls = widgets.HBox([page_size, current_page, prev_button, next_button])\n",
        "    output = widgets.Output()\n",
        "\n",
        "    # Calculate total pages\n",
        "    total_pages = max(1, (len(df) + page_size.value - 1) // page_size.value)\n",
        "    page_info = widgets.HTML(f\"<div>Page 1 of {total_pages} (Total rows: {len(df)})</div>\")\n",
        "\n",
        "    # Update function to refresh the table\n",
        "    def update_table():\n",
        "        with output:\n",
        "            clear_output()\n",
        "            start_idx = (current_page.value - 1) * page_size.value\n",
        "            end_idx = min(start_idx + page_size.value, len(df))\n",
        "\n",
        "            # Update button states\n",
        "            prev_button.disabled = current_page.value <= 1\n",
        "            next_button.disabled = current_page.value >= total_pages\n",
        "\n",
        "            # Update page info\n",
        "            page_info.value = f\"<div>Page {current_page.value} of {total_pages} (Total rows: {len(df)})</div>\"\n",
        "\n",
        "            # Display slice of DataFrame\n",
        "            display(df.iloc[start_idx:end_idx])\n",
        "\n",
        "    # Button handlers\n",
        "    def on_prev_clicked(b):\n",
        "        current_page.value = max(1, current_page.value - 1)\n",
        "        update_table()\n",
        "\n",
        "    def on_next_clicked(b):\n",
        "        current_page.value = min(total_pages, current_page.value + 1)\n",
        "        update_table()\n",
        "\n",
        "    def on_page_change(change):\n",
        "        update_table()\n",
        "\n",
        "    def on_page_size_change(change):\n",
        "        nonlocal total_pages\n",
        "        total_pages = max(1, (len(df) + change['new'] - 1) // change['new'])\n",
        "        current_page.value = min(current_page.value, total_pages)\n",
        "        update_table()\n",
        "\n",
        "    # Connect event handlers\n",
        "    prev_button.on_click(on_prev_clicked)\n",
        "    next_button.on_click(on_next_clicked)\n",
        "    current_page.observe(on_page_change, names='value')\n",
        "    page_size.observe(on_page_size_change, names='value')\n",
        "\n",
        "    # Display controls and initial table\n",
        "    display(HTML(f\"<h3>{title}</h3>\"))\n",
        "    display(widgets.VBox([controls, page_info, output]))\n",
        "    update_table()\n",
        "\n",
        "# Dedicated Export Functions\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets_direct(df, sheet_name=None):\n",
        "    \"\"\"Exports DataFrame directly to Google Sheets using authenticated session.\"\"\"\n",
        "    if sheet_name is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_name = f\"PYUSD Analysis {timestamp}\"\n",
        "\n",
        "    # Use Google Colab integration for direct export\n",
        "    html = f'''\n",
        "    <script src=\"https://apis.google.com/js/platform.js\" async defer></script>\n",
        "    <script>\n",
        "    function createSheet() {{\n",
        "        const csv = `{df.to_csv(index=False).replace('\"', '\"\"')}`;\n",
        "\n",
        "        // Create sheet using Google Colab API\n",
        "        google.colab.kernel.invokeFunction('notebook.createSheet', [csv, '{sheet_name}'], {{}});\n",
        "    }}\n",
        "\n",
        "    // Execute immediately\n",
        "    setTimeout(createSheet, 100);\n",
        "    </script>\n",
        "    <div>Creating Google Sheet \"{sheet_name}\"...</div>\n",
        "    '''\n",
        "\n",
        "    # Register the Python callback that the JavaScript will call\n",
        "    from google.colab import output\n",
        "\n",
        "    @output.register_callback('notebook.createSheet')\n",
        "    def create_sheet_callback(csv_data, name):\n",
        "        try:\n",
        "            from google.colab import auth\n",
        "            from googleapiclient.discovery import build\n",
        "            from googleapiclient.http import MediaInMemoryUpload\n",
        "            import io\n",
        "\n",
        "            # Ensure authentication\n",
        "            auth.authenticate_user()\n",
        "\n",
        "            # Create Drive API client\n",
        "            drive_service = build('drive', 'v3')\n",
        "\n",
        "            # File metadata\n",
        "            file_metadata = {\n",
        "                'name': name,\n",
        "                'mimeType': 'application/vnd.google-apps.spreadsheet'\n",
        "            }\n",
        "\n",
        "            # Create CSV upload\n",
        "            media = MediaInMemoryUpload(\n",
        "                io.BytesIO(csv_data.encode('utf-8')),\n",
        "                mimetype='text/csv',\n",
        "                resumable=True\n",
        "            )\n",
        "\n",
        "            # Create the Sheet\n",
        "            file = drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id,webViewLink'\n",
        "            ).execute()\n",
        "\n",
        "            # Return success with link\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'file_id': file.get('id'),\n",
        "                'link': file.get('webViewLink')\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': str(e)\n",
        "            }\n",
        "\n",
        "    return HTML(html)\n",
        "\n",
        "# Utility functions for replay analysis\n",
        "def compute_storage_slot_for_address(mapping_position, address):\n",
        "    \"\"\"\n",
        "    Calculate actual storage slot for an address in a mapping\n",
        "\n",
        "    Args:\n",
        "        mapping_position: Base position of the mapping in storage\n",
        "        address: Ethereum address to calculate slot for\n",
        "\n",
        "    Returns:\n",
        "        String representation of the storage slot\n",
        "    \"\"\"\n",
        "    # Convert address to bytes and pad to 32 bytes\n",
        "    address_bytes = bytes.fromhex(address.replace('0x', '').lower())\n",
        "    address_padded = address_bytes.rjust(32, b'\\0')\n",
        "\n",
        "    # Convert mapping position to bytes and pad to 32 bytes\n",
        "    position_bytes = mapping_position.to_bytes(32, 'big')\n",
        "\n",
        "    # Concatenate and hash to get the actual slot\n",
        "    concatenated = address_padded + position_bytes\n",
        "    slot_bytes = Web3.keccak(concatenated)\n",
        "\n",
        "    # Convert to hex string\n",
        "    return '0x' + slot_bytes.hex()\n",
        "\n",
        "def categorize_gas_usage(gas_used, operation_type):\n",
        "    \"\"\"\n",
        "    Categorize gas usage as low, typical, or high for a given operation\n",
        "\n",
        "    Args:\n",
        "        gas_used: Amount of gas used\n",
        "        operation_type: Type of operation (transfer, mint, etc.)\n",
        "\n",
        "    Returns:\n",
        "        Category and efficiency rating\n",
        "    \"\"\"\n",
        "    if operation_type not in PYUSD_GAS_PROFILE:\n",
        "        return \"unknown\", 0\n",
        "\n",
        "    profile = PYUSD_GAS_PROFILE[operation_type]\n",
        "\n",
        "    if gas_used <= profile[\"low\"]:\n",
        "        return \"excellent\", 100\n",
        "    elif gas_used <= profile[\"typical\"]:\n",
        "        efficiency = 100 - ((gas_used - profile[\"low\"]) / (profile[\"typical\"] - profile[\"low\"])) * 20\n",
        "        return \"good\", efficiency\n",
        "    elif gas_used <= profile[\"high\"]:\n",
        "        efficiency = 80 - ((gas_used - profile[\"typical\"]) / (profile[\"high\"] - profile[\"typical\"])) * 30\n",
        "        return \"average\", efficiency\n",
        "    else:\n",
        "        excess = (gas_used - profile[\"high\"]) / profile[\"high\"]\n",
        "        efficiency = max(0, 50 - (excess * 50))\n",
        "        return \"poor\", efficiency\n",
        "\n",
        "def interpret_pyusd_storage_slot(slot_hex, value_hex):\n",
        "    \"\"\"\n",
        "    Interpret PYUSD storage slots and their values\n",
        "\n",
        "    Args:\n",
        "        slot_hex: Storage slot in hex\n",
        "        value_hex: Value at that slot in hex\n",
        "\n",
        "    Returns:\n",
        "        Description, formatted value, and metadata\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert slot to integer\n",
        "        slot_int = int(slot_hex, 16)\n",
        "        value_int = int(value_hex, 16)\n",
        "\n",
        "        # Standard ERC20 slots\n",
        "        if slot_int == PYUSD_TOTAL_SUPPLY_SLOT:\n",
        "            formatted_value = f\"{value_int / (10**PYUSD_CONFIG['ethereum']['decimals']):,.6f} PYUSD\"\n",
        "            return \"Total Supply\", formatted_value, {\"raw_value\": value_int, \"type\": \"total_supply\"}\n",
        "\n",
        "        elif slot_int == PYUSD_OWNER_SLOT:\n",
        "            # Last 20 bytes should be the address\n",
        "            address = '0x' + value_hex[-40:]\n",
        "            return \"Contract Owner\", shorten_address(address), {\"raw_value\": address, \"type\": \"owner\"}\n",
        "\n",
        "        elif slot_int == PYUSD_PAUSED_SLOT:\n",
        "            is_paused = value_int > 0\n",
        "            return \"Paused State\", \"Paused\" if is_paused else \"Active\", {\"raw_value\": is_paused, \"type\": \"paused\"}\n",
        "\n",
        "        # Try to determine if it's a balance slot - this is complex and approximate\n",
        "        else:\n",
        "            # For demonstration - check if value looks like a balance (divisible by PYUSD decimals)\n",
        "            if value_int % 10 == 0:  # Simple heuristic, could be improved\n",
        "                formatted_value = f\"{value_int / (10**PYUSD_CONFIG['ethereum']['decimals']):,.6f} PYUSD\"\n",
        "                return \"Possible Balance\", formatted_value, {\"raw_value\": value_int, \"type\": \"balance\"}\n",
        "\n",
        "            return \"Unknown Storage\", f\"0x{value_hex}\", {\"raw_value\": value_int, \"type\": \"unknown\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"Error Interpreting\", str(e), {\"error\": str(e)}\n",
        "\n",
        "# Main analysis functions\n",
        "def analyze_replay_transaction(replay_result, tx_hash, requested_tracers):\n",
        "    \"\"\"\n",
        "    Analyzes the output dictionary from trace_replayTransaction with PYUSD insights.\n",
        "\n",
        "    Args:\n",
        "        replay_result: The raw output from trace_replayTransaction\n",
        "        tx_hash: The transaction hash being analyzed\n",
        "        requested_tracers: List of tracer types that were requested in the RPC call\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with PYUSD-relevant summary data\n",
        "    \"\"\"\n",
        "    if not isinstance(replay_result, dict):\n",
        "        console.print(f\"[error]Expected a dict from trace_replayTransaction for {shorten_address(tx_hash)}, got {type(replay_result)}.\", style=\"error\")\n",
        "        display_json(replay_result, \"Unexpected Replay Result Structure\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]PYUSD Analysis of trace_replayTransaction for {shorten_address(tx_hash)}[/bold cyan3]\")\n",
        "    console.print(f\"Requested Tracers: {', '.join(requested_tracers)}\")\n",
        "\n",
        "    summary_data = {\n",
        "        'transaction_hash': tx_hash,\n",
        "        'analysis_timestamp': datetime.now().isoformat(),\n",
        "        'tracers_used': requested_tracers,\n",
        "        'has_pyusd_interaction': False,\n",
        "        'pyusd_state_changes': 0,\n",
        "        'pyusd_balance_changes': [],\n",
        "        'pyusd_transfers': [],\n",
        "        'pyusd_operations': [],\n",
        "        'gas_metrics': {},\n",
        "        'security_flags': []\n",
        "    }\n",
        "\n",
        "    # DataFrames to store analysis results\n",
        "    state_changes_df = pd.DataFrame()\n",
        "    transfers_df = pd.DataFrame()\n",
        "    vm_operations_df = pd.DataFrame()\n",
        "\n",
        "    # --- Analyze 'trace' (if requested) ---\n",
        "    if \"trace\" in requested_tracers and \"trace\" in replay_result:\n",
        "        console.print(\"\\n\\n[bold cyan3]üìä PYUSD Trace Analysis[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        # trace analysis looking for PYUSD transfers\n",
        "        trace_list = replay_result[\"trace\"]\n",
        "\n",
        "        if isinstance(trace_list, list):\n",
        "            pyusd_interactions = 0\n",
        "            pyusd_calls_by_function = {}\n",
        "            pyusd_transfers = []\n",
        "            pyusd_operations = []\n",
        "            total_gas_used = 0\n",
        "\n",
        "            # Track sequence for visualization\n",
        "            operation_sequence = []\n",
        "\n",
        "            for i, trace_item in enumerate(trace_list):\n",
        "                if not isinstance(trace_item, dict): continue\n",
        "\n",
        "                action = trace_item.get('action', {})\n",
        "                result = trace_item.get('result', {})\n",
        "                trace_type = trace_item.get('type', 'N/A')\n",
        "                trace_addr = trace_item.get('traceAddress', [])\n",
        "                error = trace_item.get('error')\n",
        "\n",
        "                to_addr = action.get('to', '')\n",
        "                call_data = action.get('input', '0x')\n",
        "                from_addr = action.get('from', '')\n",
        "                gas_used_hex = result.get('gasUsed', '0x0')\n",
        "                gas_used = int(gas_used_hex, 16) if gas_used_hex.startswith('0x') else int(gas_used_hex)\n",
        "                total_gas_used += gas_used\n",
        "\n",
        "                # Add to operation sequence for visualization\n",
        "                operation_sequence.append({\n",
        "                    'index': i,\n",
        "                    'trace_type': trace_type,\n",
        "                    'from': from_addr,\n",
        "                    'to': to_addr,\n",
        "                    'gas_used': gas_used,\n",
        "                    'trace_addr': trace_addr,\n",
        "                    'error': error\n",
        "                })\n",
        "\n",
        "                # Check if this is a PYUSD contract interaction\n",
        "                is_pyusd_call = to_addr and to_addr.lower() in PYUSD_CONTRACTS\n",
        "                contract_name = PYUSD_CONTRACTS.get(to_addr.lower(), \"Other Contract\") if is_pyusd_call else \"External Contract\"\n",
        "\n",
        "                if is_pyusd_call:\n",
        "                    pyusd_interactions += 1\n",
        "                    summary_data['has_pyusd_interaction'] = True\n",
        "\n",
        "                    # Analyze function call\n",
        "                    if call_data and call_data != '0x':\n",
        "                        method_sig = call_data[:10]\n",
        "                        method_info = {\"signature\": method_sig, \"name\": \"Unknown\", \"category\": \"unknown\"}\n",
        "\n",
        "                        if method_sig in PYUSD_SIGNATURES:\n",
        "                            function_name = PYUSD_SIGNATURES[method_sig][\"name\"]\n",
        "                            function_category = PYUSD_SIGNATURES[method_sig][\"category\"]\n",
        "                            method_info = {\n",
        "                                \"signature\": method_sig,\n",
        "                                \"name\": function_name,\n",
        "                                \"category\": function_category\n",
        "                            }\n",
        "\n",
        "                            # Track function call\n",
        "                            if function_name in pyusd_calls_by_function:\n",
        "                                pyusd_calls_by_function[function_name] += 1\n",
        "                            else:\n",
        "                                pyusd_calls_by_function[function_name] = 1\n",
        "\n",
        "                            # Security analysis - check for admin functions\n",
        "                            if function_category == \"admin\":\n",
        "                                summary_data['security_flags'].append({\n",
        "                                    'level': 'warning',\n",
        "                                    'type': 'admin_function',\n",
        "                                    'description': f\"Admin function {function_name} called on {contract_name}\",\n",
        "                                    'details': {\n",
        "                                        'function': function_name,\n",
        "                                        'contract': contract_name,\n",
        "                                        'from': from_addr\n",
        "                                    }\n",
        "                                })\n",
        "\n",
        "                            # Track call with gas metrics\n",
        "                            operation_info = {\n",
        "                                'index': i,\n",
        "                                'from': from_addr,\n",
        "                                'to': to_addr,\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'category': function_category,\n",
        "                                'gas_used': gas_used,\n",
        "                                'error': error,\n",
        "                                'input_data': call_data,\n",
        "                                'trace_addr': trace_addr\n",
        "                            }\n",
        "\n",
        "                            # Add gas efficiency analysis\n",
        "                            if function_name.startswith(\"transfer\") or function_name.startswith(\"mint\") or function_name.startswith(\"burn\") or function_name.startswith(\"approve\"):\n",
        "                                # Get base operation type (transfer, mint, etc.)\n",
        "                                base_op = function_name.split(\"(\")[0]\n",
        "                                gas_category, efficiency = categorize_gas_usage(gas_used, base_op)\n",
        "                                operation_info['gas_category'] = gas_category\n",
        "                                operation_info['gas_efficiency'] = efficiency\n",
        "\n",
        "                            pyusd_operations.append(operation_info)\n",
        "\n",
        "                            # Extract PYUSD transfers\n",
        "                            if method_sig == '0xa9059cbb':  # transfer\n",
        "                                try:\n",
        "                                    to_offset = 10\n",
        "                                    to_param = \"0x\" + call_data[to_offset+24:to_offset+64]\n",
        "                                    amount_offset = 74\n",
        "                                    amount = int(call_data[amount_offset:amount_offset+64], 16)\n",
        "                                    value_pyusd = amount / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                    transfer_data = {\n",
        "                                        'from': from_addr,\n",
        "                                        'to': to_param,\n",
        "                                        'value': value_pyusd,\n",
        "                                        'value_raw': amount,\n",
        "                                        'function': 'transfer',\n",
        "                                        'trace_index': i,\n",
        "                                        'trace_addr': trace_addr,\n",
        "                                        'gas_used': gas_used,\n",
        "                                        'error': error\n",
        "                                    }\n",
        "                                    pyusd_transfers.append(transfer_data)\n",
        "                                    summary_data['pyusd_transfers'].append(transfer_data)\n",
        "                                except Exception:\n",
        "                                    pass\n",
        "                            elif method_sig == '0x23b872dd':  # transferFrom\n",
        "                                try:\n",
        "                                    from_offset = 10\n",
        "                                    from_param = \"0x\" + call_data[from_offset+24:from_offset+64]\n",
        "                                    to_offset = 74\n",
        "                                    to_param = \"0x\" + call_data[to_offset+24:to_offset+64]\n",
        "                                    amount_offset = 138\n",
        "                                    amount = int(call_data[amount_offset:amount_offset+64], 16)\n",
        "                                    value_pyusd = amount / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                    transfer_data = {\n",
        "                                        'from': from_param,\n",
        "                                        'to': to_param,\n",
        "                                        'value': value_pyusd,\n",
        "                                        'value_raw': amount,\n",
        "                                        'function': 'transferFrom',\n",
        "                                        'trace_index': i,\n",
        "                                        'trace_addr': trace_addr,\n",
        "                                        'gas_used': gas_used,\n",
        "                                        'error': error\n",
        "                                    }\n",
        "                                    pyusd_transfers.append(transfer_data)\n",
        "                                    summary_data['pyusd_transfers'].append(transfer_data)\n",
        "                                except Exception:\n",
        "                                    pass\n",
        "                            elif method_sig == '0x40c10f19':  # mint\n",
        "                                try:\n",
        "                                    to_offset = 10\n",
        "                                    to_param = \"0x\" + call_data[to_offset+24:to_offset+64]\n",
        "                                    amount_offset = 74\n",
        "                                    amount = int(call_data[amount_offset:amount_offset+64], 16)\n",
        "                                    value_pyusd = amount / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                    transfer_data = {\n",
        "                                        'from': '0x0000000000000000000000000000000000000000',  # Mint from zero address\n",
        "                                        'to': to_param,\n",
        "                                        'value': value_pyusd,\n",
        "                                        'value_raw': amount,\n",
        "                                        'function': 'mint',\n",
        "                                        'trace_index': i,\n",
        "                                        'trace_addr': trace_addr,\n",
        "                                        'gas_used': gas_used,\n",
        "                                        'error': error\n",
        "                                    }\n",
        "                                    pyusd_transfers.append(transfer_data)\n",
        "                                    summary_data['pyusd_transfers'].append(transfer_data)\n",
        "\n",
        "                                    # Security flag for mint operations\n",
        "                                    summary_data['security_flags'].append({\n",
        "                                        'level': 'info',\n",
        "                                        'type': 'supply_change',\n",
        "                                        'description': f\"PYUSD supply increased by {value_pyusd:,.2f}\",\n",
        "                                        'details': {\n",
        "                                            'function': 'mint',\n",
        "                                            'amount': value_pyusd,\n",
        "                                            'to': to_param\n",
        "                                        }\n",
        "                                    })\n",
        "                                except Exception:\n",
        "                                    pass\n",
        "                            elif method_sig == '0x42966c68':  # burn\n",
        "                                try:\n",
        "                                    amount_offset = 10\n",
        "                                    amount = int(call_data[amount_offset:amount_offset+64], 16)\n",
        "                                    value_pyusd = amount / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                    transfer_data = {\n",
        "                                        'from': from_addr,\n",
        "                                        'to': '0x0000000000000000000000000000000000000000',  # Burn to zero address\n",
        "                                        'value': value_pyusd,\n",
        "                                        'value_raw': amount,\n",
        "                                        'function': 'burn',\n",
        "                                        'trace_index': i,\n",
        "                                        'trace_addr': trace_addr,\n",
        "                                        'gas_used': gas_used,\n",
        "                                        'error': error\n",
        "                                    }\n",
        "                                    pyusd_transfers.append(transfer_data)\n",
        "                                    summary_data['pyusd_transfers'].append(transfer_data)\n",
        "\n",
        "                                    # Security flag for burn operations\n",
        "                                    summary_data['security_flags'].append({\n",
        "                                        'level': 'info',\n",
        "                                        'type': 'supply_change',\n",
        "                                        'description': f\"PYUSD supply decreased by {value_pyusd:,.2f}\",\n",
        "                                        'details': {\n",
        "                                            'function': 'burn',\n",
        "                                            'amount': value_pyusd,\n",
        "                                            'from': from_addr\n",
        "                                        }\n",
        "                                    })\n",
        "                                except Exception:\n",
        "                                    pass\n",
        "\n",
        "            # Store operations for export\n",
        "            summary_data['pyusd_operations'] = pyusd_operations\n",
        "            if pyusd_operations:\n",
        "                vm_operations_df = pd.DataFrame(pyusd_operations)\n",
        "\n",
        "            # Store transfer data for export\n",
        "            if pyusd_transfers:\n",
        "                transfers_df = pd.DataFrame(pyusd_transfers)\n",
        "\n",
        "            # Add gas metrics\n",
        "            summary_data['gas_metrics'] = {\n",
        "                'total_gas_used': total_gas_used,\n",
        "                'pyusd_operations_count': len(pyusd_operations),\n",
        "                'pyusd_transfers_count': len(pyusd_transfers),\n",
        "                'pyusd_calls_by_function': pyusd_calls_by_function\n",
        "            }\n",
        "\n",
        "            # Display PYUSD function call summary\n",
        "            if pyusd_calls_by_function:\n",
        "                console.print(f\"[success]Found {pyusd_interactions} PYUSD interactions in trace.\", style=\"success\")\n",
        "\n",
        "                # Create function call table\n",
        "                function_table = Table(show_header=True, header_style=\"bold green3\")\n",
        "                function_table.add_column(\"Function\")\n",
        "                function_table.add_column(\"Count\", justify=\"right\")\n",
        "                function_table.add_column(\"Category\", justify=\"center\")\n",
        "                function_table.add_column(\"Total Gas\", justify=\"right\")\n",
        "\n",
        "                for func, count in sorted(pyusd_calls_by_function.items(), key=lambda x: x[1], reverse=True):\n",
        "                    # Calculate total gas for this function\n",
        "                    func_gas = sum([op['gas_used'] for op in pyusd_operations if op.get('function') == func])\n",
        "\n",
        "                    # Get function category\n",
        "                    category = \"unknown\"\n",
        "                    for op in pyusd_operations:\n",
        "                        if op.get('function') == func:\n",
        "                            category = op.get('category', \"unknown\")\n",
        "                            break\n",
        "\n",
        "                    function_table.add_row(\n",
        "                        func,\n",
        "                        str(count),\n",
        "                        category.replace('_', ' ').title(),\n",
        "                        f\"{func_gas:,}\"\n",
        "                    )\n",
        "\n",
        "                console.print(function_table)\n",
        "            else:\n",
        "                console.print(\"[info]No PYUSD function calls detected in trace.\", style=\"info\")\n",
        "\n",
        "            # Display PYUSD transfers\n",
        "            if pyusd_transfers:\n",
        "                console.print(\"\\n\\n[bold cyan3]üîÑ PYUSD Token Movements Detected[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "                transfer_table = Table(show_header=True, header_style=\"bold cyan3\")\n",
        "                transfer_table.add_column(\"From\")\n",
        "                transfer_table.add_column(\"To\")\n",
        "                transfer_table.add_column(\"Amount\", justify=\"right\")\n",
        "                transfer_table.add_column(\"Type\", justify=\"center\")\n",
        "                transfer_table.add_column(\"Gas\", justify=\"right\")\n",
        "\n",
        "                total_volume = 0\n",
        "                for transfer in pyusd_transfers:\n",
        "                    from_addr = transfer['from']\n",
        "                    to_addr = transfer['to']\n",
        "                    amount = transfer['value']\n",
        "                    function = transfer['function']\n",
        "                    gas = transfer['gas_used']\n",
        "                    total_volume += amount\n",
        "\n",
        "                    # Determine operation type for better readability\n",
        "                    op_type = function\n",
        "                    if function == 'transfer' or function == 'transferFrom':\n",
        "                        op_type = \"Transfer\"\n",
        "                    elif function == 'mint':\n",
        "                        op_type = \"Mint\"\n",
        "                        from_addr = \"[italic]New Supply[/italic]\"\n",
        "                    elif function == 'burn':\n",
        "                        op_type = \"Burn\"\n",
        "                        to_addr = \"[italic]Removed[/italic]\"\n",
        "\n",
        "                    transfer_table.add_row(\n",
        "                        from_addr,\n",
        "                        to_addr,\n",
        "                        f\"{amount:,.6f} PYUSD\",\n",
        "                        op_type,\n",
        "                        f\"{gas:,}\"\n",
        "                    )\n",
        "\n",
        "                console.print(transfer_table)\n",
        "                console.print(f\"[info]Total PYUSD volume: {total_volume:,.6f} PYUSD\", style=\"info\")\n",
        "\n",
        "                # Create enhanced token flow visualization\n",
        "                try:\n",
        "                    console.print(\"\\n\\n[bold magenta3]PYUSD Flow Chart:[/bold magenta3]\")\n",
        "                    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                    # 1. Traditional graph visualization\n",
        "                    flow_graph = Digraph(comment=f\"PYUSD Flows in {tx_hash}\", format='png')\n",
        "                    flow_graph.attr(rankdir='TB', bgcolor='transparent')\n",
        "                    flow_graph.attr('node', shape='box', style='filled', fontname='helvetica',\n",
        "                                   fontcolor='black')\n",
        "\n",
        "                    # Track nodes we've added\n",
        "                    added_nodes = set()\n",
        "\n",
        "                    # Aggregate transfers between same addresses\n",
        "                    transfer_map = {}\n",
        "\n",
        "                    for transfer in pyusd_transfers:\n",
        "                        from_addr = transfer['from']\n",
        "                        to_addr = transfer['to']\n",
        "                        value = transfer['value']\n",
        "                        function = transfer['function']\n",
        "\n",
        "                        key = (from_addr, to_addr, function)\n",
        "                        if key in transfer_map:\n",
        "                            transfer_map[key] += value\n",
        "                        else:\n",
        "                            transfer_map[key] = value\n",
        "\n",
        "                    # Add nodes and edges\n",
        "                    for (from_addr, to_addr, function), total_value in transfer_map.items():\n",
        "                        from_addr_short = shorten_address(from_addr)\n",
        "                        to_addr_short = shorten_address(to_addr)\n",
        "\n",
        "                        # Set node colors based on function\n",
        "                        zero_addr = '0x0000000000000000000000000000000000000000'\n",
        "\n",
        "                        # Special handling for mint/burn\n",
        "                        if function == 'mint' and from_addr == zero_addr:\n",
        "                            if from_addr not in added_nodes:\n",
        "                                flow_graph.node(from_addr, label=\"New Supply\", fillcolor=\"lightblue\")\n",
        "                                added_nodes.add(from_addr)\n",
        "                        elif function == 'burn' and to_addr == zero_addr:\n",
        "                            if to_addr not in added_nodes:\n",
        "                                flow_graph.node(to_addr, label=\"Burned\", fillcolor=\"lightsalmon\")\n",
        "                                added_nodes.add(to_addr)\n",
        "                        else:\n",
        "                            # Regular addresses\n",
        "                            if from_addr not in added_nodes:\n",
        "                                flow_graph.node(from_addr, label=from_addr_short, fillcolor=\"palegreen\")\n",
        "                                added_nodes.add(from_addr)\n",
        "\n",
        "                            if to_addr not in added_nodes:\n",
        "                                flow_graph.node(to_addr, label=to_addr_short, fillcolor=\"palegreen\")\n",
        "                                added_nodes.add(to_addr)\n",
        "\n",
        "                        value_str = f\"{total_value:,.2f} PYUSD\"\n",
        "\n",
        "                        # Edge style based on function type\n",
        "                        edge_color = \"black\"\n",
        "                        edge_style = \"solid\"\n",
        "                        if function == 'mint':\n",
        "                            edge_color = \"blue\"\n",
        "                            edge_style = \"dashed\"\n",
        "                        elif function == 'burn':\n",
        "                            edge_color = \"red\"\n",
        "                            edge_style = \"dashed\"\n",
        "\n",
        "                        flow_graph.edge(from_addr, to_addr, label=value_str, color=edge_color, style=edge_style)\n",
        "\n",
        "                    display(flow_graph)\n",
        "\n",
        "                    # 2. Create Sankey diagram for better flow visualization\n",
        "                    console.print(\"\\n\\n[bold magenta3]PYUSD Token Flow in Transaction Chart:[/bold magenta3]\")\n",
        "                    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                    if len(pyusd_transfers) > 0:\n",
        "                        # Prepare data for Sankey\n",
        "                        unique_addresses = set()\n",
        "                        for transfer in pyusd_transfers:\n",
        "                            unique_addresses.add(transfer['from'])\n",
        "                            unique_addresses.add(transfer['to'])\n",
        "\n",
        "                        # Create mapping from address to index\n",
        "                        address_to_idx = {addr: i for i, addr in enumerate(unique_addresses)}\n",
        "\n",
        "                        # Prepare sources, targets, values\n",
        "                        sources = []\n",
        "                        targets = []\n",
        "                        values = []\n",
        "                        labels = []\n",
        "                        colors = []\n",
        "\n",
        "                        for addr in unique_addresses:\n",
        "                            if addr == '0x0000000000000000000000000000000000000000':\n",
        "                                labels.append('Zero Address')\n",
        "                                colors.append('rgba(211, 211, 211, 0.8)')  # Light gray for zero address\n",
        "                            else:\n",
        "                                labels.append(shorten_address(addr))\n",
        "                                colors.append('rgba(144, 238, 144, 0.8)')  # Light green for normal addresses\n",
        "\n",
        "                        for transfer in pyusd_transfers:\n",
        "                            sources.append(address_to_idx[transfer['from']])\n",
        "                            targets.append(address_to_idx[transfer['to']])\n",
        "                            values.append(transfer['value'])\n",
        "\n",
        "                        # Create Sankey diagram\n",
        "                        fig = go.Figure(data=[go.Sankey(\n",
        "                            node=dict(\n",
        "                                pad=15,\n",
        "                                thickness=20,\n",
        "                                line=dict(color=\"black\", width=0.5),\n",
        "                                label=labels,\n",
        "                                color=colors\n",
        "                            ),\n",
        "                            link=dict(\n",
        "                                source=sources,\n",
        "                                target=targets,\n",
        "                                value=values,\n",
        "                                color=['rgba(143, 188, 143, 0.4)'] * len(sources)  # Semi-transparent green\n",
        "                            )\n",
        "                        )])\n",
        "\n",
        "                        fig.update_layout(\n",
        "                            title_text=f\"PYUSD Token Flow in Transaction {shorten_address(tx_hash)}\",\n",
        "                            font_size=12\n",
        "                        )\n",
        "\n",
        "                        fig.show()\n",
        "\n",
        "                    console.print(\"[info]These visualizations show PYUSD token flows in the transaction.\", style=\"info\")\n",
        "                except Exception as viz_err:\n",
        "                    console.print(f\"[warning]Could not create PYUSD flow visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "                # Create a transaction replay visualization\n",
        "                if operation_sequence:\n",
        "                    console.print(\"\\n\\n[bold magenta3]üìä Transaction Execution Sequence Chart:[/bold magenta3]\")\n",
        "                    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                    try:\n",
        "                        # Create a timeline visualization\n",
        "                        timeline_df = pd.DataFrame(operation_sequence)\n",
        "\n",
        "                        # Add colors based on trace type and if it's a PYUSD operation\n",
        "                        timeline_df['color'] = 'lightgray'\n",
        "                        for i, op in enumerate(operation_sequence):\n",
        "                            # Check if this is a PYUSD operation\n",
        "                            is_pyusd_op = False\n",
        "                            for pyusd_op in pyusd_operations:\n",
        "                                if pyusd_op['index'] == op['index']:\n",
        "                                    is_pyusd_op = True\n",
        "                                    break\n",
        "\n",
        "                            if is_pyusd_op:\n",
        "                                timeline_df.loc[i, 'color'] = 'lightgreen'\n",
        "                            elif op['error']:\n",
        "                                timeline_df.loc[i, 'color'] = 'lightcoral'\n",
        "\n",
        "                        # Pre-format error values for better hover display\n",
        "                        timeline_df['error_display'] = timeline_df['error'].fillna('None').astype(str)\n",
        "                        timeline_df.loc[timeline_df['error_display'] == 'nan', 'error_display'] = 'None'\n",
        "\n",
        "                        # Create the figure\n",
        "                        fig = px.bar(\n",
        "                            timeline_df,\n",
        "                            x='index',\n",
        "                            y='gas_used',\n",
        "                            color='color',\n",
        "                            color_discrete_map='identity',\n",
        "                            title=f\"Transaction Execution Sequence ({tx_hash})\",\n",
        "                            labels={'index': 'Operation Index', 'gas_used': 'Gas Used'},\n",
        "                            hover_data=['trace_type', 'from', 'to', 'error_display']\n",
        "                        )\n",
        "\n",
        "                        # Improve layout\n",
        "                        fig.update_layout(\n",
        "                            showlegend=False,\n",
        "                            xaxis_title=\"Operation Sequence\",\n",
        "                            yaxis_title=\"Gas Used\",\n",
        "                            template=\"plotly_white\"\n",
        "                        )\n",
        "\n",
        "                        # Add custom hover template\n",
        "                        fig.update_traces(\n",
        "                            hovertemplate=(\n",
        "                                \"<b>Operation %{x}</b><br>\" +\n",
        "                                \"Type: %{customdata[0]}<br>\" +\n",
        "                                \"From: %{customdata[1]}<br>\" +\n",
        "                                \"To: %{customdata[2]}<br>\" +\n",
        "                                \"Gas: %{y:,}<br>\" +\n",
        "                                \"Error: %{customdata[3]}\"\n",
        "                            )\n",
        "                        )\n",
        "\n",
        "                        fig.show()\n",
        "\n",
        "                    except Exception as viz_err:\n",
        "                        console.print(f\"[warning]Could not create execution timeline visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "            summary_data['trace_actions'] = len(trace_list)\n",
        "        else:\n",
        "            console.print(\"[warning]Trace data is not in expected list format.\", style=\"warning\")\n",
        "            display_json(trace_list, \"Unexpected Trace Format\")\n",
        "            summary_data['trace_actions'] = 0\n",
        "\n",
        "    # --- Analyze 'stateDiff' (if requested) with PYUSD focus ---\n",
        "    if \"stateDiff\" in requested_tracers and \"stateDiff\" in replay_result:\n",
        "        console.print(\"\\n\\n[bold cyan3]üîç PYUSD State Change Analysis[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        state_diff = replay_result[\"stateDiff\"]\n",
        "        state_changes = []\n",
        "        pyusd_state_changes = []\n",
        "        pyusd_balance_changes = []\n",
        "        supply_changes = []\n",
        "\n",
        "        if isinstance(state_diff, dict):\n",
        "            # PYUSD token state changes counter\n",
        "            pyusd_storage_changes = 0\n",
        "\n",
        "            # Address of the PYUSD token contract (lowercase for comparison)\n",
        "            pyusd_addr_lower = PYUSD_CONFIG['ethereum']['address'].lower()\n",
        "\n",
        "            # Process all state changes in the diff\n",
        "            for address, diffs in state_diff.items():\n",
        "                address_lower = address.lower()\n",
        "                is_pyusd_contract = address_lower == pyusd_addr_lower\n",
        "                contract_name = PYUSD_CONTRACTS.get(address_lower, \"Other Contract\")\n",
        "\n",
        "                # Process each type of state change\n",
        "                if 'balance' in diffs and '*' in diffs['balance']:\n",
        "                    bal_diff = diffs['balance']['*']\n",
        "                    from_wei_hex = bal_diff.get('from', '0x0')\n",
        "                    to_wei_hex = bal_diff.get('to', '0x0')\n",
        "\n",
        "                    # Safe conversion to integers\n",
        "                    from_wei = int(from_wei_hex, 16) if from_wei_hex.startswith('0x') else int(from_wei_hex)\n",
        "                    to_wei = int(to_wei_hex, 16) if to_wei_hex.startswith('0x') else int(to_wei_hex)\n",
        "                    change_wei = to_wei - from_wei\n",
        "\n",
        "                    # Safe calculation of ETH value\n",
        "                    if change_wei < 0:\n",
        "                        change_eth = -float(w3_mainnet.from_wei(abs(change_wei), 'ether')) if w3_mainnet else -(abs(change_wei) / 1e18)\n",
        "                    else:\n",
        "                        change_eth = float(w3_mainnet.from_wei(change_wei, 'ether')) if w3_mainnet else (change_wei / 1e18)\n",
        "\n",
        "                    change_entry = {\n",
        "                        'address': address,\n",
        "                        'type': 'balance',\n",
        "                        'is_pyusd': is_pyusd_contract,\n",
        "                        'contract': contract_name,\n",
        "                        'slot/key': 'ETH',\n",
        "                        'from_value': format_value_eth(from_wei_hex),\n",
        "                        'to_value': format_value_eth(to_wei_hex),\n",
        "                        'change': f\"{change_eth:+.6f} ETH\"\n",
        "                    }\n",
        "                    state_changes.append(change_entry)\n",
        "\n",
        "                    if is_pyusd_contract:\n",
        "                        pyusd_state_changes.append(change_entry)\n",
        "\n",
        "                # Process nonce changes\n",
        "                if 'nonce' in diffs and '*' in diffs['nonce']:\n",
        "                    nonce_diff = diffs['nonce']['*']\n",
        "                    from_nonce_hex = nonce_diff.get('from', '0x0')\n",
        "                    to_nonce_hex = nonce_diff.get('to', '0x0')\n",
        "                    from_nonce = int(from_nonce_hex, 16) if from_nonce_hex.startswith('0x') else int(from_nonce_hex)\n",
        "                    to_nonce = int(to_nonce_hex, 16) if to_nonce_hex.startswith('0x') else int(to_nonce_hex)\n",
        "\n",
        "                    change_entry = {\n",
        "                        'address': address,\n",
        "                        'type': 'nonce',\n",
        "                        'is_pyusd': is_pyusd_contract,\n",
        "                        'contract': contract_name,\n",
        "                        'slot/key': 'Nonce',\n",
        "                        'from_value': str(from_nonce),\n",
        "                        'to_value': str(to_nonce),\n",
        "                        'change': f\"{to_nonce - from_nonce:+d}\"\n",
        "                    }\n",
        "                    state_changes.append(change_entry)\n",
        "\n",
        "                    if is_pyusd_contract:\n",
        "                        pyusd_state_changes.append(change_entry)\n",
        "\n",
        "                # Process code changes\n",
        "                if 'code' in diffs and '*' in diffs['code']:\n",
        "                    code_diff = diffs['code']['*']\n",
        "                    change_type = \"Code Created\" if code_diff.get('to') and not code_diff.get('from') else \\\n",
        "                                 \"Code Destroyed\" if code_diff.get('from') and not code_diff.get('to') else \\\n",
        "                                 \"Code Changed\"\n",
        "\n",
        "                    change_entry = {\n",
        "                        'address': address,\n",
        "                        'type': 'code',\n",
        "                        'is_pyusd': is_pyusd_contract,\n",
        "                        'contract': contract_name,\n",
        "                        'slot/key': 'Bytecode',\n",
        "                        'from_value': '(Exists)' if code_diff.get('from') else '(None)',\n",
        "                        'to_value': '(Exists)' if code_diff.get('to') else '(None)',\n",
        "                        'change': change_type\n",
        "                    }\n",
        "                    state_changes.append(change_entry)\n",
        "\n",
        "                    if is_pyusd_contract:\n",
        "                        pyusd_state_changes.append(change_entry)\n",
        "\n",
        "                        # Add security flag for code changes\n",
        "                        summary_data['security_flags'].append({\n",
        "                            'level': 'critical',\n",
        "                            'type': 'code_change',\n",
        "                            'description': f\"PYUSD contract code was modified - {change_type}\",\n",
        "                            'details': {\n",
        "                                'contract': contract_name,\n",
        "                                'address': address,\n",
        "                                'change_type': change_type\n",
        "                            }\n",
        "                        })\n",
        "\n",
        "                # Process storage changes - particularly important for PYUSD balances\n",
        "                if 'storage' in diffs:\n",
        "                    for slot, slot_diff_outer in diffs['storage'].items():\n",
        "                        if '*' in slot_diff_outer:\n",
        "                            slot_diff = slot_diff_outer['*']\n",
        "                            from_val = slot_diff.get('from', '0x0')\n",
        "                            to_val = slot_diff.get('to', '0x0')\n",
        "\n",
        "                            # Enhanced storage slot interpretation\n",
        "                            slot_interpretation, formatted_value, slot_metadata = interpret_pyusd_storage_slot(slot, to_val)\n",
        "\n",
        "                            # Track PYUSD contract storage changes\n",
        "                            if is_pyusd_contract:\n",
        "                                pyusd_storage_changes += 1\n",
        "\n",
        "                                # Check for important changes like total supply\n",
        "                                if slot_metadata['type'] == 'total_supply':\n",
        "                                    # Calculate value change\n",
        "                                    from_supply = int(from_val, 16) / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                                    to_supply = int(to_val, 16) / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                                    supply_change = to_supply - from_supply\n",
        "\n",
        "                                    supply_changes.append({\n",
        "                                        'from': from_supply,\n",
        "                                        'to': to_supply,\n",
        "                                        'change': supply_change\n",
        "                                    })\n",
        "\n",
        "                                    # Add security flag for supply changes\n",
        "                                    if abs(supply_change) > 0:\n",
        "                                        summary_data['security_flags'].append({\n",
        "                                            'level': 'info',\n",
        "                                            'type': 'total_supply_change',\n",
        "                                            'description': f\"PYUSD totalSupply changed by {supply_change:+,.2f}\",\n",
        "                                            'details': {\n",
        "                                                'from': from_supply,\n",
        "                                                'to': to_supply,\n",
        "                                                'change': supply_change\n",
        "                                            }\n",
        "                                        })\n",
        "\n",
        "                                elif slot_metadata['type'] == 'balance':\n",
        "                                    # Track balance changes\n",
        "                                    from_balance = int(from_val, 16) / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                                    to_balance = int(to_val, 16) / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                                    balance_change = to_balance - from_balance\n",
        "\n",
        "                                    pyusd_balance_changes.append({\n",
        "                                        'slot': slot,\n",
        "                                        'from': from_balance,\n",
        "                                        'to': to_balance,\n",
        "                                        'change': balance_change\n",
        "                                    })\n",
        "                                    summary_data['pyusd_balance_changes'].append({\n",
        "                                        'slot': slot,\n",
        "                                        'from': from_balance,\n",
        "                                        'to': to_balance,\n",
        "                                        'change': balance_change\n",
        "                                    })\n",
        "\n",
        "                                    slot_interpretation = f\"Balance Change: {balance_change:+.6f} PYUSD\"\n",
        "\n",
        "                                elif slot_metadata['type'] == 'owner':\n",
        "                                    # Add security flag for ownership changes\n",
        "                                    summary_data['security_flags'].append({\n",
        "                                        'level': 'critical',\n",
        "                                        'type': 'ownership_change',\n",
        "                                        'description': f\"PYUSD contract ownership changed\",\n",
        "                                        'details': {\n",
        "                                            'from': from_val,\n",
        "                                            'to': to_val\n",
        "                                        }\n",
        "                                    })\n",
        "\n",
        "                                elif slot_metadata['type'] == 'paused':\n",
        "                                    # Add security flag for pause state changes\n",
        "                                    new_state = \"Paused\" if slot_metadata['raw_value'] else \"Unpaused\"\n",
        "                                    summary_data['security_flags'].append({\n",
        "                                        'level': 'warning',\n",
        "                                        'type': 'pause_state_change',\n",
        "                                        'description': f\"PYUSD contract is now {new_state}\",\n",
        "                                        'details': {\n",
        "                                            'new_state': new_state,\n",
        "                                            'raw_value': slot_metadata['raw_value']\n",
        "                                        }\n",
        "                                    })\n",
        "\n",
        "                            change_entry = {\n",
        "                                'address': address,\n",
        "                                'type': 'storage',\n",
        "                                'is_pyusd': is_pyusd_contract,\n",
        "                                'contract': contract_name,\n",
        "                                'slot/key': slot,\n",
        "                                'from_value': from_val,\n",
        "                                'to_value': to_val,\n",
        "                                'change': slot_interpretation\n",
        "                            }\n",
        "                            state_changes.append(change_entry)\n",
        "\n",
        "                            if is_pyusd_contract:\n",
        "                                pyusd_state_changes.append(change_entry)\n",
        "\n",
        "            # Update summary data\n",
        "            summary_data['pyusd_state_changes'] = pyusd_storage_changes\n",
        "\n",
        "            # Store state changes for export\n",
        "            if state_changes:\n",
        "                state_changes_df = pd.DataFrame(state_changes)\n",
        "\n",
        "            # Display state changes with PYUSD focus\n",
        "            if state_changes:\n",
        "                state_diff_df = pd.DataFrame(state_changes)\n",
        "\n",
        "                console.print(f\"[info]Found {len(state_diff_df)} total state changes.\", style=\"info\")\n",
        "\n",
        "                # Show PYUSD-specific changes first\n",
        "                if pyusd_state_changes:\n",
        "                    console.print(f\"[success]Found {len(pyusd_state_changes)} PYUSD state changes.\", style=\"success\")\n",
        "                    pyusd_df = pd.DataFrame(pyusd_state_changes)\n",
        "                    display_cols = ['address', 'type', 'slot/key', 'from_value', 'to_value', 'change']\n",
        "\n",
        "                    # Ensure columns exist\n",
        "                    display_cols = [col for col in display_cols if col in pyusd_df.columns]\n",
        "\n",
        "                    console.print(\"[bold green]PYUSD State Changes:[/bold green]\")\n",
        "                    display(pyusd_df[display_cols].head(20))\n",
        "\n",
        "                    if len(pyusd_df) > 20:\n",
        "                        console.print(f\"[info]Showing first 20 of {len(pyusd_df)} PYUSD state changes.\", style=\"info\")\n",
        "\n",
        "                    # Display PYUSD balance changes if found\n",
        "                    if pyusd_balance_changes:\n",
        "                        console.print(f\"\\n[bold green]PYUSD Balance Changes Detected ({len(pyusd_balance_changes)}):[/bold green]\")\n",
        "                        balance_df = pd.DataFrame(pyusd_balance_changes)\n",
        "                        display(balance_df)\n",
        "\n",
        "                    # Display supply changes if found\n",
        "                    if supply_changes:\n",
        "                        console.print(\"\\n[bold green]PYUSD Supply Changes:[/bold green]\")\n",
        "                        for change in supply_changes:\n",
        "                            console.print(f\"Total Supply: {change['from']:,.6f} ‚Üí {change['to']:,.6f} PYUSD (Change: {change['change']:+,.6f} PYUSD)\")\n",
        "\n",
        "                # Display all state changes with improved pagination\n",
        "                console.print(\"\\n\\n[bold cyan3]üìà State Changes:[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "                display_cols = ['address', 'contract', 'type', 'slot/key', 'from_value', 'to_value', 'change']\n",
        "\n",
        "                # Ensure columns exist\n",
        "                display_cols = [col for col in display_cols if col in state_diff_df.columns]\n",
        "\n",
        "                # Use pagination display\n",
        "                display_transaction_dataframe(state_diff_df[display_cols])\n",
        "\n",
        "                summary_data['state_diff_entries'] = len(state_diff_df)\n",
        "            else:\n",
        "                console.print(\"[info]No state differences found.\", style=\"info\")\n",
        "                summary_data['state_diff_entries'] = 0\n",
        "        else:\n",
        "            console.print(\"[warning]stateDiff format not as expected (expected dict).\", style=\"warning\")\n",
        "            display_json(state_diff, \"Unexpected stateDiff Structure\")\n",
        "\n",
        "    # --- Analyze 'vmTrace' (if requested) with PYUSD focus ---\n",
        "    if \"vmTrace\" in requested_tracers and \"vmTrace\" in replay_result:\n",
        "        console.print(\"\\n[bold cyan3]üîç VM Execution Analysis[/bold cyan3]\")\n",
        "        vm_trace = replay_result[\"vmTrace\"]\n",
        "        if isinstance(vm_trace, dict) and 'ops' in vm_trace:\n",
        "            ops_list = vm_trace['ops']\n",
        "            console.print(f\"VM Trace contains {len(ops_list)} opcode steps.\")\n",
        "\n",
        "            # Analyze gas usage\n",
        "            vm_gas_used = vm_trace.get('gasUsed', 'N/A')\n",
        "            if isinstance(vm_gas_used, str) and vm_gas_used.startswith('0x'):\n",
        "                vm_gas_used = int(vm_gas_used, 16)\n",
        "            formatted_gas = format_gas(vm_gas_used)\n",
        "            console.print(f\"VM Trace Gas Used: {formatted_gas}\")\n",
        "\n",
        "            # Enhanced VM operations analysis\n",
        "            pyusd_ops = 0\n",
        "            sstore_count = 0\n",
        "            gas_by_opcode = {}\n",
        "            memory_operations = 0\n",
        "            stack_operations = 0\n",
        "\n",
        "            for op in ops_list:\n",
        "                if 'op' in op:\n",
        "                    opcode = op['op']\n",
        "                    gas = op.get('gas', 0)\n",
        "\n",
        "                    # Track gas usage by opcode\n",
        "                    if opcode in gas_by_opcode:\n",
        "                        gas_by_opcode[opcode]['count'] += 1\n",
        "                        gas_by_opcode[opcode]['gas'] += gas\n",
        "                    else:\n",
        "                        gas_by_opcode[opcode] = {'count': 1, 'gas': gas}\n",
        "\n",
        "                    # Count storage operations\n",
        "                    if opcode == 'SSTORE':\n",
        "                        sstore_count += 1\n",
        "\n",
        "                    # Count memory operations\n",
        "                    if 'MEM' in opcode or opcode in ['MLOAD', 'MSTORE', 'MSTORE8']:\n",
        "                        memory_operations += 1\n",
        "\n",
        "                    # Count stack operations\n",
        "                    if opcode.startswith('PUSH') or opcode.startswith('DUP') or opcode.startswith('SWAP'):\n",
        "                        stack_operations += 1\n",
        "\n",
        "            # Create a table of top gas-using opcodes\n",
        "            if gas_by_opcode:\n",
        "                console.print(\"\\n[bold green]Top Gas-Consuming Opcodes:[/bold green]\")\n",
        "\n",
        "                opcode_table = Table(show_header=True, header_style=\"bold green\")\n",
        "                opcode_table.add_column(\"Opcode\", style=\"dim\")\n",
        "                opcode_table.add_column(\"Count\", justify=\"right\")\n",
        "                opcode_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "                opcode_table.add_column(\"% of Total\", justify=\"right\")\n",
        "\n",
        "                # Sort by gas usage\n",
        "                sorted_opcodes = sorted(gas_by_opcode.items(), key=lambda x: x[1]['gas'], reverse=True)\n",
        "\n",
        "                # Show top 10\n",
        "                for opcode, data in sorted_opcodes[:10]:\n",
        "                    gas_pct = (data['gas'] / vm_gas_used * 100) if isinstance(vm_gas_used, int) else 0\n",
        "                    opcode_table.add_row(\n",
        "                        opcode,\n",
        "                        str(data['count']),\n",
        "                        f\"{data['gas']:,}\",\n",
        "                        f\"{gas_pct:.1f}%\"\n",
        "                    )\n",
        "\n",
        "                console.print(opcode_table)\n",
        "\n",
        "            console.print(f\"Storage write operations (SSTORE): {sstore_count}\")\n",
        "            console.print(f\"Memory operations: {memory_operations}\")\n",
        "            console.print(f\"Stack operations: {stack_operations}\")\n",
        "\n",
        "            summary_data['vm_trace_steps'] = len(ops_list)\n",
        "            summary_data['vm_sstore_count'] = sstore_count\n",
        "            summary_data['vm_operations'] = {\n",
        "                'storage_writes': sstore_count,\n",
        "                'memory_operations': memory_operations,\n",
        "                'stack_operations': stack_operations,\n",
        "                'top_gas_opcodes': [{'opcode': op, 'count': data['count'], 'gas': data['gas']}\n",
        "                                  for op, data in sorted_opcodes[:5]] if 'sorted_opcodes' in locals() else []\n",
        "            }\n",
        "        else:\n",
        "            console.print(\"[warning]vmTrace format not as expected (expected dict with 'ops').\", style=\"warning\")\n",
        "            display_json(vm_trace, \"Unexpected vmTrace Structure\")\n",
        "\n",
        "    # Final PYUSD summary with enhanced security insights\n",
        "    console.print(\"\\n\\n[bold yellow3]PYUSD Transaction Summary[/bold yellow3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "    summary_table = Table(show_header=False, box=None, padding=(0, 1))\n",
        "    summary_table.add_column(\"Metric\")\n",
        "    summary_table.add_column(\"Value\")\n",
        "\n",
        "    # PYUSD Interaction stats\n",
        "    has_pyusd = summary_data['has_pyusd_interaction']\n",
        "    summary_table.add_row(\"[bold yellow3]PYUSD Interaction:[/bold yellow3]\", \"[green3]Yes[/green3]\" if has_pyusd else \"[bright_cyan]No[/bright_cyan]\")\n",
        "\n",
        "    # PYUSD State Changes\n",
        "    pyusd_state_changes = summary_data['pyusd_state_changes']\n",
        "    summary_table.add_row(\"[bold yellow3]PYUSD State Changes:[/bold yellow3]\", str(pyusd_state_changes))\n",
        "\n",
        "    # PYUSD Transfers\n",
        "    pyusd_transfers = len(summary_data['pyusd_transfers'])\n",
        "    summary_table.add_row(\"[bold yellow3]PYUSD Transfers:[/bold yellow3]\", str(pyusd_transfers))\n",
        "\n",
        "    # PYUSD Balance Changes\n",
        "    pyusd_balance_changes = len(summary_data['pyusd_balance_changes'])\n",
        "    summary_table.add_row(\"[bold yellow3]PYUSD Balance Changes:[/bold yellow3]\", str(pyusd_balance_changes))\n",
        "\n",
        "    # Security flags\n",
        "    security_flags = len(summary_data['security_flags'])\n",
        "    security_color = \"green3\" if security_flags == 0 else SECURITY_COLORS[\"warning\"] if security_flags < 2 else SECURITY_COLORS[\"critical\"]\n",
        "    summary_table.add_row(\"[bold yellow3]Security Flags:[/bold yellow3]\", f\"[{security_color}]{security_flags}[/{security_color}]\")\n",
        "\n",
        "    console.print(summary_table)\n",
        "\n",
        "    # Display security flags if any\n",
        "    if summary_data['security_flags']:\n",
        "        console.print(f\"\\n\\n[bold {SECURITY_COLORS['high']}]‚ö†Ô∏è Security Analysis[/bold {SECURITY_COLORS['high']}]\")\n",
        "\n",
        "        security_table = Table(show_header=True, header_style=f\"bold {SECURITY_COLORS['high']}\")\n",
        "        security_table.add_column(\"Level\", style=\"dim\", justify=\"center\")\n",
        "        security_table.add_column(\"Type\", style=\"dim\")\n",
        "        security_table.add_column(\"Description\")\n",
        "\n",
        "        for flag in summary_data['security_flags']:\n",
        "            level = flag['level']\n",
        "            level_color = SECURITY_COLORS[\"critical\"] if level == \"critical\" else SECURITY_COLORS[\"high\"] if level == \"high\" else SECURITY_COLORS[\"warning\"] if level == \"warning\" else SECURITY_COLORS[\"info\"]\n",
        "\n",
        "            security_table.add_row(\n",
        "                f\"[{level_color}]{level.upper()}[/{level_color}]\",\n",
        "                flag['type'].replace('_', ' ').title(),\n",
        "                flag['description']\n",
        "            )\n",
        "\n",
        "        console.print(security_table)\n",
        "\n",
        "    # Add export options\n",
        "    console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create export buttons\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Add dropdown for export content selection\n",
        "    export_content = widgets.Dropdown(\n",
        "        options=['All Data', 'State Changes', 'Transfers', 'PYUSD Operations'],\n",
        "        value='All Data',\n",
        "        description='Export:',\n",
        "        layout=widgets.Layout(width='250px')\n",
        "    )\n",
        "\n",
        "    # Display selection control\n",
        "    display(export_content)\n",
        "\n",
        "    # Export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "            # Select appropriate DataFrame based on user choice\n",
        "            selected_content = export_content.value\n",
        "            if selected_content == 'State Changes' and not state_changes_df.empty:\n",
        "                df_to_export = state_changes_df\n",
        "                filename = f\"replay_tx_{shorten_address(tx_hash)}_state_changes_{timestamp}.csv\"\n",
        "            elif selected_content == 'Transfers' and not transfers_df.empty:\n",
        "                df_to_export = transfers_df\n",
        "                filename = f\"replay_tx_{shorten_address(tx_hash)}_transfers_{timestamp}.csv\"\n",
        "            elif selected_content == 'PYUSD Operations' and not vm_operations_df.empty:\n",
        "                df_to_export = vm_operations_df\n",
        "                filename = f\"replay_tx_{shorten_address(tx_hash)}_operations_{timestamp}.csv\"\n",
        "            else:\n",
        "                # For 'All Data' or if specific DataFrame is empty, create a combined DataFrame\n",
        "                combined_data = []\n",
        "\n",
        "                # Add summary\n",
        "                combined_data.append({\n",
        "                    'section': 'Summary',\n",
        "                    'key': 'transaction_hash',\n",
        "                    'value': tx_hash\n",
        "                })\n",
        "                combined_data.append({\n",
        "                    'section': 'Summary',\n",
        "                    'key': 'has_pyusd_interaction',\n",
        "                    'value': str(summary_data['has_pyusd_interaction'])\n",
        "                })\n",
        "                combined_data.append({\n",
        "                    'section': 'Summary',\n",
        "                    'key': 'pyusd_state_changes',\n",
        "                    'value': str(summary_data['pyusd_state_changes'])\n",
        "                })\n",
        "                combined_data.append({\n",
        "                    'section': 'Summary',\n",
        "                    'key': 'pyusd_transfers_count',\n",
        "                    'value': str(len(summary_data['pyusd_transfers']))\n",
        "                })\n",
        "\n",
        "                # Add security flags\n",
        "                for i, flag in enumerate(summary_data['security_flags']):\n",
        "                    combined_data.append({\n",
        "                        'section': 'Security Flag',\n",
        "                        'key': f\"flag_{i+1}\",\n",
        "                        'value': f\"{flag['level'].upper()} - {flag['description']}\"\n",
        "                    })\n",
        "\n",
        "                df_to_export = pd.DataFrame(combined_data)\n",
        "                filename = f\"replay_tx_{shorten_address(tx_hash)}_summary_{timestamp}.csv\"\n",
        "\n",
        "            display(download_csv_direct(df_to_export, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"replay_tx_{shorten_address(tx_hash)}_{timestamp}.json\"\n",
        "\n",
        "            # Full JSON export with all data\n",
        "            display(download_json_direct(summary_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "            # Select appropriate DataFrame based on user choice\n",
        "            selected_content = export_content.value\n",
        "            if selected_content == 'State Changes' and not state_changes_df.empty:\n",
        "                df_to_export = state_changes_df\n",
        "                sheet_name = f\"Replay TX {shorten_address(tx_hash)} - State Changes\"\n",
        "            elif selected_content == 'Transfers' and not transfers_df.empty:\n",
        "                df_to_export = transfers_df\n",
        "                sheet_name = f\"Replay TX {shorten_address(tx_hash)} - Transfers\"\n",
        "            elif selected_content == 'PYUSD Operations' and not vm_operations_df.empty:\n",
        "                df_to_export = vm_operations_df\n",
        "                sheet_name = f\"Replay TX {shorten_address(tx_hash)} - Operations\"\n",
        "            else:\n",
        "                # For 'All Data', create a summary DataFrame\n",
        "                summary_rows = []\n",
        "                for key, value in summary_data.items():\n",
        "                    if key not in ['pyusd_transfers', 'pyusd_balance_changes', 'pyusd_operations', 'security_flags']:\n",
        "                        if isinstance(value, dict):\n",
        "                            for sub_key, sub_value in value.items():\n",
        "                                summary_rows.append({\n",
        "                                    'category': key,\n",
        "                                    'key': sub_key,\n",
        "                                    'value': str(sub_value)\n",
        "                                })\n",
        "                        else:\n",
        "                            summary_rows.append({\n",
        "                                'category': 'transaction',\n",
        "                                'key': key,\n",
        "                                'value': str(value)\n",
        "                            })\n",
        "\n",
        "                df_to_export = pd.DataFrame(summary_rows)\n",
        "                sheet_name = f\"Replay TX {shorten_address(tx_hash)} - Summary\"\n",
        "\n",
        "            display(export_to_google_sheets_direct(df_to_export, sheet_name))\n",
        "\n",
        "    # Connect callbacks\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    return summary_data\n",
        "\n",
        "\n",
        "def analyze_replay_block(replay_block_list, block_identifier, requested_tracers):\n",
        "    \"\"\"\n",
        "    Analyzes the output list from trace_replayBlockTransactions with PYUSD focus.\n",
        "\n",
        "    Args:\n",
        "        replay_block_list: List of replay results for each transaction\n",
        "        block_identifier: Block number or hash being analyzed\n",
        "        requested_tracers: List of tracer types that were requested\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with transaction-level PYUSD analysis\n",
        "    \"\"\"\n",
        "    if not isinstance(replay_block_list, list):\n",
        "        console.print(f\"[error]Expected list from trace_replayBlockTransactions for {block_identifier}, got {type(replay_block_list)}.\", style=\"error\")\n",
        "        display_json(replay_block_list, \"Unexpected Replay Block Result\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]PYUSD Analysis of trace_replayBlockTransactions for {block_identifier}[/bold cyan3]\")\n",
        "    console.print(f\"Results for {len(replay_block_list)} transactions. Requested Tracers: {', '.join(requested_tracers)}\")\n",
        "\n",
        "    block_summary = []\n",
        "    total_state_changes = 0\n",
        "    txs_with_pyusd_state_change = 0\n",
        "    total_pyusd_transfers = 0\n",
        "    total_pyusd_volume = 0\n",
        "    pyusd_state_changes_by_type = {\n",
        "        'balance': 0,\n",
        "        'storage': 0,\n",
        "        'code': 0,\n",
        "        'other': 0\n",
        "    }\n",
        "    security_flags = []\n",
        "\n",
        "    for i, tx_replay_result in enumerate(replay_block_list):\n",
        "        tx_summary = {'tx_index': i}\n",
        "        # Get tx hash if available (might be nested differently)\n",
        "        tx_hash = tx_replay_result.get('txHash', tx_replay_result.get('transactionHash', f'tx_{i}'))\n",
        "        tx_summary['tx_hash'] = tx_hash\n",
        "\n",
        "        # Initialize PYUSD metrics\n",
        "        tx_summary['has_pyusd_call'] = False\n",
        "        tx_summary['pyusd_state_changes'] = 0\n",
        "        tx_summary['pyusd_transfers'] = 0\n",
        "        tx_summary['pyusd_volume'] = 0\n",
        "        tx_summary['security_flags'] = []\n",
        "\n",
        "        # Analyze trace data if available\n",
        "        if \"trace\" in requested_tracers and \"trace\" in tx_replay_result:\n",
        "            trace_list = tx_replay_result[\"trace\"]\n",
        "            if isinstance(trace_list, list):\n",
        "                # Check for PYUSD interactions in the trace\n",
        "                for trace_item in trace_list:\n",
        "                    if not isinstance(trace_item, dict): continue\n",
        "\n",
        "                    action = trace_item.get('action', {})\n",
        "                    to_addr = action.get('to', '')\n",
        "                    call_data = action.get('input', '0x')\n",
        "\n",
        "                    # Check if this is a PYUSD contract interaction\n",
        "                    if to_addr and to_addr.lower() in PYUSD_CONTRACTS:\n",
        "                        tx_summary['has_pyusd_call'] = True\n",
        "\n",
        "                        # Check for transfer functions\n",
        "                        if call_data and call_data.startswith('0xa9059cbb'):  # transfer\n",
        "                            try:\n",
        "                                to_offset = 10\n",
        "                                to_param = \"0x\" + call_data[to_offset+24:to_offset+64]\n",
        "                                amount_offset = 74\n",
        "                                amount = int(call_data[amount_offset:amount_offset+64], 16)\n",
        "                                value_pyusd = amount / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                tx_summary['pyusd_transfers'] += 1\n",
        "                                tx_summary['pyusd_volume'] += value_pyusd\n",
        "                                total_pyusd_transfers += 1\n",
        "                                total_pyusd_volume += value_pyusd\n",
        "                            except Exception:\n",
        "                                pass\n",
        "                        elif call_data and call_data.startswith('0x23b872dd'):  # transferFrom\n",
        "                            try:\n",
        "                                from_offset = 10\n",
        "                                from_param = \"0x\" + call_data[from_offset+24:from_offset+64]\n",
        "                                to_offset = 74\n",
        "                                to_param = \"0x\" + call_data[to_offset+24:to_offset+64]\n",
        "                                amount_offset = 138\n",
        "                                amount = int(call_data[amount_offset:amount_offset+64], 16)\n",
        "                                value_pyusd = amount / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                tx_summary['pyusd_transfers'] += 1\n",
        "                                tx_summary['pyusd_volume'] += value_pyusd\n",
        "                                total_pyusd_transfers += 1\n",
        "                                total_pyusd_volume += value_pyusd\n",
        "                            except Exception:\n",
        "                                pass\n",
        "\n",
        "                        # Check for admin functions\n",
        "                        method_sig = call_data[:10]\n",
        "                        if method_sig in PYUSD_SIGNATURES:\n",
        "                            function_info = PYUSD_SIGNATURES[method_sig]\n",
        "                            if function_info[\"category\"] == \"admin\":\n",
        "                                # Add security flag\n",
        "                                security_flag = {\n",
        "                                    'tx_hash': tx_hash,\n",
        "                                    'tx_index': i,\n",
        "                                    'level': 'warning',\n",
        "                                    'type': 'admin_function',\n",
        "                                    'description': f\"Admin function {function_info['name']} called\"\n",
        "                                }\n",
        "                                tx_summary['security_flags'].append(security_flag)\n",
        "                                security_flags.append(security_flag)\n",
        "\n",
        "        # Analyze state diff if available\n",
        "        if \"stateDiff\" in requested_tracers and \"stateDiff\" in tx_replay_result:\n",
        "            state_diff = tx_replay_result[\"stateDiff\"]\n",
        "            tx_state_changes = 0\n",
        "            tx_pyusd_changes = 0\n",
        "            tx_pyusd_change = False\n",
        "\n",
        "            if isinstance(state_diff, dict):\n",
        "                for address, diffs in state_diff.items():\n",
        "                    is_pyusd_contract = address.lower() == PYUSD_CONFIG['ethereum']['address'].lower()\n",
        "\n",
        "                    # Count various types of changes\n",
        "                    for change_type in ['balance', 'nonce', 'code', 'storage']:\n",
        "                        if change_type in diffs:\n",
        "                            tx_state_changes += 1\n",
        "                            if change_type == 'storage':\n",
        "                                tx_state_changes += len(diffs[change_type]) - 1\n",
        "\n",
        "                            if is_pyusd_contract:\n",
        "                                tx_pyusd_change = True\n",
        "                                tx_pyusd_changes += 1\n",
        "                                if change_type in pyusd_state_changes_by_type:\n",
        "                                    pyusd_state_changes_by_type[change_type] += 1\n",
        "                                else:\n",
        "                                    pyusd_state_changes_by_type['other'] += 1\n",
        "\n",
        "                                # Security check for critical changes\n",
        "                                if change_type == 'code':\n",
        "                                    security_flag = {\n",
        "                                        'tx_hash': tx_hash,\n",
        "                                        'tx_index': i,\n",
        "                                        'level': 'critical',\n",
        "                                        'type': 'code_change',\n",
        "                                        'description': f\"PYUSD contract code was modified\"\n",
        "                                    }\n",
        "                                    tx_summary['security_flags'].append(security_flag)\n",
        "                                    security_flags.append(security_flag)\n",
        "\n",
        "            tx_summary['state_changes'] = tx_state_changes\n",
        "            tx_summary['pyusd_state_changes'] = tx_pyusd_changes\n",
        "            tx_summary['pyusd_state_change'] = tx_pyusd_change\n",
        "\n",
        "            total_state_changes += tx_state_changes\n",
        "            if tx_pyusd_change:\n",
        "                txs_with_pyusd_state_change += 1\n",
        "\n",
        "        block_summary.append(tx_summary)\n",
        "\n",
        "    summary_df = pd.DataFrame(block_summary)\n",
        "\n",
        "    # Calculate PYUSD metrics\n",
        "    pyusd_txs_count = summary_df['has_pyusd_call'].sum() if 'has_pyusd_call' in summary_df.columns else 0\n",
        "    pyusd_tx_percentage = (pyusd_txs_count / len(replay_block_list) * 100) if replay_block_list else 0\n",
        "\n",
        "    # Block summary with PYUSD focus - enhanced colors for dark themes\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold cyan3]PYUSD Block Activity Summary ({block_identifier})[/bold cyan3]\n",
        "[bold cyan3]Transactions Processed:[/bold cyan3] {len(replay_block_list)}\n",
        "[bold cyan3]Total State Changes:[/bold cyan3] {total_state_changes:,}\n",
        "\n",
        "[bold green3]PYUSD Activity[/bold green3]\n",
        "[bold green3]PYUSD Transactions:[/bold green3] {pyusd_txs_count} ({pyusd_tx_percentage:.1f}% of transactions)\n",
        "[bold green3]PYUSD State Changes:[/bold green3] {txs_with_pyusd_state_change} transactions affected\n",
        "[bold green3]PYUSD Transfers:[/bold green3] {total_pyusd_transfers}\n",
        "[bold green3]PYUSD Volume:[/bold green3] {total_pyusd_volume:,.6f} PYUSD\n",
        "\n",
        "[bold {SECURITY_COLORS['high']}]Security:[/bold {SECURITY_COLORS['high']}]\n",
        "Security Flags: {len(security_flags)}\"\"\",\n",
        "        title=\"PYUSD Block Analysis\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # Display security flags if any\n",
        "    if security_flags:\n",
        "        console.print(f\"\\n\\n[bold {SECURITY_COLORS['high']}]üõ°Ô∏è Security Concerns in Block[/bold {SECURITY_COLORS['high']}]\")\n",
        "        console.print(f\"[{SECURITY_COLORS['high']}]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[/{SECURITY_COLORS['high']}]\")\n",
        "\n",
        "        security_table = Table(show_header=True, header_style=f\"bold {SECURITY_COLORS['high']}\")\n",
        "        security_table.add_column(\"TX Index\", justify=\"right\")\n",
        "        security_table.add_column(\"TX Hash\")\n",
        "        security_table.add_column(\"Level\", justify=\"center\")\n",
        "        security_table.add_column(\"Description\")\n",
        "\n",
        "        for flag in security_flags:\n",
        "            level = flag['level']\n",
        "            level_color = SECURITY_COLORS[\"critical\"] if level == \"critical\" else SECURITY_COLORS[\"high\"] if level == \"high\" else SECURITY_COLORS[\"warning\"] if level == \"warning\" else SECURITY_COLORS[\"info\"]\n",
        "\n",
        "            security_table.add_row(\n",
        "                str(flag['tx_index']),\n",
        "                shorten_address(flag['tx_hash']),\n",
        "                f\"[{level_color}]{level.upper()}[/{level_color}]\",\n",
        "                flag['description']\n",
        "            )\n",
        "\n",
        "        console.print(security_table)\n",
        "\n",
        "    # Display PYUSD state change distribution\n",
        "    if txs_with_pyusd_state_change > 0:\n",
        "        console.print(\"\\n\\n[bold green3]PYUSD State Change Types[/bold green3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "\n",
        "        state_change_table = Table(title=\"\", show_header=True, header_style=\"bold green3\")\n",
        "        state_change_table.add_column(\"Change Type\")\n",
        "        state_change_table.add_column(\"Count\", justify=\"right\")\n",
        "        state_change_table.add_column(\"Description\", style=\"italic\")\n",
        "\n",
        "        descriptions = {\n",
        "            'balance': \"ETH balance of PYUSD contracts\",\n",
        "            'storage': \"Contract storage values (incl. balances, allowances, etc.)\",\n",
        "            'code': \"Contract bytecode changes (upgrades, etc.)\",\n",
        "            'other': \"Other state changes\"\n",
        "        }\n",
        "\n",
        "        for change_type, count in pyusd_state_changes_by_type.items():\n",
        "            if count > 0:\n",
        "                state_change_table.add_row(\n",
        "                    change_type.title(),\n",
        "                    str(count),\n",
        "                    descriptions.get(change_type, \"\")\n",
        "                )\n",
        "\n",
        "        console.print(state_change_table)\n",
        "\n",
        "        # Create visualization for state changes\n",
        "        console.print(\"\\n\\n[bold magenta3]üìà PYUSD State Change Types in Block Chart:[/bold magenta3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        try:\n",
        "            state_changes_data = pd.DataFrame([\n",
        "                {\"type\": change_type.title(), \"count\": count}\n",
        "                for change_type, count in pyusd_state_changes_by_type.items() if count > 0\n",
        "            ])\n",
        "\n",
        "            if not state_changes_data.empty:\n",
        "                fig_state = px.pie(\n",
        "                    state_changes_data, values='count', names='type',\n",
        "                    title=f'PYUSD State Change Types in Block {block_identifier}',\n",
        "                    color_discrete_sequence=px.colors.qualitative.Pastel\n",
        "                )\n",
        "                fig_state.update_layout(template=\"plotly_white\")\n",
        "                fig_state.show()\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create state change visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Transaction table with PYUSD focus\n",
        "    if not summary_df.empty:\n",
        "        console.print(\"\\n\\n[bold cyan3]üìä PYUSD Block Transaction Summary[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        # Filter and prepare display columns\n",
        "        display_cols = ['tx_index', 'tx_hash']\n",
        "\n",
        "        # Add PYUSD-specific columns if they exist\n",
        "        for col in ['has_pyusd_call', 'pyusd_transfers', 'pyusd_volume', 'pyusd_state_changes', 'state_changes']:\n",
        "            if col in summary_df.columns:\n",
        "                display_cols.append(col)\n",
        "\n",
        "        # Only include columns that exist in the DataFrame\n",
        "        display_cols = [col for col in display_cols if col in summary_df.columns]\n",
        "\n",
        "        # Use the new pagination display function\n",
        "        display_transaction_dataframe(summary_df[display_cols])\n",
        "\n",
        "        # Create PYUSD activity visualization if there's enough data\n",
        "        console.print(\"\\n\\n[bold magenta3]üöö PYUSD Transaction Volume Distribution in Block Chart:[/bold magenta3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        if pyusd_txs_count > 0 and 'pyusd_volume' in summary_df.columns:\n",
        "            try:\n",
        "                # Filter for PYUSD transactions\n",
        "                pyusd_txs = summary_df[summary_df['pyusd_volume'] > 0].copy()\n",
        "\n",
        "                if not pyusd_txs.empty:\n",
        "                    # Create volume distribution chart\n",
        "                    fig_volume = px.bar(\n",
        "                        pyusd_txs, x='tx_index', y='pyusd_volume',\n",
        "                        title=f'PYUSD Transaction Volume Distribution in Block {block_identifier}',\n",
        "                        labels={'tx_index': 'Transaction Index', 'pyusd_volume': 'PYUSD Volume'},\n",
        "                        color='pyusd_volume',\n",
        "                        color_continuous_scale='Viridis'\n",
        "                    )\n",
        "                    fig_volume.update_layout(template=\"plotly_white\")\n",
        "                    fig_volume.show()\n",
        "\n",
        "                    # Create heatmap of PYUSD activity\n",
        "                    console.print(\"\\n\\n[bold magenta3]‚¨ú PYUSD Transaction Activity Heatmap in Block Chart:[/bold magenta3]\")\n",
        "                    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                    if len(pyusd_txs) >= 2:  # Only create heatmap if we have 2+ transactions\n",
        "                        pyusd_txs['log_volume'] = np.log10(pyusd_txs['pyusd_volume'] + 1)  # log scale for better visualization\n",
        "                        fig_heat = px.scatter(\n",
        "                            pyusd_txs,\n",
        "                            x='tx_index',\n",
        "                            y='pyusd_state_changes',\n",
        "                            size='log_volume',\n",
        "                            color='pyusd_volume',\n",
        "                            hover_data=['pyusd_transfers', 'pyusd_volume', 'tx_hash'],\n",
        "                            title=f'PYUSD Transaction Activity Heatmap in Block {block_identifier}'\n",
        "                        )\n",
        "                        fig_heat.update_layout(template=\"plotly_white\")\n",
        "                        fig_heat.show()\n",
        "            except Exception as viz_err:\n",
        "                console.print(f\"[warning]Could not create PYUSD volume visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Add export options\n",
        "    console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Export buttons with better styling\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Export handlers with block-specific data\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"replay_block_{block_identifier}_{timestamp}.csv\"\n",
        "            display(download_csv_direct(summary_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"replay_block_{block_identifier}_{timestamp}.json\"\n",
        "\n",
        "            # Create rich JSON export\n",
        "            export_data = {\n",
        "                \"block_identifier\": block_identifier,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"tracers_used\": requested_tracers,\n",
        "                \"summary\": {\n",
        "                    \"transactions_count\": len(replay_block_list),\n",
        "                    \"pyusd_transactions_count\": int(pyusd_txs_count),\n",
        "                    \"pyusd_transactions_percentage\": float(pyusd_tx_percentage),\n",
        "                    \"total_state_changes\": total_state_changes,\n",
        "                    \"txs_with_pyusd_state_change\": txs_with_pyusd_state_change,\n",
        "                    \"total_pyusd_transfers\": total_pyusd_transfers,\n",
        "                    \"total_pyusd_volume\": float(total_pyusd_volume),\n",
        "                    \"security_flags_count\": len(security_flags)\n",
        "                },\n",
        "                \"state_changes_by_type\": pyusd_state_changes_by_type,\n",
        "                \"security_flags\": security_flags,\n",
        "                \"transactions\": summary_df.to_dict('records')\n",
        "            }\n",
        "\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            sheet_name = f\"Block {block_identifier} Replay {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "            display(export_to_google_sheets_direct(summary_df, sheet_name))\n",
        "\n",
        "    # Connect callbacks\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    return summary_df\n",
        "\n",
        "# --- Execute trace_replayTransaction with PYUSD focus ---\n",
        "RUN_REPLAY_TX = True # <<< SET TO TRUE TO RUN THIS (100x COST!)\n",
        "REPLAY_TRACERS = [\"trace\", \"stateDiff\"] # Choose tracers: \"trace\", \"vmTrace\", \"stateDiff\"\n",
        "\n",
        "if not validate_tx_hash:\n",
        "    console.print(\"[warning]Skipping 'trace_replayTransaction': TARGET_TX_HASH invalid or not set.\", style=\"warning\")\n",
        "elif RUN_REPLAY_TX:\n",
        "    console.print(\"\\n\\n[bold chartreuse1]üîÑ Replay Transaction with trace_replayTransaction[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    console.print(f\"\\n\\n[warning]Attempting replaying transaction using 'trace_replayTransaction' for {TARGET_TX_HASH} (100x cost!) with tracers: {REPLAY_TRACERS}...[/warning]\", style=\"warning\")\n",
        "    params = [TARGET_TX_HASH, REPLAY_TRACERS]\n",
        "    replay_result_data = make_rpc_request(\"trace_replayTransaction\", params, network='mainnet')\n",
        "\n",
        "    if replay_result_data:\n",
        "        console.print(\"[success]trace_replayTransaction completed.\", style=\"success\")\n",
        "        analysis_summary = analyze_replay_transaction(replay_result_data, TARGET_TX_HASH, REPLAY_TRACERS)\n",
        "    else:\n",
        "        console.print(f\"[error]Failed to replay transaction {TARGET_TX_HASH}.\", style=\"error\")\n",
        "else:\n",
        "    console.print(\"\\n[info]Skipping 'trace_replayTransaction' as RUN_REPLAY_TX is False.\", style=\"info\")\n",
        "\n",
        "\n",
        "# --- Execute trace_replayBlockTransactions with PYUSD focus ---\n",
        "RUN_REPLAY_BLOCK = True # <<< SET TO TRUE TO RUN THIS (EXTREME 100x COST!)\n",
        "REPLAY_BLOCK_TRACERS = [\"stateDiff\", \"trace\"] # Choose tracers cautiously\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_replay = TARGET_BLOCK_IDENTIFIER\n",
        "    block_param_replay = None\n",
        "    # Replay methods require specific block hash or number (hex), not tags\n",
        "    if isinstance(block_id_replay, int):\n",
        "        block_param_replay = hex(block_id_replay)\n",
        "    elif isinstance(block_id_replay, str) and block_id_replay.startswith('0x') and len(block_id_replay) == 66:\n",
        "        block_param_replay = block_id_replay # Assume block hash\n",
        "    elif isinstance(block_id_replay, str) and block_id_replay.startswith('0x'):\n",
        "        # Assume hex block number\n",
        "        block_param_replay = block_id_replay\n",
        "    elif isinstance(block_id_replay, str) and block_id_replay.isdigit():\n",
        "        # Convert decimal string to hex\n",
        "        block_param_replay = hex(int(block_id_replay))\n",
        "\n",
        "    if RUN_REPLAY_BLOCK and block_param_replay:\n",
        "        console.print(\"\\n\\n[bold chartreuse1]üîÑ Replay Transaction with trace_replayTransaction[/bold chartreuse1]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "        console.print(f\"\\n\\n[warning]Attempting replaying transactions using 'trace_replayBlockTransactions' for {block_param_replay} (EXTREME COST!) with tracers: {REPLAY_BLOCK_TRACERS}...[/warning]\", style=\"warning\")\n",
        "\n",
        "        params = [block_param_replay, REPLAY_BLOCK_TRACERS]\n",
        "        replay_block_result = make_rpc_request(\"trace_replayBlockTransactions\", params, network='mainnet')\n",
        "\n",
        "        if replay_block_result:\n",
        "            console.print(\"[success]trace_replayBlockTransactions completed.\", style=\"success\")\n",
        "            analyze_replay_block(replay_block_result, block_param_replay, REPLAY_BLOCK_TRACERS)\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to replay block transactions for {block_param_replay}.\", style=\"error\")\n",
        "    elif not RUN_REPLAY_BLOCK:\n",
        "        console.print(f\"\\n\\n[info]Skipping 'trace_replayBlockTransactions' as RUN_REPLAY_BLOCK is False.\", style=\"info\")\n",
        "    elif not block_param_replay:\n",
        "        console.print(\"[error]Could not convert TARGET_BLOCK_IDENTIFIER to a valid block parameter.\", style=\"error\")\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping block replay analysis.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "cmMV5aC3gLEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.10 üíæ `debug_storageRangeAt`: Inspecting Raw Contract Storage\n",
        "---\n",
        "\n",
        "This section uses `debug_storageRangeAt` to directly query and retrieve the raw values stored in a contract's storage slots at a specific point in time (defined by a block hash and transaction index within that block). This provides a low-level snapshot of the contract's persistent state.\n",
        "\n",
        "Interpreting the output requires understanding the contract's storage layout (how variables are packed into 256-bit slots). For complex contracts, this can be challenging, but it's invaluable for:\n",
        "\n",
        "*   **Verifying State:** Directly checking values like `totalSupply`, `owner`, `paused` status if their slots are known.\n",
        "*   **Debugging:** Examining storage values around the time a transaction failed.\n",
        "*   **Proxy Analysis:** Identifying implementation/admin addresses stored in standard EIP-1967 slots.\n",
        "*   **Mapping Analysis:** Calculating and querying specific slots within mappings (like balances or allowances) for targeted addresses.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `debug_storageRangeAt`\n",
        "> *   **Multiplier:** `50x`\n",
        "> *   **GCP Advantage:** Fetching storage ranges, especially large ones, requires significant node resources. GCP reliably provides this data access.\n",
        "> *   **PYUSD Insight:** Enables us to:\n",
        ">     *   Directly read the **PYUSD `totalSupply`**, **`owner`**, **`paused` state**, and **proxy implementation/admin addresses** by querying their known storage slots.\n",
        ">     *   Investigate the **balance or allowance** for specific addresses by calculating and querying the corresponding mapping slots (demonstrated in helper functions).\n",
        ">     *   Compare storage snapshots **before and after** a key transaction to pinpoint state changes (using the comparison function).\n",
        ">     *   Analyze the **storage layout patterns** to confirm adherence to standards (ERC20, Proxy, Pausable).\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Storage Dump:** Calls `debug_storageRangeAt` specifying the target contract address, block hash, transaction index (usually 0 for state before the block's transactions), starting slot key (often \"0x0\"), and the maximum number of slots to retrieve.\n",
        "2.  **Parse & Interpret:** The `analyze_storage_dump` function processes the returned storage map:\n",
        "    *   It identifies known slots (ERC20 standards, EIP-1967 proxy slots, PYUSD-specific slots) based on predefined patterns.\n",
        "    *   It attempts to decode values into addresses, booleans, small integers, or formatted PYUSD amounts where possible.\n",
        "    *   It categorizes slots based on their likely purpose (supply, balances, allowances, proxy, control, metadata, access control).\n",
        "3.  **Visualize & Summarize:**\n",
        "    *   **Contract Info Panel:** Displays key decoded values like total supply, paused state, implementation address.\n",
        "    *   **Proxy Visualization:** If analyzing a proxy, shows a Graphviz diagram of the proxy-implementation(-admin) relationship.\n",
        "    *   **Storage Table:** Presents the retrieved slots, decoded values, and interpretations in a filterable table (using `ipywidgets`).\n",
        "    *   **Storage Layout Visualizations:** Generates plots (pie chart, bar chart) showing the distribution of storage slots by category and the layout of initial slots.\n",
        "    *   **Security Analysis:** Flags potential security-relevant findings based on storage patterns (e.g., paused state, proxy details).\n",
        "    *   **Pattern Detection:** Summarizes detected storage patterns (ERC20, Proxy, Pausable, etc.).\n",
        "4.  **Advanced Features:**\n",
        "    *   **Storage Comparison:** The `compare_storage` function fetches dumps from two different blocks and highlights the changed slots.\n",
        "    *   **Mapping Analysis:** The `analyze_mapping_storage` function calculates and queries storage slots for specific keys within a mapping (e.g., checking balances for a list of addresses).\n",
        "    *   **Balance Analysis:** The `analyze_pyusd_balances` function specifically focuses on decoding and visualizing the PYUSD balance mapping.\n",
        "    *   **Historical Tracking:** The `analyze_storage_history` function tracks a single slot's value across multiple blocks.\n",
        "5.  **Export Options:** Download parsed storage data, comparisons, or mapping analysis.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Known Slots:** Verify expected values in slots like `totalSupply`, proxy implementation/admin, or paused state.\n",
        "*   **Decoded Values:** Examine decoded addresses, PYUSD amounts, or boolean flags.\n",
        "*   **Storage Categories:** Understand the composition of the contract's storage (how much is used for balances, allowances, control, etc.).\n",
        "*   **(Comparison):** Focus on the highlighted rows showing changed values between blocks.\n",
        "*   **(Mapping Analysis):** Check the balances or allowances for specific addresses of interest."
      ],
      "metadata": {
        "id": "nAa0XEc4x9Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üíæ Contract Storage Analysis with debug_storageRangeAt\n",
        "# =============================================================================================\n",
        "# This cell utilizes the `debug_storageRangeAt` RPC method for deep inspection of contract storage state:\n",
        "# - Fetches raw storage slots for a specified contract at a given block hash.\n",
        "# - Parses and decodes storage values into meaningful types (addresses, uints, bools, strings).\n",
        "# - Applies specific interpretations for known PYUSD, ERC20, and OpenZeppelin patterns (e.g., totalSupply, balances, proxy slots, roles, paused state).\n",
        "# - Analyzes and visualizes the storage layout, categorizing slots by function (supply, access control, proxy, metadata).\n",
        "# - Compares storage snapshots between two blocks to highlight state changes, particularly useful for identifying supply/balance modifications.\n",
        "# - Investigates mapping structures (like balances or allowances) by calculating storage keys and retrieving values.\n",
        "# - Tracks the historical changes of specific storage slots across multiple blocks.\n",
        "# - Automatically detects common contract design patterns (Proxy, Pausable, AccessControl) from the storage layout.\n",
        "# - Generates comprehensive reports using Rich tables, Plotly/Matplotlib charts, and Graphviz diagrams.\n",
        "# - Provides interactive filtering and direct export options (CSV, JSON, Google Sheets) for the analyzed data.\n",
        "# =============================================================================================\n",
        "\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, clear_output, display\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from graphviz import Digraph\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "import time\n",
        "import re\n",
        "from eth_utils import decode_hex, to_hex, to_int\n",
        "from web3 import Web3\n",
        "\n",
        "\n",
        "def analyze_storage_dump(storage_dump_result, contract_address, block_hash, is_proxy=None):\n",
        "    \"\"\"Parser for debug_storageRangeAt with PYUSD-specific interpretations.\"\"\"\n",
        "    if not storage_dump_result or 'storage' not in storage_dump_result:\n",
        "        console.print(\"[error]Invalid or empty storage dump result received.\", style=\"error\")\n",
        "        display_json(storage_dump_result, \"Received Storage Dump Result\")\n",
        "        return None\n",
        "\n",
        "    # Detect if target is proxy or implementation based on address if not specified\n",
        "    if is_proxy is None:\n",
        "        is_proxy = contract_address.lower() == PYUSD_PROXY.lower()\n",
        "\n",
        "    contract_type = \"Proxy\" if is_proxy else \"Implementation\"\n",
        "    storage_map = storage_dump_result['storage']\n",
        "    console.print(f\"\\n\\n[success]Retrieved {len(storage_map)} storage slots for {shorten_address(contract_address)} ({contract_type}) at block {shorten_address(block_hash)}.\", style=\"success\")\n",
        "\n",
        "    # Known storage patterns for PYUSD (based on common ERC20 and OpenZeppelin patterns)\n",
        "    known_slots = {\n",
        "        # Common ERC20 slots\n",
        "        0: \"totalSupply (or part of it)\",\n",
        "        1: \"name (string pointer or part)\",\n",
        "        2: \"symbol (string pointer or part)\",\n",
        "        3: \"decimals (or part of mapping pointer)\",\n",
        "        4: \"balances mapping base\",\n",
        "        5: \"allowances mapping base\",\n",
        "        # OpenZeppelin Proxy slots\n",
        "        \"0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc\": \"EIP-1967 implementation slot\",\n",
        "        \"0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103\": \"EIP-1967 admin slot\",\n",
        "        \"0xa3f0ad74e5423aebfd80d3ef4346578335a9a72aeaee59ff6cb3582b35133d50\": \"EIP-1967 beacon slot\",\n",
        "        # OpenZeppelin AccessControl patterns\n",
        "        \"0xb09aa5aeb3702cfd50b6b62bc4532604938f21248a27a1d5ca736082b6819cc1\": \"Admin role hash\",\n",
        "        # OpenZeppelin Pausable pattern\n",
        "        \"0x5ac1dce9f7971a63e05025b10b44b6f3c868ae576a5e4a815201051d3eae29cb\": \"Paused state\",\n",
        "        # PYUSD-specific patterns\n",
        "        \"0x0000000000000000000000000000000000000000000000000000000000000014\": \"PYUSD version\",\n",
        "        # Role slots - more precise for PYUSD's specific structure\n",
        "        \"0x523a704056dcd17bcbde8daf7c077f098d4c0543350248342941a5f0bd09013b\": \"MINTER_ROLE hash\",\n",
        "        \"0xe79898c174bd7837e39256eb383695fecfbd06b222fb859d684c784cbd5997bb\": \"PAUSER_ROLE hash\",\n",
        "        \"0x7a8dc26796a1e50e6e190b70259f58f6a4edd5b21680169636c3b97720af2ffc\": \"TOKEN_CONTROLLER_ROLE hash\",\n",
        "    }\n",
        "\n",
        "    # Add mapping prefix patterns\n",
        "    balances_mapping_prefix = None\n",
        "    allowances_mapping_prefix = None\n",
        "\n",
        "    storage_list = []\n",
        "    # Track key storage patterns\n",
        "    total_supply = None\n",
        "    paused_state = None\n",
        "    implementation_address = None\n",
        "    version = None\n",
        "    roles = {}\n",
        "\n",
        "    # First pass - identify key slots and extract basics\n",
        "    for slot_hash, data in storage_map.items():\n",
        "        try:\n",
        "            # Convert slot hash to int when possible for better sorting\n",
        "            if slot_hash.startswith('0x'):\n",
        "                try:\n",
        "                    slot_int = int(slot_hash, 16)\n",
        "                    slot_display = slot_int\n",
        "                except ValueError:\n",
        "                    slot_int = None\n",
        "                    slot_display = slot_hash\n",
        "            else:\n",
        "                slot_int = None\n",
        "                slot_display = slot_hash\n",
        "\n",
        "            # Get raw value\n",
        "            value = data.get('value', 'N/A')\n",
        "\n",
        "            # Store raw data first\n",
        "            slot_entry = {\n",
        "                'slot_int': slot_int,\n",
        "                'slot_hex': slot_hash,\n",
        "                'slot_display': slot_display,\n",
        "                'raw_value': value,\n",
        "                'decoded_value': None,\n",
        "                'interpretation': None,\n",
        "                'type': None,\n",
        "                'category': 'unknown'  # Category for better organization\n",
        "            }\n",
        "\n",
        "            # Check for known slots by hash\n",
        "            if slot_hash in known_slots:\n",
        "                slot_entry['interpretation'] = known_slots[slot_hash]\n",
        "\n",
        "                # Handle special slots with extra processing\n",
        "                if slot_hash == \"0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc\":\n",
        "                    # Implementation slot\n",
        "                    impl_addr = \"0x\" + value[-40:]\n",
        "                    implementation_address = Web3.to_checksum_address(impl_addr)\n",
        "                    slot_entry['decoded_value'] = implementation_address\n",
        "                    slot_entry['type'] = \"address\"\n",
        "                    slot_entry['category'] = 'proxy'\n",
        "\n",
        "                # EIP-1967 admin slot\n",
        "                elif slot_hash == \"0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103\":\n",
        "                    admin_addr = \"0x\" + value[-40:]\n",
        "                    slot_entry['decoded_value'] = Web3.to_checksum_address(admin_addr)\n",
        "                    slot_entry['type'] = \"address\"\n",
        "                    slot_entry['category'] = 'proxy'\n",
        "\n",
        "                # Paused state slot\n",
        "                elif slot_hash == \"0x5ac1dce9f7971a63e05025b10b44b6f3c868ae576a5e4a815201051d3eae29cb\":\n",
        "                    paused_state = int(value, 16) == 1\n",
        "                    slot_entry['decoded_value'] = str(paused_state)\n",
        "                    slot_entry['type'] = \"bool\"\n",
        "                    slot_entry['category'] = 'control'\n",
        "\n",
        "                # Role related slots\n",
        "                elif 'role' in slot_entry['interpretation'].lower():\n",
        "                    role_name = slot_entry['interpretation'].replace(' hash', '')\n",
        "                    slot_entry['category'] = 'access_control'\n",
        "\n",
        "                    # Store for role visualization\n",
        "                    roles[role_name] = {\n",
        "                        'slot': slot_hash,\n",
        "                        'value': value\n",
        "                    }\n",
        "\n",
        "            # Check for known slots by position\n",
        "            elif slot_int is not None and slot_int in known_slots:\n",
        "                slot_entry['interpretation'] = known_slots[slot_int]\n",
        "\n",
        "                # Handle common ERC20 patterns\n",
        "                if slot_int == 0 and value != '0x0':\n",
        "                    # Likely total supply\n",
        "                    try:\n",
        "                        total_supply = int(value, 16)\n",
        "                        slot_entry['decoded_value'] = format_value_pyusd(total_supply)\n",
        "                        slot_entry['type'] = \"uint256\"\n",
        "                        slot_entry['category'] = 'supply'\n",
        "                    except ValueError:\n",
        "                        pass\n",
        "\n",
        "                # Check for balances mapping root\n",
        "                elif slot_int == 4:\n",
        "                    balances_mapping_prefix = slot_int\n",
        "                    slot_entry['category'] = 'balances'\n",
        "\n",
        "                # Check for allowances mapping root\n",
        "                elif slot_int == 5:\n",
        "                    allowances_mapping_prefix = slot_int\n",
        "                    slot_entry['category'] = 'allowances'\n",
        "\n",
        "                # Check for PYUSD version\n",
        "                elif slot_int == 20:\n",
        "                    try:\n",
        "                        version = int(value, 16)\n",
        "                        slot_entry['decoded_value'] = f\"v{version}\"\n",
        "                        slot_entry['type'] = \"uint256\"\n",
        "                        slot_entry['category'] = 'version'\n",
        "                    except ValueError:\n",
        "                        pass\n",
        "\n",
        "            # Add to our results list\n",
        "            storage_list.append(slot_entry)\n",
        "\n",
        "        except Exception as e:\n",
        "            console.print(f\"[warning]Error processing slot {slot_hash}: {str(e)}\", style=\"warning\")\n",
        "            # Still add the raw data\n",
        "            storage_list.append({\n",
        "                'slot_hex': slot_hash,\n",
        "                'raw_value': data.get('value', 'N/A'),\n",
        "                'error': str(e)\n",
        "            })\n",
        "\n",
        "    # Second pass - advanced decoding and interpretation\n",
        "    for slot_entry in storage_list:\n",
        "        if slot_entry.get('decoded_value') is not None:\n",
        "            # Skip already processed entries\n",
        "            continue\n",
        "\n",
        "        value = slot_entry['raw_value']\n",
        "\n",
        "        # Try to decode the value based on common patterns\n",
        "        try:\n",
        "            if len(value) == 66 and value.startswith('0x'):\n",
        "                value_int = int(value, 16)\n",
        "\n",
        "                # Small number - likely uint8/uint256\n",
        "                if value_int < 1e12:\n",
        "                    slot_entry['decoded_value'] = f\"{value_int}\"\n",
        "                    slot_entry['type'] = \"uint256\"\n",
        "\n",
        "                    # Check for boolean value\n",
        "                    if value_int == 0 or value_int == 1:\n",
        "                        slot_entry['interpretation'] = f\"Possible boolean: {'true' if value_int == 1 else 'false'}\"\n",
        "                        slot_entry['type'] = \"bool\"\n",
        "\n",
        "                        # Check for paused state in known paused slot\n",
        "                        if slot_entry['slot_hex'] == \"0x5ac1dce9f7971a63e05025b10b44b6f3c868ae576a5e4a815201051d3eae29cb\":\n",
        "                            paused_state = value_int == 1\n",
        "                            slot_entry['interpretation'] = f\"Paused state: {'true' if paused_state else 'false'}\"\n",
        "                            slot_entry['category'] = 'control'\n",
        "\n",
        "                # Potential address\n",
        "                elif value.startswith('0x000000000000000000000000'):\n",
        "                    potential_addr = \"0x\" + value[-40:]\n",
        "                    try:\n",
        "                        checksummed_addr = Web3.to_checksum_address(potential_addr)\n",
        "                        slot_entry['decoded_value'] = checksummed_addr\n",
        "                        slot_entry['type'] = \"address\"\n",
        "\n",
        "                        # Additional context if it's a PYUSD contract\n",
        "                        if is_pyusd_contract(checksummed_addr):\n",
        "                            contract_name = get_contract_name(checksummed_addr)\n",
        "                            slot_entry['interpretation'] = f\"PYUSD Contract: {contract_name}\"\n",
        "                            slot_entry['category'] = 'pyusd_contract'\n",
        "                    except ValueError:\n",
        "                        # Not a valid address\n",
        "                        slot_entry['decoded_value'] = f\"Possible address pattern: {potential_addr}\"\n",
        "\n",
        "                # Possibly part of a string or bytes\n",
        "                else:\n",
        "                    # Try to decode as ASCII/UTF-8 if it contains printable characters\n",
        "                    bytes_value = bytes.fromhex(value[2:])\n",
        "                    if all(32 <= b <= 126 for b in bytes_value if b != 0):\n",
        "                        # Remove trailing zeros\n",
        "                        bytes_value = bytes_value.rstrip(b'\\x00')\n",
        "                        try:\n",
        "                            string_value = bytes_value.decode('utf-8')\n",
        "                            if string_value and len(string_value) > 2:  # Only if we got something meaningful\n",
        "                                slot_entry['decoded_value'] = f\"'{string_value}'\"\n",
        "                                slot_entry['type'] = \"string/bytes\"\n",
        "                                slot_entry['category'] = 'metadata'\n",
        "                        except UnicodeDecodeError:\n",
        "                            pass\n",
        "        except Exception as e:\n",
        "            # If decoding fails, just leave as is\n",
        "            pass\n",
        "\n",
        "        # If we haven't set a decoded value, use a simplified version of the raw\n",
        "        if slot_entry.get('decoded_value') is None:\n",
        "            if value.startswith('0x'):\n",
        "                slot_entry['decoded_value'] = f\"{value[:10]}...{value[-8:]}\"\n",
        "            else:\n",
        "                slot_entry['decoded_value'] = value\n",
        "\n",
        "        # If category not set, try to infer from type or interpretation\n",
        "        if slot_entry.get('category') == 'unknown':\n",
        "            if slot_entry.get('type') == 'address':\n",
        "                slot_entry['category'] = 'address'\n",
        "            elif slot_entry.get('type') == 'string/bytes':\n",
        "                slot_entry['category'] = 'metadata'\n",
        "            elif slot_entry.get('interpretation') and 'role' in slot_entry.get('interpretation').lower():\n",
        "                slot_entry['category'] = 'access_control'\n",
        "\n",
        "    # Categorize slots for better analysis\n",
        "    pyusd_categories = {\n",
        "        'supply': [],\n",
        "        'balances': [],\n",
        "        'allowances': [],\n",
        "        'access_control': [],\n",
        "        'proxy': [],\n",
        "        'metadata': [],\n",
        "        'paused': []\n",
        "    }\n",
        "\n",
        "    for slot_entry in storage_list:\n",
        "        category = slot_entry.get('category', 'unknown')\n",
        "        if category in pyusd_categories:\n",
        "            pyusd_categories[category].append(slot_entry)\n",
        "        elif category == 'control' and 'paused' in slot_entry.get('interpretation', '').lower():\n",
        "            pyusd_categories['paused'].append(slot_entry)\n",
        "\n",
        "    # Create DataFrame with better organization\n",
        "    storage_df = pd.DataFrame(storage_list)\n",
        "\n",
        "    # Add contextual summary\n",
        "    console.print(\"\\n\\n[bold cyan3]üìä PYUSD Contract Storage Analysis[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Display contract info\n",
        "    console.print(f\"\\n\\n[bold cyan3]Contract Information - {contract_address}[/bold cyan3]\")\n",
        "    contract_info = Table(title=\"\", title_style=\"bold cyan3\")\n",
        "    contract_info.add_column(\"Property\", style=\"cyan3\")\n",
        "    contract_info.add_column(\"Value\", style=\"green3\")\n",
        "\n",
        "    contract_info.add_row(\"Contract Type\", contract_type)\n",
        "    contract_info.add_row(\"Block\", shorten_address(block_hash))\n",
        "\n",
        "    if is_proxy and implementation_address:\n",
        "        contract_info.add_row(\"Implementation\", f\"{implementation_address} ({get_contract_name(implementation_address)})\")\n",
        "\n",
        "    if total_supply is not None:\n",
        "        contract_info.add_row(\"Total Supply\", format_value_pyusd(total_supply))\n",
        "\n",
        "    if paused_state is not None:\n",
        "        contract_info.add_row(\"Paused State\", str(paused_state))\n",
        "\n",
        "    if version is not None:\n",
        "        contract_info.add_row(\"PYUSD Version\", f\"v{version}\")\n",
        "\n",
        "    if roles:\n",
        "        contract_info.add_row(\"Roles Detected\", str(len(roles)))\n",
        "\n",
        "    console.print(contract_info)\n",
        "\n",
        "    # Display PYUSD proxy information if applicable\n",
        "    if is_proxy and implementation_address:\n",
        "        console.print(\"\\n[bold cyan3]üîÑ PYUSD Proxy Pattern Analysis[/bold cyan3]\")\n",
        "\n",
        "        # Enhanced proxy contract info\n",
        "        proxy_table = Table(title=\"PYUSD Proxy Implementation\", title_style=\"bold cyan\")\n",
        "        proxy_table.add_column(\"Property\", style=\"cyan\")\n",
        "        proxy_table.add_column(\"Value\", style=\"green\")\n",
        "\n",
        "        proxy_table.add_row(\"Proxy Contract\", shorten_address(contract_address))\n",
        "        proxy_table.add_row(\"Implementation\", shorten_address(implementation_address))\n",
        "        proxy_table.add_row(\"Implementation Name\", get_contract_name(implementation_address))\n",
        "\n",
        "        # Try to find admin slot\n",
        "        admin_slot = \"0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103\"\n",
        "        admin_entry = next((item for item in storage_list if item.get('slot_hex') == admin_slot), None)\n",
        "\n",
        "        if admin_entry and 'decoded_value' in admin_entry:\n",
        "            admin_address = admin_entry['decoded_value']\n",
        "            proxy_table.add_row(\"Admin Address\", shorten_address(admin_address))\n",
        "\n",
        "        console.print(proxy_table)\n",
        "\n",
        "        # Create proxy diagram\n",
        "        try:\n",
        "            proxy_graph = Digraph(comment='PYUSD Proxy Pattern')\n",
        "            proxy_graph.attr(rankdir='LR', bgcolor='transparent')\n",
        "\n",
        "            # Add nodes\n",
        "            proxy_graph.node('proxy', f'Proxy\\n{shorten_address(contract_address)}',\n",
        "                           shape='box', style='filled', fillcolor='lightblue')\n",
        "            proxy_graph.node('impl', f'Implementation\\n{shorten_address(implementation_address)}',\n",
        "                           shape='box', style='filled', fillcolor='lightgreen')\n",
        "\n",
        "            # Add edge\n",
        "            proxy_graph.edge('proxy', 'impl', label='delegates to')\n",
        "\n",
        "            # Add admin if found\n",
        "            if admin_entry and 'decoded_value' in admin_entry:\n",
        "                proxy_graph.node('admin', f'Admin\\n{shorten_address(admin_address)}',\n",
        "                               shape='box', style='filled', fillcolor='lightsalmon')\n",
        "                proxy_graph.edge('admin', 'proxy', label='controls')\n",
        "\n",
        "            display(proxy_graph)\n",
        "            console.print(\"[info]This diagram shows the PYUSD proxy pattern architecture.\", style=\"info\")\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create proxy visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Organize display of storage slots\n",
        "    if 'slot_int' in storage_df.columns and storage_df['slot_int'].notna().any():\n",
        "        # Sort by numeric slot first, then any non-numeric slots\n",
        "        numeric_slots = storage_df[storage_df['slot_int'].notna()].sort_values('slot_int')\n",
        "        non_numeric_slots = storage_df[storage_df['slot_int'].isna()].sort_values('slot_hex')\n",
        "        storage_df = pd.concat([numeric_slots, non_numeric_slots])\n",
        "    else:\n",
        "        # Fallback sort if no numeric conversion\n",
        "        storage_df = storage_df.sort_values('slot_hex')\n",
        "\n",
        "    # Select and reorder columns for display\n",
        "    display_columns = ['slot_display', 'decoded_value', 'interpretation', 'category', 'type', 'slot_hex']\n",
        "    display_df = storage_df[[col for col in display_columns if col in storage_df.columns]]\n",
        "\n",
        "    # Rename columns for better readability\n",
        "    renamed_columns = {\n",
        "        'slot_display': 'Slot',\n",
        "        'decoded_value': 'Decoded Value',\n",
        "        'interpretation': 'Interpretation',\n",
        "        'type': 'Type',\n",
        "        'slot_hex': 'Slot Hex',\n",
        "        'category': 'Category'\n",
        "    }\n",
        "    display_df = display_df.rename(columns={col: renamed_columns.get(col, col) for col in display_df.columns})\n",
        "\n",
        "    # Create filter buttons for categories\n",
        "    filter_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='All Slots',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='120px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Supply',\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='100px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Proxy',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='100px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Access Control',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Display the filter buttons\n",
        "    display(widgets.HTML(\"<h3>Filter Storage Slots:</h3>\"))\n",
        "    display(filter_buttons)\n",
        "\n",
        "    # Data table container\n",
        "    data_table_container = widgets.Output()\n",
        "    display(data_table_container)\n",
        "\n",
        "    # Filter functions\n",
        "    def show_all_slots(b):\n",
        "        with data_table_container:\n",
        "            clear_output()\n",
        "            display(display_df)\n",
        "\n",
        "    def show_supply_slots(b):\n",
        "        with data_table_container:\n",
        "            clear_output()\n",
        "            supply_df = display_df[display_df['Category'].str.lower() == 'supply'] if 'Category' in display_df.columns else pd.DataFrame()\n",
        "            if len(supply_df) > 0:\n",
        "                display(supply_df)\n",
        "            else:\n",
        "                display(widgets.HTML(\"<p>No supply-related slots found.</p>\"))\n",
        "\n",
        "    def show_proxy_slots(b):\n",
        "        with data_table_container:\n",
        "            clear_output()\n",
        "            proxy_df = display_df[display_df['Category'].str.lower() == 'proxy'] if 'Category' in display_df.columns else pd.DataFrame()\n",
        "            if len(proxy_df) > 0:\n",
        "                display(proxy_df)\n",
        "            else:\n",
        "                display(widgets.HTML(\"<p>No proxy-related slots found.</p>\"))\n",
        "\n",
        "    def show_access_control_slots(b):\n",
        "        with data_table_container:\n",
        "            clear_output()\n",
        "            access_df = display_df[display_df['Category'].str.lower() == 'access_control'] if 'Category' in display_df.columns else pd.DataFrame()\n",
        "            if len(access_df) > 0:\n",
        "                display(access_df)\n",
        "            else:\n",
        "                display(widgets.HTML(\"<p>No access control slots found.</p>\"))\n",
        "\n",
        "    # Connect filter buttons\n",
        "    filter_buttons.children[0].on_click(show_all_slots)\n",
        "    filter_buttons.children[1].on_click(show_supply_slots)\n",
        "    filter_buttons.children[2].on_click(show_proxy_slots)\n",
        "    filter_buttons.children[3].on_click(show_access_control_slots)\n",
        "\n",
        "    # Show all slots by default\n",
        "    show_all_slots(None)\n",
        "\n",
        "    # Create storage structure visualization\n",
        "    console.print(\"\\n\\n[bold cyan3]üíæ PYUSD Storage Structure Analysis[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Enhance slot categorization (keeping the same recategorize_slots function)\n",
        "    def recategorize_slots(storage_df):\n",
        "        \"\"\"Improve categorization of storage slots to reduce unknowns.\"\"\"\n",
        "        if 'category' not in storage_df.columns:\n",
        "            storage_df['category'] = 'unknown'\n",
        "\n",
        "        for i, row in storage_df.iterrows():\n",
        "            if row['category'] != 'unknown':\n",
        "                continue\n",
        "\n",
        "            slot_int = row.get('slot_int')\n",
        "            interpretation = str(row.get('interpretation', ''))\n",
        "            decoded_value = str(row.get('decoded_value', ''))\n",
        "\n",
        "            if slot_int == 0:\n",
        "                storage_df.at[i, 'category'] = 'supply'\n",
        "            elif slot_int is not None and (slot_int == 1 or slot_int == 4):\n",
        "                storage_df.at[i, 'category'] = 'balances'\n",
        "            elif slot_int is not None and (slot_int == 2 or slot_int == 5):\n",
        "                storage_df.at[i, 'category'] = 'allowances'\n",
        "            elif row.get('type') == 'string/bytes':\n",
        "                storage_df.at[i, 'category'] = 'metadata'\n",
        "            elif 'role' in interpretation.lower():\n",
        "                storage_df.at[i, 'category'] = 'access_control'\n",
        "            elif interpretation and 'paused' in interpretation.lower():\n",
        "                storage_df.at[i, 'category'] = 'control'\n",
        "            elif \"'\" in decoded_value:\n",
        "                storage_df.at[i, 'category'] = 'metadata'\n",
        "            elif row.get('type') == 'address':\n",
        "                storage_df.at[i, 'category'] = 'address'\n",
        "\n",
        "        return storage_df\n",
        "\n",
        "    # Apply enhanced categorization\n",
        "    storage_df = recategorize_slots(storage_df)\n",
        "\n",
        "    try:\n",
        "        # Create storage category distribution table\n",
        "        category_table = Table(title=\"\", title_style=\"bold cyan3\")\n",
        "        category_table.add_column(\"Category\", style=\"cyan3\")\n",
        "        category_table.add_column(\"Count\", justify=\"right\", style=\"green3\")\n",
        "        category_table.add_column(\"Description\")\n",
        "\n",
        "        category_descriptions = {\n",
        "            'supply': 'Total PYUSD supply data',\n",
        "            'balances': 'User token balance mapping',\n",
        "            'allowances': 'Token spending approvals',\n",
        "            'access_control': 'Role-based permission system',\n",
        "            'proxy': 'Upgradeable contract implementation',\n",
        "            'control': 'Contract control mechanisms like pause',\n",
        "            'metadata': 'Token metadata like name and symbol',\n",
        "            'address': 'Ethereum addresses storage',\n",
        "            'pyusd_contract': 'References to PYUSD contracts',\n",
        "            'unknown': 'Unidentified storage purpose'\n",
        "        }\n",
        "\n",
        "        category_counts = storage_df['category'].value_counts()\n",
        "        for category, count in category_counts.items():\n",
        "            category_table.add_row(\n",
        "                category,\n",
        "                str(count),\n",
        "                category_descriptions.get(category, \"\")\n",
        "            )\n",
        "\n",
        "        console.print(category_table)\n",
        "\n",
        "        # Function to format slot numbers\n",
        "        def format_slot(slot):\n",
        "            \"\"\"Format slot numbers to be more compact\"\"\"\n",
        "            if isinstance(slot, int):\n",
        "                if slot < 20:  # Small numbers kept as is\n",
        "                    return str(slot)\n",
        "                else:  # Large numbers shown in hex\n",
        "                    return f\"0x{slot:x}\"[:6] + \"...\"\n",
        "            return str(slot)\n",
        "\n",
        "        # 1. Pie chart of storage categories\n",
        "        if not category_counts.empty:\n",
        "            console.print(\"\\n\\n[bold magenta3]üìä Storage Category Distribution Chart:[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            wedges, texts, autotexts = plt.pie(\n",
        "                category_counts.values,\n",
        "                labels=category_counts.index,\n",
        "                autopct='%1.1f%%',\n",
        "                startangle=90,\n",
        "                shadow=False\n",
        "            )\n",
        "\n",
        "            # Make percentage text bold\n",
        "            for autotext in autotexts:\n",
        "                autotext.set_weight('bold')\n",
        "\n",
        "            plt.axis('equal')  # Equal aspect ratio ensures pie is drawn as a circle\n",
        "            plt.title('PYUSD Storage Categories', fontweight='bold', fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            plt.close()  # Close the figure to ensure separation\n",
        "\n",
        "        # 2. Bar chart of first 15 numeric slots (reduced from 20 for cleaner display)\n",
        "        numeric_slots = storage_df[storage_df['slot_int'].notna()].sort_values('slot_int').head(15)\n",
        "\n",
        "        if not numeric_slots.empty:\n",
        "            console.print(\"\\n\\n[bold magenta3]üìä Storage Slot Layout Chart:[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            plt.figure(figsize=(12, 5))\n",
        "\n",
        "            # Create colors dictionary for categories\n",
        "            unique_categories = numeric_slots['category'].unique()\n",
        "            colors = plt.cm.tab10(np.linspace(0, 1, len(unique_categories)))\n",
        "            category_colors = dict(zip(unique_categories, colors))\n",
        "\n",
        "            # Create bar colors based on category\n",
        "            bar_colors = [category_colors[cat] for cat in numeric_slots['category']]\n",
        "\n",
        "            # Format slot numbers for display\n",
        "            slot_labels = [format_slot(slot) for slot in numeric_slots['slot_int']]\n",
        "\n",
        "            # Create the bar chart\n",
        "            bars = plt.bar(\n",
        "                slot_labels,\n",
        "                [1] * len(numeric_slots),  # All bars same height\n",
        "                color=bar_colors\n",
        "            )\n",
        "\n",
        "            # Add annotations for important slots - only for slots with interpretations\n",
        "            for i, (idx, row) in enumerate(numeric_slots.iterrows()):\n",
        "                if row.get('interpretation'):\n",
        "                    # Get first word only, truncate if too long\n",
        "                    interp = row['interpretation'].split(' ')[0]\n",
        "                    if len(interp) > 10:\n",
        "                        interp = interp[:8] + '..'\n",
        "\n",
        "                    plt.annotate(\n",
        "                        interp,\n",
        "                        xy=(i, 0.5),  # Use index instead of slot value\n",
        "                        rotation=90,\n",
        "                        fontsize=9,\n",
        "                        fontweight='bold',\n",
        "                        ha='center'\n",
        "                    )\n",
        "\n",
        "            # Add legend\n",
        "            from matplotlib.patches import Patch\n",
        "            legend_elements = [\n",
        "                Patch(facecolor=category_colors[cat], label=cat)\n",
        "                for cat in unique_categories\n",
        "            ]\n",
        "            plt.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=4)\n",
        "\n",
        "            plt.title('PYUSD Storage Slot Layout', fontweight='bold', fontsize=14)\n",
        "            plt.xlabel('Storage Slot', fontweight='bold')\n",
        "            plt.ylabel('')\n",
        "            plt.yticks([])  # Hide y-axis ticks\n",
        "            plt.xticks(rotation=45)  # Rotate x-axis labels\n",
        "            plt.tight_layout(pad=2.0)  # Add padding\n",
        "            plt.show()\n",
        "            plt.close()  # Close the figure to ensure separation\n",
        "\n",
        "        # 3. Category distribution bar chart\n",
        "        if not category_counts.empty:\n",
        "            console.print(\"\\n\\n[bold magenta3]üìä Storage Composition Chart:[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            plt.figure(figsize=(10, 4))\n",
        "\n",
        "            # Sort categories by count for better visualization\n",
        "            sorted_categories = category_counts.sort_values(ascending=False)\n",
        "\n",
        "            # Create horizontal bar chart\n",
        "            bars = plt.barh(\n",
        "                sorted_categories.index,\n",
        "                sorted_categories.values,\n",
        "                color=plt.cm.tab10(np.linspace(0, 1, len(sorted_categories)))\n",
        "            )\n",
        "\n",
        "            # Add count labels to the bars\n",
        "            for bar in bars:\n",
        "                width = bar.get_width()\n",
        "                plt.text(\n",
        "                    width + 0.3,\n",
        "                    bar.get_y() + bar.get_height()/2,\n",
        "                    f\"{width}\",\n",
        "                    ha='left',\n",
        "                    va='center',\n",
        "                    fontweight='bold'\n",
        "                )\n",
        "\n",
        "            plt.xlabel('Number of Storage Slots', fontweight='bold')\n",
        "            plt.title('PYUSD Storage Composition', fontweight='bold', fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            plt.close()  # Close the figure to ensure separation\n",
        "\n",
        "        console.print(\"\\n\\n[info]Storage analysis visualization complete.\", style=\"info\")\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create matplotlib visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "        # Always show text summary as backup\n",
        "        console.print(\"\\n\\n[bold cyan3]PYUSD Storage Categories:[/bold cyan3]\")\n",
        "        for category, count in storage_df['category'].value_counts().items():\n",
        "            console.print(f\"  ‚Ä¢ {category}: {count} slots\")\n",
        "\n",
        "    # Check for security-relevant patterns\n",
        "    console.print(\"\\n\\n[bold cyan3]üîí PYUSD Security Analysis[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    security_flags = []\n",
        "\n",
        "    # Check for proxy implementation\n",
        "    implementation_slot = \"0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc\"\n",
        "    impl_entry = next((item for item in storage_list if item.get('slot_hex') == implementation_slot), None)\n",
        "    if impl_entry and impl_entry.get('decoded_value'):\n",
        "        security_flags.append({\n",
        "            'level': 'info',\n",
        "            'type': 'proxy_implementation',\n",
        "            'description': f\"PYUSD implementation: {impl_entry.get('decoded_value')}\",\n",
        "            'details': {'address': impl_entry.get('decoded_value')}\n",
        "        })\n",
        "\n",
        "    # Check for proxy admin\n",
        "    admin_slot = \"0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103\"\n",
        "    admin_entry = next((item for item in storage_list if item.get('slot_hex') == admin_slot), None)\n",
        "    if admin_entry and admin_entry.get('decoded_value'):\n",
        "        security_flags.append({\n",
        "            'level': 'info',\n",
        "            'type': 'proxy_admin',\n",
        "            'description': f\"PYUSD proxy admin: {admin_entry.get('decoded_value')}\",\n",
        "            'details': {'address': admin_entry.get('decoded_value')}\n",
        "        })\n",
        "\n",
        "    # Check for paused state\n",
        "    paused_slot = \"0x5ac1dce9f7971a63e05025b10b44b6f3c868ae576a5e4a815201051d3eae29cb\"\n",
        "    paused_entry = next((item for item in storage_list if item.get('slot_hex') == paused_slot), None)\n",
        "    if paused_entry and paused_entry.get('raw_value'):\n",
        "        paused_value = int(paused_entry.get('raw_value'), 16) if paused_entry.get('raw_value').startswith('0x') else 0\n",
        "        if paused_value == 1:\n",
        "            security_flags.append({\n",
        "                'level': 'warning',\n",
        "                'type': 'contract_paused',\n",
        "                'description': \"PYUSD contract is currently paused\",\n",
        "                'details': {'paused': True}\n",
        "            })\n",
        "\n",
        "    # Display security insights if any\n",
        "    if security_flags:\n",
        "        security_table = Table(show_header=True, header_style=f\"bold {SECURITY_COLORS['high']}\")\n",
        "        security_table.add_column(\"Level\", style=\"dim\", justify=\"center\")\n",
        "        security_table.add_column(\"Type\", style=\"dim\")\n",
        "        security_table.add_column(\"Description\")\n",
        "\n",
        "        for flag in security_flags:\n",
        "            level = flag['level']\n",
        "            level_color = SECURITY_COLORS[\"critical\"] if level == \"critical\" else SECURITY_COLORS[\"high\"] if level == \"high\" else SECURITY_COLORS[\"warning\"] if level == \"warning\" else SECURITY_COLORS[\"info\"]\n",
        "\n",
        "            security_table.add_row(\n",
        "                f\"[{level_color}]{level.upper()}[/{level_color}]\",\n",
        "                flag['type'].replace('_', ' ').title(),\n",
        "                flag['description']\n",
        "            )\n",
        "\n",
        "        console.print(security_table)\n",
        "    else:\n",
        "        console.print(\"[info]No security-relevant findings in storage analysis.\", style=\"info\")\n",
        "\n",
        "    # Add export options\n",
        "    console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create export buttons\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Add dropdown for export content selection\n",
        "    export_content = widgets.Dropdown(\n",
        "        options=['All Storage', 'PYUSD Contract Info', 'Proxy Configuration', 'Critical Slots'],\n",
        "        value='All Storage',\n",
        "        description='Export:',\n",
        "        layout=widgets.Layout(width='250px')\n",
        "    )\n",
        "\n",
        "    # Display selection control\n",
        "    display(export_content)\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    # Export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "            # Select appropriate data based on user choice\n",
        "            selected_content = export_content.value\n",
        "            if selected_content == 'PYUSD Contract Info':\n",
        "                # Create contract info summary\n",
        "                info_data = []\n",
        "                for key, value in {\n",
        "                    'address': contract_address,\n",
        "                    'type': contract_type,\n",
        "                    'block_hash': block_hash,\n",
        "                    'implementation': implementation_address,\n",
        "                    'total_supply': total_supply,\n",
        "                    'paused_state': paused_state,\n",
        "                    'version': version\n",
        "                }.items():\n",
        "                    if value is not None:\n",
        "                        info_data.append({\n",
        "                            'property': key,\n",
        "                            'value': str(value)\n",
        "                        })\n",
        "                # Add categories summary\n",
        "                for category, slots in pyusd_categories.items():\n",
        "                    if slots:\n",
        "                        info_data.append({\n",
        "                            'property': f\"{category} slots\",\n",
        "                            'value': str(len(slots))\n",
        "                        })\n",
        "\n",
        "                df_to_export = pd.DataFrame(info_data)\n",
        "                filename = f\"pyusd_contract_{shorten_address(contract_address)}_{timestamp}.csv\"\n",
        "            elif selected_content == 'Proxy Configuration' and contract_type == 'Proxy':\n",
        "                # Filter to proxy-related data\n",
        "                proxy_data = storage_df[storage_df['slot_hex'].isin([\n",
        "                    \"0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc\",  # implementation\n",
        "                    \"0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103\"   # admin\n",
        "                ])]\n",
        "                df_to_export = proxy_data\n",
        "                filename = f\"pyusd_proxy_{shorten_address(contract_address)}_{timestamp}.csv\"\n",
        "            elif selected_content == 'Critical Slots':\n",
        "                # Filter to slots with interpretations\n",
        "                critical_data = storage_df[storage_df['interpretation'].notna()]\n",
        "                df_to_export = critical_data\n",
        "                filename = f\"pyusd_critical_{shorten_address(contract_address)}_{timestamp}.csv\"\n",
        "            else:\n",
        "                # All storage\n",
        "                df_to_export = storage_df\n",
        "                filename = f\"pyusd_storage_{shorten_address(contract_address)}_{timestamp}.csv\"\n",
        "\n",
        "            display(download_csv_direct(df_to_export, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_storage_{shorten_address(contract_address)}_{timestamp}.json\"\n",
        "\n",
        "            # Create comprehensive export with metadata\n",
        "            export_data = {\n",
        "                \"metadata\": {\n",
        "                    \"contract_address\": contract_address,\n",
        "                    \"contract_type\": contract_type,\n",
        "                    \"block_hash\": block_hash,\n",
        "                    \"analysis_timestamp\": datetime.now().isoformat(),\n",
        "                    \"slots_analyzed\": len(storage_df)\n",
        "                },\n",
        "                \"contract_info\": {\n",
        "                    \"implementation\": implementation_address,\n",
        "                    \"total_supply\": total_supply,\n",
        "                    \"paused_state\": paused_state,\n",
        "                    \"version\": version,\n",
        "                    \"roles\": roles\n",
        "                },\n",
        "                \"storage_data\": storage_df.to_dict('records'),\n",
        "                \"pyusd_categories\": {k: [s['slot_hex'] for s in v] for k, v in pyusd_categories.items() if v},\n",
        "                \"security_flags\": security_flags\n",
        "            }\n",
        "\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "            # Select appropriate data based on user choice\n",
        "            selected_content = export_content.value\n",
        "            if selected_content == 'PYUSD Contract Info':\n",
        "                # Create contract info summary\n",
        "                info_data = []\n",
        "                for key, value in {\n",
        "                    'address': contract_address,\n",
        "                    'type': contract_type,\n",
        "                    'block_hash': block_hash,\n",
        "                    'implementation': implementation_address,\n",
        "                    'total_supply': total_supply,\n",
        "                    'paused_state': paused_state,\n",
        "                    'version': version\n",
        "                }.items():\n",
        "                    if value is not None:\n",
        "                        info_data.append({\n",
        "                            'property': key,\n",
        "                            'value': str(value)\n",
        "                        })\n",
        "                # Add categories summary\n",
        "                for category, slots in pyusd_categories.items():\n",
        "                    if slots:\n",
        "                        info_data.append({\n",
        "                            'property': f\"{category} slots\",\n",
        "                            'value': str(len(slots))\n",
        "                        })\n",
        "\n",
        "                df_to_export = pd.DataFrame(info_data)\n",
        "                sheet_name = f\"PYUSD Info - {shorten_address(contract_address)}\"\n",
        "            elif selected_content == 'Proxy Configuration' and contract_type == 'Proxy':\n",
        "                proxy_data = storage_df[storage_df['slot_hex'].isin([\n",
        "                    \"0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc\",\n",
        "                    \"0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103\"\n",
        "                ])]\n",
        "                df_to_export = proxy_data\n",
        "                sheet_name = f\"PYUSD Proxy - {shorten_address(contract_address)}\"\n",
        "            elif selected_content == 'Critical Slots':\n",
        "                critical_data = storage_df[storage_df['interpretation'].notna()]\n",
        "                df_to_export = critical_data\n",
        "                sheet_name = f\"PYUSD Critical - {shorten_address(contract_address)}\"\n",
        "            else:\n",
        "                df_to_export = storage_df\n",
        "                sheet_name = f\"PYUSD Storage - {shorten_address(contract_address)}\"\n",
        "\n",
        "            display(export_to_google_sheets_direct(df_to_export, sheet_name))\n",
        "\n",
        "    # Connect callbacks\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    # Return the organized data for further analysis\n",
        "    return {\n",
        "        'storage_df': storage_df,\n",
        "        'contract_info': {\n",
        "            'address': contract_address,\n",
        "            'type': contract_type,\n",
        "            'block_hash': block_hash,\n",
        "            'implementation': implementation_address,\n",
        "            'total_supply': total_supply,\n",
        "            'paused_state': paused_state,\n",
        "            'version': version,\n",
        "            'roles': roles,\n",
        "            'pyusd_categories': {k: len(v) for k, v in pyusd_categories.items() if v}\n",
        "        },\n",
        "        'security_flags': security_flags\n",
        "    }\n",
        "\n",
        "\n",
        "def compare_storage(address, block_hash1, block_hash2, tx_index1=0, tx_index2=0, slot_count=20, start_slot=\"0x0\"):\n",
        "    \"\"\"Compare contract storage between two blocks to identify changes.\"\"\"\n",
        "    console.print(f\"[info]Comparing storage for {shorten_address(address)} between two blocks...\", style=\"info\")\n",
        "\n",
        "    # Get storage for first block\n",
        "    params1 = [block_hash1, tx_index1, address, start_slot, slot_count]\n",
        "    storage_dump1 = make_rpc_request(\"debug_storageRangeAt\", params1, network='mainnet')\n",
        "\n",
        "    # Get storage for second block\n",
        "    params2 = [block_hash2, tx_index2, address, start_slot, slot_count]\n",
        "    storage_dump2 = make_rpc_request(\"debug_storageRangeAt\", params2, network='mainnet')\n",
        "\n",
        "    if not storage_dump1 or not storage_dump2:\n",
        "        console.print(\"[error]Failed to retrieve storage for comparison.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    # Transform storage data for easier comparison\n",
        "    def transform_storage(storage_dump):\n",
        "        result = {}\n",
        "        for slot, data in storage_dump.get('storage', {}).items():\n",
        "            result[slot] = data.get('value')\n",
        "        return result\n",
        "\n",
        "    storage1 = transform_storage(storage_dump1)\n",
        "    storage2 = transform_storage(storage_dump2)\n",
        "\n",
        "    # Find all unique slots\n",
        "    all_slots = set(list(storage1.keys()) + list(storage2.keys()))\n",
        "\n",
        "    # Build comparison data\n",
        "    comparison = []\n",
        "    for slot in all_slots:\n",
        "        value1 = storage1.get(slot, 'N/A')\n",
        "        value2 = storage2.get(slot, 'N/A')\n",
        "        changed = value1 != value2\n",
        "\n",
        "        # Try to decode the values\n",
        "        try:\n",
        "            if value1 != 'N/A' and value2 != 'N/A':\n",
        "                value1_int = int(value1, 16)\n",
        "                value2_int = int(value2, 16)\n",
        "\n",
        "                if abs(value1_int) < 1e12 and abs(value2_int) < 1e12:\n",
        "                    # If small numbers, show the difference\n",
        "                    diff = value2_int - value1_int\n",
        "                    diff_str = f\"{diff:+}\" if changed else \"No change\"\n",
        "\n",
        "                    # For PYUSD values, add formatted difference\n",
        "                    if diff != 0 and abs(diff) < 1e9:  # Reasonable token amount\n",
        "                        formatted_diff = format_value_pyusd(abs(diff))\n",
        "                        diff_str += f\" ({formatted_diff} {'decrease' if diff < 0 else 'increase'})\"\n",
        "                else:\n",
        "                    diff_str = \"Changed\" if changed else \"No change\"\n",
        "                    diff = None\n",
        "            else:\n",
        "                diff_str = \"Added/Removed\" if changed else \"No change\"\n",
        "                diff = None\n",
        "        except:\n",
        "            diff_str = \"Changed\" if changed else \"No change\"\n",
        "            diff = None\n",
        "\n",
        "        # Check if this might be a balance/supply change\n",
        "        is_balance_change = False\n",
        "        is_supply_change = False\n",
        "\n",
        "        # Look for potential balance slot (typically derived from keccak256(address + mapping_slot))\n",
        "        if slot.startswith('0x') and len(slot) == 66 and changed and diff is not None:\n",
        "            if abs(diff) < 1e12:  # Reasonable token amount\n",
        "                is_balance_change = True\n",
        "\n",
        "        # Check if this might be total supply slot\n",
        "        if (slot == '0x0' or int(slot, 16) == 0 if slot.startswith('0x') else False) and changed and diff is not None:\n",
        "            is_supply_change = True\n",
        "\n",
        "        comparison.append({\n",
        "            'slot': slot,\n",
        "            'value_block1': value1,\n",
        "            'value_block2': value2,\n",
        "            'changed': changed,\n",
        "            'diff': diff_str,\n",
        "            'numeric_diff': diff,\n",
        "            'is_balance_change': is_balance_change,\n",
        "            'is_supply_change': is_supply_change\n",
        "        })\n",
        "\n",
        "    # Create DataFrame for display\n",
        "    comparison_df = pd.DataFrame(comparison)\n",
        "    comparison_df = comparison_df.sort_values(['changed', 'is_supply_change', 'is_balance_change'],\n",
        "                                             ascending=[False, False, False])\n",
        "\n",
        "    # Display results\n",
        "    console.print(f\"\\n[bold cyan3]üìä Storage Comparison Results[/bold cyan3]\")\n",
        "    console.print(f\"Block 1: {shorten_address(block_hash1)}\")\n",
        "    console.print(f\"Block 2: {shorten_address(block_hash2)}\")\n",
        "    console.print(f\"Changes detected: {comparison_df['changed'].sum()} of {len(comparison_df)} slots\\n\")\n",
        "\n",
        "    # Highlight changes in display\n",
        "    def highlight_changes(row):\n",
        "        if row['changed']:\n",
        "            # Different highlighting based on type of change\n",
        "            if row.get('is_supply_change', False):\n",
        "                return ['background-color: #ffcc99'] * len(row)  # Orange for supply\n",
        "            elif row.get('is_balance_change', False):\n",
        "                return ['background-color: #ccffcc'] * len(row)  # Green for balances\n",
        "            else:\n",
        "                return ['background-color: #ffcccc'] * len(row)  # Red for other changes\n",
        "        return [''] * len(row)\n",
        "\n",
        "    # Apply styling and display\n",
        "    styled_df = comparison_df.style.apply(highlight_changes, axis=1)\n",
        "    display(styled_df)\n",
        "\n",
        "    # Create change visualization if changes detected\n",
        "    if comparison_df['changed'].sum() > 0:\n",
        "        console.print(\"\\n[bold cyan3]üìä Storage Change Visualization[/bold cyan3]\")\n",
        "\n",
        "        try:\n",
        "            # Filter to changed values\n",
        "            changes = comparison_df[comparison_df['changed']].copy()\n",
        "\n",
        "            # Add change category\n",
        "            def categorize_change(row):\n",
        "                if row.get('is_supply_change', False):\n",
        "                    return 'Supply'\n",
        "                elif row.get('is_balance_change', False):\n",
        "                    return 'Balance'\n",
        "                elif 'slot' in row and row['slot'] == \"0x5ac1dce9f7971a63e05025b10b44b6f3c868ae576a5e4a815201051d3eae29cb\":\n",
        "                    return 'Pause State'\n",
        "                elif 'slot' in row and row['slot'] == \"0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc\":\n",
        "                    return 'Implementation'\n",
        "                else:\n",
        "                    return 'Other'\n",
        "\n",
        "            changes['category'] = changes.apply(categorize_change, axis=1)\n",
        "\n",
        "            # Create bar chart of changes by category\n",
        "            category_counts = changes['category'].value_counts().reset_index()\n",
        "            category_counts.columns = ['Category', 'Count']\n",
        "\n",
        "            fig = px.bar(\n",
        "                category_counts,\n",
        "                x='Category',\n",
        "                y='Count',\n",
        "                color='Category',\n",
        "                title=f'PYUSD Storage Changes by Type - {shorten_address(address)}',\n",
        "                labels={'Count': 'Number of Changes'}\n",
        "            )\n",
        "\n",
        "            fig.update_layout(template=\"plotly_white\")\n",
        "            fig.show()\n",
        "\n",
        "            # If we have supply changes, create a specialized visualization\n",
        "            supply_changes = changes[changes['category'] == 'Supply']\n",
        "            if not supply_changes.empty:\n",
        "                try:\n",
        "                    # Get supply values\n",
        "                    from_value = int(supply_changes.iloc[0]['value_block1'], 16) / 1e6  # PYUSD has 6 decimals\n",
        "                    to_value = int(supply_changes.iloc[0]['value_block2'], 16) / 1e6\n",
        "                    diff = to_value - from_value\n",
        "\n",
        "                    # Create gauge chart\n",
        "                    fig = go.Figure(go.Indicator(\n",
        "                        mode = \"gauge+number+delta\",\n",
        "                        value = to_value,\n",
        "                        title = {'text': \"PYUSD Supply\"},\n",
        "                        delta = {'reference': from_value, 'relative': False},\n",
        "                        gauge = {\n",
        "                            'axis': {'range': [None, max(from_value, to_value) * 1.1]},\n",
        "                            'bar': {'color': \"green\" if diff >= 0 else \"red\"},\n",
        "                            'steps': [\n",
        "                                {'range': [0, from_value], 'color': \"lightgray\"}\n",
        "                            ]\n",
        "                        }\n",
        "                    ))\n",
        "\n",
        "                    fig.update_layout(\n",
        "                        title=f\"PYUSD Supply Change: {diff:+,.2f} ({diff/from_value*100:+.2f}%)\",\n",
        "                        template=\"plotly_white\"\n",
        "                    )\n",
        "\n",
        "                    fig.show()\n",
        "                except Exception as e:\n",
        "                    console.print(f\"[warning]Could not create supply change gauge: {e}\", style=\"warning\")\n",
        "\n",
        "            console.print(\"[info]These visualizations highlight key changes in PYUSD storage between blocks.\", style=\"info\")\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create change visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Add export options\n",
        "    console.print(\"\\n[bold cyan3]üì§ Export Options[/bold cyan3]\")\n",
        "\n",
        "    # Create export buttons\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Display export controls\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    # Export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_storage_comparison_{shorten_address(address)}_{timestamp}.csv\"\n",
        "            display(download_csv_direct(comparison_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "\n",
        "            # Enhanced JSON with metadata\n",
        "            export_data = {\n",
        "                \"metadata\": {\n",
        "                    \"contract_address\": address,\n",
        "                    \"block_hash1\": block_hash1,\n",
        "                    \"block_hash2\": block_hash2,\n",
        "                    \"analysis_time\": datetime.now().isoformat(),\n",
        "                    \"changes_detected\": int(comparison_df['changed'].sum()),\n",
        "                    \"slots_analyzed\": len(comparison_df)\n",
        "                },\n",
        "                \"comparison_data\": comparison_df.to_dict('records')\n",
        "            }\n",
        "\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_storage_comparison_{shorten_address(address)}_{timestamp}.json\"\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            sheet_name = f\"PYUSD Storage Comparison - {shorten_address(address)}\"\n",
        "            display(export_to_google_sheets_direct(comparison_df, sheet_name))\n",
        "\n",
        "    # Connect callbacks\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "\n",
        "def analyze_mapping_storage(contract_address, mapping_slot, keys, block_hash, tx_index=0):\n",
        "    \"\"\"Analyze a specific mapping in contract storage by calculating keccak hash of key+slot.\"\"\"\n",
        "    console.print(f\"[info]Analyzing mapping at slot {mapping_slot} for {shorten_address(contract_address)}...\", style=\"info\")\n",
        "\n",
        "    # Ensure mapping slot is in correct format\n",
        "    if isinstance(mapping_slot, int):\n",
        "        mapping_slot_hex = f\"0x{mapping_slot:064x}\"\n",
        "    elif isinstance(mapping_slot, str) and mapping_slot.startswith('0x'):\n",
        "        mapping_slot_hex = mapping_slot\n",
        "    else:\n",
        "        console.print(\"[error]Invalid mapping slot format.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    results = []\n",
        "    for key in keys:\n",
        "        # Ensure key is in correct format (32 bytes padded address for typical ERC20 mapping)\n",
        "        if isinstance(key, str) and key.startswith('0x') and len(key) == 42:\n",
        "            # Convert address to padded 32-byte value\n",
        "            padded_key = f\"0x{key[2:].lower().zfill(64)}\"\n",
        "        elif isinstance(key, int):\n",
        "            padded_key = f\"0x{key:064x}\"\n",
        "        else:\n",
        "            padded_key = key\n",
        "\n",
        "        # Calculate storage slot for this mapping key\n",
        "        # For typical mappings: keccak256(key + slot)\n",
        "        concat_hex = padded_key[2:] + mapping_slot_hex[2:]  # Remove '0x' prefix before concatenating\n",
        "        slot_to_read = Web3.keccak(hexstr=concat_hex).hex()\n",
        "\n",
        "        # Read the storage at this calculated slot\n",
        "        params = [block_hash, tx_index, contract_address, slot_to_read, 1]\n",
        "        storage_result = make_rpc_request(\"debug_storageRangeAt\", params, network='mainnet')\n",
        "\n",
        "        if not storage_result or 'storage' not in storage_result:\n",
        "            value = \"Error reading slot\"\n",
        "            raw_value = None\n",
        "        else:\n",
        "            value = storage_result['storage'].get(slot_to_read, {}).get('value', 'N/A')\n",
        "            raw_value = value\n",
        "\n",
        "            # Try to decode the value\n",
        "            try:\n",
        "                if value != 'N/A':\n",
        "                    value_int = int(value, 16)\n",
        "                    if value_int < 1e12:  # Small number - probably amount\n",
        "                        if mapping_slot == 0 or mapping_slot == 4:  # Common slots for ERC20 balances\n",
        "                            decoded = format_value_pyusd(value_int)\n",
        "                        else:\n",
        "                            decoded = f\"{value_int}\"\n",
        "                    else:\n",
        "                        decoded = value\n",
        "                else:\n",
        "                    decoded = \"0\"\n",
        "                    value_int = 0\n",
        "            except:\n",
        "                decoded = value\n",
        "                value_int = None\n",
        "\n",
        "        # Key formatting for display\n",
        "        if isinstance(key, str) and key.startswith('0x') and len(key) == 42:\n",
        "            # It's an address - add context\n",
        "            key_display = shorten_address(key)\n",
        "            key_type = \"address\"\n",
        "\n",
        "            # Check if it's a known PYUSD contract\n",
        "            if is_pyusd_contract(key):\n",
        "                key_context = f\"PYUSD: {get_contract_name(key)}\"\n",
        "            else:\n",
        "                # Try to add extra context like \"token holder\"\n",
        "                if mapping_slot == 0 or mapping_slot == 4:  # Balances mapping\n",
        "                    key_context = \"Token Holder\"\n",
        "                elif mapping_slot == 1 or mapping_slot == 5:  # Allowances mapping (first key is owner)\n",
        "                    key_context = \"Token Owner\"\n",
        "                else:\n",
        "                    key_context = \"Account\"\n",
        "        elif isinstance(key, int) or (isinstance(key, str) and key.isdigit()):\n",
        "            # It's a number\n",
        "            key_display = str(key)\n",
        "            key_type = \"uint256\"\n",
        "            key_context = \"Index\"\n",
        "        else:\n",
        "            # Other format\n",
        "            key_display = str(key)\n",
        "            key_type = \"unknown\"\n",
        "            key_context = \"\"\n",
        "\n",
        "        # Record the result\n",
        "        results.append({\n",
        "            'key': key,\n",
        "            'key_display': key_display,\n",
        "            'key_type': key_type,\n",
        "            'key_context': key_context,\n",
        "            'calculated_slot': slot_to_read,\n",
        "            'raw_value': raw_value,\n",
        "            'value': value,\n",
        "            'decoded_value': decoded,\n",
        "            'value_int': value_int if 'value_int' in locals() else None\n",
        "        })\n",
        "\n",
        "    # Create DataFrame\n",
        "    mapping_df = pd.DataFrame(results)\n",
        "\n",
        "    # Sort by value if numeric\n",
        "    if 'value_int' in mapping_df.columns and mapping_df['value_int'].notna().any():\n",
        "        mapping_df = mapping_df.sort_values('value_int', ascending=False)\n",
        "\n",
        "    # Select columns for display\n",
        "    display_cols = ['key_display', 'key_context', 'decoded_value', 'calculated_slot']\n",
        "    display_df = mapping_df[display_cols]\n",
        "\n",
        "    # Rename columns for display\n",
        "    renamed_columns = {\n",
        "        'key_display': 'Key',\n",
        "        'key_context': 'Context',\n",
        "        'decoded_value': 'Value',\n",
        "        'calculated_slot': 'Storage Slot'\n",
        "    }\n",
        "    display_df = display_df.rename(columns=renamed_columns)\n",
        "\n",
        "    console.print(f\"\\n[bold cyan3]üìä Mapping Analysis Results for Slot {mapping_slot}[/bold cyan3]\")\n",
        "    display(display_df)\n",
        "\n",
        "    # Create balance visualization if appropriate\n",
        "    if mapping_slot == 0 or mapping_slot == 4:  # ERC20 balances mapping\n",
        "        console.print(\"\\n[bold cyan3]üìä PYUSD Balance Distribution[/bold cyan3]\")\n",
        "        try:\n",
        "            # Filter non-zero balances\n",
        "            non_zero_balances = mapping_df[mapping_df['value_int'] > 0].copy()\n",
        "\n",
        "            if not non_zero_balances.empty:\n",
        "                # For better visualization, normalize values\n",
        "                non_zero_balances['formatted_value'] = non_zero_balances['value_int'].apply(\n",
        "                    lambda x: float(x) / 1e6 if x else 0  # Convert to PYUSD units\n",
        "                )\n",
        "\n",
        "                # Create balance distribution chart\n",
        "                fig = px.pie(\n",
        "                    non_zero_balances,\n",
        "                    values='formatted_value',\n",
        "                    names='key_display',\n",
        "                    title=f'PYUSD Balance Distribution - {len(non_zero_balances)} addresses',\n",
        "                    hover_data=['key_context', 'decoded_value']\n",
        "                )\n",
        "\n",
        "                fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "                fig.update_layout(template=\"plotly_white\")\n",
        "\n",
        "                fig.show()\n",
        "\n",
        "                # Create bar chart of top holders\n",
        "                if len(non_zero_balances) > 1:\n",
        "                    # Take top 10 for bar chart\n",
        "                    top_holders = non_zero_balances.nlargest(10, 'formatted_value')\n",
        "\n",
        "                    fig = px.bar(\n",
        "                        top_holders,\n",
        "                        y='key_display',\n",
        "                        x='formatted_value',\n",
        "                        color='key_context',\n",
        "                        title=f'Top PYUSD Holders - Slot {mapping_slot}',\n",
        "                        labels={\n",
        "                            'formatted_value': 'Balance (PYUSD)',\n",
        "                            'key_display': 'Address',\n",
        "                            'key_context': 'Type'\n",
        "                        },\n",
        "                        orientation='h'  # Horizontal bars\n",
        "                    )\n",
        "\n",
        "                    fig.update_layout(template=\"plotly_white\")\n",
        "                    fig.show()\n",
        "            else:\n",
        "                console.print(\"[info]No non-zero balances found to visualize.\", style=\"info\")\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create balance visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Add export options\n",
        "    console.print(\"\\n[bold cyan3]üì§ Export Options[/bold cyan3]\")\n",
        "\n",
        "    # Create export buttons\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Display export controls\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    # Export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_mapping_slot{mapping_slot}_{shorten_address(contract_address)}_{timestamp}.csv\"\n",
        "            display(download_csv_direct(mapping_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "\n",
        "            # Create structured JSON with metadata\n",
        "            export_data = {\n",
        "                \"metadata\": {\n",
        "                    \"contract_address\": contract_address,\n",
        "                    \"mapping_slot\": mapping_slot,\n",
        "                    \"block_hash\": block_hash,\n",
        "                    \"analysis_time\": datetime.now().isoformat(),\n",
        "                    \"keys_analyzed\": len(mapping_df)\n",
        "                },\n",
        "                \"mapping_type\": \"balances\" if mapping_slot == 0 or mapping_slot == 4 else\n",
        "                              \"allowances\" if mapping_slot == 1 or mapping_slot == 5 else\n",
        "                              \"unknown\",\n",
        "                \"mapping_data\": mapping_df.to_dict('records')\n",
        "            }\n",
        "\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_mapping_slot{mapping_slot}_{shorten_address(contract_address)}_{timestamp}.json\"\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            sheet_name = f\"PYUSD Mapping Slot {mapping_slot} - {shorten_address(contract_address)}\"\n",
        "            display(export_to_google_sheets_direct(mapping_df, sheet_name))\n",
        "\n",
        "    # Connect callbacks\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    return mapping_df\n",
        "\n",
        "\n",
        "def analyze_pyusd_balances(contract_address, block_hash, key_addresses, tx_index=0):\n",
        "    \"\"\"Deep analysis of PYUSD balances mapping with visual distribution.\"\"\"\n",
        "    console.print(f\"[info]Analyzing PYUSD balance mapping for {len(key_addresses)} addresses...\", style=\"info\")\n",
        "\n",
        "    # PYUSD balances are typically at slot 4 (OpenZeppelin implementation)\n",
        "    balances_slot = 4\n",
        "    mapping_results = []\n",
        "\n",
        "    for address in key_addresses:\n",
        "        # Calculate storage slot for this address's balance\n",
        "        padded_address = f\"0x{address[2:].lower().zfill(64)}\"\n",
        "        concat_hex = padded_address[2:] + f\"{balances_slot:064x}\"\n",
        "        slot_to_read = Web3.keccak(hexstr=concat_hex).hex()\n",
        "\n",
        "        # Read the storage\n",
        "        params = [block_hash, tx_index, contract_address, slot_to_read, 1]\n",
        "        storage_result = make_rpc_request(\"debug_storageRangeAt\", params, network='mainnet')\n",
        "\n",
        "        if storage_result and 'storage' in storage_result:\n",
        "            value_hex = storage_result['storage'].get(slot_to_read, {}).get('value', '0x0')\n",
        "            value_int = int(value_hex, 16)\n",
        "            balance_pyusd = value_int / 10**6  # PYUSD uses 6 decimals\n",
        "\n",
        "            # Check if address is a contract\n",
        "            is_contract = False\n",
        "            contract_name = None\n",
        "            try:\n",
        "                if w3_mainnet:\n",
        "                    code = w3_mainnet.eth.get_code(address)\n",
        "                    is_contract = len(code) > 2  # '0x' for non-contracts\n",
        "\n",
        "                # Check if it's a known PYUSD-related contract\n",
        "                if address.lower() in PYUSD_CONTRACTS:\n",
        "                    contract_name = PYUSD_CONTRACTS[address.lower()]\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            mapping_results.append({\n",
        "                'address': address,\n",
        "                'display_address': shorten_address(address),\n",
        "                'balance': balance_pyusd,\n",
        "                'balance_raw': value_int,\n",
        "                'is_contract': is_contract,\n",
        "                'contract_name': contract_name,\n",
        "                'slot': slot_to_read\n",
        "            })\n",
        "\n",
        "    # Create DataFrame\n",
        "    balances_df = pd.DataFrame(mapping_results)\n",
        "\n",
        "    # Display balances table\n",
        "    if not balances_df.empty:\n",
        "        # Sort by balance\n",
        "        balances_df = balances_df.sort_values('balance', ascending=False)\n",
        "\n",
        "        console.print(f\"\\n[bold cyan3]üìä PYUSD Balance Distribution ({len(balances_df)} addresses)[/bold cyan3]\")\n",
        "\n",
        "        # Create enhanced balance table\n",
        "        balance_table = Table(title=\"PYUSD Balances\", title_style=\"bold cyan\")\n",
        "        balance_table.add_column(\"Address\", style=\"dim\")\n",
        "        balance_table.add_column(\"Type\", style=\"cyan\")\n",
        "        balance_table.add_column(\"Balance (PYUSD)\", justify=\"right\", style=\"green\")\n",
        "        balance_table.add_column(\"% of Sample\", justify=\"right\")\n",
        "\n",
        "        total_sample = balances_df['balance'].sum()\n",
        "\n",
        "        for _, row in balances_df.head(10).iterrows():\n",
        "            addr_display = row['display_address']\n",
        "            if row['contract_name']:\n",
        "                addr_display += f\" ({row['contract_name']})\"\n",
        "\n",
        "            balance = row['balance']\n",
        "            percent = (balance / total_sample * 100) if total_sample > 0 else 0\n",
        "\n",
        "            addr_type = \"Contract\" if row['is_contract'] else \"EOA\"\n",
        "\n",
        "            balance_table.add_row(\n",
        "                addr_display,\n",
        "                addr_type,\n",
        "                f\"{balance:,.6f}\",\n",
        "                f\"{percent:.2f}%\"\n",
        "            )\n",
        "\n",
        "        if len(balances_df) > 10:\n",
        "            balance_table.add_row(\"...\", \"...\", f\"+ {len(balances_df) - 10} more\", \"\")\n",
        "\n",
        "        console.print(balance_table)\n",
        "\n",
        "        # Create balance distribution visualization\n",
        "        try:\n",
        "            # Prepare data for pie chart - get top holders\n",
        "            if len(balances_df) > 8:\n",
        "                top_holders = balances_df.nlargest(7, 'balance')\n",
        "                others_sum = balances_df.nsmallest(len(balances_df) - 7, 'balance')['balance'].sum()\n",
        "                others_row = pd.DataFrame([{\n",
        "                    'display_address': f\"Others ({len(balances_df) - 7} addresses)\",\n",
        "                    'balance': others_sum,\n",
        "                    'is_contract': False,\n",
        "                    'contract_name': None\n",
        "                }])\n",
        "                viz_df = pd.concat([top_holders, others_row])\n",
        "            else:\n",
        "                viz_df = balances_df\n",
        "\n",
        "            # Create pie chart\n",
        "            fig = px.pie(\n",
        "                viz_df,\n",
        "                values='balance',\n",
        "                names='display_address',\n",
        "                title=f'PYUSD Balance Distribution at Block {shorten_address(block_hash)}',\n",
        "                hover_data=['balance', 'is_contract']\n",
        "            )\n",
        "\n",
        "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "            fig.update_layout(template=\"plotly_white\")\n",
        "\n",
        "            fig.show()\n",
        "\n",
        "            # Create bar chart showing contract vs EOA distribution\n",
        "            contract_summary = balances_df.groupby('is_contract').agg(\n",
        "                count=('balance', 'count'),\n",
        "                total_balance=('balance', 'sum')\n",
        "            ).reset_index()\n",
        "\n",
        "            contract_summary['type'] = contract_summary['is_contract'].apply(\n",
        "                lambda x: 'Smart Contracts' if x else 'User Wallets'\n",
        "            )\n",
        "\n",
        "            # Create two subplots - count and balance\n",
        "            fig = make_subplots(rows=1, cols=2,\n",
        "                             subplot_titles=('Address Count', 'Balance Distribution'),\n",
        "                             specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}]])\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Pie(\n",
        "                    labels=contract_summary['type'],\n",
        "                    values=contract_summary['count'],\n",
        "                    textinfo='percent+label'\n",
        "                ),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Pie(\n",
        "                    labels=contract_summary['type'],\n",
        "                    values=contract_summary['total_balance'],\n",
        "                    textinfo='percent+label'\n",
        "                ),\n",
        "                row=1, col=2\n",
        "            )\n",
        "\n",
        "            fig.update_layout(\n",
        "                title_text=\"PYUSD Distribution: Contracts vs. User Wallets\",\n",
        "                template=\"plotly_white\"\n",
        "            )\n",
        "\n",
        "            fig.show()\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create balance visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Add export options\n",
        "    console.print(\"\\n[bold cyan3]üì§ Export Options[/bold cyan3]\")\n",
        "\n",
        "    # Create export buttons\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    export_output = widgets.Output()\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    # Export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_balances_{shorten_address(contract_address)}_{timestamp}.csv\"\n",
        "            display(download_csv_direct(balances_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_balances_{shorten_address(contract_address)}_{timestamp}.json\"\n",
        "\n",
        "            export_data = {\n",
        "                \"metadata\": {\n",
        "                    \"contract_address\": contract_address,\n",
        "                    \"block_hash\": block_hash,\n",
        "                    \"analysis_time\": datetime.now().isoformat(),\n",
        "                    \"addresses_analyzed\": len(balances_df),\n",
        "                    \"total_balance\": balances_df['balance'].sum()\n",
        "                },\n",
        "                \"balance_data\": balances_df.to_dict('records')\n",
        "            }\n",
        "\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "\n",
        "    return balances_df\n",
        "\n",
        "\n",
        "def analyze_storage_history(contract_address, block_numbers, slot_to_track, network='mainnet'):\n",
        "    \"\"\"Track a specific storage slot across multiple blocks to see how it changes over time.\"\"\"\n",
        "    console.print(f\"[info]Analyzing historical values of slot {slot_to_track} across {len(block_numbers)} blocks...\", style=\"info\")\n",
        "\n",
        "    history = []\n",
        "\n",
        "    for block_num in block_numbers:\n",
        "        try:\n",
        "            # Get block hash\n",
        "            block_info = w3_mainnet.eth.get_block(block_num)\n",
        "            block_hash = block_info['hash'].hex()\n",
        "            block_timestamp = block_info['timestamp']\n",
        "\n",
        "            # Read storage at this block\n",
        "            params = [block_hash, 0, contract_address, slot_to_track, 1]\n",
        "            storage_result = make_rpc_request(\"debug_storageRangeAt\", params, network=network)\n",
        "\n",
        "            if storage_result and 'storage' in storage_result:\n",
        "                value_hex = storage_result['storage'].get(slot_to_track, {}).get('value', '0x0')\n",
        "                value_int = int(value_hex, 16)\n",
        "\n",
        "                # Special handling for total supply (assuming slot 0)\n",
        "                if slot_to_track == \"0x0\":\n",
        "                    formatted_value = f\"{value_int / 10**6:,.6f} PYUSD\"\n",
        "                    value_type = \"total_supply\"\n",
        "                # Special handling for paused state\n",
        "                elif slot_to_track == \"0x5ac1dce9f7971a63e05025b10b44b6f3c868ae576a5e4a815201051d3eae29cb\":\n",
        "                    formatted_value = \"Paused\" if value_int == 1 else \"Active\"\n",
        "                    value_type = \"paused_state\"\n",
        "                else:\n",
        "                    formatted_value = value_hex\n",
        "                    value_type = \"raw\"\n",
        "\n",
        "                history.append({\n",
        "                    'block': block_num,\n",
        "                    'block_hash': block_hash,\n",
        "                    'timestamp': block_timestamp,\n",
        "                    'datetime': datetime.fromtimestamp(block_timestamp),\n",
        "                    'value_hex': value_hex,\n",
        "                    'value_int': value_int,\n",
        "                    'formatted_value': formatted_value,\n",
        "                    'value_type': value_type\n",
        "                })\n",
        "        except Exception as e:\n",
        "            console.print(f\"[warning]Error reading block {block_num}: {e}\", style=\"warning\")\n",
        "\n",
        "    if history:\n",
        "        history_df = pd.DataFrame(history)\n",
        "\n",
        "        # Display history table\n",
        "        console.print(f\"\\n[bold cyan3]üìä Historical Values for Slot {slot_to_track}[/bold cyan3]\")\n",
        "\n",
        "        # Create timeline visualization\n",
        "        try:\n",
        "            # Time series plot of values\n",
        "            fig = px.line(\n",
        "                history_df,\n",
        "                x='datetime',\n",
        "                y='value_int',\n",
        "                title=f'PYUSD Storage Slot {slot_to_track} - Historical Values',\n",
        "                labels={'value_int': 'Value', 'datetime': 'Block Time'},\n",
        "                markers=True\n",
        "            )\n",
        "\n",
        "            fig.update_layout(template=\"plotly_white\")\n",
        "            fig.show()\n",
        "\n",
        "            # Create table view of history data\n",
        "            display_cols = ['block', 'datetime', 'formatted_value']\n",
        "            display(history_df[display_cols])\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create history visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "        return history_df\n",
        "    else:\n",
        "        console.print(\"[warning]No historical data retrieved.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def detect_storage_patterns(storage_df):\n",
        "    \"\"\"Automatically detect and classify storage patterns specific to PYUSD.\"\"\"\n",
        "    console.print(f\"[info]Analyzing storage patterns across {len(storage_df)} slots...\", style=\"info\")\n",
        "\n",
        "    patterns = {\n",
        "        'erc20_standard': False,\n",
        "        'proxy_pattern': False,\n",
        "        'access_control': False,\n",
        "        'pausable': False,\n",
        "        'upgradeable': False,\n",
        "        'detailed_patterns': []\n",
        "    }\n",
        "\n",
        "    # Check for ERC20 standard slots\n",
        "    if 0 in storage_df['slot_int'].values:\n",
        "        # Slot 0 typically has totalSupply\n",
        "        patterns['erc20_standard'] = True\n",
        "        patterns['detailed_patterns'].append({\n",
        "            'type': 'erc20',\n",
        "            'confidence': 'high',\n",
        "            'description': 'Standard ERC20 storage layout detected (totalSupply at slot 0)'\n",
        "        })\n",
        "\n",
        "    # Check for proxy pattern\n",
        "    impl_slot = \"0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc\"\n",
        "    admin_slot = \"0xb53127684a568b3173ae13b9f8a6016e243e63b6e8ee1178d6a717850b5d6103\"\n",
        "\n",
        "    has_impl = impl_slot in storage_df['slot_hex'].values\n",
        "    has_admin = admin_slot in storage_df['slot_hex'].values\n",
        "\n",
        "    if has_impl or has_admin:\n",
        "        patterns['proxy_pattern'] = True\n",
        "        confidence = 'high' if (has_impl and has_admin) else 'medium'\n",
        "        patterns['detailed_patterns'].append({\n",
        "            'type': 'proxy',\n",
        "            'confidence': confidence,\n",
        "            'description': f'EIP-1967 proxy pattern detected ({[\"admin\", \"implementation\"][has_impl]} slot found)'\n",
        "        })\n",
        "\n",
        "    # Check for pausable pattern\n",
        "    paused_slot = \"0x5ac1dce9f7971a63e05025b10b44b6f3c868ae576a5e4a815201051d3eae29cb\"\n",
        "    if paused_slot in storage_df['slot_hex'].values:\n",
        "        patterns['pausable'] = True\n",
        "        patterns['detailed_patterns'].append({\n",
        "            'type': 'pausable',\n",
        "            'confidence': 'high',\n",
        "            'description': 'OpenZeppelin Pausable pattern detected (paused state slot found)'\n",
        "        })\n",
        "\n",
        "    # Check for AccessControl pattern\n",
        "    role_admin_slot = \"0xb09aa5aeb3702cfd50b6b62bc4532604938f21248a27a1d5ca736082b6819cc1\"\n",
        "    if role_admin_slot in storage_df['slot_hex'].values:\n",
        "        patterns['access_control'] = True\n",
        "        patterns['detailed_patterns'].append({\n",
        "            'type': 'access_control',\n",
        "            'confidence': 'high',\n",
        "            'description': 'OpenZeppelin AccessControl pattern detected (role admin slot found)'\n",
        "        })\n",
        "\n",
        "    # Display detected patterns\n",
        "    console.print(f\"\\n[bold cyan3]üß© PYUSD Storage Pattern Analysis[/bold cyan3]\")\n",
        "\n",
        "    pattern_table = Table(title=\"Detected Storage Patterns\", title_style=\"bold cyan\")\n",
        "    pattern_table.add_column(\"Pattern\", style=\"cyan\")\n",
        "    pattern_table.add_column(\"Detected\", justify=\"center\")\n",
        "    pattern_table.add_column(\"Confidence\", justify=\"center\")\n",
        "    pattern_table.add_column(\"Description\")\n",
        "\n",
        "    for pattern in patterns['detailed_patterns']:\n",
        "        pattern_table.add_row(\n",
        "            pattern['type'].replace('_', ' ').title(),\n",
        "            \"‚úì\",\n",
        "            pattern['confidence'].upper(),\n",
        "            pattern['description']\n",
        "        )\n",
        "\n",
        "    console.print(pattern_table)\n",
        "\n",
        "    # Create pattern visualization\n",
        "    try:\n",
        "        # Create hierarchy diagram\n",
        "        storage_graph = Digraph(comment='PYUSD Storage Patterns')\n",
        "        storage_graph.attr(rankdir='TB', bgcolor='transparent')\n",
        "\n",
        "        # Main contract node\n",
        "        storage_graph.node('contract', 'PYUSD Token', shape='box', style='filled', fillcolor='lightblue')\n",
        "\n",
        "        # Add pattern nodes\n",
        "        if patterns['erc20_standard']:\n",
        "            storage_graph.node('erc20', 'ERC20 Standard', shape='ellipse', style='filled', fillcolor='palegreen')\n",
        "            storage_graph.edge('contract', 'erc20')\n",
        "\n",
        "        if patterns['proxy_pattern']:\n",
        "            storage_graph.node('proxy', 'Proxy Pattern', shape='ellipse', style='filled', fillcolor='lightyellow')\n",
        "            storage_graph.edge('contract', 'proxy')\n",
        "\n",
        "        if patterns['pausable']:\n",
        "            storage_graph.node('pausable', 'Pausable', shape='ellipse', style='filled', fillcolor='lightpink')\n",
        "            storage_graph.edge('contract', 'pausable')\n",
        "\n",
        "        if patterns['access_control']:\n",
        "            storage_graph.node('access', 'Access Control', shape='ellipse', style='filled', fillcolor='lightcyan')\n",
        "            storage_graph.edge('contract', 'access')\n",
        "\n",
        "        display(storage_graph)\n",
        "        console.print(\"[info]This diagram shows the detected storage patterns in PYUSD contract.\", style=\"info\")\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create pattern visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    return patterns\n",
        "\n",
        "\n",
        "# --- Convenience function for common ERC20 analysis ---\n",
        "def analyze_erc20_storage(token_address, block_hash, accounts_to_check=None):\n",
        "    \"\"\"Analyze key ERC20 storage including: totalSupply, balances, allowances.\"\"\"\n",
        "    console.print(f\"[info]Analyzing ERC20 storage for {shorten_address(token_address)}...\", style=\"info\")\n",
        "\n",
        "    # First get basic storage\n",
        "    params = [block_hash, 0, token_address, \"0x0\", 10]  # First 10 slots for base data\n",
        "    storage_result = make_rpc_request(\"debug_storageRangeAt\", params, network='mainnet')\n",
        "\n",
        "    if not storage_result:\n",
        "        console.print(\"[error]Failed to retrieve basic ERC20 storage.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    # Analyze base contract storage\n",
        "    base_analysis = analyze_storage_dump(storage_result, token_address, block_hash)\n",
        "\n",
        "    # If accounts provided, also check balances\n",
        "    balances_results = None\n",
        "    if accounts_to_check and isinstance(accounts_to_check, list) and len(accounts_to_check) > 0:\n",
        "        console.print(f\"[info]Checking balances for {len(accounts_to_check)} accounts...\", style=\"info\")\n",
        "\n",
        "        # Common ERC20 storage slots\n",
        "        balances_slot = 4  # OpenZeppelin ERC20 uses slot 4 for balances\n",
        "\n",
        "        # Get balances for accounts\n",
        "        balances_results = analyze_mapping_storage(token_address, balances_slot, accounts_to_check, block_hash)\n",
        "\n",
        "        # For a deeper analysis, use the specialized balances function\n",
        "        console.print(\"\\n[bold cyan3]üîç Advanced PYUSD Balance Analysis[/bold cyan3]\")\n",
        "        analyze_pyusd_balances(token_address, block_hash, accounts_to_check)\n",
        "\n",
        "    # Detect and display storage patterns\n",
        "    detect_storage_patterns(base_analysis['storage_df'])\n",
        "\n",
        "    # Return comprehensive analysis\n",
        "    return {\n",
        "        'base_analysis': base_analysis,\n",
        "        'balances': balances_results,\n",
        "        'contract_address': token_address,\n",
        "        'block_hash': block_hash\n",
        "    }\n",
        "\n",
        "# --- Execute Storage analysis ---\n",
        "RUN_STORAGE_DUMP = True # <<< SET TO TRUE TO RUN THIS\n",
        "STORAGE_TARGET_CONTRACT = PYUSD_PROXY # Target contract (Proxy or Implementation)\n",
        "STORAGE_SLOT_COUNT = 20 # Number of slots to dump from 0\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    target_block_num_for_storage = TARGET_BLOCK_IDENTIFIER\n",
        "    block_hash_for_storage = None\n",
        "\n",
        "    # --- Get Block Hash ---\n",
        "    # debug_storageRangeAt requires a block HASH, not number or tag\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold chartreuse1]üíæ Inspecting Raw Contract Storage with `debug_storageRangeAt`[/bold chartreuse1]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "        console.print(f\"\\n\\n[info]Fetching block hash for identifier '{target_block_num_for_storage}'\", style=\"info\")\n",
        "        if w3_mainnet:\n",
        "            # Ensure identifier is suitable for get_block\n",
        "            block_identifier_param = target_block_num_for_storage\n",
        "            if isinstance(target_block_num_for_storage, str) and not target_block_num_for_storage.startswith('0x'):\n",
        "                if target_block_num_for_storage not in [\"latest\", \"earliest\", \"pending\"]:\n",
        "                    try: # Convert string number to int\n",
        "                        block_identifier_param = int(target_block_num_for_storage)\n",
        "                    except ValueError:\n",
        "                        console.print(f\"[error]Invalid block identifier string '{target_block_num_for_storage}' for get_block.\", style=\"error\")\n",
        "                        block_identifier_param = None\n",
        "\n",
        "            if block_identifier_param is not None:\n",
        "                block_info = w3_mainnet.eth.get_block(block_identifier_param)\n",
        "                if block_info and 'hash' in block_info:\n",
        "                    block_hash_for_storage = block_info['hash'].hex()\n",
        "                    console.print(f\"[info]Using block hash: {block_hash_for_storage}\", style=\"info\")\n",
        "                else:\n",
        "                    console.print(f\"[error]Could not retrieve block info or hash for identifier '{target_block_num_for_storage}'.\", style=\"error\")\n",
        "        else:\n",
        "            console.print(\"[error]Mainnet client not available to fetch block hash.\", style=\"error\")\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error retrieving block hash for '{target_block_num_for_storage}': {e}\", style=\"error\")\n",
        "\n",
        "    # --- Execute RPC Call ---\n",
        "    if RUN_STORAGE_DUMP and block_hash_for_storage:\n",
        "        tx_index_in_block = 0 # State before first tx in the block\n",
        "        start_key_slot = \"0x0000000000000000000000000000000000000000000000000000000000000000\"\n",
        "\n",
        "        params = [block_hash_for_storage, tx_index_in_block, STORAGE_TARGET_CONTRACT, start_key_slot, STORAGE_SLOT_COUNT]\n",
        "        console.print(f\"\\n\\n[info]Attempting debug_storageRangeAt for {STORAGE_TARGET_CONTRACT} at block {block_hash_for_storage} (Tx Index {tx_index_in_block}, {STORAGE_SLOT_COUNT} slots)\", style=\"info\")\n",
        "        storage_dump_result_data = make_rpc_request(\"debug_storageRangeAt\", params, network='mainnet')\n",
        "\n",
        "        if storage_dump_result_data:\n",
        "            # Use Enhanced Storage analysis\n",
        "            storage_analysis = analyze_storage_dump(storage_dump_result_data, STORAGE_TARGET_CONTRACT, block_hash_for_storage)\n",
        "\n",
        "            # Optional: For in-depth ERC20 analysis with key wallets\n",
        "            # Uncomment and modify the addresses list below to run this analysis\n",
        "            # key_addresses = [\"0x1234...\", \"0x5678...\"]  # Add addresses you want to check\n",
        "            # analyze_erc20_storage(STORAGE_TARGET_CONTRACT, block_hash_for_storage, key_addresses)\n",
        "\n",
        "            # Optional: For historical analysis of a specific slot (e.g., total supply)\n",
        "            # Uncomment and modify the block list below to run this analysis\n",
        "            # historical_blocks = [17000000, 17010000, 17020000]  # Add block numbers to check\n",
        "            # analyze_storage_history(STORAGE_TARGET_CONTRACT, historical_blocks, \"0x0\")  # Track slot 0 (total supply)\n",
        "        else:\n",
        "            console.print(\"[error]Failed to retrieve storage range. Method might be unavailable or params incorrect.\", style=\"error\")\n",
        "\n",
        "    elif RUN_STORAGE_DUMP:\n",
        "        console.print(\"[warning]Skipping 'debug_storageRangeAt': Block hash could not be determined.\", style=\"warning\")\n",
        "    else:\n",
        "        console.print(\"\\n\\n[info]Skipping 'debug_storageRangeAt' as RUN_STORAGE_DUMP is False.\", style=\"info\")\n",
        "\n",
        "elif RUN_STORAGE_DUMP:\n",
        "    console.print(\"[warning]Skipping 'debug_storageRangeAt': TARGET_BLOCK_IDENTIFIER invalid or not set.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "6JS4Nl_byBMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.11 üèä `txpool_status`: Monitoring Network Congestion\n",
        "---\n",
        "\n",
        "This section utilizes the `txpool_status` RPC method to query the connected Ethereum node about the current state of its transaction pool (mempool). It returns the number of transactions currently pending (ready for inclusion in the next blocks) and queued (waiting for prerequisites like a correct nonce or sufficient sender balance).\n",
        "\n",
        "This provides a valuable snapshot of network activity and potential congestion *from the perspective of the specific node you are connected to*.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `txpool_status`\n",
        "> *   **Multiplier:** `50x`\n",
        "> *   **GCP Advantage:** While conceptually simple, accessing mempool data can be restricted or less reliable on public nodes. GCP's dedicated infrastructure provides stable access to this information.\n",
        "> *   **PYUSD Insight:** `txpool_status` helps assess:\n",
        ">     *   **Current Network Load:** Understand how busy the network is when considering sending a PYUSD transaction.\n",
        ">     *   **Estimated Confirmation Times:** Gauge how long a PYUSD transaction might take to get mined based on the pending queue size.\n",
        ">     *   **Gas Price Strategy:** Inform decisions on appropriate gas prices needed for timely PYUSD transaction inclusion based on current congestion levels.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Status:** Calls `txpool_status` on the connected node(s) (Mainnet, optionally testnets).\n",
        "2.  **Parse Counts:** Extracts the `pending` and `queued` transaction counts (converting from hex).\n",
        "3.  **Analyze Congestion:** Uses helper functions (`analyze_network_congestion`, `estimate_confirmation_time`) to interpret the pending count and classify the congestion level (Low, Moderate, High, Extreme).\n",
        "4.  **Recommend Gas (Mainnet):** Fetches the current `baseFeePerGas` from the latest block and uses `recommend_gas_prices` to suggest appropriate gas prices (maxFeePerGas/maxPriorityFeePerGas) for different confirmation speeds based on current congestion.\n",
        "5.  **Visualize & Summarize:**\n",
        "    *   **Status Tables:** Displays pending/queued counts, congestion level, and estimated confirmation time for each checked network.\n",
        "    *   **Gas Recommendation Table (Mainnet):** Shows suggested gas prices (Gwei) for Slow, Standard, Fast, and Rapid confirmation targets.\n",
        "    *   **Congestion Gauge:** Provides a visual indicator of the current network congestion level (based on pending count).\n",
        "    *   **Network Comparison:** If multiple networks are checked, displays a comparative table and bar chart of pending/queued counts.\n",
        "6.  **(Optional Advanced Analysis):** Includes code (controlled by `RUN_TXPOOL_CONTENT`, default `True`) to call the **extremely expensive (`~100x`)** `txpool_content` method to fetch *all* transactions from the pool and specifically identify pending PYUSD transactions using `analyze_txpool_for_pyusd`. This part is highly resource-intensive.\n",
        "7.  **Export Options (if `txpool_content` is run):** Download details of pending PYUSD transactions.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Pending Count:** A high pending count indicates network congestion.\n",
        "*   **Congestion Level & Confirmation Time:** Use these to set expectations for how quickly your PYUSD transaction might be processed.\n",
        "*   **Gas Recommendations:** Use the suggested Gwei values as a starting point when sending transactions, adjusting based on urgency.\n",
        "*   **(If `txpool_content` run):** Observe the number and types (transfer, approve) of PYUSD transactions currently waiting in the mempool."
      ],
      "metadata": {
        "id": "wl5HPXHP4Yim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üèä Transaction Pool Analysis using txpool_status (50x Cost)\n",
        "# =============================================================================================\n",
        "# This cell provides a comprehensive analysis of the Ethereum transaction pool (mempool):\n",
        "# - Fetches basic pool statistics (pending/queued counts) using `txpool_status`.\n",
        "# - Analyzes network congestion levels based on pending transactions and visualizes it with a gauge chart.\n",
        "# - Estimates transaction confirmation times based on pool size.\n",
        "# - Retrieves the current network base fee and provides recommended gas prices for different confirmation speeds (Slow, Standard, Fast, Rapid).\n",
        "# - Optionally fetches detailed transaction data from the pool using the expensive `txpool_content` method.\n",
        "# - Scans the detailed pool content to identify PYUSD-related transactions by checking the 'to' address and function signatures.\n",
        "# - Displays detailed information about identified PYUSD transactions in an interactive table.\n",
        "# - Analyzes and displays the distribution of different PYUSD functions found in the mempool.\n",
        "# - Compares transaction pool status across multiple connected networks (e.g., Mainnet, Sepolia, Holesky).\n",
        "# - Includes robust helper functions for direct data export to CSV, JSON, and formatted Google Sheets.\n",
        "# =============================================================================================\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from datetime import datetime, timedelta\n",
        "import base64\n",
        "import json\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Set larger text size for all output\n",
        "display(HTML(\"<style>.container { font-size: 1.2em; }</style>\"))\n",
        "\n",
        "# --- Define helper functions for download capabilities ---\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"\n",
        "    Creates a direct download for CSV without intermediate display.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to export\n",
        "        filename: Optional custom filename (default: auto-generated with timestamp)\n",
        "\n",
        "    Returns:\n",
        "        HTML object that triggers browser download\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"txpool_pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"\n",
        "    Creates a direct download for JSON without intermediate display.\n",
        "\n",
        "    Args:\n",
        "        data: Dict or list to export as JSON\n",
        "        filename: Optional custom filename (default: auto-generated with timestamp)\n",
        "\n",
        "    Returns:\n",
        "        HTML object that triggers browser download\n",
        "    \"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"txpool_pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, title_prefix=\"PYUSD Mempool Analysis\"):\n",
        "    \"\"\"\n",
        "    Export transaction pool analysis data to Google Sheets with rich formatting.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with transaction data\n",
        "        data_dict: Dictionary with additional structured data\n",
        "        title_prefix: Prefix for the sheet title\n",
        "\n",
        "    Returns:\n",
        "        HTML object that opens the created Google Sheet\n",
        "    \"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[cyan3]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"{title_prefix} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"PYUSD Transactions\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transactions in Mempool Analysis\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A2\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 4  # Start after header\n",
        "\n",
        "        # Add transaction stats summary\n",
        "        if \"summary\" in data_dict:\n",
        "            stats = data_dict[\"summary\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Summary\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "\n",
        "                # Try to format numerical values with commas\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        formatted_value = f\"{value:,}\"\n",
        "                    else:\n",
        "                        formatted_value = str(value)\n",
        "                except:\n",
        "                    formatted_value = str(value)\n",
        "\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 2  # Add extra space after table\n",
        "\n",
        "        # Add function distribution if available\n",
        "        if \"function_distribution\" in data_dict:\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Function Distribution\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.7, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add distribution data\n",
        "            dist_rows = []\n",
        "            dist_rows.append([\"Function\", \"Count\", \"Percentage\"])  # Header row\n",
        "\n",
        "            for func, data in data_dict[\"function_distribution\"].items():\n",
        "                dist_rows.append([func, data[\"count\"], f\"{data['percentage']:.1f}%\"])\n",
        "\n",
        "            # Add distribution table\n",
        "            dist_start_row = current_row\n",
        "            worksheet.update(f\"A{dist_start_row}\", dist_rows)\n",
        "\n",
        "            # Format distribution table header\n",
        "            worksheet.format(f\"A{dist_start_row}:C{dist_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(dist_rows) + 2  # Add extra space after table\n",
        "\n",
        "        # Add main DataFrame data\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"PYUSD Transactions Details\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [df.columns.tolist()] + df.values.tolist()\n",
        "\n",
        "            # Format values for better readability\n",
        "            for i in range(1, len(df_values)):\n",
        "                for j, col in enumerate(df.columns):\n",
        "                    val = df_values[i][j]\n",
        "\n",
        "                    # Format different column types appropriately\n",
        "                    if pd.isnull(val):\n",
        "                        df_values[i][j] = \"\"\n",
        "                    elif col == \"gas_price_gwei\" and isinstance(val, (int, float)):\n",
        "                        df_values[i][j] = f\"{val:.2f}\"\n",
        "                    else:\n",
        "                        df_values[i][j] = str(val)\n",
        "\n",
        "            worksheet.update(f\"A{current_row}\", df_values)\n",
        "\n",
        "            # Format the DataFrame header\n",
        "            worksheet.format(f\"A{current_row}:{chr(65+len(df.columns)-1)}{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            # Add alternating row colors for readability\n",
        "            data_rows = len(df_values)\n",
        "            for i in range(2, data_rows + 1, 2):\n",
        "                row_num = current_row + i - 1\n",
        "                worksheet.format(f\"A{row_num}:{chr(65+len(df.columns)-1)}{row_num}\", {\n",
        "                    \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Attempt to resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Clear loading message and show success message\n",
        "        clear_output()\n",
        "        console.print(\"‚úì Successfully exported to Google Sheets\", style=\"spring_green3\")\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clear loading message and show error\n",
        "        clear_output()\n",
        "        console.print(f\"‚ùå Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "\n",
        "# --- Define helper functions for advanced txpool analysis ---\n",
        "\n",
        "def estimate_confirmation_time(pending_count):\n",
        "    \"\"\"\n",
        "    Estimate confirmation time based on pending transaction count.\n",
        "\n",
        "    Args:\n",
        "        pending_count: Number of pending transactions\n",
        "\n",
        "    Returns:\n",
        "        Human-readable estimated confirmation time string\n",
        "    \"\"\"\n",
        "    # Ethereum processes ~15 tx/sec on average (more with optimizations)\n",
        "    # Each block contains ~250 transactions and comes every ~12 seconds\n",
        "    avg_tx_per_block = 250\n",
        "    avg_block_time_sec = 12\n",
        "\n",
        "    # Calculate blocks until this transaction would be processed\n",
        "    blocks_to_wait = max(1, pending_count / avg_tx_per_block)\n",
        "\n",
        "    # Calculate time in seconds\n",
        "    wait_time_sec = blocks_to_wait * avg_block_time_sec\n",
        "\n",
        "    # Return human-readable time\n",
        "    if wait_time_sec < 60:\n",
        "        return f\"~{int(wait_time_sec)} seconds\"\n",
        "    elif wait_time_sec < 3600:\n",
        "        return f\"~{int(wait_time_sec/60)} minutes\"\n",
        "    else:\n",
        "        return f\"~{wait_time_sec/3600:.1f} hours\"\n",
        "\n",
        "\n",
        "def analyze_network_congestion(pending_count):\n",
        "    \"\"\"\n",
        "    Analyze network congestion level based on pending tx count.\n",
        "\n",
        "    Args:\n",
        "        pending_count: Number of pending transactions\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with congestion analysis details\n",
        "    \"\"\"\n",
        "    if pending_count < 1000:\n",
        "        return {\n",
        "            \"level\": \"Low\",\n",
        "            \"description\": \"Network is not congested. Transactions should confirm quickly with standard gas prices.\",\n",
        "            \"color\": \"green\",\n",
        "            \"factor\": 0.2,  # Congestion factor (0-1)\n",
        "        }\n",
        "    elif pending_count < 5000:\n",
        "        return {\n",
        "            \"level\": \"Moderate\",\n",
        "            \"description\": \"Some network congestion. Consider using slightly higher gas prices for faster confirmation.\",\n",
        "            \"color\": \"yellow\",\n",
        "            \"factor\": 0.5,\n",
        "        }\n",
        "    elif pending_count < 15000:\n",
        "        return {\n",
        "            \"level\": \"High\",\n",
        "            \"description\": \"Network is congested. Higher gas prices recommended for reasonable confirmation times.\",\n",
        "            \"color\": \"orange\",\n",
        "            \"factor\": 0.8,\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            \"level\": \"Extreme\",\n",
        "            \"description\": \"Network is extremely congested. High gas prices required for timely confirmation.\",\n",
        "            \"color\": \"red\",\n",
        "            \"factor\": 1.0,\n",
        "        }\n",
        "\n",
        "\n",
        "def recommend_gas_prices(base_fee, congestion_factor):\n",
        "    \"\"\"\n",
        "    Recommend gas prices based on current network conditions.\n",
        "\n",
        "    Args:\n",
        "        base_fee: Current base fee in gwei\n",
        "        congestion_factor: Current network congestion factor (0-1)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with recommended gas prices for different speed tiers\n",
        "    \"\"\"\n",
        "    # Base gas prices based on current base fee (in gwei)\n",
        "    # These are multipliers on the base fee\n",
        "    multipliers = {\n",
        "        \"slow\": 1.0,      # Just the base fee for next block inclusion\n",
        "        \"standard\": 1.1,  # Base fee + 10% for quicker inclusion\n",
        "        \"fast\": 1.25,     # Base fee + 25% for fast inclusion\n",
        "        \"rapid\": 1.5      # Base fee + 50% for urgent transactions\n",
        "    }\n",
        "\n",
        "    # Adjust multipliers based on congestion (increase spread during congestion)\n",
        "    if congestion_factor > 0.7:  # High congestion\n",
        "        multipliers[\"standard\"] = 1.2\n",
        "        multipliers[\"fast\"] = 1.5\n",
        "        multipliers[\"rapid\"] = 2.0\n",
        "    elif congestion_factor > 0.4:  # Moderate congestion\n",
        "        multipliers[\"standard\"] = 1.15\n",
        "        multipliers[\"fast\"] = 1.35\n",
        "        multipliers[\"rapid\"] = 1.7\n",
        "\n",
        "    # Calculate recommended prices\n",
        "    recommendations = {}\n",
        "    for speed, multiplier in multipliers.items():\n",
        "        recommendations[speed] = round(base_fee * multiplier, 2)\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "def get_current_base_fee(network=\"mainnet\"):\n",
        "    \"\"\"\n",
        "    Get the current base fee from the latest block for the specified network.\n",
        "\n",
        "    Args:\n",
        "        network (str): Network to query (mainnet, holesky, sepolia)\n",
        "\n",
        "    Returns:\n",
        "        float: Current base fee in gwei\n",
        "    \"\"\"\n",
        "    try:\n",
        "        w3 = w3_clients[network]\n",
        "        latest_block = w3.eth.get_block('latest')\n",
        "        # Convert Wei to Gwei\n",
        "        base_fee_gwei = w3.from_wei(latest_block.baseFeePerGas, 'gwei')\n",
        "        return float(base_fee_gwei)\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not get current base fee for {network}: {str(e)}\", style=\"warning\")\n",
        "        # Return an estimated value if we can't get the actual value\n",
        "        return 15.0  # Default fallback value in gwei\n",
        "\n",
        "def create_congestion_gauge(congestion_factor, title=\"Network Congestion\"):\n",
        "    \"\"\"\n",
        "    Create a gauge chart showing network congestion level.\n",
        "\n",
        "    Args:\n",
        "        congestion_factor: Current network congestion factor (0-1)\n",
        "        title: Chart title\n",
        "\n",
        "    Returns:\n",
        "        Plotly Figure object\n",
        "    \"\"\"\n",
        "    fig = go.Figure(go.Indicator(\n",
        "        mode = \"gauge+number\",\n",
        "        value = congestion_factor * 100,\n",
        "        domain = {'x': [0, 1], 'y': [0, 1]},\n",
        "        title = {'text': title, 'font': {'size': 24}},  # Larger title font\n",
        "        gauge = {\n",
        "            'axis': {'range': [0, 100], 'tickwidth': 1, 'tickcolor': \"darkgray\", 'tickfont': {'size': 14}},\n",
        "            'bar': {'color': \"royalblue\"},\n",
        "            'bgcolor': \"white\",\n",
        "            'borderwidth': 2,\n",
        "            'bordercolor': \"gray\",\n",
        "            'steps': [\n",
        "                {'range': [0, 25], 'color': 'green'},\n",
        "                {'range': [25, 50], 'color': 'yellow'},\n",
        "                {'range': [50, 75], 'color': 'orange'},\n",
        "                {'range': [75, 100], 'color': 'red'},\n",
        "            ],\n",
        "        }\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=350,  # Slightly taller\n",
        "        margin=dict(l=20, r=20, t=50, b=20),\n",
        "        font=dict(size=16)  # Larger font for all text elements\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def analyze_txpool_for_pyusd(txpool_content, pending_only=True):\n",
        "    \"\"\"\n",
        "    Analyze transaction pool content to find PYUSD-related transactions.\n",
        "\n",
        "    Args:\n",
        "        txpool_content: Transaction pool content from RPC\n",
        "        pending_only: Whether to analyze only pending transactions (True) or both pending and queued (False)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with PYUSD transaction analysis results\n",
        "    \"\"\"\n",
        "    if not txpool_content:\n",
        "        return {\"count\": 0, \"transactions\": []}\n",
        "\n",
        "    pyusd_txs = []\n",
        "    total_count = 0\n",
        "\n",
        "    # Only analyze pending if specified, otherwise look at both pending and queued\n",
        "    sections = [\"pending\"] if pending_only else [\"pending\", \"queued\"]\n",
        "\n",
        "    for section in sections:\n",
        "        if section not in txpool_content:\n",
        "            continue\n",
        "\n",
        "        for sender, nonce_dict in txpool_content[section].items():\n",
        "            for nonce, tx_data in nonce_dict.items():\n",
        "                total_count += 1\n",
        "\n",
        "                # Check if this transaction is PYUSD-related\n",
        "                is_pyusd_tx = False\n",
        "\n",
        "                # Check if to address is a PYUSD contract - Handle None case properly\n",
        "                to_address = tx_data.get(\"to\", \"\")\n",
        "                if to_address is not None:\n",
        "                    to_address = to_address.lower()\n",
        "                    if to_address in PYUSD_CONTRACTS:\n",
        "                        is_pyusd_tx = True\n",
        "\n",
        "                # Check input data for PYUSD function signatures\n",
        "                input_data = tx_data.get(\"input\", \"\")\n",
        "                if len(input_data) >= 10:  # At least contains a function selector\n",
        "                    method_sig = input_data[:10]\n",
        "                    if method_sig in PYUSD_SIGNATURES:\n",
        "                        is_pyusd_tx = True\n",
        "\n",
        "                if is_pyusd_tx:\n",
        "                    # Extract useful information\n",
        "                    gas_price = int(tx_data.get(\"gasPrice\", \"0x0\"), 16) / 1e9  # Convert to Gwei\n",
        "\n",
        "                    pyusd_txs.append({\n",
        "                        \"hash\": tx_data.get(\"hash\", \"Unknown\"),\n",
        "                        \"from\": sender,\n",
        "                        \"to\": to_address if to_address is not None else \"Contract Creation\",\n",
        "                        \"nonce\": int(nonce, 16) if isinstance(nonce, str) else nonce,\n",
        "                        \"function\": decode_pyusd_function(input_data) if len(input_data) >= 10 else \"Unknown\",\n",
        "                        \"gas_price_gwei\": gas_price,\n",
        "                        \"status\": section\n",
        "                    })\n",
        "\n",
        "    return {\n",
        "        \"count\": len(pyusd_txs),\n",
        "        \"total_analyzed\": total_count,\n",
        "        \"transactions\": pyusd_txs\n",
        "    }\n",
        "\n",
        "\n",
        "# =============================================================================================\n",
        "# --- Execute txpool_status Analysis ---\n",
        "# =============================================================================================\n",
        "\n",
        "RUN_TXPOOL_STATUS = True # <<< SET TO TRUE TO RUN THIS (50x COST)\n",
        "RUN_TXPOOL_CONTENT = True # <<< SET TO TRUE TO ANALYZE FULL POOL CONTENT (VERY EXPENSIVE, 100x Cost)\n",
        "\n",
        "if RUN_TXPOOL_STATUS:\n",
        "    console.print(\"\\n\\n[bold cyan3]üèä Transaction Pool Analysis with `tx_pool`[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    console.print(\"\\n\\nAnalyzing network congestion and transaction confirmation times...\")\n",
        "\n",
        "    # Get txpool status from multiple networks if available\n",
        "    networks_to_check = [\"mainnet\"]\n",
        "    if 'holesky' in w3_clients and w3_clients['holesky'].is_connected():\n",
        "        networks_to_check.append(\"holesky\")\n",
        "    if 'sepolia' in w3_clients and w3_clients['sepolia'].is_connected():\n",
        "        networks_to_check.append(\"sepolia\")\n",
        "\n",
        "    network_results = {}\n",
        "\n",
        "    for network in networks_to_check:\n",
        "        console.print(f\"\\n\\n[info]Fetching txpool status on {network.capitalize()}...\", style=\"info\")\n",
        "        txpool_status_result = make_rpc_request(\"txpool_status\", [], network=network)\n",
        "\n",
        "        if txpool_status_result:\n",
        "            # Result values are hex strings\n",
        "            pending_count = int(txpool_status_result.get('pending', '0x0'), 16)\n",
        "            queued_count = int(txpool_status_result.get('queued', '0x0'), 16)\n",
        "            total_count = pending_count + queued_count\n",
        "\n",
        "            # Analyze network congestion\n",
        "            congestion_analysis = analyze_network_congestion(pending_count)\n",
        "            est_confirmation_time = estimate_confirmation_time(pending_count)\n",
        "\n",
        "            # Store for network comparison\n",
        "            network_results[network] = {\n",
        "                \"pending\": pending_count,\n",
        "                \"queued\": queued_count,\n",
        "                \"total\": total_count,\n",
        "                \"congestion\": congestion_analysis,\n",
        "                \"confirmation_time\": est_confirmation_time\n",
        "            }\n",
        "\n",
        "            # Display network results\n",
        "            console.print(f\"\\n\\n[bold cyan3]‚õìÔ∏è {network.capitalize()} Transaction Pool [/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            status_table = Table(title=\"\", title_style=\"bold cyan3\", border_style=\"cyan3\")\n",
        "            status_table.add_column(\"Metric\", header_style=\"bold cyan3\")\n",
        "            status_table.add_column(\"Value\", header_style=\"bold cyan3\")\n",
        "            status_table.add_column(\"Details\", header_style=\"bold cyan3\")\n",
        "\n",
        "            status_table.add_row(\n",
        "                \"Pending Transactions\",\n",
        "                f\"{pending_count:,}\",\n",
        "                \"Waiting to be included in next blocks\"\n",
        "            )\n",
        "            status_table.add_row(\n",
        "                \"Queued Transactions\",\n",
        "                f\"{queued_count:,}\",\n",
        "                \"Waiting for prerequisites (nonce, funds)\"\n",
        "            )\n",
        "            status_table.add_row(\n",
        "                \"Total Transactions\",\n",
        "                f\"{total_count:,}\",\n",
        "                \"Combined pending + queued\"\n",
        "            )\n",
        "            status_table.add_row(\n",
        "                \"Network Congestion\",\n",
        "                f\"[{congestion_analysis['color']}]{congestion_analysis['level']}[/{congestion_analysis['color']}]\",\n",
        "                congestion_analysis['description']\n",
        "            )\n",
        "            status_table.add_row(\n",
        "                \"Est. Confirmation Time\",\n",
        "                est_confirmation_time,\n",
        "                \"Average time for new transactions\"\n",
        "            )\n",
        "\n",
        "            console.print(status_table)\n",
        "\n",
        "            # For mainnet, provide additional gas price recommendations\n",
        "            console.print(f\"\\n\\n[bold yellow3]‚õΩ Gas Price Recommendations for {network.capitalize()}[/bold yellow3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "            if network in [\"mainnet\", \"holesky\", \"sepolia\"]:\n",
        "                # Get current base fee\n",
        "                current_base_fee = get_current_base_fee(network)\n",
        "\n",
        "                # Get gas price recommendations\n",
        "                gas_recommendations = recommend_gas_prices(\n",
        "                    current_base_fee,\n",
        "                    congestion_analysis['factor']\n",
        "                )\n",
        "\n",
        "                # Display gas price recommendations\n",
        "                gas_table = Table(title=\"\", title_style=\"bold yellow3\", border_style=\"yellow3\")\n",
        "                gas_table.add_column(\"Speed\", header_style=\"bold yellow3\")\n",
        "                gas_table.add_column(\"Gas Price (Gwei)\", header_style=\"bold yellow3\")\n",
        "                gas_table.add_column(\"Expected Confirmation\", header_style=\"bold yellow3\")\n",
        "\n",
        "                gas_table.add_row(\n",
        "                    \"üê¢ Slow\",\n",
        "                    f\"{gas_recommendations['slow']:.2f}\",\n",
        "                    \"Within ~5 minutes\"\n",
        "                )\n",
        "                gas_table.add_row(\n",
        "                    \"üö∂ Standard\",\n",
        "                    f\"{gas_recommendations['standard']:.2f}\",\n",
        "                    \"Within ~2 minutes\"\n",
        "                )\n",
        "                gas_table.add_row(\n",
        "                    \"üèÉ Fast\",\n",
        "                    f\"{gas_recommendations['fast']:.2f}\",\n",
        "                    \"Within ~30 seconds\"\n",
        "                )\n",
        "                gas_table.add_row(\n",
        "                    \"üöÄ Rapid\",\n",
        "                    f\"{gas_recommendations['rapid']:.2f}\",\n",
        "                    \"Next block (~12 seconds)\"\n",
        "                )\n",
        "\n",
        "                console.print(gas_table)\n",
        "\n",
        "                # Display congestion gauge visualization\n",
        "                console.print(f\"\\n\\n[bold magenta3]üì∂ Network Congestion Gauge for {network.capitalize()}[/bold magenta3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                try:\n",
        "                    fig = create_congestion_gauge(congestion_analysis['factor'])\n",
        "                    display(fig)\n",
        "                except Exception as e:\n",
        "                    console.print(f\"[warning]Could not create visualization: {str(e)}\", style=\"warning\")\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to get txpool status for {network}. Method might be unavailable on this node.\", style=\"error\")\n",
        "\n",
        "    # If we have multiple networks, show a comparison\n",
        "    if len(network_results) > 1:\n",
        "        console.print(\"\\n\\n[bold chartreuse1]‚öñÔ∏è Network Transaction Pool Comparison[/bold chartreuse1]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "        comparison_table = Table(title=\"\", title_style=\"bold chartreuse1\", border_style=\"chartreuse1\")\n",
        "        comparison_table.add_column(\"Network\", header_style=\"bold chartreuse1\")\n",
        "        comparison_table.add_column(\"Pending\", header_style=\"bold chartreuse1\")\n",
        "        comparison_table.add_column(\"Queued\", header_style=\"bold chartreuse1\")\n",
        "        comparison_table.add_column(\"Congestion\", header_style=\"bold chartreuse1\")\n",
        "\n",
        "        for network, data in network_results.items():\n",
        "            comparison_table.add_row(\n",
        "                network.capitalize(),\n",
        "                f\"{data['pending']:,}\",\n",
        "                f\"{data['queued']:,}\",\n",
        "                f\"[{data['congestion']['color']}]{data['congestion']['level']}[/{data['congestion']['color']}]\"\n",
        "            )\n",
        "\n",
        "        console.print(comparison_table)\n",
        "\n",
        "        # Create a bar chart comparison\n",
        "        try:\n",
        "            console.print(\"\\n\\n[bold magenta3]üåä Transaction Pool Comparison Across Networks[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            # Prepare data for plotting\n",
        "            networks = list(network_results.keys())\n",
        "            pending_values = [network_results[n]['pending'] for n in networks]\n",
        "            queued_values = [network_results[n]['queued'] for n in networks]\n",
        "\n",
        "            # Create subplots with 1 row and 1 column\n",
        "            fig = make_subplots(rows=1, cols=1)\n",
        "\n",
        "            # Add bars for pending and queued transactions\n",
        "            fig.add_trace(\n",
        "                go.Bar(x=networks, y=pending_values, name=\"Pending\",\n",
        "                      marker_color='royalblue'),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "            fig.add_trace(\n",
        "                go.Bar(x=networks, y=queued_values, name=\"Queued\",\n",
        "                      marker_color='lightblue'),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "            # Update layout with larger font\n",
        "            fig.update_layout(\n",
        "                title={\n",
        "                    'text': \"Transaction Pool Comparison Across Networks\",\n",
        "                    'font': {'size': 24}\n",
        "                },\n",
        "                xaxis_title={\n",
        "                    'text': \"Network\",\n",
        "                    'font': {'size': 18}\n",
        "                },\n",
        "                yaxis_title={\n",
        "                    'text': \"Number of Transactions\",\n",
        "                    'font': {'size': 18}\n",
        "                },\n",
        "                height=450,\n",
        "                barmode='stack',\n",
        "                font=dict(size=16)  # Increase overall font size\n",
        "            )\n",
        "\n",
        "            display(fig)\n",
        "        except Exception as e:\n",
        "            console.print(f\"[warning]Could not create comparison visualization: {str(e)}\", style=\"warning\")\n",
        "\n",
        "    # =============================================================================================\n",
        "    # Advanced PYUSD-specific Analysis (optional, expensive)\n",
        "    # =============================================================================================\n",
        "    if RUN_TXPOOL_CONTENT and \"mainnet\" in network_results:\n",
        "        console.print(\"\\n\\n[bold cyan3]ü´ß PYUSD Transaction Analysis in Mempool[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        console.print(\"\\n\\n[info]Fetching detailed transaction pool content (this is very expensive)...\", style=\"info\")\n",
        "\n",
        "        # This is much more expensive than txpool_status\n",
        "        txpool_content = make_rpc_request(\"txpool_content\", [], network=\"mainnet\")\n",
        "\n",
        "        if txpool_content:\n",
        "            console.print(\"\\n\\n[success]Successfully retrieved transaction pool content.\", style=\"success\")\n",
        "\n",
        "            # Analyze the pool for PYUSD transactions\n",
        "            pyusd_analysis = analyze_txpool_for_pyusd(txpool_content)\n",
        "\n",
        "            console.print(f\"[info]Found {pyusd_analysis['count']} PYUSD-related transactions out of {pyusd_analysis['total_analyzed']} transactions in the pending pool.\", style=\"info\")\n",
        "\n",
        "            if pyusd_analysis['count'] > 0:\n",
        "                # Convert to DataFrame for interactive display and export\n",
        "                pyusd_tx_data = pyusd_analysis['transactions']\n",
        "                pyusd_df = pd.DataFrame(pyusd_tx_data)\n",
        "\n",
        "                # Only format numeric values, keep full addresses and hashes\n",
        "                if 'gas_price_gwei' in pyusd_df.columns:\n",
        "                    pyusd_df['gas_price_gwei'] = pyusd_df['gas_price_gwei'].apply(\n",
        "                        lambda g: f\"{g:.2f}\" if isinstance(g, (int, float)) else g\n",
        "                    )\n",
        "\n",
        "                # Display interactive data table with all PYUSD transactions\n",
        "                console.print(\"\\n\\n[bold cyan3]üìä PYUSD Transactions in Mempool[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "                # Use IPython's display to show the interactive dataframe with full addresses\n",
        "                # Set pandas display options for better readability\n",
        "                with pd.option_context('display.max_rows', None,\n",
        "                                      'display.max_columns', None,\n",
        "                                      'display.width', None):\n",
        "                    display(HTML(\"<style>.dataframe th, .dataframe td { font-size: 1.1em; }</style>\"))\n",
        "                    display(pyusd_df)\n",
        "\n",
        "                # Analyze function distribution\n",
        "                function_counts = {}\n",
        "                for tx in pyusd_analysis['transactions']:\n",
        "                    function = tx[\"function\"]\n",
        "                    # Check if function is a dictionary and extract a meaningful key\n",
        "                    if isinstance(function, dict) and \"name\" in function:\n",
        "                        function_key = function[\"name\"]\n",
        "                    # Fallback to string representation if it's a dict without name\n",
        "                    elif isinstance(function, dict):\n",
        "                        function_key = str(function)\n",
        "                    # Use as is if it's already a string or other hashable type\n",
        "                    else:\n",
        "                        function_key = function\n",
        "\n",
        "                    function_counts[function_key] = function_counts.get(function_key, 0) + 1\n",
        "\n",
        "                # Prepare function distribution data for export\n",
        "                function_distribution = {}\n",
        "                for function, count in function_counts.items():\n",
        "                    percentage = count / pyusd_analysis['count'] * 100\n",
        "                    function_distribution[function] = {\n",
        "                        \"count\": count,\n",
        "                        \"percentage\": percentage\n",
        "                    }\n",
        "\n",
        "                # Display function distribution\n",
        "                if len(function_counts) > 1:\n",
        "                    console.print(\"\\n\\n[bold cyan3]ü™ô PYUSD Function Distribution in Pending Transactions:[/bold cyan3]\")\n",
        "                    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "                    dist_table = Table(title=\"\", title_style=\"bold cyan3\", border_style=\"cyan3\")\n",
        "                    dist_table.add_column(\"Function\", header_style=\"cyan3\")\n",
        "                    dist_table.add_column(\"Count\", justify=\"right\", header_style=\"cyan3\")\n",
        "                    dist_table.add_column(\"Percentage\", justify=\"right\", header_style=\"cyan3\")\n",
        "\n",
        "                    for function, count in sorted(function_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "                        percentage = count / pyusd_analysis['count'] * 100\n",
        "                        dist_table.add_row(\n",
        "                            function,\n",
        "                            f\"{count}\",\n",
        "                            f\"{percentage:.1f}%\"\n",
        "                        )\n",
        "\n",
        "                    console.print(dist_table)\n",
        "\n",
        "                # =============================================================================================\n",
        "                # Export Options Section\n",
        "                # =============================================================================================\n",
        "                console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "                # Create export output area\n",
        "                export_output = widgets.Output()\n",
        "\n",
        "                # Create export buttons with proper styling and larger size\n",
        "                export_buttons = widgets.HBox([\n",
        "                    widgets.Button(\n",
        "                        description='Export to CSV',\n",
        "                        button_style='primary',  # Green\n",
        "                        layout=widgets.Layout(width='180px', height='40px')  # Larger buttons\n",
        "                    ),\n",
        "                    widgets.Button(\n",
        "                        description='Export as JSON',\n",
        "                        button_style='warning',  # Orange\n",
        "                        layout=widgets.Layout(width='180px', height='40px')\n",
        "                    ),\n",
        "                    widgets.Button(\n",
        "                        description='Export to Google Sheets',\n",
        "                        button_style='info',     # Blue\n",
        "                        layout=widgets.Layout(width='220px', height='40px')\n",
        "                    )\n",
        "                ])\n",
        "\n",
        "                # Define export handlers\n",
        "                def export_csv(b):\n",
        "                    with export_output:\n",
        "                        clear_output()\n",
        "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                        filename = f\"pyusd_mempool_transactions_{timestamp}.csv\"\n",
        "                        display(download_csv_direct(pyusd_df, filename))\n",
        "\n",
        "                def export_json(b):\n",
        "                    with export_output:\n",
        "                        clear_output()\n",
        "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                        filename = f\"pyusd_mempool_transactions_{timestamp}.json\"\n",
        "                        # Prepare export data with analysis information\n",
        "                        export_data = {\n",
        "                            \"analysis_type\": \"PYUSD Mempool Transactions\",\n",
        "                            \"analysis_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                            \"summary\": {\n",
        "                                \"total_transactions_analyzed\": pyusd_analysis['total_analyzed'],\n",
        "                                \"pyusd_transactions_found\": pyusd_analysis['count'],\n",
        "                                \"pyusd_percentage\": (pyusd_analysis['count'] / pyusd_analysis['total_analyzed'] * 100) if pyusd_analysis['total_analyzed'] > 0 else 0\n",
        "                            },\n",
        "                            \"function_distribution\": function_distribution,\n",
        "                            \"transactions\": pyusd_tx_data\n",
        "                        }\n",
        "                        display(download_json_direct(export_data, filename))\n",
        "\n",
        "                def export_to_sheets(b):\n",
        "                    with export_output:\n",
        "                        clear_output()\n",
        "                        try:\n",
        "                            # Prepare export data with analysis information\n",
        "                            export_data = {\n",
        "                                \"summary\": {\n",
        "                                    \"total_transactions_analyzed\": pyusd_analysis['total_analyzed'],\n",
        "                                    \"pyusd_transactions_found\": pyusd_analysis['count'],\n",
        "                                    \"pyusd_percentage\": (pyusd_analysis['count'] / pyusd_analysis['total_analyzed'] * 100) if pyusd_analysis['total_analyzed'] > 0 else 0,\n",
        "                                    \"analysis_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                                },\n",
        "                                \"function_distribution\": function_distribution\n",
        "                            }\n",
        "                            display(export_to_google_sheets(pyusd_df, export_data))\n",
        "                        except Exception as e:\n",
        "                            html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                            display(HTML(html))\n",
        "\n",
        "                            # Fallback to CSV\n",
        "                            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                            filename = f\"pyusd_mempool_transactions_{timestamp}.csv\"\n",
        "                            display(download_csv_direct(pyusd_df, filename))\n",
        "                            display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "                # Connect handlers to buttons\n",
        "                export_buttons.children[0].on_click(export_csv)\n",
        "                export_buttons.children[1].on_click(export_json)\n",
        "                export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "                # Display button container and output area\n",
        "                display(export_buttons)\n",
        "                display(export_output)\n",
        "        else:\n",
        "            console.print(\"[error]Failed to get detailed transaction pool content. This method is often restricted.\", style=\"error\")\n",
        "\n",
        "else:\n",
        "    console.print(\"\\n\\n[info]Skipping 'txpool_status' analysis as RUN_TXPOOL_STATUS is False.\", style=\"info\")"
      ],
      "metadata": {
        "id": "fuR68xiM4f3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Conclusion: PyFlow & The GCP Advantage for Deep Blockchain Intelligence\n",
        "\n",
        "This notebook, **PyFlow**, set out to demonstrate how deep, computationally intensive analysis of the PYUSD stablecoin could be achieved effectively and affordably. The challenge lies in the significant cost and resource requirements typically associated with advanced blockchain RPC methods needed for such insights.\n",
        "\n",
        "**PyFlow successfully showcased a comprehensive suite of advanced analytical techniques by specifically leveraging the unique advantages of Google Cloud Platform's Blockchain Node Engine.**\n",
        "\n",
        "**üöÄ The Critical GCP Enabler: Cost-Effective High-Multiplier Methods**\n",
        "\n",
        "The core achievement highlighted throughout this analysis is the **practical feasibility** of using high-multiplier RPC methods like:\n",
        "\n",
        "*   `debug_traceTransaction` (`50x`) for granular execution tracing.\n",
        "*   `eth_getLogs` (`50x`) for efficient event filtering.\n",
        "*   `debug_storageRangeAt` (`50x`) for direct state inspection.\n",
        "*   `trace_block` / `debug_traceBlock*` (`50x`) for block-level context.\n",
        "*   `trace_call` (`50x`) for powerful simulations.\n",
        "*   **Critically:** `trace_replayTransaction` and `trace_replayBlockTransactions` (`100x`) with `stateDiff` for precise state change analysis.\n",
        "\n",
        "On most platforms, the **prohibitive cost multipliers** (especially the `100x` for replay methods) associated with these calls would make the analyses performed in this notebook impractical or extremely expensive for regular use or extensive research. **GCP's Blockchain Node Engine, with its generous free quotas that encompass these high-cost methods, fundamentally changes the economics of deep blockchain analysis.** It democratizes access to capabilities previously requiring specialized, costly infrastructure.\n",
        "\n",
        "**üí° Key Capabilities Demonstrated:**\n",
        "\n",
        "Through PyFlow, we applied these GCP-enabled methods to PYUSD, demonstrating capabilities such as:\n",
        "\n",
        "1.  **Forensic Transaction Tracing:** Dissecting complex PYUSD flows (`debug_traceTransaction`, `trace_transaction`).\n",
        "2.  **Precise State Auditing:** Observing exact balance, allowance, and supply changes (`stateDiff` via `trace_replayTransaction`).\n",
        "3.  **Efficient Event Monitoring:** Isolating specific PYUSD events like Transfers and Approvals (`eth_getLogs`).\n",
        "4.  **Contract Verification & Analysis:** Inspecting bytecode and storage layout (`eth_getCode`, `debug_storageRangeAt`).\n",
        "5.  **Simulation & Gas Estimation:** Predicting transaction outcomes and costs (`trace_call`).\n",
        "6.  **Block-Level Context:** Understanding PYUSD activity within the broader context of a block (`trace_block`, `debug_traceBlock*`).\n",
        "7.  **Network Health Assessment:** Gauging congestion and estimating confirmation times (`txpool_status`).\n",
        "\n",
        "\n",
        "**üéØ Impact for PYUSD & Beyond:**\n",
        "\n",
        "By making these advanced analyses accessible, GCP empowers developers, analysts, auditors, and researchers to gain unparalleled insights into the PYUSD ecosystem and other on-chain assets. This enables more robust security practices, better gas optimization, deeper economic understanding, and enhanced regulatory compliance tooling.\n",
        "\n",
        "**Future Directions:**\n",
        "\n",
        "The foundation laid by PyFlow could be extended towards:\n",
        "\n",
        "*   Real-time monitoring and alerting systems for PYUSD anomalies.\n",
        "*   Integration with machine learning models for predictive analytics (e.g., fraud detection, flow prediction).\n",
        "*   Building user-friendly dashboards (like the suggested Streamlit app) for specific analytical tasks.\n",
        "*   Cross-chain analysis, leveraging GCP's potential support for other blockchains.\n",
        "*  Cryptographic State Verification: Proving historical state using Merkle proofs (`eth_getProof`).\n",
        "\n",
        "\n",
        "In conclusion, **PyFlow serves as a powerful testament to how Google Cloud's Blockchain Node Engine removes economic barriers to sophisticated blockchain analysis, unlocking a new level of transparency and understanding for critical assets like PYUSD.**"
      ],
      "metadata": {
        "id": "_SNNpQIE8MAw"
      }
    }
  ]
}