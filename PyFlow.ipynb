{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPVOz3xj9/yb/1xJmGC/CX5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìä PyFlow: Deep PYUSD Analysis with Google Cloud's Premium RPC Methods\n",
        "\n",
        "**Hackathon Context:** This notebook is developed for the **PayPal x Google Cloud Web3 Bounty**, demonstrating how **Google Cloud Platform's Blockchain Node Engine** unlocks powerful, cost-effective analysis of the **PayPal USD (PYUSD)** stablecoin on Ethereum.\n",
        "\n",
        "---\n",
        "\n",
        "## The Challenge: Unlocking Deep Blockchain Insights\n",
        "\n",
        "Understanding the intricate movements, internal logic, and real-world interactions of stablecoins like **PYUSD** often requires deep, computationally intensive blockchain analysis. Standard block explorers and basic RPC calls provide only surface-level data, while accessing advanced tracing and state inspection methods on most platforms is prohibitively expensive or heavily rate-limited due to their high computational demands.\n",
        "\n",
        "## The Solution: PyFlow leveraging GCP's Advantage\n",
        "\n",
        "This notebook, **PyFlow**, provides a comprehensive toolkit for advanced PYUSD analysis by specifically utilizing **Google Cloud Platform's premium RPC debug and trace methods**.\n",
        "\n",
        "> **üöÄ GCP's Unique Offering: Cost-Effective Access to High-Multiplier Methods**\n",
        ">\n",
        "> Many advanced RPC methods carry significant **request multipliers** due to their computational intensity. For example, a method with a `50x` multiplier consumes the equivalent quota/cost of 50 basic calls (like `eth_call`). Methods like `trace_replayTransaction` have an even higher `100x` multiplier.\n",
        ">\n",
        "> **GCP's Blockchain Node Engine stands out by offering generous free quotas even for these high-multiplier methods**, effectively democratizing access to capabilities previously reserved for specialized infrastructure or high budgets.\n",
        "\n",
        "This allows PyFlow to perform analysis typically infeasible elsewhere, such as:\n",
        "\n",
        "*   **Forensic Accounting:** Tracing PYUSD flow through complex multi-contract DeFi interactions using methods like `debug_traceTransaction` (`50x`).\n",
        "*   **Gas Optimization Analysis:** Pinpointing exact gas costs within internal PYUSD functions or integrations.\n",
        "*   **Security Investigations:** Replaying failed transactions (`trace_replayTransaction`, `100x`) or examining state changes (`stateDiff` via replay).\n",
        "*   **Smart Contract Auditing:** Verifying internal logic, storage layout (`debug_storageRangeAt`, `50x`), and event emission (`eth_getLogs`, `50x`).\n",
        "*   **Network Health Insights:** Analyzing pending transaction queues (`txpool_status`, `50x`) and estimating confirmation times.\n",
        "\n",
        "## üõ†Ô∏è Methods Explored (with GCP Request Multipliers):\n",
        "\n",
        "This notebook provides practical implementations and analysis using the following GCP-powered methods for PYUSD on Ethereum. Multipliers indicate the relative request cost compared to a standard call:\n",
        "\n",
        "*   **Detailed Tracing:**\n",
        "    *   `debug_traceTransaction` (`50x`): In-depth EVM execution trace (using `callTracer` & `structLog`).\n",
        "    *   `trace_transaction` (`50x`): Alternative transaction tracing method.\n",
        "*   **Block-Level Analysis:**\n",
        "    *   `trace_block` (`50x`, Mainnet only): Trace all transactions within a specified block.\n",
        "    *   `debug_traceBlockByNumber` / `debug_traceBlockByHash` (`50x`): Alternative block tracing.\n",
        "*   **State Replay & Simulation:**\n",
        "    *   `trace_replayTransaction` (`100x`, Mainnet only): Re-execute a past transaction with tracers.\n",
        "    *   `trace_replayBlockTransactions` (`100x`, Mainnet only): Re-execute all transactions in a block with tracers.\n",
        "    *   `trace_call` (`50x`, Mainnet only): Simulate transaction calls without sending to the network.\n",
        "*   **State & Data Retrieval:**\n",
        "    *   `eth_getLogs` (`50x`): Efficiently fetch specific PYUSD events (e.g., Transfers, Approvals).\n",
        "    *   `eth_getCode` (`10x`): Retrieve deployed contract bytecode.\n",
        "    *   `debug_storageRangeAt` (`50x`): Inspect raw contract storage slots.\n",
        "    *   `eth_getProof` (`50x`): Fetch Merkle proofs for state verification.\n",
        "*   **Network Monitoring:**\n",
        "    *   `txpool_status` (`50x`): Analyze pending/queued transaction counts.\n",
        "\n",
        "*(Note: Multipliers are based on GCP documentation and highlight the computational intensity absorbed by the service.)*\n",
        "\n",
        "---\n",
        "\n",
        "**üí° Goal:** By the end of this notebook, you will understand how to leverage GCP's unique RPC capabilities, including high-multiplier methods offered with generous quotas, to perform advanced, cost-effective blockchain intelligence specifically tailored for the PYUSD stablecoin.\n"
      ],
      "metadata": {
        "id": "F-UdW5sIniuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Environment Setup: Installing Dependencies for PyFlow\n",
        "---\n",
        "\n",
        "This cell installs the necessary Python packages to run the PyFlow analysis notebook. It sets up a complete environment for interacting with the Ethereum blockchain (via GCP), analyzing PYUSD data, generating visualizations, and connecting to Google Cloud services.\n",
        "\n",
        "### üìä Key Dependencies & Purpose:\n",
        "\n",
        "| Category                 | Packages                                                       | Purpose                                                             |\n",
        "| :----------------------- | :------------------------------------------------------------- | :------------------------------------------------------------------ |\n",
        "| **Core Blockchain/Data** | `web3`, `pandas`, `numpy`                                    | Ethereum RPC interaction, data manipulation                         |\n",
        "| **Visualization**        | `matplotlib`, `plotly`, `seaborn`, `networkx`, `graphviz`    | Charts, transaction graphs, visual analysis                         |\n",
        "| **Google Cloud**         |  `gspread`, `oauth2client` | Accessing Google Sheets export, Authentication |\n",
        "| **Ethereum Utilities**   | `eth-utils`, `rlp`, `tqdm`                                   | Cryptographic functions, RLP encoding, progress bars                |\n",
        "| **Notebook Enhancement** | `ipywidgets`, `rich`                                         | Interactive controls, improved console output                     |\n",
        "\n",
        "### ‚öôÔ∏è Runtime Notes:\n",
        "\n",
        "*   **Environment:** Designed primarily for Google Colab.\n",
        "*   **Resources:** A standard Colab runtime is usually sufficient, but a High-RAM runtime is recommended for analyzing very large blocks or complex transaction traces. GPU is generally not required.\n",
        "*   **Colab Features:** The setup automatically installs system-level `graphviz` and enables interactive data tables within Colab.\n",
        "\n",
        "> **‚è≥ Installation Time:** The process uses `pip` and typically completes in **1-2 minutes**. Please ensure this cell executes successfully before proceeding."
      ],
      "metadata": {
        "id": "Zn0aZAlQop7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üõ†Ô∏è Environment Setup and Package Installation\n",
        "# =============================================================================================\n",
        "# This cell installs and configures all necessary packages for blockchain data analysis.\n",
        "# The setup process may take 1-2 minutes to complete.\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",          # Informational messages\n",
        "    \"success\": \"spring_green3\", # Success indicators\n",
        "    \"warning\": \"gold3\",       # Warning messages\n",
        "    \"error\": \"red3\",          # Error messages\n",
        "    \"highlight\": \"royal_blue1\"  # Highlighted information\n",
        "})\n",
        "\n",
        "# Create console with auto color system detection for better visual feedback\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "console.print(\"\\n‚ú® Environment Setup and Package Installation ‚ú®\", style=\"bold cyan3\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "console.print(\"üîÑ Starting package installation process...\", style=\"info\")\n",
        "\n",
        "# Function to install packages and handle errors with better formatting\n",
        "# This provides visual feedback during the installation process\n",
        "def install_packages(packages, description):\n",
        "    \"\"\"Install specified packages with progress indicator and error handling\"\"\"\n",
        "    with Progress(\n",
        "        SpinnerColumn(),\n",
        "        TextColumn(f\"[info]Installing {description}...\"),\n",
        "        transient=True,\n",
        "    ) as progress:\n",
        "        task = progress.add_task(\"\", total=None)\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages.split())\n",
        "            console.print(f\"‚úì {description} installed\", style=\"success\")\n",
        "            return True\n",
        "        except subprocess.CalledProcessError:\n",
        "            console.print(f\"‚ùå Error installing {description}\", style=\"error\")\n",
        "            return False\n",
        "\n",
        "# =============================================================================================\n",
        "# Core Libraries Installation\n",
        "# =============================================================================================\n",
        "\n",
        "# Install core data processing libraries\n",
        "# - web3: For blockchain interaction and smart contract calls\n",
        "# - pandas: For data manipulation and analysis\n",
        "# - numpy: For numerical operations\n",
        "# - matplotlib: For basic visualization\n",
        "success = install_packages(\"web3==6.11.1 pandas numpy matplotlib\",\n",
        "                         \"Core data libraries (web3, pandas, numpy, matplotlib)\")\n",
        "\n",
        "# Install advanced visualization and analysis libraries\n",
        "# - plotly: For interactive charts\n",
        "# - seaborn: For statistical visualizations\n",
        "# - networkx: For blockchain transaction network analysis\n",
        "if success:\n",
        "    success = install_packages(\"plotly seaborn networkx\",\n",
        "                             \"Visualization and analysis libraries (plotly, seaborn, networkx)\")\n",
        "\n",
        "# Install visualization export libraries\n",
        "# - kaleido: For high-quality Plotly chart exports to PNG/PDF/SVG\n",
        "if success:\n",
        "    success = install_packages(\"kaleido\",\n",
        "                             \"Visualization export library (required for exporting charts to images)\")\n",
        "\n",
        "# Install Google API libraries for data access and storage\n",
        "# - gspread: For Google Sheets integration\n",
        "# - oauth2client: For authentication with Google services\n",
        "if success:\n",
        "    success = install_packages(\"gspread oauth2client\",\n",
        "                             \"Google API libraries (gspread, oauth2client)\")\n",
        "\n",
        "# Install interactive widgets for Jupyter/Colab notebooks\n",
        "# - ipywidgets: For creating interactive controls and dashboards\n",
        "if success:\n",
        "    success = install_packages(\"ipywidgets\",\n",
        "                             \"Interactive widgets for Jupyter notebooks\")\n",
        "\n",
        "# Install Ethereum proof verification and analysis libraries\n",
        "# - eth-utils: For cryptographic functions and general Ethereum utilities\n",
        "# - rlp: For Recursive Length Prefix encoding used in Ethereum\n",
        "# - tqdm: For progress visualization in notebook environments\n",
        "# - graphviz: For visualizing Merkle proofs and contract structures\n",
        "if success:\n",
        "    success = install_packages(\"eth-utils rlp tqdm graphviz\",\n",
        "                             \"Ethereum proof verification libraries\")\n",
        "\n",
        "# For Colab environments, install system-level graphviz for visualization\n",
        "\n",
        "try:\n",
        "    # Check if running in Google Colab\n",
        "    import google.colab\n",
        "    console.print(\"\\n\\nüîÑ Installing system dependencies for visualization...\", style=\"info\")\n",
        "    # Install graphviz system package (used for rendering graphs)\n",
        "    subprocess.check_call(['apt-get', '-qq', 'install', 'graphviz'])\n",
        "    console.print(\"‚úì System-level graphviz installed for advanced visualizations\", style=\"success\")\n",
        "\n",
        "    # Enable enhanced data visualization and export capabilities\n",
        "    console.print(\"\\n\\nüîÑ Enabling enhanced data visualization and export...\", style=\"info\")\n",
        "\n",
        "    # Enable interactive data tables from Google Colab\n",
        "    try:\n",
        "        from google.colab import data_table\n",
        "        data_table.enable_dataframe_formatter()\n",
        "        console.print(\"‚úì Interactive data tables enabled\", style=\"success\")\n",
        "    except ImportError:\n",
        "        console.print(\"‚ö†Ô∏è Could not enable interactive data tables\", style=\"warning\")\n",
        "\n",
        "    # Import additional components for file exports and Google Sheets integration\n",
        "    try:\n",
        "        # For direct CSV/JSON downloads\n",
        "        import base64\n",
        "        import io\n",
        "\n",
        "        # For Google Sheets export\n",
        "        from google.colab import output\n",
        "        from googleapiclient.discovery import build\n",
        "        from googleapiclient.http import MediaInMemoryUpload\n",
        "\n",
        "        console.print(\"‚úì Export functionality enabled\", style=\"success\")\n",
        "    except ImportError:\n",
        "        console.print(\"‚ö†Ô∏è Some export functions may be limited\", style=\"warning\")\n",
        "\n",
        "    # Verify data table display\n",
        "    try:\n",
        "        from IPython.display import display, HTML\n",
        "        console.print(\"‚úì Data table display verified\", style=\"success\")\n",
        "    except:\n",
        "        console.print(\"‚ö†Ô∏è Data table display verification failed\", style=\"warning\")\n",
        "\n",
        "except ImportError:\n",
        "    console.print(\"‚ÑπÔ∏è Not running in Colab, skipping system-level installations\", style=\"info\")\n",
        "except Exception as e:\n",
        "    console.print(f\"‚ö†Ô∏è Note: Could not install graphviz system package: {e}. Some visualizations may be limited.\", style=\"warning\")\n",
        "\n",
        "# Final status message with extra spacing\n",
        "if success:\n",
        "    console.print(\"\\n\\nüì¶ ‚úì All required packages installed successfully!\", style=\"success\")\n",
        "else:\n",
        "    console.print(\"\\n\\n‚ö†Ô∏è [bold]Some packages failed to install. Please check the errors above.[/bold]\", style=\"warning\")\n",
        "\n",
        "# =============================================================================================\n",
        "# Environment Verification\n",
        "# =============================================================================================\n",
        "# Verify all packages imported correctly and set up the analytics environment\n",
        "\n",
        "try:\n",
        "    # Core data and utility libraries\n",
        "    import os\n",
        "    import json\n",
        "    import time\n",
        "    import warnings\n",
        "    import hashlib\n",
        "\n",
        "    # Data analysis stack\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "\n",
        "    # Network and graph analysis\n",
        "    import networkx as nx\n",
        "\n",
        "    # Visualization libraries\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "\n",
        "    # Date handling\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    # Collections and data structures\n",
        "    from collections import defaultdict, Counter\n",
        "\n",
        "    # Blockchain interaction libraries\n",
        "    from web3 import Web3\n",
        "    from web3.exceptions import TransactionNotFound\n",
        "    from web3.middleware import geth_poa_middleware\n",
        "    from hexbytes import HexBytes\n",
        "\n",
        "    # Google Cloud and authentication (for gspread)\n",
        "    from google.colab import auth # Kept for potential gspread auth if needed in Colab\n",
        "    from google.oauth2 import service_account\n",
        "    import gspread\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "    # Import ipywidgets components for interactive dashboards\n",
        "    import ipywidgets as widgets\n",
        "    from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "    # Rich components for improved CLI-style output\n",
        "    from rich.panel import Panel\n",
        "    from rich.syntax import Syntax\n",
        "    from rich.table import Table\n",
        "\n",
        "    # Ethereum specific utilities for cryptography and data structures\n",
        "    from eth_utils import keccak, to_bytes, to_hex\n",
        "    import rlp\n",
        "    from tqdm.notebook import tqdm\n",
        "    from graphviz import Digraph\n",
        "\n",
        "    # Suppress warnings for cleaner output\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # Configure pandas display settings for better readability\n",
        "    pd.set_option('display.max_columns', None)  # Show all columns\n",
        "    pd.set_option('display.max_rows', 100)      # Reasonable number of rows\n",
        "    pd.set_option('display.float_format', '{:.6f}'.format)  # Format for amounts\n",
        "\n",
        "    # Setup Plotly for better Jupyter/Colab integration\n",
        "    import plotly.io as pio\n",
        "    pio.templates.default = \"plotly_white\"\n",
        "\n",
        "    console.print(\"\\n\\nüöÄ ‚úì Setup complete! Analytics platform initialized.\", style=\"success\")\n",
        "except ImportError as e:\n",
        "    console.print(f\"\\n\\n‚ùå Error importing libraries: {e}\", style=\"error\")\n",
        "    console.print(\"‚ö†Ô∏è Some required packages may not have been installed correctly.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "jDFZ9R4Iotee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Configuration & Authentication: Connecting to GCP and Ethereum RPC\n",
        "---\n",
        "\n",
        "This crucial cell configures PyFlow to connect to Google Cloud Platform services (for authentication and Google Sheets) and the necessary Ethereum networks via GCP's Blockchain Node Engine. **You MUST edit this cell with your specific credentials before running it.**\n",
        "\n",
        "### üìã Step 1: Provide Your GCP Credentials\n",
        "\n",
        "To use GCP's Blockchain RPC and potentially Google Sheets, you need:\n",
        "\n",
        "1.  **Your GCP Project ID:**\n",
        "    *   **Purpose:** Identifies your Google Cloud project, primarily used here to scope authentication requests for Google Drive/Sheets access.\n",
        "    *   **How to Obtain:** If you don't have one, create it at [GCP Console](https://console.cloud.google.com/projectcreate).\n",
        "    *   **‚û°Ô∏è ACTION REQUIRED:** Find the `GCP_PROJECT_ID` variable in the code below and replace `\"YOUR_PROJECT_ID\"` with your actual Project ID string.\n",
        "2.  **Your GCP Blockchain RPC Endpoints (with API Key):**\n",
        "    *   **Purpose:** Secure URLs to connect to Ethereum Mainnet and testnets via GCP. This is key to interacting with the blockchain using `web3.py`.\n",
        "    *   **How to Obtain:**\n",
        "        1.  Go to the [GCP Blockchain Node Engine Console](https://console.cloud.google.com/blockchain/node-engine) in your project.\n",
        "        2.  Enable the API if you haven't already.\n",
        "        3.  Copy the **full HTTPS RPC endpoint URL** (including `?key=...`) for **Ethereum Mainnet**. Optionally, copy URLs for testnets (Holesky, Sepolia) if needed.\n",
        "    *   **‚û°Ô∏è ACTION REQUIRED:** Find the `BLOCKCHAIN_RPC` dictionary in the code below. Replace the placeholder URLs (e.g., `\"https://blockchain.googleapis.com/...\"`) with your *complete* copied endpoint URLs for `'mainnet'`, `'holesky'`, and `'sepolia'`.\n",
        "\n",
        "    *Example Format (Use your actual URLs):*\n",
        "    ```python\n",
        "    BLOCKCHAIN_RPC = {\n",
        "        'ethereum': {\n",
        "            'mainnet': 'https://YOUR_MAINNET_ENDPOINT_URL?key=YOUR_API_KEY',\n",
        "            # Optional testnets:\n",
        "            'holesky': 'https://YOUR_HOLESKY_ENDPOINT_URL?key=YOUR_API_KEY',\n",
        "            'sepolia': 'https://YOUR_SEPOLIA_ENDPOINT_URL?key=YOUR_API_KEY'\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "\n",
        "### üåê Step 2: Enable Required GCP APIs\n",
        "\n",
        "Ensure the following APIs are **enabled** in your GCP Project *before* running this cell for authentication and Google Sheets integration to work correctly:\n",
        "\n",
        "*   **Blockchain Node Engine API:** ([Enable Link](Coming Soon))\n",
        "*   **Google Drive API:** Required for Google Sheets export/import functionality via `gspread`. ([Enable Link](https://console.cloud.google.com/apis/library/drive.googleapis.com))\n",
        "*   **Google Sheets API:** Required for Google Sheets export/import functionality via `gspread`. ([Enable Link](https://console.cloud.google.com/apis/library/sheets.googleapis.com))\n",
        "\n",
        "> #### **üí°Tip: Follow README for Video Instructions.**\n",
        "\n",
        "### üîê Step 3: Run the Cell & Authenticate\n",
        "\n",
        "When you execute the code cell below:\n",
        "\n",
        "1.  It will define constants (like PYUSD contract addresses) and configurations (trace settings).\n",
        "2.  It will attempt to **authenticate** your Google account (via a pop-up in Colab) to grant access to the enabled GCP services needed for Google Sheets (Drive, Sheets). Follow the prompts.\n",
        "3.  It will initialize `web3.py` clients using your provided RPC endpoints.\n",
        "4.  It will initialize a client for Google Sheets (`gspread`).\n",
        "5.  It will perform **connection tests** (check RPC node block height) and display a status summary.\n",
        "\n",
        "> **‚ö†Ô∏è IMPORTANT:** Double-check that you have replaced the placeholder `GCP_PROJECT_ID` and the **full** `BLOCKCHAIN_RPC` URLs before running. The notebook relies heavily on a successful connection to the **Ethereum Mainnet** endpoint via GCP for most subsequent analysis."
      ],
      "metadata": {
        "id": "caZ8zeBkpW9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üìã Configuration and Authentication for Blockchain Analytics\n",
        "# =============================================================================================\n",
        "# This cell configures & Authenticates for blockchain data analysis.\n",
        "\n",
        "# Import necessary libraries\n",
        "import google.auth\n",
        "\n",
        "try:\n",
        "    from google.colab import auth\n",
        "except ImportError:\n",
        "    auth = None\n",
        "    print(\"Note: Not running in Google Colab, standard gcloud auth will be used if available.\")\n",
        "\n",
        "import gspread\n",
        "from web3 import Web3\n",
        "from web3.middleware import geth_poa_middleware\n",
        "from rich.console import Console\n",
        "from rich.theme import Theme\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn, TimeElapsedColumn\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",\n",
        "    \"success\": \"spring_green3\",\n",
        "    \"warning\": \"gold3\",\n",
        "    \"error\": \"red3\",\n",
        "    \"highlight\": \"royal_blue1\"\n",
        "})\n",
        "\n",
        "# Ensure console is created with the theme\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# =============================================================================================\n",
        "# Contract Configuration: PYUSD Stablecoin Addresses\n",
        "# =============================================================================================\n",
        "\n",
        "# Main PYUSD Contract addresses (used for querying transactions and events)\n",
        "PYUSD_PROXY = Web3.to_checksum_address('0x6c3ea9036406852006290770bedfcaba0e23a0e8')\n",
        "PYUSD_IMPLEMENTATION = Web3.to_checksum_address('0x8EcaE0B0402E29694B3Af35d5943D4631Ee568dC')\n",
        "SUPPLY_CONTROL_PROXY = Web3.to_checksum_address('0x31d9bDEa6F104606C954f8FE6ba614F1BD347Ec3')\n",
        "SUPPLY_CONTROL_IMPLEMENTATION = Web3.to_checksum_address('0xFaB5891ED867a1195303251912013b92c4fc3a1D')\n",
        "\n",
        "# PYUSD Contract Registry with implementation contracts\n",
        "PYUSD_CONTRACTS = {\n",
        "    PYUSD_PROXY.lower(): \"PYUSD Token\",\n",
        "    PYUSD_IMPLEMENTATION.lower(): \"PYUSD Implementation\",\n",
        "    SUPPLY_CONTROL_PROXY.lower(): \"Supply Control\",\n",
        "    SUPPLY_CONTROL_IMPLEMENTATION.lower(): \"Supply Control Impl\"\n",
        "}\n",
        "\n",
        "# Define event topics first\n",
        "TRANSFER_EVENT_TOPIC = Web3.keccak(text=\"Transfer(address,address,uint256)\").hex()\n",
        "APPROVAL_EVENT_TOPIC = Web3.keccak(text=\"Approval(address,address,uint256)\").hex()\n",
        "PAUSED_EVENT_TOPIC = Web3.keccak(text=\"Paused(address)\").hex()\n",
        "UNPAUSED_EVENT_TOPIC = Web3.keccak(text=\"Unpaused(address)\").hex()\n",
        "\n",
        "# Comprehensive PYUSD configuration\n",
        "PYUSD_CONFIG = {\n",
        "    'ethereum': {\n",
        "        'address': PYUSD_PROXY,\n",
        "        'implementation': PYUSD_IMPLEMENTATION,\n",
        "        'decimals': 6,\n",
        "        'symbol': 'PYUSD',\n",
        "        'deployment_block': 15921958,\n",
        "        'transfer_event_topic': TRANSFER_EVENT_TOPIC,\n",
        "        'approval_event_topic': APPROVAL_EVENT_TOPIC,\n",
        "        'pause_event_topic': PAUSED_EVENT_TOPIC,\n",
        "        'unpause_event_topic': UNPAUSED_EVENT_TOPIC\n",
        "    }\n",
        "}\n",
        "\n",
        "PYUSD_ADDRESS_LOWER_ETH = PYUSD_CONFIG['ethereum']['address'].lower()\n",
        "\n",
        "# PYUSD Function Signature Registry\n",
        "PYUSD_SIGNATURES = {\n",
        "    '0xa9059cbb': {\"name\": \"transfer(address,uint256)\", \"type\": \"function\", \"category\": \"token_movement\"},\n",
        "    '0x095ea7b3': {\"name\": \"approve(address,uint256)\", \"type\": \"function\", \"category\": \"allowance\"},\n",
        "    '0x23b872dd': {\"name\": \"transferFrom(address,address,uint256)\", \"type\": \"function\", \"category\": \"token_movement\"},\n",
        "    '0x40c10f19': {\"name\": \"mint(address,uint256)\", \"type\": \"function\", \"category\": \"supply_change\"},\n",
        "    '0x42966c68': {\"name\": \"burn(uint256)\", \"type\": \"function\", \"category\": \"supply_change\"},\n",
        "    '0x18160ddd': {\"name\": \"totalSupply()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x70a08231': {\"name\": \"balanceOf(address)\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0xdd62ed3e': {\"name\": \"allowance(address,address)\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x313ce567': {\"name\": \"decimals()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x06fdde03': {\"name\": \"name()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x95d89b41': {\"name\": \"symbol()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x8456cb59': {\"name\": \"pause()\", \"type\": \"function\", \"category\": \"control\"},\n",
        "    '0x3f4ba83a': {\"name\": \"unpause()\", \"type\": \"function\", \"category\": \"control\"},\n",
        "    '0x5c975abb': {\"name\": \"paused()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0xf2fde38b': {\"name\": \"transferOwnership(address)\", \"type\": \"function\", \"category\": \"admin\"},\n",
        "    '0x8da5cb5b': {\"name\": \"owner()\", \"type\": \"function\", \"category\": \"view\"},\n",
        "    '0x715018a6': {\"name\": \"renounceOwnership()\", \"type\": \"function\", \"category\": \"admin\"}\n",
        "}\n",
        "\n",
        "# PYUSD Event Signature Registry with decoders - using the defined event topics\n",
        "PYUSD_EVENTS = {\n",
        "    TRANSFER_EVENT_TOPIC: {\n",
        "        \"name\": \"Transfer(address,address,uint256)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"from\": Web3.to_checksum_address('0x' + topics[1][-40:]),\n",
        "            \"to\": Web3.to_checksum_address('0x' + topics[2][-40:]),\n",
        "            \"value\": int(data, 16)\n",
        "        }\n",
        "    },\n",
        "    APPROVAL_EVENT_TOPIC: {\n",
        "        \"name\": \"Approval(address,address,uint256)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"owner\": Web3.to_checksum_address('0x' + topics[1][-40:]),\n",
        "            \"spender\": Web3.to_checksum_address('0x' + topics[2][-40:]),\n",
        "            \"value\": int(data, 16)\n",
        "        }\n",
        "    },\n",
        "    PAUSED_EVENT_TOPIC: {\n",
        "        \"name\": \"Paused(address)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"account\": Web3.to_checksum_address('0x' + topics[1][-40:]) if len(topics) > 1 else None\n",
        "        }\n",
        "    },\n",
        "    UNPAUSED_EVENT_TOPIC: {\n",
        "        \"name\": \"Unpaused(address)\",\n",
        "        \"decoder\": lambda topics, data: {\n",
        "            \"account\": Web3.to_checksum_address('0x' + topics[1][-40:]) if len(topics) > 1 else None\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Tracing configurations\n",
        "TRACE_CONFIGS = {\n",
        "    \"callTracer\": {\n",
        "        \"withLog\": True,\n",
        "        \"enableReturnData\": True,\n",
        "        \"enableMemory\": True,\n",
        "        \"enableStack\": True\n",
        "    },\n",
        "    \"structLog\": {\n",
        "        \"disableStorage\": False,\n",
        "        \"disableMemory\": False,\n",
        "        \"disableStack\": False,\n",
        "        \"fullStorage\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "# Gas analysis categories\n",
        "GAS_CATEGORIES = {\n",
        "    \"token_movement\": [\"transfer\", \"transferFrom\"],\n",
        "    \"supply_change\": [\"mint\", \"burn\"],\n",
        "    \"allowance\": [\"approve\", \"increaseAllowance\", \"decreaseAllowance\"],\n",
        "    \"control\": [\"pause\", \"unpause\"],\n",
        "    \"admin\": [\"transferOwnership\", \"renounceOwnership\", \"addMinter\", \"removeMinter\"],\n",
        "    \"view\": [\"balanceOf\", \"allowance\", \"totalSupply\", \"decimals\", \"name\", \"symbol\", \"paused\", \"owner\"],\n",
        "    \"other\": []\n",
        "}\n",
        "\n",
        "\n",
        "# =============================================================================================\n",
        "# Data Source Configuration: Google Cloud & Blockchain RPC\n",
        "# =============================================================================================\n",
        "\n",
        "# Replace \"YOUR_PROJECT_ID\" with your actual GCP Project ID (needed for GSheets auth scope)\n",
        "GCP_PROJECT_ID = \"YOUR_PROJECT_ID\"\n",
        "if \"YOUR_PROJECT_ID\" in GCP_PROJECT_ID or not GCP_PROJECT_ID:\n",
        "    console.print(\"[error]üö® CRITICAL: Please replace placeholder or provide your actual GCP Project ID in GCP_PROJECT_ID.\", style=\"bold red\")\n",
        "\n",
        "# Replace \"YOUR_MAINNET_BLOCKCHAIN_RPC_URL\", \"YOUR_HOLESKY_BLOCKCHAIN_RPC_URL\", \"YOUR_SEPOLIA_BLOCKCHAIN_RPC_URL\" with your FULL RPC endpoint URLs including your API key.\n",
        "# e.g., 'mainnet': 'https://blockchain.googleapis.com/v1/projects/...........'\n",
        "BLOCKCHAIN_RPC = {\n",
        "    'ethereum': {\n",
        "        'holesky': 'YOUR_HOLESKY_BLOCKCHAIN_RPC_URL',\n",
        "        'mainnet': 'YOUR_MAINNET_BLOCKCHAIN_RPC_URL',\n",
        "        'sepolia': 'YOUR_SEPOLIA_BLOCKCHAIN_RPC_URL'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Basic Validation checks for placeholders in URLs\n",
        "rpc_urls_valid = True\n",
        "if 'ethereum' not in BLOCKCHAIN_RPC or not BLOCKCHAIN_RPC['ethereum']: # Check if ethereum key exists and has entries\n",
        "    console.print(\"[error]üö® CRITICAL: BLOCKCHAIN_RPC['ethereum'] is missing or empty.\", style=\"bold red\")\n",
        "    rpc_urls_valid = False\n",
        "else:\n",
        "    for network, url in BLOCKCHAIN_RPC.get('ethereum', {}).items():\n",
        "        # More robust check for placeholders or incomplete URLs\n",
        "        if not url or \"xxx\" in url.lower() or \"/v1/\" not in url or \"key=\" not in url or url.endswith(\"key=\"):\n",
        "            console.print(f\"[error]üö® CRITICAL: RPC URL for '{network}' seems invalid or uses placeholder ('{url}'). Use full URL with API key.\", style=\"bold red\")\n",
        "            rpc_urls_valid = False\n",
        "\n",
        "# Transaction tracing configuration (for detailed transaction analysis)\n",
        "# Increased timeout for complex traces\n",
        "DEFAULT_TRACE_CONFIG = {\n",
        "    'tracer': 'callTracer',\n",
        "    'timeout': '120s',\n",
        "    'tracerConfig': {\n",
        "        'onlyTopCall': False,\n",
        "        'withLog': True,\n",
        "    }\n",
        "}\n",
        "\n",
        "STRUCTLOG_TRACE_CONFIG = {\n",
        "    'tracer': 'structLog',\n",
        "    # 'timeout': '120s',\n",
        "}\n",
        "\n",
        "# =============================================================================================\n",
        "# Global Client Variables\n",
        "# =============================================================================================\n",
        "gc_sheets = None\n",
        "w3_clients = {}\n",
        "\n",
        "# =============================================================================================\n",
        "# Utility Functions: Testing & System Verification\n",
        "# =============================================================================================\n",
        "\n",
        "def authenticate_gcp(progress, task_id):\n",
        "    \"\"\"Authenticate to GCP, initialize Google Sheets client (updates progress descriptively).\"\"\"\n",
        "    global gc_sheets\n",
        "    progress.update(task_id, description=\"[info]Initiating GCP Authentication...\")\n",
        "    if not GCP_PROJECT_ID or \"project_id\" in GCP_PROJECT_ID:\n",
        "         progress.update(task_id, description=\"[error]GCP Auth Failed (No Project ID)\")\n",
        "         return False\n",
        "    auth_success = False\n",
        "    gs_init_success = False\n",
        "    effective_project_id = GCP_PROJECT_ID\n",
        "\n",
        "    try:\n",
        "        # Step 1: Authentication (Colab vs. Default)\n",
        "        creds = None\n",
        "        if auth: # If google.colab.auth was imported successfully\n",
        "            progress.update(task_id, description=\"[info]Waiting for Colab user authentication...\")\n",
        "            auth.authenticate_user(project_id=effective_project_id) # Use project ID here if needed by Colab auth context\n",
        "            auth_success = True\n",
        "            progress.update(task_id, description=\"[info]Colab user authenticated. Getting credentials...\")\n",
        "            creds, _ = google.auth.default() # Get default credentials after Colab auth\n",
        "        else:\n",
        "            # Attempt standard ADC (Application Default Credentials) - works in VM, Cloud Shell, local gcloud auth login\n",
        "            progress.update(task_id, description=\"[info]Attempting default GCP authentication...\")\n",
        "            try:\n",
        "                creds, inferred_project_id = google.auth.default()\n",
        "                if not creds:\n",
        "                     raise Exception(\"Could not get default credentials.\")\n",
        "                auth_success = True\n",
        "                progress.update(task_id, description=\"[info]Default GCP credentials obtained.\")\n",
        "            except Exception as adc_error:\n",
        "                progress.update(task_id, description=\"[error]Default GCP Authentication Failed!\")\n",
        "                console.print(f\"‚ùå Default GCP Auth error: {adc_error}\", style=\"error\")\n",
        "                return False # Hard stop if auth fails\n",
        "\n",
        "        # Ensure we have credentials before proceeding\n",
        "        if not creds:\n",
        "             progress.update(task_id, description=\"[error]Credentials not obtained after auth attempt.\")\n",
        "             return False\n",
        "\n",
        "        # Step 2: Initialize Google Sheets Client\n",
        "        progress.update(task_id, description=\"[info]Initializing Google Sheets client...\")\n",
        "        gc_sheets = gspread.authorize(creds)\n",
        "        # Perform a minimal check (e.g., list spreadsheets) if needed, but authorize usually suffices\n",
        "        # gc_sheets.list_spreadsheet_files(max_results=1)\n",
        "        gs_init_success = True\n",
        "\n",
        "        progress.update(task_id, description=\"[success]GCP Authentication & GSheets Client Initialized\")\n",
        "        return True # Overall success\n",
        "\n",
        "    except Exception as e:\n",
        "        error_stage = \"GCP Setup Error!\"\n",
        "        if not auth_success:\n",
        "            error_stage = \"GCP Authentication Failed!\"\n",
        "        elif not gs_init_success:\n",
        "            error_stage = \"Google Sheets Client Init Failed!\"\n",
        "        progress.update(task_id, description=f\"[error]{error_stage}\")\n",
        "        console.print(f\"‚ùå {error_stage}: {str(e)}\", style=\"error\")\n",
        "        if not gs_init_success: gc_sheets = None\n",
        "        return False\n",
        "\n",
        "\n",
        "def initialize_all_web3_clients(progress, task_id):\n",
        "    \"\"\"Initializes Web3 clients for all networks (updates progress descriptively).\"\"\"\n",
        "    global w3_clients\n",
        "    progress.update(task_id, description=\"[info]Initializing Web3 Clients...\")\n",
        "    w3_clients = {}\n",
        "    success_count = 0\n",
        "    total_networks = 0\n",
        "    if 'ethereum' not in BLOCKCHAIN_RPC or not BLOCKCHAIN_RPC['ethereum']:\n",
        "        progress.update(task_id, description=\"[error]No valid RPC Config found!\")\n",
        "        return False\n",
        "    total_networks = len(BLOCKCHAIN_RPC['ethereum'])\n",
        "    network_statuses = []\n",
        "\n",
        "    for network, rpc_url in BLOCKCHAIN_RPC['ethereum'].items():\n",
        "        progress.update(task_id, description=f\"[info]Connecting to {network.capitalize()}...\")\n",
        "        time.sleep(0.1) # Small delay for visual update\n",
        "        # Find the original url value before the loop modified it\n",
        "        original_url = BLOCKCHAIN_RPC.get('ethereum', {}).get(network, \"\")\n",
        "        is_invalid_url = not original_url or \"xxx\" in original_url.lower() or \"/v1/\" not in original_url or \"key=\" not in original_url or original_url.endswith(\"key=\")\n",
        "        if is_invalid_url:\n",
        "            w3_clients[network] = None\n",
        "            network_statuses.append(f\"{network.capitalize()}:[error]Skipped (Invalid URL)[/error]\")\n",
        "            progress.update(task_id, description=f\"[warning]Skipping {network.capitalize()} (Invalid URL)...\")\n",
        "            continue\n",
        "        try:\n",
        "            # Increased timeout slightly for potentially slower network conditions\n",
        "            provider = Web3.HTTPProvider(rpc_url, request_kwargs={'timeout': 120})\n",
        "            w3_client = Web3(provider)\n",
        "            # Inject middleware only if needed (e.g., for PoA testnets like Goerli, Rinkeby - less relevant for Mainnet/Sepolia/Holesky now)\n",
        "            # Check chain ID if necessary to decide on middleware, but generally safe to add\n",
        "            w3_client.middleware_onion.inject(geth_poa_middleware, layer=0)\n",
        "\n",
        "            # Test connection with get_block_number\n",
        "            block_num = w3_client.eth.get_block_number()\n",
        "            w3_clients[network] = w3_client\n",
        "            success_count += 1\n",
        "            network_statuses.append(f\"{network.capitalize()}:[success]OK (Block: {block_num:,})[/success]\")\n",
        "            progress.update(task_id, description=f\"[info]Connecting... ({success_count}/{total_networks} OK)\")\n",
        "        except Exception as e:\n",
        "            error_short = type(e).__name__\n",
        "            # Add more detail for common errors\n",
        "            if \"Max retries exceeded\" in str(e): error_short = \"ConnectionTimeout\"\n",
        "            elif \"Failed to establish a new connection\" in str(e): error_short = \"ConnectionRefused\"\n",
        "            network_statuses.append(f\"{network.capitalize()}:[error]{error_short}[/error]\")\n",
        "            w3_clients[network] = None\n",
        "            progress.update(task_id, description=f\"[warning]Failed {network.capitalize()} ({error_short})...\")\n",
        "            console.print(f\"[warning]Web3 connection error for {network.capitalize()}: {e}\", style=\"warning\")\n",
        "\n",
        "\n",
        "    final_web3_status = f\"[success]Web3 Clients Initialized ({success_count}/{total_networks} OK)\"\n",
        "    if success_count == 0:\n",
        "        final_web3_status = \"[error]Web3 Client Init Failed (All Networks)\"\n",
        "    elif success_count < total_networks:\n",
        "         final_web3_status = f\"[warning]Web3 Clients Initialized ({success_count}/{total_networks} OK)\"\n",
        "    progress.update(task_id, description=final_web3_status)\n",
        "\n",
        "    # Return True if mainnet client initialized successfully\n",
        "    return w3_clients.get('mainnet') is not None\n",
        "\n",
        "# =============================================================================================\n",
        "# Main Execution: System Initialization and Status Check (with Progress)\n",
        "# =============================================================================================\n",
        "\n",
        "# --- Title Display ---\n",
        "console.print(\"\\n‚ú® Configuration and Authentication ‚ú®\", style=\"bold cyan3\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "# Initialize status variables\n",
        "gcp_auth_success = False\n",
        "any_web3_success = False\n",
        "mainnet_ready = False\n",
        "\n",
        "# Use Rich Progress for initialization steps\n",
        "# Set transient=True to make the progress bar disappear on completion\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    TimeElapsedColumn(),\n",
        "    console=console, # Ensure progress uses the themed console\n",
        "    transient=True # Make spinner disappear when done\n",
        ") as progress:\n",
        "    # Add tasks for each step (total=1 means they complete in one update)\n",
        "    auth_task = progress.add_task(\"GCP Authentication...\", total=1)\n",
        "    web3_task = progress.add_task(\"Initializing Web3 Clients...\", total=1)\n",
        "\n",
        "    # --- Run Initialization Steps (functions update progress description) ---\n",
        "    gcp_auth_success = authenticate_gcp(progress, auth_task)\n",
        "    progress.update(auth_task, completed=1) # Mark as done\n",
        "\n",
        "    if rpc_urls_valid:\n",
        "        any_web3_success = initialize_all_web3_clients(progress, web3_task)\n",
        "    else:\n",
        "        progress.update(web3_task, description=\"[error]Skipped Web3 Init (Invalid URLs)\")\n",
        "    progress.update(web3_task, completed=1)\n",
        "\n",
        "\n",
        "# --- Get Final Status ---\n",
        "mainnet_ready = any_web3_success # mainnet_ready directly reflects if mainnet client succeeded\n",
        "overall_success = gcp_auth_success and mainnet_ready\n",
        "\n",
        "# --- Display Intermediate Success Messages (Now that progress is done) ---\n",
        "if gcp_auth_success:\n",
        "    console.print(f\"‚úì User authentication successful!\", style=\"success\")\n",
        "    if gc_sheets: console.print(f\"‚úì Google Sheets client initialized\", style=\"success\")\n",
        "else:\n",
        "    console.print(f\"‚ùå GCP authentication failed.\", style=\"error\")\n",
        "\n",
        "# Updated Web3 success message based on w3_clients dictionary\n",
        "if w3_clients:\n",
        "    connected_nets = [net.capitalize() for net, client in w3_clients.items() if client]\n",
        "    if connected_nets:\n",
        "        console.print(f\"‚úì Web3 clients connected: {', '.join(connected_nets)}\", style=\"success\")\n",
        "    elif rpc_urls_valid: # Only show warning if init was attempted but failed all\n",
        "         console.print(\"[warning]Web3 clients initialized, but none connected successfully.\", style=\"warning\")\n",
        "else:\n",
        "     # This case occurs if rpc_urls_valid was False\n",
        "     console.print(\"[error]Web3 client initialization skipped due to invalid RPC URLs.\", style=\"error\")\n",
        "\n",
        "\n",
        "# --- Display Final System Status Summary ---\n",
        "console.print(\"\\n\\nüìä System Status Summary\", style=\"highlight\")\n",
        "# RPC Status\n",
        "if w3_clients:\n",
        "    for network, client in w3_clients.items():\n",
        "        connected = client is not None\n",
        "        status_msg = \"[red]Failed/Skipped[/red]\" # Default if not connected\n",
        "        if connected:\n",
        "             try:\n",
        "                 block_num = client.eth.block_number # Get block number again for final status\n",
        "                 block_num_str = f\"(Block #{block_num:,})\"\n",
        "                 status_msg = f\"[green]Connected[/green] {block_num_str}\"\n",
        "             except Exception as e:\n",
        "                  # If client exists but fails here, mark as unresponsive\n",
        "                  status_msg = f\"[orange3]Unresponsive ({type(e).__name__})[/orange3]\"\n",
        "                  w3_clients[network] = None # Clear bad client for consistency\n",
        "                  console.print(f\"[warning]RPC ({network.capitalize()}) became unresponsive: {e}\", style=\"warning\")\n",
        "        else:\n",
        "            # Add reason if skipped due to invalid URL during init\n",
        "            original_url = BLOCKCHAIN_RPC.get('ethereum', {}).get(network, \"\")\n",
        "            if not original_url or \"xxx\" in original_url.lower():\n",
        "                 status_msg = \"[red]Skipped (Invalid URL)[/red]\"\n",
        "\n",
        "        console.print(f\"  ‚Ä¢ Ethereum RPC ({network.capitalize()}): {status_msg}\")\n",
        "elif not rpc_urls_valid:\n",
        "    console.print(\"  ‚Ä¢ Ethereum RPC: [red]Skipped (Invalid URLs)[/red]\")\n",
        "else:\n",
        "    console.print(\"  ‚Ä¢ Ethereum RPC: [red]Initialization Failed[/red]\")\n",
        "\n",
        "# GCP Status\n",
        "status_auth = \"[green]Successful[/green]\" if gcp_auth_success else \"[red]Failed[/red]\"\n",
        "console.print(f\"  ‚Ä¢ GCP Authentication: {status_auth}\")\n",
        "\n",
        "# Google Sheets Status\n",
        "status_gs = \"[green]Initialized[/green]\" if gc_sheets else \"[red]Not Initialized[/red]\"\n",
        "if not gcp_auth_success: # Also mark skipped if auth failed\n",
        "    status_gs = \"[yellow]Skipped[/yellow]\"\n",
        "console.print(f\"  ‚Ä¢ Google Sheets Client: {status_gs}\")\n",
        "\n",
        "# --- Final Ready/Failure Message with Checkmark ---\n",
        "if overall_success:\n",
        "    console.print(\"\\n\\n[bold green]‚úì Configuration Complete:[/bold green] System Ready for Ethereum Blockchain Analytics (via RPC) and Google Sheets\")\n",
        "    # Optional warnings for testnets can still be useful\n",
        "    if 'holesky' in w3_clients and w3_clients.get('holesky') is None: console.print(\"  [warning](Note: Holesky testnet connection failed/skipped/unresponsive)\", style=\"warning\")\n",
        "    if 'sepolia' in w3_clients and w3_clients.get('sepolia') is None: console.print(\"  [warning](Note: Sepolia testnet connection failed/skipped/unresponsive)\", style=\"warning\")\n",
        "else:\n",
        "     failure_reasons = []\n",
        "     if not gcp_auth_success: failure_reasons.append(\"GCP Auth Failed\")\n",
        "     if not w3_clients.get('mainnet'): failure_reasons.append(\"Mainnet RPC Connection Failed/Skipped\")\n",
        "     if gcp_auth_success and not gc_sheets: failure_reasons.append(\"Google Sheets Client Failed\") # Check if GSheets failed despite auth success\n",
        "     if not rpc_urls_valid: failure_reasons.append(\"Invalid RPC URL Placeholders\")\n",
        "\n",
        "\n",
        "     reason_str = ', '.join(failure_reasons) if failure_reasons else \"Unknown Issues\"\n",
        "     console.print(f\"\\n\\n[bold red]‚ùå Configuration Failed:[/bold red] System setup encountered issues ({reason_str}). Review status messages above.\")"
      ],
      "metadata": {
        "id": "PLaPz_r4paFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 üéØ Analysis Targets & Utility Functions\n",
        "---\n",
        "\n",
        "This cell handles target validation and prepares the essential utilities needed for transaction/block analysis:\n",
        "\n",
        "1.  **üåê Network Verification:**\n",
        "    *   Verifies connectivity to Ethereum Mainnet and available testnets\n",
        "    *   Displays current block heights and chain IDs\n",
        "    *   Attempts reconnection if mainnet client is unavailable\n",
        "\n",
        "2.  **üéØ Define Analysis Targets:**\n",
        "    *   Set the specific Ethereum Mainnet **transaction hash** (`TARGET_TX_HASH`) or **block identifier** (`TARGET_BLOCK_IDENTIFIER`) you wish to analyze\n",
        "    *   **ACTION:** Modify these values to analyze different transactions or blocks relevant to PYUSD\n",
        "    *   Targets are automatically validated for proper format and existence on-chain\n",
        "\n",
        "3.  **üîß Helper Function Library:**\n",
        "    *   Initializes essential functions used throughout the notebook for:\n",
        "        *   Making raw RPC requests (`make_rpc_request`) to Ethereum nodes\n",
        "        *   Decoding PYUSD-specific function calls and events\n",
        "        *   Formatting blockchain values (ETH/PYUSD amounts, gas)\n",
        "        *   Handling addresses and transaction data\n",
        "        *   Creating visualizations for transaction analysis\n",
        "\n",
        "> **Note:** If a target validation fails, specific diagnostic information will be displayed to help troubleshoot the issue."
      ],
      "metadata": {
        "id": "5vZzVowv-D0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üéØ Target Selection & Helper Functions for Tracing\n",
        "# =============================================================================================\n",
        "# This cell validates targets, initializes tracing configurations, and sets up helper functions.\n",
        "\n",
        "# Ensure web3 clients dictionary is loaded from the previous cell\n",
        "if 'w3_clients' not in locals() or not isinstance(w3_clients, dict):\n",
        "     raise NameError(\"Web3 clients dictionary 'w3_clients' not initialized. Please run 'üîë Configuration & Authentication: Connecting to GCP and Ethereum RPC' Cell\")\n",
        "\n",
        "# --- Network Status Verification ---\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    console=console,\n",
        "    transient=True\n",
        ") as progress:\n",
        "    verification_task = progress.add_task(\"[info]Verifying network connections...\", total=1)\n",
        "\n",
        "    w3_mainnet = w3_clients.get('mainnet')\n",
        "    if not w3_mainnet or not w3_mainnet.is_connected():\n",
        "         # Attempt re-initialization with visual feedback\n",
        "         progress.update(verification_task, description=\"[warning]‚ö†Ô∏è Mainnet client not found. Attempting re-initialization...\")\n",
        "         web3_task = progress.add_task(\"[info]Reinitializing Web3 clients...\", total=1)\n",
        "         initialize_all_web3_clients(progress, web3_task)\n",
        "         progress.update(web3_task, completed=1)\n",
        "\n",
        "         # Check if reconnection succeeded\n",
        "         w3_mainnet = w3_clients.get('mainnet')\n",
        "         if not w3_mainnet or not w3_mainnet.is_connected():\n",
        "              raise ConnectionError(\"Cannot proceed without a connected Mainnet Web3 client. Check your RPC endpoints.\")\n",
        "\n",
        "    # Get testnet client if available (for testing function implementations)\n",
        "    progress.update(verification_task, description=\"[info]Checking for testnet availability...\")\n",
        "    w3_testnet = w3_clients.get('sepolia') or w3_clients.get('holesky') # Prefer Sepolia if available\n",
        "    if w3_testnet and w3_testnet.is_connected():\n",
        "        # Find the network name ('holesky' or 'sepolia')\n",
        "        testnet_name = next((name for name in ['sepolia', 'holesky'] if w3_clients.get(name) == w3_testnet), None)\n",
        "    else:\n",
        "        testnet_name = None # No connections with testnet\n",
        "\n",
        "    progress.update(verification_task, completed=1)\n",
        "\n",
        "# --- Network Status Table ---\n",
        "console.print(\"[bold cyan3 size=20]üåê Network Connections[/]\", justify=\"left\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "network_table = Table(show_header=True, header_style=\"bold cyan3\")\n",
        "network_table.add_column(\"Network\", style=\"dim\")\n",
        "network_table.add_column(\"Status\", justify=\"center\")\n",
        "network_table.add_column(\"Block Height\", justify=\"right\")\n",
        "network_table.add_column(\"Chain ID\", justify=\"right\")\n",
        "\n",
        "# Add Mainnet info\n",
        "latest_block_mainnet = w3_mainnet.eth.block_number if w3_mainnet else \"N/A\"\n",
        "chain_id_mainnet = w3_mainnet.eth.chain_id if w3_mainnet else \"N/A\"\n",
        "network_table.add_row(\n",
        "    \"Ethereum Mainnet\",\n",
        "    \"[spring_green3]Connected[/spring_green3]\" if w3_mainnet and w3_mainnet.is_connected() else \"[red3]Disconnected[/red3]\",\n",
        "    f\"{latest_block_mainnet:,}\" if isinstance(latest_block_mainnet, int) else str(latest_block_mainnet),\n",
        "    str(chain_id_mainnet)\n",
        ")\n",
        "\n",
        "# Add Testnet info if available\n",
        "if testnet_name:\n",
        "    latest_block_testnet = w3_testnet.eth.block_number if w3_testnet else \"N/A\"\n",
        "    chain_id_testnet = w3_testnet.eth.chain_id if w3_testnet else \"N/A\"\n",
        "    network_table.add_row(\n",
        "        f\"{testnet_name.capitalize()} Testnet\",\n",
        "        \"[spring_green3]Connected[/spring_green3]\" if w3_testnet and w3_testnet.is_connected() else \"[red3]Disconnected[/red3]\",\n",
        "        f\"{latest_block_testnet:,}\" if isinstance(latest_block_testnet, int) else str(latest_block_testnet),\n",
        "        str(chain_id_testnet)\n",
        "    )\n",
        "else:\n",
        "    network_table.add_row(\"Testnet\", \"[gold3]Not Available[/gold3]\", \"N/A\", \"N/A\")\n",
        "\n",
        "# Display the network connection table\n",
        "console.print(network_table)\n",
        "console.print(\"\\n\\n\")  # Empty lines for better spacing\n",
        "\n",
        "############################################################\n",
        "# üéØ DEFINE YOUR ETHEREUM ANALYSIS TARGET\n",
        "# Set BOTH values below for optimal analysis capabilities.\n",
        "############################################################\n",
        "\n",
        "# Transaction Hash for analysis\n",
        "# Required by certain analysis functions.\n",
        "TARGET_TX_HASH = \"YOUR_TARGET_TX_HASH\"\n",
        "\n",
        "# Block Number/Identifier for analysis\n",
        "# Required by other analysis functions (often related to block context).\n",
        "# Use the block containing the target transaction, or the specific block you want to analyze.\n",
        "TARGET_BLOCK_IDENTIFIER = YOUR_TARGET_BLOCK_NUMBER # Or block hash, \"latest\", etc.\n",
        "\n",
        "# Important Notes:\n",
        "# - Full analysis experience requires both TARGET_TX_HASH and TARGET_BLOCK_IDENTIFIER.\n",
        "# - Some functions specifically need the block context, others the transaction details.\n",
        "# - If both values are set, TARGET_TX_HASH takes precedence in situations where\n",
        "#   only one identifier can be used as the primary target.\n",
        "############################################################\n",
        "\n",
        "# Import necessary packages for helper functions\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from graphviz import Digraph\n",
        "from IPython.display import display, Javascript\n",
        "from hexbytes import HexBytes\n",
        "from rich.panel import Panel\n",
        "from rich.syntax import Syntax\n",
        "from rich.table import Table\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Plotly configuration for Colab\n",
        "try:\n",
        "    display(Javascript('''\n",
        "        require.config({\n",
        "            paths: {\n",
        "                plotly: 'https://cdn.plot.ly/plotly-latest.min.js'\n",
        "            }\n",
        "        });\n",
        "    '''))\n",
        "except Exception as e:\n",
        "    console.print(f\"[warning]Could not re-configure Plotly: {e}\", style=\"warning\")\n",
        "\n",
        "# --- Target Validation Functions ---\n",
        "def validate_tx_hash(tx_hash):\n",
        "    \"\"\"Validates a transaction hash with detailed diagnostics\"\"\"\n",
        "    if not tx_hash:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Missing\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Transaction hash not provided\"\n",
        "        }\n",
        "\n",
        "    if not isinstance(tx_hash, str):\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Type\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Expected string, got {type(tx_hash).__name__}\"\n",
        "        }\n",
        "\n",
        "    if not tx_hash.startswith('0x'):\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Format\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Transaction hash must start with '0x'\"\n",
        "        }\n",
        "\n",
        "    if len(tx_hash) < 66:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Too Short\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Length is {len(tx_hash)}, should be 66 characters\"\n",
        "        }\n",
        "\n",
        "    if len(tx_hash) > 66:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Too Long\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': f\"Length is {len(tx_hash)}, should be 66 characters (including '0x')\"\n",
        "        }\n",
        "\n",
        "    # Check if characters are valid hex\n",
        "    try:\n",
        "        int(tx_hash[2:], 16)\n",
        "    except ValueError:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Invalid Hex\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Contains non-hexadecimal characters\"\n",
        "        }\n",
        "\n",
        "    # At this point, the format is valid, try to retrieve it\n",
        "    try:\n",
        "        tx_receipt = w3_mainnet.eth.get_transaction_receipt(tx_hash[:66])  # Truncate to valid length for retrieval\n",
        "        tx_details = w3_mainnet.eth.get_transaction(tx_hash[:66])\n",
        "\n",
        "        # Format gas info\n",
        "        gas_used = tx_receipt.get('gasUsed', 0)\n",
        "        gas_limit = tx_details.get('gas', 0)\n",
        "        gas_percentage = (gas_used / gas_limit * 100) if gas_limit else 0\n",
        "\n",
        "        # Check if transaction was successful\n",
        "        is_success = tx_receipt.get('status') == 1\n",
        "\n",
        "        return {\n",
        "            'valid': True,\n",
        "            'status': \"Found\" if is_success else \"Failed Transaction\",\n",
        "            'status_color': \"spring_green3\" if is_success else \"gold3\",\n",
        "            'details': f\"Block: {tx_receipt.get('blockNumber')}, Gas: {gas_used:,}/{gas_limit:,} ({gas_percentage:.1f}%)\",\n",
        "            'data': {\n",
        "                'receipt': tx_receipt,\n",
        "                'transaction': tx_details,\n",
        "                'success': is_success\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'valid': True,  # Format is valid but transaction not found\n",
        "            'status': \"Valid Format, Not Found\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': f\"Error: {str(e)}\"  # No truncation\n",
        "        }\n",
        "\n",
        "def validate_block_identifier(block_id):\n",
        "    \"\"\"Validates a block identifier with detailed diagnostics\"\"\"\n",
        "    if block_id is None:\n",
        "        return {\n",
        "            'valid': False,\n",
        "            'status': \"Missing\",\n",
        "            'status_color': \"red3\",\n",
        "            'details': \"Block identifier not provided\"\n",
        "        }\n",
        "\n",
        "    # For integer block numbers\n",
        "    if isinstance(block_id, int):\n",
        "        if block_id < 0:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Negative Number\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Block number cannot be negative\"\n",
        "            }\n",
        "\n",
        "        # Check if block is within realistic range\n",
        "        latest_block = w3_mainnet.eth.block_number if w3_mainnet else None\n",
        "        if latest_block and block_id > latest_block:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Future Block\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': f\"Block {block_id:,} exceeds current mainnet height ({latest_block:,})\"\n",
        "            }\n",
        "\n",
        "        # Block is valid by format, try to retrieve it\n",
        "        try:\n",
        "            block_details = w3_mainnet.eth.get_block(block_id)\n",
        "\n",
        "            # Format timestamp from Unix timestamp\n",
        "            block_time = datetime.fromtimestamp(block_details.timestamp)\n",
        "\n",
        "            return {\n",
        "                'valid': True,\n",
        "                'status': \"Found\",\n",
        "                'status_color': \"spring_green3\",\n",
        "                'details': f\"Time: {block_time.strftime('%Y-%m-%d %H:%M:%S')}, TX Count: {len(block_details['transactions'])}\",\n",
        "                'data': block_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'valid': True,  # Format is valid but block not found\n",
        "                'status': \"Valid Format, Not Found\",\n",
        "                'status_color': \"gold3\",\n",
        "                'details': f\"Error: {str(e)}\"  # No truncation\n",
        "            }\n",
        "\n",
        "    # For hex string or hash\n",
        "    if isinstance(block_id, str):\n",
        "        if not block_id.startswith('0x'):\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Invalid Format\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Block hash must start with '0x'\"\n",
        "            }\n",
        "\n",
        "        # Check if characters are valid hex\n",
        "        try:\n",
        "            int(block_id[2:], 16)\n",
        "        except ValueError:\n",
        "            return {\n",
        "                'valid': False,\n",
        "                'status': \"Invalid Hex\",\n",
        "                'status_color': \"red3\",\n",
        "                'details': \"Contains non-hexadecimal characters\"\n",
        "            }\n",
        "\n",
        "        # Block hash is valid by format, try to retrieve it\n",
        "        try:\n",
        "            block_details = w3_mainnet.eth.get_block(block_id)\n",
        "\n",
        "            # Format timestamp from Unix timestamp\n",
        "            block_time = datetime.fromtimestamp(block_details.timestamp)\n",
        "\n",
        "            return {\n",
        "                'valid': True,\n",
        "                'status': \"Found\",\n",
        "                'status_color': \"spring_green3\",\n",
        "                'details': f\"Time: {block_time.strftime('%Y-%m-%d %H:%M:%S')}, TX Count: {len(block_details['transactions'])}\",\n",
        "                'data': block_details\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'valid': True,  # Format is valid but block not found\n",
        "                'status': \"Valid Format, Not Found\",\n",
        "                'status_color': \"gold3\",\n",
        "                'details': f\"Error: {str(e)}\"  # No truncation\n",
        "            }\n",
        "\n",
        "    # If not int or str\n",
        "    return {\n",
        "        'valid': False,\n",
        "        'status': \"Invalid Type\",\n",
        "        'status_color': \"red3\",\n",
        "        'details': f\"Expected int or string, got {type(block_id).__name__}\"\n",
        "    }\n",
        "\n",
        "# --- Target Verification & Information Retrieval with progress indicator ---\n",
        "with Progress(\n",
        "    SpinnerColumn(),\n",
        "    TextColumn(\"[progress.description]{task.description}\"),\n",
        "    console=console,\n",
        "    transient=True\n",
        ") as progress:\n",
        "    validate_task = progress.add_task(\"[info]Validating analysis targets...\", total=2)\n",
        "\n",
        "    # Validate transaction hash\n",
        "    progress.update(validate_task, description=\"[info]Analyzing transaction hash...\")\n",
        "    if 'TARGET_TX_HASH' in locals() and TARGET_TX_HASH:\n",
        "        tx_validation = validate_tx_hash(TARGET_TX_HASH)\n",
        "        tx_valid = tx_validation['valid']\n",
        "    else:\n",
        "        tx_valid = False\n",
        "        tx_validation = {\n",
        "            'status': \"Skipped\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': \"No transaction hash provided\"\n",
        "        }\n",
        "\n",
        "    progress.update(validate_task, advance=1)\n",
        "\n",
        "    # Validate block identifier\n",
        "    progress.update(validate_task, description=\"[info]Analyzing block identifier...\")\n",
        "    if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "        block_validation = validate_block_identifier(TARGET_BLOCK_IDENTIFIER)\n",
        "        block_valid = block_validation['valid']\n",
        "    else:\n",
        "        block_valid = False\n",
        "        block_validation = {\n",
        "            'status': \"Skipped\",\n",
        "            'status_color': \"gold3\",\n",
        "            'details': \"No block identifier provided\"\n",
        "        }\n",
        "\n",
        "    progress.update(validate_task, completed=1)\n",
        "\n",
        "# --- Target Status Display (Key-Value Format) ---\n",
        "console.print(\"[bold royal_blue1 size=20]üéØ Analysis Targets[/]\", justify=\"left\")\n",
        "console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"royal_blue1\")\n",
        "console.print(\"\\n\")  # Extra spacing\n",
        "\n",
        "# Transaction Target\n",
        "console.print(\"[bold]Target Type - Transaction Hash[/bold]\")\n",
        "if 'TARGET_TX_HASH' in locals() and TARGET_TX_HASH:\n",
        "    console.print(f\"[dim]Value:[/dim] [cyan3]{TARGET_TX_HASH}[/cyan3]\")\n",
        "else:\n",
        "    console.print(\"[dim]Value:[/dim] Nil\")\n",
        "\n",
        "console.print(f\"[dim]Status:[/dim] [{tx_validation['status_color']}]{tx_validation.get('status', 'Unknown')}[/{tx_validation['status_color']}]\")\n",
        "console.print(f\"[dim]Diagnostics:[/dim] {tx_validation.get('details', 'No information available')}\")\n",
        "\n",
        "# Separator\n",
        "console.print(\"\\n\" + \"‚îÄ\" * 50 + \"\\n\")\n",
        "\n",
        "# Block Target\n",
        "console.print(\"[bold]Target Type - Block[/bold]\")\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    console.print(f\"[dim]Value:[/dim] [cyan3]{TARGET_BLOCK_IDENTIFIER}[/cyan3]\")\n",
        "else:\n",
        "    console.print(\"[dim]Value:[/dim] Nil\")\n",
        "\n",
        "console.print(f\"[dim]Status:[/dim] [{block_validation['status_color']}]{block_validation.get('status', 'Unknown')}[/{block_validation['status_color']}]\")\n",
        "console.print(f\"[dim]Diagnostics:[/dim] {block_validation.get('details', 'No information available')}\")\n",
        "\n",
        "console.print(\"\\n\")  # Extra spacing\n",
        "\n",
        "# Show target selection status message\n",
        "if not tx_valid and not block_valid:\n",
        "    console.print(\"[error]‚ö†Ô∏è No valid targets found. Please set either TARGET_TX_HASH or TARGET_BLOCK_IDENTIFIER.[/error]\", style=\"bold red3\")\n",
        "elif tx_valid and block_valid:\n",
        "    # Check if both targets exist but the transaction validation found the transaction and the block validation found the block\n",
        "    if tx_validation.get('status') == \"Found\" and block_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]‚ÑπÔ∏è Both transaction and block targets are found. Transaction analysis will take priority.[/info]\", style=\"bold royal_blue1\")\n",
        "    else:\n",
        "        console.print(\"[info]‚ÑπÔ∏è Both transaction and block targets are provided but at least one wasn't found. Valid target will be used.[/info]\", style=\"bold royal_blue1\")\n",
        "elif tx_valid:\n",
        "    if tx_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]‚úì Transaction target is valid and found. Ready for analysis.[/info]\", style=\"bold spring_green3\")\n",
        "    else:\n",
        "        console.print(\"[warning]‚ö†Ô∏è Transaction target format is valid but transaction wasn't found. Check the hash.[/warning]\", style=\"bold gold3\")\n",
        "elif block_valid:\n",
        "    if block_validation.get('status') == \"Found\":\n",
        "        console.print(\"[info]‚úì Block target is valid and found. Ready for analysis.[/info]\", style=\"bold spring_green3\")\n",
        "    else:\n",
        "        console.print(\"[warning]‚ö†Ô∏è Block target format is valid but block wasn't found. Check the number/hash.[/warning]\", style=\"bold gold3\")\n",
        "\n",
        "console.print(\"\\n\")  # Empty line for better spacing\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def make_rpc_request(method, params, network='mainnet'):\n",
        "    \"\"\"Helper function to make raw RPC requests via the specified network's provider.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "    try:\n",
        "        response = w3_client.provider.make_request(method, params)\n",
        "        if 'error' in response:\n",
        "            console.print(f\"[error]RPC Error ({method} on {network}): {response['error']['message']} (Code: {response['error']['code']})\", style=\"error\")\n",
        "            return None\n",
        "        return response.get('result')\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Exception during RPC call ({method} on {network}): {str(e)}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "# --- PYUSD Contract Helpers ---\n",
        "def is_pyusd_contract(address):\n",
        "    \"\"\"Checks if an address is a known PYUSD contract.\"\"\"\n",
        "    if not address:\n",
        "        return False\n",
        "    address_lower = address.lower() if isinstance(address, str) else str(address).lower()\n",
        "    return address_lower in PYUSD_CONTRACTS\n",
        "\n",
        "def get_contract_name(address):\n",
        "    \"\"\"Gets the friendly name for a contract address.\"\"\"\n",
        "    if not address:\n",
        "        return \"Unknown\"\n",
        "    address_lower = address.lower() if isinstance(address, str) else str(address).lower()\n",
        "    return PYUSD_CONTRACTS.get(address_lower, \"Other Contract\")\n",
        "\n",
        "def decode_pyusd_function(input_data):\n",
        "    \"\"\"Decodes PYUSD function calls using the signature registry.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"Empty call data\"\n",
        "\n",
        "    method_sig = input_data[:10]\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        return PYUSD_SIGNATURES[method_sig][\"name\"]\n",
        "    return f\"Unknown function: {method_sig}\"\n",
        "\n",
        "def get_function_category(input_data):\n",
        "    \"\"\"Gets the category of a function from its input data.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"other\"\n",
        "\n",
        "    method_sig = input_data[:10]\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        return PYUSD_SIGNATURES[method_sig][\"category\"]\n",
        "    return \"other\"\n",
        "\n",
        "def decode_pyusd_event(topic0, topics, data):\n",
        "    \"\"\"Decodes PYUSD events using the event registry.\"\"\"\n",
        "    if not topic0 or topic0 not in PYUSD_EVENTS:\n",
        "        return {\"name\": \"Unknown event\", \"details\": \"Cannot decode\"}\n",
        "\n",
        "    event_info = PYUSD_EVENTS[topic0]\n",
        "\n",
        "    try:\n",
        "        decoded = event_info[\"decoder\"](topics, data)\n",
        "        return {\n",
        "            \"name\": event_info[\"name\"],\n",
        "            \"decoded\": decoded\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"name\": event_info[\"name\"],\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# --- Formatting Helpers ---\n",
        "def format_value_pyusd(value_raw):\n",
        "    \"\"\"Formats raw PYUSD value (int) to decimal string.\"\"\"\n",
        "    if value_raw is None: return \"0 PYUSD\"\n",
        "    try:\n",
        "        decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "        value_float = int(value_raw) / (10**decimals)\n",
        "        return f\"{value_float:,.{decimals}f} PYUSD\"\n",
        "    except (ValueError, TypeError):\n",
        "        return \"Invalid PYUSD Value\"\n",
        "\n",
        "def format_value_eth(value_wei):\n",
        "    \"\"\"Formats Wei value to Ether string.\"\"\"\n",
        "    if value_wei is None: return \"0 ETH\"\n",
        "    try:\n",
        "        # Ensure value_wei is int or can be converted (handle hex strings from traces)\n",
        "        if isinstance(value_wei, str):\n",
        "            value_int = int(value_wei, 16)\n",
        "        else:\n",
        "             value_int = int(value_wei)\n",
        "        # Use mainnet client for formatting ETH value regardless of target network\n",
        "        if w3_mainnet: # Check if mainnet client exists\n",
        "            return f\"{w3_mainnet.from_wei(value_int, 'ether'):.6f} ETH\"\n",
        "        else:\n",
        "            return f\"{value_int / 1e18:.6f} ETH (approx)\" # Fallback if mainnet client missing\n",
        "    except (ValueError, TypeError, AttributeError):\n",
        "        return \"Invalid ETH Value\"\n",
        "\n",
        "def format_gas(gas):\n",
        "    \"\"\"Formats gas value (int or hex string).\"\"\"\n",
        "    if gas is None: return \"N/A\"\n",
        "    try:\n",
        "       gas_int = int(gas, 16) if isinstance(gas, str) and gas.startswith('0x') else int(gas)\n",
        "       return f\"{gas_int:,}\"\n",
        "    except (ValueError, TypeError):\n",
        "        return \"Invalid Gas Value\"\n",
        "\n",
        "def shorten_address(address):\n",
        "    \"\"\"Shortens an Ethereum address for display.\"\"\"\n",
        "    if not isinstance(address, str) or not address.startswith('0x') or len(address) != 42:\n",
        "        return str(address) # Return original if not a valid address string\n",
        "    return f\"{address[:6]}...{address[-4:]}\"\n",
        "\n",
        "def display_json(data, title=\"JSON Output\"):\n",
        "    \"\"\"Pretty prints JSON data using Rich.\"\"\"\n",
        "    if data is None:\n",
        "        console.print(f\"[warning]{title}: No data to display.\", style=\"warning\")\n",
        "        return\n",
        "    try:\n",
        "        # Use default=str to handle potential non-serializable types like HexBytes\n",
        "        json_str = json.dumps(data, indent=2, default=str)\n",
        "        console.print(Panel(Syntax(json_str, \"json\", theme=\"default\", line_numbers=False),\n",
        "                      title=title, border_style=\"cyan3\", expand=False))\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Could not display JSON for {title}: {e}\", style=\"error\")\n",
        "        # Fallback to printing raw data (limited length)\n",
        "        try:\n",
        "            raw_str = str(data)\n",
        "            console.print(raw_str[:1000] + (\"...\" if len(raw_str) > 1000 else \"\"))\n",
        "        except Exception:\n",
        "            console.print(\"[error]Could not print raw data fallback.\", style=\"error\")\n",
        "\n",
        "# --- Visualization Helpers ---\n",
        "def create_gas_usage_chart(gas_data, title=\"Gas Usage Distribution\"):\n",
        "    \"\"\"Creates a pie chart showing gas usage distribution.\"\"\"\n",
        "    try:\n",
        "        fig = px.pie(gas_data, values='gas_used', names='category',\n",
        "                      title=title)\n",
        "        fig.update_layout(template=\"plotly_white\")\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not create gas usage chart: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "def create_call_sequence_chart(calls_df, highlight_pyusd=True):\n",
        "    \"\"\"Creates a bar chart showing the sequence of calls with gas usage.\"\"\"\n",
        "    try:\n",
        "        if highlight_pyusd:\n",
        "            fig = px.bar(calls_df, x='id', y='gasUsed', color='is_pyusd',\n",
        "                         title='Gas Usage by Call Sequence',\n",
        "                         hover_data=['type', 'depth', 'from', 'to'])\n",
        "        else:\n",
        "            fig = px.bar(calls_df, x='id', y='gasUsed',\n",
        "                         title='Gas Usage by Call Sequence',\n",
        "                         hover_data=['type', 'depth', 'from', 'to'])\n",
        "\n",
        "        fig.update_layout(template=\"plotly_white\")\n",
        "        return fig\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not create call sequence chart: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "# --- Final Tracing Configuration Setup ---\n",
        "# Set up trace configuration based on targets\n",
        "if tx_valid and tx_validation.get('status') == \"Found\":\n",
        "    # If valid transaction hash found, prepare for transaction tracing\n",
        "    ACTIVE_TRACE_CONFIG = DEFAULT_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[info]Trace configuration ready for transaction analysis\", style=\"info\")\n",
        "elif block_valid and block_validation.get('status') == \"Found\":\n",
        "    # If valid block found, prepare for block tracing\n",
        "    ACTIVE_TRACE_CONFIG = STRUCTLOG_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[info]Trace configuration ready for block analysis\", style=\"info\")\n",
        "else:\n",
        "    # If no valid targets, set a default trace config\n",
        "    ACTIVE_TRACE_CONFIG = DEFAULT_TRACE_CONFIG.copy()\n",
        "    console.print(f\"[warning]Using default trace configuration (no valid target found)\", style=\"warning\")\n",
        "\n",
        "# Final status message\n",
        "status_icon = \"‚úì\" if (tx_valid and tx_validation.get('status') == \"Found\") or (block_valid and block_validation.get('status') == \"Found\") else \"‚ö†Ô∏è\"\n",
        "status_style = \"bold spring_green3\" if status_icon == \"‚úì\" else \"bold gold3\"\n",
        "console.print(f\"[{status_style}]{status_icon} Target selection and helper functions initialized[/{status_style}]\")"
      ],
      "metadata": {
        "id": "hsqesrWl-Eyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 üîç `debug_traceTransaction` - Deep Dive into Transaction Execution\n",
        "---\n",
        "This section utilizes the powerful `debug_traceTransaction` RPC method to dissect the internal workings of a specific PYUSD transaction defined by `TARGET_TX_HASH`. This goes far beyond standard block explorers by revealing the step-by-step execution flow within the EVM. We will explore two main tracers: `callTracer` and `structLog`."
      ],
      "metadata": {
        "id": "3vkos_TxP4pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Using `callTracer`: Mapping Internal Calls, Gas & Events (Recommended)\n",
        "\n",
        "The `callTracer` provides a structured, hierarchical view of the transaction's execution flow. It's generally the most useful tracer for understanding high-level interactions, gas consumption patterns, and event emissions.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `debug_traceTransaction` with `tracer: \"callTracer\"`\n",
        "> *   **Multiplier:** `50x` (Consumes 50x the quota/cost of a basic call)\n",
        "> *   **GCP Advantage:** Performing this detailed trace is computationally intensive. GCP's generous free quotas for this high-multiplier method make such in-depth analysis accessible and cost-effective.\n",
        "> *   **PYUSD Insight:** `callTracer` allows us to:\n",
        ">     *   Visualize the **exact interaction path** when PYUSD interacts with other DeFi protocols (e.g., DEXs, lending platforms).\n",
        ">     *   Identify specific **internal PYUSD function calls** (`transfer`, `approve`, `mint`, `burn`) and their parameters within the overall transaction.\n",
        ">     *   Pinpoint **gas consumption** within specific PYUSD operations vs. external contract interactions.\n",
        ">     *   Verify the **emission and content** of crucial PYUSD events like `Transfer` and `Approval`.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Trace:** The code calls `debug_traceTransaction` using the `TARGET_TX_HASH` and the `callTracer` configuration.\n",
        "2.  **Parse Data:** The complex JSON response is processed by `parse_call_trace` to extract structured information about calls, logs, gas, and state changes.\n",
        "3.  **Visualize & Summarize:** The results are presented through:\n",
        "    *   **Trace Overview & Metrics:** Key stats like call count, depth, gas, and status.\n",
        "    *   **Interaction Graphs:** High-level contract interactions and detailed call sequences (Interactive Plotly). PYUSD calls are highlighted.\n",
        "    *   **Token Flow:** A specific graph visualizing PYUSD movements (transfers, mints, burns).\n",
        "    *   **State & Gas Analysis:** Tables and charts showing PYUSD state changes and gas usage breakdown.\n",
        "    *   **Event Log Analysis:** Decoded PYUSD events emitted.\n",
        "    *   **Data Tables:** DataFrames showing key calls and high gas usage operations.\n",
        "    *   **Recommendations:** Automated observations based on trace patterns.\n",
        "    *   **Export Options:** Download parsed data (CSV/JSON) or export a report to Google Sheets (Colab).\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Call Graph:** Observe the sequence and depth of calls. Identify the green/blue highlighted nodes representing PYUSD/Supply Controller interactions. Note the gas usage (`Gas: ...`) on each node.\n",
        "*   **Token Flow Graph:** Track how PYUSD moved between addresses.\n",
        "*   **Gas Usage Pie Chart:** See which *types* of operations (transfer, approval, supply change) consumed the most gas.\n",
        "*   **Event Table:** Correlate events like `Transfer` with the calls shown in the graph.\n",
        "*   **Recommendations:** Check for automated insights about gas or complexity."
      ],
      "metadata": {
        "id": "VVhppRHRP8Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üî¨ Trace Transaction using debug_traceTransaction (callTracer)\n",
        "# =============================================================================================\n",
        "# This cell validates transaction targets, initializes blockchain tracing configurations, and sets up helper functions.\n",
        "# It prepares the environment for detailed transaction analysis by:\n",
        "# - Validating the transaction hash format and existence\n",
        "# - Configuring tracer parameters for debug_traceTransaction\n",
        "# - Setting up utility functions for address formatting, value conversion, and data processing\n",
        "# - Initializing transaction-specific constants and analysis options\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Javascript\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import networkx as nx\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, tx_hash):\n",
        "    \"\"\"Export analysis data to Google Sheets with rich formatting and visualization references.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[cyan3]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD TX Analysis {tx_hash[:10]} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Transaction Analysis\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transaction Analysis\"],\n",
        "            [f\"Transaction: {tx_hash}\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # 1. Add transaction stats summary with improved formatting\n",
        "        if \"transaction_stats\" in data_dict:\n",
        "            stats = data_dict[\"transaction_stats\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Transaction Metrics\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "                if key == 'total_gas':\n",
        "                    formatted_value = f\"{value:,} gas units\"\n",
        "                else:\n",
        "                    formatted_value = str(value)\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 1  # Add space after table\n",
        "\n",
        "        # 2. Add Contract Interaction Graph reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Contract Interaction Overview\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Contract interaction visualization is available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # 3. Add Call Graph Visualization reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Detailed Call Graph Visualization\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.7, \"green\": 0.8, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Detailed call graph visualization is available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # 4. Add gas usage section\n",
        "        if \"gas_distribution\" in data_dict and data_dict[\"gas_distribution\"]:\n",
        "            gas_data = data_dict[\"gas_distribution\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Create gas usage table\n",
        "            gas_header = [\"Category\", \"Gas Used\", \"Percentage\"]\n",
        "            gas_rows = [gas_header]\n",
        "\n",
        "            total_gas = sum(item[\"gas_used\"] for item in gas_data)\n",
        "            for item in gas_data:\n",
        "                category = item[\"category\"].replace(\"_\", \" \").title()\n",
        "                gas_used = item[\"gas_used\"]\n",
        "                percentage = (gas_used / total_gas * 100) if total_gas > 0 else 0\n",
        "                gas_rows.append([category, f\"{gas_used:,}\", f\"{percentage:.1f}%\"])\n",
        "\n",
        "            gas_table_row = current_row\n",
        "            worksheet.update(f\"A{gas_table_row}\", gas_rows)\n",
        "\n",
        "            # Format gas table headers\n",
        "            worksheet.format(f\"A{gas_table_row}:C{gas_table_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(gas_rows) + 1\n",
        "\n",
        "            # Add pie chart reference\n",
        "            worksheet.update(f\"A{current_row}\", [[\"üìä Gas usage pie chart visualization is available in the notebook\"]])\n",
        "            current_row += 2\n",
        "\n",
        "        # 5. Add PYUSD Token Flow section\n",
        "        if \"pyusd_transfers\" in data_dict and data_dict[\"pyusd_transfers\"]:\n",
        "            transfers = data_dict[\"pyusd_transfers\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"PYUSD Token Flow Analysis\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.7, \"green\": 1.0, \"blue\": 0.8}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add description\n",
        "            worksheet.update(f\"A{current_row}\", [[\"This shows the movement of PYUSD tokens in this transaction.\"]])\n",
        "            current_row += 1\n",
        "\n",
        "            # Add transfer data as a table\n",
        "            transfer_header = [\"From\", \"To\", \"Amount\", \"Gas Used\"]\n",
        "            transfer_rows = [transfer_header]\n",
        "\n",
        "            for transfer in transfers:\n",
        "                from_addr = shorten_address(transfer[\"from\"])\n",
        "                to_addr = shorten_address(transfer[\"to\"])\n",
        "                amount = format_value_pyusd(transfer[\"amount\"])\n",
        "                gas = f\"{transfer.get('gas_used', 0):,}\"\n",
        "                transfer_rows.append([from_addr, to_addr, amount, gas])\n",
        "\n",
        "            transfer_table_row = current_row\n",
        "            worksheet.update(f\"A{transfer_table_row}\", transfer_rows)\n",
        "\n",
        "            # Format transfer table headers\n",
        "            worksheet.format(f\"A{transfer_table_row}:D{transfer_table_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(transfer_rows) + 1\n",
        "\n",
        "            # Add flow graph reference\n",
        "            worksheet.update(f\"A{current_row}\", [[\"üîÑ Token flow visualization is available in the notebook\"]])\n",
        "            current_row += 2\n",
        "\n",
        "        # 6. Add PYUSD State Changes\n",
        "        if \"state_changes\" in data_dict and data_dict[\"state_changes\"]:\n",
        "            state_changes = data_dict[\"state_changes\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"PYUSD State Changes\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 1.0, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add description\n",
        "            worksheet.update(f\"A{current_row}\", [[\"The following state changes occurred in PYUSD contracts:\"]])\n",
        "            current_row += 1\n",
        "\n",
        "            # Create state changes table\n",
        "            if isinstance(state_changes, list) and state_changes:\n",
        "                # Define headers\n",
        "                headers = [\"contract\", \"function\", \"type\", \"amount\", \"gas_used\"]\n",
        "                display_headers = [\"Contract\", \"Function\", \"Type\", \"Amount\", \"Gas Used\"]\n",
        "\n",
        "                # Create the table data\n",
        "                state_rows = [display_headers]  # Header row\n",
        "                for change in state_changes:\n",
        "                    row_data = []\n",
        "                    for key in headers:\n",
        "                        if key == \"amount\" and \"amount\" in change:\n",
        "                            # Format PYUSD amounts nicely\n",
        "                            value = format_value_pyusd(change[\"amount\"])\n",
        "                        elif key == \"gas_used\":\n",
        "                            value = f\"{change.get(key, 0):,}\"\n",
        "                        else:\n",
        "                            value = str(change.get(key, \"\"))\n",
        "                        row_data.append(value)\n",
        "                    state_rows.append(row_data)\n",
        "\n",
        "                # Add to sheet\n",
        "                state_start_row = current_row\n",
        "                worksheet.update(f\"A{state_start_row}\", state_rows)\n",
        "\n",
        "                # Format headers\n",
        "                header_range = f\"A{state_start_row}:E{state_start_row}\"\n",
        "                worksheet.format(header_range, {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                current_row += len(state_rows) + 1\n",
        "\n",
        "        # 7. Add Event Analysis summary\n",
        "        if \"logs_df\" in data_dict and isinstance(data_dict[\"logs_df\"], pd.DataFrame) and not data_dict[\"logs_df\"].empty:\n",
        "            logs_df = data_dict[\"logs_df\"]\n",
        "            pyusd_logs = logs_df[logs_df['is_pyusd']] if 'is_pyusd' in logs_df.columns else pd.DataFrame()\n",
        "\n",
        "            if not pyusd_logs.empty:\n",
        "                # Add section title\n",
        "                worksheet.update(f\"A{current_row}\", [[\"PYUSD Events Analysis\"]])\n",
        "                worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                    \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                    \"backgroundColor\": {\"red\": 0.7, \"green\": 1.0, \"blue\": 0.8}\n",
        "                })\n",
        "                current_row += 1\n",
        "\n",
        "                # Add summary count\n",
        "                worksheet.update(f\"A{current_row}\", [[f\"Found {len(pyusd_logs)} PYUSD events in this transaction.\"]])\n",
        "                current_row += 1\n",
        "\n",
        "                # Add event counts if available\n",
        "                if 'event_name' in pyusd_logs.columns:\n",
        "                    event_counts = pyusd_logs['event_name'].value_counts()\n",
        "\n",
        "                    # Create event counts table\n",
        "                    event_table = [[\"Event Type\", \"Count\"]]  # Header row\n",
        "                    for event, count in event_counts.items():\n",
        "                        event_table.append([event, str(count)])\n",
        "\n",
        "                    # Add to sheet\n",
        "                    event_table_row = current_row\n",
        "                    worksheet.update(f\"A{event_table_row}\", event_table)\n",
        "\n",
        "                    # Format headers\n",
        "                    worksheet.format(f\"A{event_table_row}:B{event_table_row}\", {\n",
        "                        \"textFormat\": {\"bold\": True},\n",
        "                        \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                    })\n",
        "\n",
        "                    current_row += len(event_table) + 1\n",
        "\n",
        "                # Add event details\n",
        "                worksheet.update(f\"A{current_row}\", [[\"PYUSD Event Details:\"]])\n",
        "                worksheet.format(f\"A{current_row}:A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "                current_row += 1\n",
        "\n",
        "                # Display key event details\n",
        "                event_cols = ['contract', 'event_name', 'details']\n",
        "                event_cols = [col for col in event_cols if col in pyusd_logs.columns]\n",
        "\n",
        "                if event_cols:\n",
        "                    # Convert to list for sheet\n",
        "                    event_data = [event_cols]  # Header row\n",
        "                    for _, row in pyusd_logs[event_cols].iterrows():\n",
        "                        # Format each value appropriately\n",
        "                        row_values = []\n",
        "                        for col in event_cols:\n",
        "                            if pd.isnull(row[col]):\n",
        "                                value = \"\"\n",
        "                            else:\n",
        "                                value = str(row[col])\n",
        "                            row_values.append(value)\n",
        "                        event_data.append(row_values)\n",
        "\n",
        "                    # Add to sheet\n",
        "                    event_start_row = current_row\n",
        "                    worksheet.update(f\"A{event_start_row}\", event_data)\n",
        "\n",
        "                    # Format headers\n",
        "                    header_range = f\"A{event_start_row}:{chr(65+len(event_cols)-1)}{event_start_row}\"\n",
        "                    worksheet.format(header_range, {\n",
        "                        \"textFormat\": {\"bold\": True},\n",
        "                        \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                    })\n",
        "\n",
        "                    current_row += len(event_data) + 1\n",
        "\n",
        "                # Add transfer value summary if available\n",
        "                if 'amount' in pyusd_logs.columns and 'is_transfer' in pyusd_logs.columns:\n",
        "                    transfer_logs = pyusd_logs[pyusd_logs['is_transfer']]\n",
        "                    if not transfer_logs.empty:\n",
        "                        total_transferred = transfer_logs['amount'].sum()\n",
        "                        worksheet.update(f\"A{current_row}\", [[f\"Total PYUSD transferred: {format_value_pyusd(total_transferred)}\"]])\n",
        "                        current_row += 2\n",
        "\n",
        "        # 8. Add Recommendations\n",
        "        if \"recommendations\" in data_dict and data_dict[\"recommendations\"]:\n",
        "            recommendations = data_dict[\"recommendations\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Observations & Recommendations\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.7, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add each recommendation\n",
        "            for rec in recommendations:\n",
        "                worksheet.update(f\"A{current_row}\", [[rec]])\n",
        "                current_row += 1\n",
        "\n",
        "            current_row += 1  # Extra space\n",
        "\n",
        "        # 9. Add main DataFrame data (selected columns only for better readability)\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Key Contract Calls\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Select important columns to display\n",
        "            display_cols = ['id', 'type', 'depth', 'contract', 'function_category', 'gasUsed', 'is_pyusd']\n",
        "            display_cols = [col for col in display_cols if col in df.columns]\n",
        "\n",
        "            # First show PYUSD calls\n",
        "            pyusd_calls = df[df['is_pyusd']] if 'is_pyusd' in df.columns else pd.DataFrame()\n",
        "\n",
        "            if not pyusd_calls.empty:\n",
        "                worksheet.update(f\"A{current_row}\", [[f\"Found {len(pyusd_calls)} PYUSD-related calls:\"]])\n",
        "                current_row += 1\n",
        "\n",
        "                # Convert DataFrame to list of lists for the worksheet\n",
        "                pyusd_df_values = [display_cols] + pyusd_calls[display_cols].values.tolist()\n",
        "\n",
        "                # Format values for display\n",
        "                for i in range(1, len(pyusd_df_values)):\n",
        "                    for j, col in enumerate(display_cols):\n",
        "                        val = pyusd_df_values[i][j]\n",
        "                        if col == 'gasUsed' and pd.notnull(val):\n",
        "                            pyusd_df_values[i][j] = f\"{val:,}\"\n",
        "                        elif pd.isnull(val):\n",
        "                            pyusd_df_values[i][j] = \"NULL\"\n",
        "                        else:\n",
        "                            pyusd_df_values[i][j] = str(val)\n",
        "\n",
        "                worksheet.update(f\"A{current_row}\", pyusd_df_values)\n",
        "\n",
        "                # Format the DataFrame header\n",
        "                worksheet.format(f\"A{current_row}:{chr(65+len(display_cols)-1)}{current_row}\", {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                # Add alternating row colors for readability\n",
        "                data_rows = len(pyusd_df_values)\n",
        "                for i in range(2, data_rows + 1, 2):\n",
        "                    row_num = current_row + i - 1\n",
        "                    worksheet.format(f\"A{row_num}:{chr(65+len(display_cols)-1)}{row_num}\", {\n",
        "                        \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                    })\n",
        "\n",
        "                current_row += len(pyusd_df_values) + 2\n",
        "\n",
        "            # Then show highest gas usage calls\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Highest Gas Usage Calls:\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "            current_row += 1\n",
        "\n",
        "            # Get top 5 by gas usage\n",
        "            high_gas_cols = ['id', 'type', 'contract', 'function_category', 'gasUsed']\n",
        "            high_gas_cols = [col for col in high_gas_cols if col in df.columns]\n",
        "\n",
        "            high_gas_calls = df.nlargest(5, 'gasUsed') if 'gasUsed' in df.columns else pd.DataFrame()\n",
        "\n",
        "            if not high_gas_calls.empty:\n",
        "                # Convert to list for sheet\n",
        "                high_gas_data = [high_gas_cols]  # Header row\n",
        "                for _, row in high_gas_calls[high_gas_cols].iterrows():\n",
        "                    # Format each value appropriately\n",
        "                    row_values = []\n",
        "                    for col in high_gas_cols:\n",
        "                        if col == 'gasUsed':\n",
        "                            value = f\"{row[col]:,}\" if pd.notnull(row[col]) else \"0\"\n",
        "                        elif pd.isnull(row[col]):\n",
        "                            value = \"NULL\"\n",
        "                        else:\n",
        "                            value = str(row[col])\n",
        "                        row_values.append(value)\n",
        "                    high_gas_data.append(row_values)\n",
        "\n",
        "                # Add to sheet\n",
        "                worksheet.update(f\"A{current_row}\", high_gas_data)\n",
        "\n",
        "                # Format headers\n",
        "                header_range = f\"A{current_row}:{chr(65+len(high_gas_cols)-1)}{current_row}\"\n",
        "                worksheet.format(header_range, {\n",
        "                    \"textFormat\": {\"bold\": True},\n",
        "                    \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "                })\n",
        "\n",
        "                # Add alternating row colors\n",
        "                for i in range(2, len(high_gas_data) + 1, 2):\n",
        "                    row_num = current_row + i - 1\n",
        "                    worksheet.format(f\"A{row_num}:{chr(65+len(high_gas_cols)-1)}{row_num}\", {\n",
        "                        \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                    })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Attempt to resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Return spreadsheet URL and title for opening\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        return (spreadsheet_url, sheet_title)\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        raise Exception(f\"Error creating Google Sheet: {str(e)}\")\n",
        "\n",
        "# Function to display loading indicator while rendering visualization\n",
        "def show_loading_indicator():\n",
        "    \"\"\"Display a loading indicator while rendering graphs\"\"\"\n",
        "    loading_html = \"\"\"\n",
        "    <div style=\"display: flex; justify-content: center; align-items: center; height: 50px;\">\n",
        "        <div style=\"text-align: center;\">\n",
        "            <div class=\"spinner-border\" role=\"status\">\n",
        "                <span class=\"sr-only\">Loading...</span>\n",
        "            </div>\n",
        "            <p style=\"margin-top: 10px; color: #555;\">Generating visualization...</p>\n",
        "        </div>\n",
        "    </div>\n",
        "    <style>\n",
        "    .spinner-border {\n",
        "        display: inline-block;\n",
        "        width: 2rem;\n",
        "        height: 2rem;\n",
        "        vertical-align: text-bottom;\n",
        "        border: 0.25em solid currentColor;\n",
        "        border-right-color: transparent;\n",
        "        border-radius: 50%;\n",
        "        animation: spinner-border .75s linear infinite;\n",
        "    }\n",
        "    @keyframes spinner-border {\n",
        "        to { transform: rotate(360deg); }\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    display(HTML(loading_html))\n",
        "\n",
        "# Function to get human-readable function descriptions\n",
        "def get_function_description(input_data, is_pyusd, contract_name):\n",
        "    \"\"\"Get a human-readable function description.\"\"\"\n",
        "    if not input_data or input_data == '0x':\n",
        "        return \"Contract Creation\" if not input_data else \"ETH Transfer\"\n",
        "\n",
        "    # Extract method signature (first 10 characters including 0x)\n",
        "    method_sig = input_data[:10] if len(input_data) >= 10 else input_data\n",
        "\n",
        "    # Check PYUSD signatures first\n",
        "    if method_sig in PYUSD_SIGNATURES:\n",
        "        function_info = PYUSD_SIGNATURES[method_sig]\n",
        "        return function_info[\"name\"]\n",
        "\n",
        "    # Check common ERC20/generic function signatures\n",
        "    common_sigs = {\n",
        "        '0xa9059cbb': \"transfer(address,uint256)\",\n",
        "        '0x095ea7b3': \"approve(address,uint256)\",\n",
        "        '0x23b872dd': \"transferFrom(address,address,uint256)\",\n",
        "        '0x18160ddd': \"totalSupply()\",\n",
        "        '0x70a08231': \"balanceOf(address)\",\n",
        "        '0xdd62ed3e': \"allowance(address,address)\",\n",
        "        '0x06fdde03': \"name()\",\n",
        "        '0x95d89b41': \"symbol()\",\n",
        "        '0x313ce567': \"decimals()\",\n",
        "        '0x8da5cb5b': \"owner()\",\n",
        "        '0x715018a6': \"renounceOwnership()\",\n",
        "        '0xf2fde38b': \"transferOwnership(address)\",\n",
        "        '0x01ffc9a7': \"supportsInterface(bytes4)\",\n",
        "        '0x3644e515': \"DOMAIN_SEPARATOR()\",\n",
        "        '0x7ecebe00': \"nonces(address)\",\n",
        "        '0xd505accf': \"permit(address,address,uint256,uint256,uint8,bytes32,bytes32)\"\n",
        "    }\n",
        "\n",
        "    return common_sigs.get(method_sig, f\"Function {method_sig}\")\n",
        "\n",
        "# function for creating interactive Plotly Contract Interaction Graph\n",
        "def create_plotly_contract_interaction_graph(contract_interactions):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for contract interactions with directional arrows\"\"\"\n",
        "    import math\n",
        "\n",
        "    if not contract_interactions:\n",
        "        return None\n",
        "\n",
        "    # Create a networkx graph from the interaction data\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes for all contracts in interactions\n",
        "    contracts_seen = set()\n",
        "    for src, dst in contract_interactions:\n",
        "        if src not in contracts_seen:\n",
        "            src_name = PYUSD_CONTRACTS.get(src, \"External Contract\")\n",
        "            G.add_node(src, name=src_name, is_pyusd=(src in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(src)\n",
        "\n",
        "        if dst not in contracts_seen:\n",
        "            dst_name = PYUSD_CONTRACTS.get(dst, \"External Contract\")\n",
        "            G.add_node(dst, name=dst_name, is_pyusd=(dst in PYUSD_CONTRACTS))\n",
        "            contracts_seen.add(dst)\n",
        "\n",
        "        # Add edge\n",
        "        G.add_edge(src, dst)\n",
        "\n",
        "    # Calculate layout with more spacing for readability\n",
        "    pos = nx.spring_layout(G, seed=42, k=1.5)\n",
        "\n",
        "    # Create edge traces with arrows\n",
        "    edge_traces = []\n",
        "\n",
        "    for edge in G.edges():\n",
        "        src, dst = edge\n",
        "        src_name = G.nodes[src]['name']\n",
        "        dst_name = G.nodes[dst]['name']\n",
        "\n",
        "        x0, y0 = pos[src]\n",
        "        x1, y1 = pos[dst]\n",
        "\n",
        "        # Calculate direction vector for arrow\n",
        "        dx = x1 - x0\n",
        "        dy = y1 - y0\n",
        "\n",
        "        # Normalize the vector\n",
        "        length = math.sqrt(dx**2 + dy**2)\n",
        "        if length > 0:\n",
        "            udx = dx / length\n",
        "            udy = dy / length\n",
        "        else:\n",
        "            udx, udy = 0, 0\n",
        "\n",
        "        # Position arrow slightly before the destination node (80% along the edge)\n",
        "        arrow_ratio = 0.8\n",
        "        arrow_x = x0 + arrow_ratio * dx\n",
        "        arrow_y = y0 + arrow_ratio * dy\n",
        "\n",
        "        # Angle for the arrow in degrees\n",
        "        angle = math.degrees(math.atan2(dy, dx))\n",
        "\n",
        "        # Main edge line\n",
        "        edge_trace = go.Scatter(\n",
        "            x=[x0, x1],\n",
        "            y=[y0, y1],\n",
        "            line=dict(width=1.5, color='rgba(50, 50, 50, 0.8)'),\n",
        "            hoverinfo='text',\n",
        "            text=f\"From: {src_name}<br>To: {dst_name}<br>From address: {src}<br>To address: {dst}\",\n",
        "            mode='lines',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        # Arrow marker\n",
        "        arrow_trace = go.Scatter(\n",
        "            x=[arrow_x],\n",
        "            y=[arrow_y],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                symbol='triangle-right',\n",
        "                size=12,\n",
        "                color='rgba(50, 50, 50, 0.8)',\n",
        "                angle=angle  # Apply the calculated angle\n",
        "            ),\n",
        "            hoverinfo='none',\n",
        "            showlegend=False\n",
        "        )\n",
        "\n",
        "        edge_traces.append(edge_trace)\n",
        "        edge_traces.append(arrow_trace)\n",
        "\n",
        "    # Create node trace\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    hover_texts = []\n",
        "    node_addresses = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        node_data = G.nodes[node]\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Node color based on contract type\n",
        "        if node_data['is_pyusd']:\n",
        "            if \"PYUSD Token\" in node_data['name']:\n",
        "                node_colors.append('rgba(144, 238, 144, 0.9)')  # palegreen\n",
        "            elif \"Supply Control\" in node_data['name']:\n",
        "                node_colors.append('rgba(135, 206, 250, 0.9)')  # lightskyblue\n",
        "            else:\n",
        "                node_colors.append('rgba(224, 255, 255, 0.9)')  # lightcyan\n",
        "        else:\n",
        "            node_colors.append('rgba(211, 211, 211, 0.9)')  # lightgray\n",
        "\n",
        "        # Node size: bigger for PYUSD contracts\n",
        "        node_sizes.append(25 if node_data['is_pyusd'] else 18)\n",
        "\n",
        "        # Full address for node label\n",
        "        node_addresses.append(node)\n",
        "\n",
        "        # Hover text with full contract information\n",
        "        hover_texts.append(f\"<b>{node_data['name']}</b><br>Address: {node}\")\n",
        "\n",
        "    # Create node trace with text labels showing full addresses\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_addresses,\n",
        "        textposition=\"bottom center\",\n",
        "        hovertext=hover_texts,\n",
        "        marker=dict(\n",
        "            showscale=False,\n",
        "            color=node_colors,\n",
        "            size=node_sizes,\n",
        "            line=dict(width=1, color='#000')\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"monospace\",\n",
        "            size=10,\n",
        "            color=\"black\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add legend traces for different node types\n",
        "    legend_traces = [\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'),\n",
        "            name='PYUSD Token',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'),\n",
        "            name='Supply Control',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'),\n",
        "            name='External Contract',\n",
        "            showlegend=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Create figure with styled layout\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add all traces\n",
        "    for trace in edge_traces:\n",
        "        fig.add_trace(trace)\n",
        "\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    for trace in legend_traces:\n",
        "        fig.add_trace(trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>Contract Interaction Overview</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Contract Types\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=600,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# function for creating interactive Plotly Call Graph\n",
        "def create_plotly_call_graph(call_data_list):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for the call trace hierarchy\"\"\"\n",
        "    if not call_data_list:\n",
        "        return None\n",
        "\n",
        "    # Process relationships and parent-child connections\n",
        "    # We need to reconstruct parent/child relationships based on depth\n",
        "    for i, call in enumerate(call_data_list):\n",
        "        # Initialize parent_id field if it doesn't exist\n",
        "        if 'parent_id' not in call:\n",
        "            call['parent_id'] = None\n",
        "\n",
        "        # If not root node, find parent\n",
        "        if call['depth'] > 0 and i > 0:\n",
        "            # Look backward for potential parents at the previous depth level\n",
        "            for j in range(i-1, -1, -1):\n",
        "                potential_parent = call_data_list[j]\n",
        "                if potential_parent['depth'] == call['depth'] - 1:\n",
        "                    call['parent_id'] = potential_parent['id']\n",
        "                    break\n",
        "\n",
        "    # Create a networkx graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add all nodes with their attributes\n",
        "    for call in call_data_list:\n",
        "        G.add_node(call['id'], **call)\n",
        "\n",
        "    # Add edges based on parent-child relationships\n",
        "    for call in call_data_list:\n",
        "        if call['parent_id']:\n",
        "            G.add_edge(call['parent_id'], call['id'])\n",
        "\n",
        "    # Try using graphviz layout if available\n",
        "    try:\n",
        "        import pygraphviz as pgv\n",
        "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')  # Hierarchical layout\n",
        "    except:\n",
        "        # Fallback to custom hierarchical layout\n",
        "        pos = {}\n",
        "        depth_to_nodes = {}\n",
        "\n",
        "        for node, data in G.nodes(data=True):\n",
        "            depth = data['depth']\n",
        "            if depth not in depth_to_nodes:\n",
        "                depth_to_nodes[depth] = []\n",
        "            depth_to_nodes[depth].append(node)\n",
        "\n",
        "        # Calculate positions based on depth\n",
        "        max_depth = max(depth_to_nodes.keys()) if depth_to_nodes else 0\n",
        "\n",
        "        for depth, nodes in depth_to_nodes.items():\n",
        "            nodes.sort()  # For consistent layout\n",
        "            node_count = len(nodes)\n",
        "            for i, node in enumerate(nodes):\n",
        "                # Horizontal spacing based on node count, vertical based on depth\n",
        "                x_pos = i / (node_count + 1) if node_count > 1 else 0.5\n",
        "                y_pos = 1.0 - (depth / (max_depth + 1)) if max_depth > 0 else 0.5\n",
        "                pos[node] = (x_pos, y_pos)\n",
        "\n",
        "    # Create edge traces with different colors by call type\n",
        "    edge_traces_by_type = {}\n",
        "    edge_types = set()\n",
        "\n",
        "    for edge in G.edges():\n",
        "        source, target = edge\n",
        "        source_data = G.nodes[source]\n",
        "        target_data = G.nodes[target]\n",
        "\n",
        "        call_type = target_data['type']\n",
        "        edge_types.add(call_type)\n",
        "\n",
        "        if call_type not in edge_traces_by_type:\n",
        "            edge_traces_by_type[call_type] = {\n",
        "                'x': [], 'y': [], 'text': [], 'color': '', 'style': '', 'width': 1\n",
        "            }\n",
        "\n",
        "            # Set color and style based on call type\n",
        "            if call_type == 'DELEGATECALL':\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(0, 0, 255, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'dash'\n",
        "                edge_traces_by_type[call_type]['width'] = 2\n",
        "            elif call_type == 'STATICCALL':\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(0, 128, 0, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'dot'\n",
        "                edge_traces_by_type[call_type]['width'] = 1.5\n",
        "            else:\n",
        "                edge_traces_by_type[call_type]['color'] = 'rgba(128, 128, 128, 0.7)'\n",
        "                edge_traces_by_type[call_type]['style'] = 'solid'\n",
        "                edge_traces_by_type[call_type]['width'] = 1\n",
        "\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        edge_traces_by_type[call_type]['x'].extend([x0, x1, None])\n",
        "        edge_traces_by_type[call_type]['y'].extend([y0, y1, None])\n",
        "\n",
        "        # Create full hover info\n",
        "        hover_text = (\n",
        "            f\"<b>From:</b> {source_data['from']}<br>\"\n",
        "            f\"<b>To:</b> {target_data['to']}<br>\"\n",
        "            f\"<b>Type:</b> {target_data['type']}<br>\"\n",
        "            f\"<b>Depth:</b> {target_data['depth']}<br>\"\n",
        "        )\n",
        "\n",
        "        if target_data['value_eth'] > 0:\n",
        "            hover_text += f\"<b>Value:</b> {target_data['value_eth']} ETH<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Gas:</b> {target_data['gasUsed']:,}<br>\"\n",
        "\n",
        "        if target_data['is_pyusd']:\n",
        "            hover_text += f\"<b>Contract:</b> {target_data['contract']}<br>\"\n",
        "\n",
        "        if target_data.get('error'):\n",
        "            hover_text += f\"<b style='color:red'>Error:</b> {target_data['error']}<br>\"\n",
        "\n",
        "        edge_traces_by_type[call_type]['text'].append(hover_text)\n",
        "\n",
        "    # Create scatter traces for each call type\n",
        "    edge_traces = []\n",
        "    for call_type, trace_data in edge_traces_by_type.items():\n",
        "        edge_traces.append(\n",
        "            go.Scatter(\n",
        "                x=trace_data['x'],\n",
        "                y=trace_data['y'],\n",
        "                line=dict(\n",
        "                    width=trace_data['width'],\n",
        "                    color=trace_data['color'],\n",
        "                    dash=trace_data['style']\n",
        "                ),\n",
        "                hoverinfo='text',\n",
        "                text=trace_data['text'],\n",
        "                mode='lines',\n",
        "                name=call_type\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Create node trace with improved hover information\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    node_text = []  # Function name displayed on node\n",
        "    hover_texts = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        node_data = G.nodes[node]\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Create more detailed text for nodes\n",
        "        function_name = get_function_description(\n",
        "            node_data.get('input_preview', '0x'),\n",
        "            node_data['is_pyusd'],\n",
        "            node_data.get('contract', 'Other')\n",
        "        )\n",
        "\n",
        "        # Short text for display (truncated for space)\n",
        "        short_name = function_name.split('(')[0] if '(' in function_name else function_name\n",
        "        if len(short_name) > 12:\n",
        "            short_name = short_name[:10] + '...'\n",
        "        node_text.append(short_name)\n",
        "\n",
        "        # Create detailed hover text\n",
        "        hover_text = f\"<b style='font-size:12px'>{node_data['type']} Call</b><br>\"\n",
        "        hover_text += f\"<b>From:</b> {node_data['from']}<br>\"\n",
        "        hover_text += f\"<b>To:</b> {node_data['to']}<br>\"\n",
        "        hover_text += f\"<b>Depth:</b> {node_data['depth']}<br>\"\n",
        "\n",
        "        if node_data['value_eth'] > 0:\n",
        "            hover_text += f\"<b>Value:</b> {node_data['value_eth']} ETH<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Gas Used:</b> {node_data['gasUsed']:,}<br>\"\n",
        "\n",
        "        if node_data['is_pyusd']:\n",
        "            hover_text += f\"<b>PYUSD Contract:</b> {node_data['contract']}<br>\"\n",
        "            hover_text += f\"<b>Function Category:</b> {node_data['function_category']}<br>\"\n",
        "\n",
        "        hover_text += f\"<b>Function:</b> {function_name}<br>\"\n",
        "\n",
        "        if node_data.get('error'):\n",
        "            hover_text += f\"<b style='color:red'>Error:</b> {node_data['error']}<br>\"\n",
        "\n",
        "        hover_texts.append(hover_text)\n",
        "\n",
        "        # Node color based on contract type and error status\n",
        "        if node_data.get('error'):\n",
        "            node_colors.append('rgba(255, 99, 71, 0.9)')  # tomato for errors\n",
        "        elif node_data['is_pyusd']:\n",
        "            if \"PYUSD Token\" in node_data.get('contract', ''):\n",
        "                node_colors.append('rgba(144, 238, 144, 0.9)')  # palegreen\n",
        "            elif \"Supply Control\" in node_data.get('contract', ''):\n",
        "                node_colors.append('rgba(135, 206, 250, 0.9)')  # lightskyblue\n",
        "            else:\n",
        "                node_colors.append('rgba(224, 255, 255, 0.9)')  # lightcyan\n",
        "        else:\n",
        "            # Gradient based on depth for non-PYUSD calls\n",
        "            intensity = min(95, max(70, 95 - node_data['depth'] * 5))\n",
        "            rgb_val = intensity / 100.0\n",
        "            node_colors.append(f'rgba({int(rgb_val*255)}, {int(rgb_val*255)}, {int(rgb_val*255)}, 0.9)')\n",
        "\n",
        "        # Size based on gas used\n",
        "        gas_used = node_data['gasUsed']\n",
        "        # Scale node size based on gas used (within reasonable bounds)\n",
        "        size = max(15, min(40, 15 + (gas_used / 50000)))\n",
        "        node_sizes.append(size)\n",
        "\n",
        "    # Create node trace\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        textposition=\"top center\",\n",
        "        hovertext=hover_texts,\n",
        "        marker=dict(\n",
        "            showscale=False,\n",
        "            color=node_colors,\n",
        "            size=node_sizes,\n",
        "            line=dict(width=1, color='#000')\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"Arial\",\n",
        "            size=9,\n",
        "            color=\"#333\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Create legend traces for node colors\n",
        "    node_color_legend = [\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(144, 238, 144, 0.9)'),\n",
        "            name='PYUSD Token',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(135, 206, 250, 0.9)'),\n",
        "            name='Supply Control',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(211, 211, 211, 0.9)'),\n",
        "            name='Other Contract',\n",
        "            showlegend=True\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=[None], y=[None],\n",
        "            mode='markers',\n",
        "            marker=dict(size=15, color='rgba(255, 99, 71, 0.9)'),\n",
        "            name='Error',\n",
        "            showlegend=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Create figure with all traces\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add traces\n",
        "    for edge_trace in edge_traces:\n",
        "        fig.add_trace(edge_trace)\n",
        "\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    # Add legend traces\n",
        "    for legend_trace in node_color_legend:\n",
        "        fig.add_trace(legend_trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>Detailed Call Graph Visualization</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Call Types\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=40, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=700,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# New function for creating interactive Plotly PYUSD Flow Graph\n",
        "def create_plotly_flow_graph(transfers):\n",
        "    \"\"\"Creates an interactive Plotly Network graph for PYUSD token flows\"\"\"\n",
        "    if not transfers:\n",
        "        return None\n",
        "\n",
        "    # Create a directed graph for token flows\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Track total transfer amount per edge for aggregation\n",
        "    transfer_totals = {}\n",
        "\n",
        "    # Calculate aggregate transfers\n",
        "    for transfer in transfers:\n",
        "        from_addr = transfer['from']\n",
        "        to_addr = transfer['to']\n",
        "        amount = transfer['amount']\n",
        "\n",
        "        edge_key = (from_addr, to_addr)\n",
        "        if edge_key in transfer_totals:\n",
        "            transfer_totals[edge_key] += amount\n",
        "        else:\n",
        "            transfer_totals[edge_key] = amount\n",
        "\n",
        "    # Add nodes and edges to networkx graph\n",
        "    for (from_addr, to_addr), total_amount in transfer_totals.items():\n",
        "        # Add nodes if they don't exist\n",
        "        if from_addr not in G:\n",
        "            G.add_node(from_addr, address=from_addr, label=shorten_address(from_addr))\n",
        "\n",
        "        if to_addr not in G:\n",
        "            G.add_node(to_addr, address=to_addr, label=shorten_address(to_addr))\n",
        "\n",
        "        # Add edge with amount\n",
        "        G.add_edge(from_addr, to_addr, amount=total_amount, label=format_value_pyusd(total_amount))\n",
        "\n",
        "    # Calculate layout\n",
        "    pos = nx.spring_layout(G, k=1.0, seed=42)\n",
        "\n",
        "    # Create edge trace\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edge_text = []\n",
        "    edge_amount_texts = []\n",
        "\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        # Calculate midpoint for displaying amount\n",
        "        mid_x = (x0 + x1) / 2\n",
        "        mid_y = (y0 + y1) / 2\n",
        "\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "\n",
        "        amount_str = format_value_pyusd(data['amount'])\n",
        "        edge_text.append(f\"Transfer: {amount_str}<br>From: {shorten_address(source)}<br>To: {shorten_address(target)}\")\n",
        "        edge_amount_texts.append(amount_str)\n",
        "\n",
        "    # Create edge trace with arrows\n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x, y=edge_y,\n",
        "        line=dict(width=2, color='rgba(50, 150, 50, 0.8)'),\n",
        "        hoverinfo='text',\n",
        "        text=edge_text,\n",
        "        mode='lines',\n",
        "        name='Transfer'\n",
        "    )\n",
        "\n",
        "    # Create a separate trace for each edge label (amount)\n",
        "    edge_label_traces = []\n",
        "    edge_idx = 0\n",
        "    for edge in G.edges(data=True):\n",
        "        source, target, data = edge\n",
        "        x0, y0 = pos[source]\n",
        "        x1, y1 = pos[target]\n",
        "\n",
        "        # Calculate midpoint for the label\n",
        "        mid_x = (x0 + x1) / 2\n",
        "        mid_y = (y0 + y1) / 2\n",
        "\n",
        "        # Add label trace\n",
        "        edge_label_traces.append(\n",
        "            go.Scatter(\n",
        "                x=[mid_x],\n",
        "                y=[mid_y],\n",
        "                text=[format_value_pyusd(data['amount'])],\n",
        "                mode='text',\n",
        "                hoverinfo='none',\n",
        "                showlegend=False,\n",
        "                textfont=dict(\n",
        "                    size=10,\n",
        "                    color='darkgreen'\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add arrow trace (small marker at the target end)\n",
        "        # Calculate the position for the arrow (slightly before the target)\n",
        "        arrow_ratio = 0.8  # How far along the edge to place the arrow (0.8 = 80% of the way to target)\n",
        "        arrow_x = x0 + (x1 - x0) * arrow_ratio\n",
        "        arrow_y = y0 + (y1 - y0) * arrow_ratio\n",
        "\n",
        "        edge_label_traces.append(\n",
        "            go.Scatter(\n",
        "                x=[arrow_x],\n",
        "                y=[arrow_y],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    symbol='triangle-right',\n",
        "                    size=12,\n",
        "                    color='rgba(50, 150, 50, 0.8)',\n",
        "                    angle=45\n",
        "                ),\n",
        "                hoverinfo='none',\n",
        "                showlegend=False\n",
        "            )\n",
        "        )\n",
        "\n",
        "        edge_idx += 1\n",
        "\n",
        "    # Create node trace with full addresses\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    node_hover = []\n",
        "\n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "\n",
        "        # Use full address for display\n",
        "        node_text.append(node)\n",
        "\n",
        "        # Create hover text\n",
        "        node_hover.append(f\"<b>Address:</b> {node}\")\n",
        "\n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        textposition=\"bottom center\",\n",
        "        hovertext=node_hover,\n",
        "        marker=dict(\n",
        "            color='rgba(144, 238, 144, 0.8)',  # palegreen\n",
        "            size=25,\n",
        "            line=dict(width=1, color='darkgreen'),\n",
        "            symbol='circle'\n",
        "        ),\n",
        "        textfont=dict(\n",
        "            family=\"monospace\",\n",
        "            size=9,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        name='Address'\n",
        "    )\n",
        "\n",
        "    # Create figure with styled layout\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add all traces\n",
        "    fig.add_trace(edge_trace)\n",
        "    for label_trace in edge_label_traces:\n",
        "        fig.add_trace(label_trace)\n",
        "    fig.add_trace(node_trace)\n",
        "\n",
        "    # Style the figure\n",
        "    fig.update_layout(\n",
        "        title='<b>PYUSD Token Flow Analysis</b>',\n",
        "        titlefont=dict(size=16),\n",
        "        showlegend=True,\n",
        "        legend=dict(\n",
        "            title=\"Elements\",\n",
        "            orientation=\"h\",\n",
        "            yanchor=\"bottom\",\n",
        "            y=1.02,\n",
        "            xanchor=\"right\",\n",
        "            x=1,\n",
        "            bgcolor=\"rgba(255, 255, 255, 0.8)\"\n",
        "        ),\n",
        "        hovermode='closest',\n",
        "        margin=dict(b=20, l=5, r=5, t=60),\n",
        "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "        template=\"plotly_white\",\n",
        "        height=600,\n",
        "        paper_bgcolor='rgba(255,255,255,0.8)',\n",
        "        plot_bgcolor='rgba(255,255,255,0.8)'\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def parse_call_trace(trace_result, tx_hash):\n",
        "    \"\"\"Parses the output of callTracer and generates insights & visualizations.\"\"\"\n",
        "    if not trace_result:\n",
        "        console.print(\"[warning]No trace result provided for parsing.\", style=\"warning\")\n",
        "        return None, None, None, None, None, None, None, None\n",
        "\n",
        "    # --- Basic Info Panel ---\n",
        "    to_address = trace_result.get('to', 'N/A').lower()\n",
        "    is_pyusd_tx = to_address in PYUSD_CONTRACTS\n",
        "    pyusd_label = f\"[bold green]({PYUSD_CONTRACTS[to_address]})[/bold green]\" if is_pyusd_tx else \"\"\n",
        "\n",
        "    # Extract gas metrics for analysis\n",
        "    gas_used = int(trace_result.get('gasUsed', '0x0'), 16) if isinstance(trace_result.get('gasUsed', '0x0'), str) and trace_result.get('gasUsed', '0x0').startswith('0x') else int(trace_result.get('gasUsed', 0))\n",
        "\n",
        "    overview_text = f\"\"\"\n",
        "      [bold]Trace Summary for {shorten_address(tx_hash)}[/bold] {pyusd_label}\n",
        "      Type: {trace_result.get('type', 'N/A')}\n",
        "      From: {shorten_address(trace_result.get('from', 'N/A'))}\n",
        "      To: {shorten_address(trace_result.get('to', 'N/A'))}\n",
        "      Value: {format_value_eth(trace_result.get('value', '0x0'))}\n",
        "      Gas Used: {format_gas(trace_result.get('gasUsed', '0x0'))} ({gas_used:,} units)\n",
        "      Status: [bold red]Error: {trace_result['error']}[/bold red]\"\"\" if 'error' in trace_result else \"[bold green]Success[/bold green]\"\n",
        "    console.print(Panel(overview_text, title=\"Trace Overview\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    node_counter = 0\n",
        "    call_data_list = []\n",
        "    state_changes = []\n",
        "\n",
        "    # Track PYUSD transfer data for visualization\n",
        "    pyusd_transfers = []\n",
        "\n",
        "    # Track contract interactions for relationship mapping\n",
        "    contract_interactions = set()\n",
        "\n",
        "    # Track gas usage by category\n",
        "    gas_by_category = {category: 0 for category in GAS_CATEGORIES.keys()}\n",
        "\n",
        "    def add_nodes_edges(call, parent_node_id=None, depth=0, parent_addr=None):\n",
        "        nonlocal node_counter\n",
        "        current_node_id = f\"node_{node_counter}\"\n",
        "        node_counter += 1\n",
        "\n",
        "        call_type = call.get('type', 'N/A').upper()\n",
        "\n",
        "        # Extract call data for label\n",
        "        from_addr = call.get('from', 'N/A')\n",
        "        from_addr_short = shorten_address(from_addr)\n",
        "        to_addr = call.get('to', 'N/A')\n",
        "        to_addr_lower = to_addr.lower() if to_addr else ''\n",
        "        to_addr_short = shorten_address(to_addr)\n",
        "\n",
        "        # Track contract interaction\n",
        "        if parent_addr and to_addr_lower:\n",
        "            contract_interactions.add((parent_addr.lower(), to_addr_lower))\n",
        "\n",
        "        # Check for PYUSD contracts\n",
        "        is_pyusd_call = to_addr_lower in PYUSD_CONTRACTS\n",
        "        contract_name = PYUSD_CONTRACTS.get(to_addr_lower, None)\n",
        "\n",
        "        # function signature detection for PYUSD calls\n",
        "        input_data = call.get('input', '0x')\n",
        "        function_category = \"other\"\n",
        "        if input_data != '0x':\n",
        "            method_sig = input_data[:10]\n",
        "\n",
        "            if method_sig in PYUSD_SIGNATURES:\n",
        "                function_info = PYUSD_SIGNATURES[method_sig]\n",
        "                function_name = function_info[\"name\"]\n",
        "                function_category = function_info[\"category\"]\n",
        "\n",
        "                # Process specific functions for deeper analysis\n",
        "                if is_pyusd_call and \"PYUSD Token\" in contract_name:\n",
        "                    if method_sig == '0xa9059cbb':  # transfer\n",
        "                        try:\n",
        "                            # Extract params\n",
        "                            to_offset = 10\n",
        "                            to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            pyusd_transfers.append({\n",
        "                                'from': from_addr,\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'transfer',\n",
        "                                'from': from_addr,\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                    elif method_sig == '0x40c10f19':  # mint\n",
        "                        try:\n",
        "                            to_offset = 10\n",
        "                            to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'mint',\n",
        "                                'to': to_param,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                    elif method_sig == '0x9dc29fac':  # burn\n",
        "                        try:\n",
        "                            from_offset = 10\n",
        "                            from_param = \"0x\" + input_data[from_offset+24:from_offset+64]\n",
        "                            amount_offset = 74\n",
        "                            amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                            # Track state change\n",
        "                            state_changes.append({\n",
        "                                'contract': contract_name,\n",
        "                                'function': function_name,\n",
        "                                'type': 'burn',\n",
        "                                'from': from_addr,\n",
        "                                'amount': amount,\n",
        "                                'gas_used': int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "                            })\n",
        "                        except Exception:\n",
        "                            pass\n",
        "\n",
        "        # Update gas usage by category - AFTER function_category is defined\n",
        "        call_gas = int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "        if is_pyusd_call:\n",
        "            gas_by_category[function_category] += call_gas\n",
        "        else:\n",
        "            gas_by_category[\"other\"] += call_gas\n",
        "\n",
        "        # Extract output and error data\n",
        "        output_data = call.get('output', '0x')\n",
        "        error_msg = call.get('error')\n",
        "\n",
        "        # Store call data for dataframe\n",
        "        try:\n",
        "            gas_used_val = int(call.get('gasUsed', '0x0'), 16) if call.get('gasUsed', '0x0').startswith('0x') else int(call.get('gasUsed', 0))\n",
        "            value_raw_wei = int(call.get('value', '0x0'), 16) if call.get('value', '0x0').startswith('0x') else int(call.get('value', 0))\n",
        "            value_eth_float = float(w3_mainnet.from_wei(value_raw_wei, 'ether')) if w3_mainnet else (value_raw_wei / 1e18)\n",
        "        except (ValueError, TypeError, AttributeError):\n",
        "            gas_used_val = 0\n",
        "            value_eth_float = 0.0\n",
        "\n",
        "        # Build call info for dataframe with data\n",
        "        call_info = {\n",
        "            'id': current_node_id,\n",
        "            'parent_id': parent_node_id,  # Track parent-child relationship\n",
        "            'type': call_type,\n",
        "            'depth': depth,\n",
        "            'from': from_addr,\n",
        "            'to': to_addr,\n",
        "            'value_eth': value_eth_float,\n",
        "            'gasUsed': gas_used_val,\n",
        "            'is_pyusd': is_pyusd_call,\n",
        "            'contract': contract_name if is_pyusd_call else \"Other\",\n",
        "            'function_category': function_category,\n",
        "            'error': error_msg,\n",
        "            'input_preview': input_data[:10] + \"...\" if len(input_data) > 10 else input_data,\n",
        "            'output_preview': output_data[:10] + \"...\" if len(output_data) > 10 else output_data,\n",
        "        }\n",
        "        call_data_list.append(call_info)\n",
        "\n",
        "        # Process sub-calls recursively\n",
        "        if 'calls' in call and isinstance(call['calls'], list):\n",
        "            for sub_call in call['calls']:\n",
        "                add_nodes_edges(sub_call, current_node_id, depth + 1, to_addr)\n",
        "\n",
        "    # --- Start processing the trace from the top-level call ---\n",
        "    add_nodes_edges(trace_result, depth=0)\n",
        "\n",
        "    # Create a dataframe from collected call data\n",
        "    call_df = pd.DataFrame(call_data_list)\n",
        "\n",
        "    # Create state changes dataframe\n",
        "    state_changes_df = pd.DataFrame(state_changes) if state_changes else None\n",
        "\n",
        "    # --- Extract Logs from trace with decoding ---\n",
        "    logs_data = []\n",
        "    log_counter_trace = 0\n",
        "\n",
        "    def extract_logs_recursive(call):\n",
        "        nonlocal log_counter_trace\n",
        "        if 'logs' in call and isinstance(call['logs'], list):\n",
        "            for log in call['logs']:\n",
        "                # Ensure log is a dictionary\n",
        "                if not isinstance(log, dict): continue\n",
        "\n",
        "                log_details = {\n",
        "                    \"address\": log.get(\"address\", \"N/A\"),\n",
        "                    \"topics\": log.get(\"topics\", []),\n",
        "                    \"data\": log.get(\"data\", \"0x\"),\n",
        "                    \"log_index_trace\": log_counter_trace\n",
        "                }\n",
        "                log_counter_trace += 1\n",
        "\n",
        "                # Check if log is from PYUSD contract\n",
        "                address_lower = log_details[\"address\"].lower()\n",
        "                is_pyusd_contract = address_lower in PYUSD_CONTRACTS\n",
        "\n",
        "                # Basic data for all logs\n",
        "                log_entry = {\n",
        "                    \"log_idx_trace\": log_details[\"log_index_trace\"],\n",
        "                    \"address\": log_details[\"address\"],\n",
        "                    \"contract\": PYUSD_CONTRACTS.get(address_lower, \"Other\"),\n",
        "                    \"is_pyusd\": is_pyusd_contract,\n",
        "                    \"topic0\": log_details[\"topics\"][0] if log_details[\"topics\"] else \"N/A\",\n",
        "                    \"topic0_short\": log_details[\"topics\"][0][:10]+\"...\" if log_details[\"topics\"] else \"N/A\",\n",
        "                    \"details\": \"Not Decoded\",\n",
        "                    \"event_name\": \"Unknown\"\n",
        "                }\n",
        "\n",
        "                # event decoding with the registry\n",
        "                if is_pyusd_contract and isinstance(log_details[\"topics\"], list) and log_details[\"topics\"]:\n",
        "                    event_topic = log_details[\"topics\"][0]\n",
        "                    if event_topic in PYUSD_EVENTS:\n",
        "                        event_info = PYUSD_EVENTS[event_topic]\n",
        "                        log_entry[\"event_name\"] = event_info[\"name\"]\n",
        "\n",
        "                        try:\n",
        "                            # Decode event data using registered decoder\n",
        "                            decoded_data = event_info[\"decoder\"](log_details[\"topics\"], log_details[\"data\"])\n",
        "\n",
        "                            # Format details based on event type\n",
        "                            if \"Transfer\" in event_info[\"name\"]:\n",
        "                                value_pyusd_str = format_value_pyusd(decoded_data[\"value\"])\n",
        "                                log_entry[\"details\"] = f\"PYUSD Transfer: {value_pyusd_str} from {shorten_address(decoded_data['from'])} to {shorten_address(decoded_data['to'])}\"\n",
        "                                log_entry[\"is_transfer\"] = True\n",
        "                                log_entry[\"amount\"] = decoded_data[\"value\"]\n",
        "                                log_entry[\"from_addr\"] = decoded_data[\"from\"]\n",
        "                                log_entry[\"to_addr\"] = decoded_data[\"to\"]\n",
        "                            elif \"Approval\" in event_info[\"name\"]:\n",
        "                                value_pyusd_str = format_value_pyusd(decoded_data[\"value\"])\n",
        "                                log_entry[\"details\"] = f\"PYUSD Approval: {shorten_address(decoded_data['owner'])} approved {value_pyusd_str} for {shorten_address(decoded_data['spender'])}\"\n",
        "                                log_entry[\"is_approval\"] = True\n",
        "                                log_entry[\"amount\"] = decoded_data[\"value\"]\n",
        "                                log_entry[\"owner\"] = decoded_data[\"owner\"]\n",
        "                                log_entry[\"spender\"] = decoded_data[\"spender\"]\n",
        "                            elif \"Paused\" in event_info[\"name\"]:\n",
        "                                account = decoded_data.get(\"account\", \"N/A\")\n",
        "                                log_entry[\"details\"] = f\"PYUSD Paused by {shorten_address(account) if account else 'N/A'}\"\n",
        "                                log_entry[\"is_pause\"] = True\n",
        "                            elif \"Unpaused\" in event_info[\"name\"]:\n",
        "                                account = decoded_data.get(\"account\", \"N/A\")\n",
        "                                log_entry[\"details\"] = f\"PYUSD Unpaused by {shorten_address(account) if account else 'N/A'}\"\n",
        "                                log_entry[\"is_unpause\"] = True\n",
        "\n",
        "                        except Exception as decode_err:\n",
        "                            log_entry[\"details\"] = f\"PYUSD Event (Decode Error: {decode_err})\"\n",
        "\n",
        "                logs_data.append(log_entry)\n",
        "\n",
        "        # Check sub-calls recursively\n",
        "        if 'calls' in call and isinstance(call['calls'], list):\n",
        "            for sub_call in call['calls']:\n",
        "                extract_logs_recursive(sub_call)\n",
        "\n",
        "    # Extract logs if present in trace config\n",
        "    extract_logs_recursive(trace_result)\n",
        "    logs_df = pd.DataFrame(logs_data) if logs_data else pd.DataFrame()\n",
        "\n",
        "    # --- Create Contract Interaction Graph with Plotly ---\n",
        "    contract_graph = None\n",
        "    if contract_interactions:\n",
        "        try:\n",
        "            contract_graph = create_plotly_contract_interaction_graph(contract_interactions)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create contract interaction graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # --- Create Detailed Call Graph with Plotly ---\n",
        "    call_graph = None\n",
        "    if call_data_list:\n",
        "        try:\n",
        "            call_graph = create_plotly_call_graph(call_data_list)\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create detailed call graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Create PYUSD flow graph if transfers exist\n",
        "    flow_graph = None\n",
        "    if pyusd_transfers:\n",
        "        try:\n",
        "            flow_graph = create_plotly_flow_graph(pyusd_transfers)\n",
        "        except Exception as flow_err:\n",
        "            console.print(f\"[warning]Could not create PYUSD flow graph: {flow_err}\", style=\"warning\")\n",
        "\n",
        "    # Create Gas Usage by Category\n",
        "    gas_category_df = pd.DataFrame(\n",
        "        [{\"category\": k, \"gas_used\": v} for k, v in gas_by_category.items() if v > 0]\n",
        "    )\n",
        "\n",
        "    return call_graph, call_df, logs_df, flow_graph, contract_graph, gas_category_df, state_changes_df, pyusd_transfers\n",
        "\n",
        "# =============================================================================================\n",
        "# --- Execute callTracer Analysis ---\n",
        "# =============================================================================================\n",
        "if 'TARGET_TX_HASH' in locals() and validate_tx_hash: # Use the validation flag from setup cell\n",
        "    console.print(\"\\n\\n[bold]üéØ Using callTracer on Mainnet[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    console.print(f\"Target Transaction : {TARGET_TX_HASH}\")\n",
        "\n",
        "    # Use the trace config from the configuration\n",
        "    trace_result_call = make_rpc_request(\"debug_traceTransaction\",\n",
        "                                         [TARGET_TX_HASH, {\"tracer\": \"callTracer\", \"tracerConfig\": TRACE_CONFIGS[\"callTracer\"]}],\n",
        "                                         network='mainnet')\n",
        "\n",
        "    if trace_result_call:\n",
        "        console.print(\"[success]Successfully received trace data.\", style=\"success\")\n",
        "\n",
        "        # --- Parse and Visualize ---\n",
        "        try:\n",
        "            call_graph, call_df, logs_df, pyusd_flow, contract_graph, gas_category_df, state_changes_df, pyusd_transfers = parse_call_trace(trace_result_call, TARGET_TX_HASH)\n",
        "\n",
        "            # Create output widgets for each visualization (add this right after parsing the trace)\n",
        "            contract_graph_output = widgets.Output()\n",
        "            call_graph_output = widgets.Output()\n",
        "            flow_graph_output = widgets.Output()\n",
        "\n",
        "            # 1. TRANSACTION OVERVIEW DASHBOARD\n",
        "            console.print(\"\\n\\n[bold cyan3]üîç PYUSD TRANSACTION ANALYSIS DASHBOARD[/bold cyan3]\", justify=\"left\")\n",
        "            console.print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\", style=\"cyan3\", justify=\"left\")\n",
        "\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                # Basic transaction metrics\n",
        "                tx_stats = {\n",
        "                    \"total_calls\": len(call_df),\n",
        "                    \"pyusd_calls\": len(call_df[call_df['is_pyusd']]),\n",
        "                    \"max_call_depth\": call_df['depth'].max(),\n",
        "                    \"total_gas\": call_df['gasUsed'].sum(),\n",
        "                    \"errors\": len(call_df[call_df['error'].notnull()])\n",
        "                }\n",
        "\n",
        "                stats_table = Table(title=\"Transaction Metrics\", show_header=True, header_style=\"bold cyan\")\n",
        "                stats_table.add_column(\"Metric\", style=\"dim\")\n",
        "                stats_table.add_column(\"Value\")\n",
        "\n",
        "                for k, v in tx_stats.items():\n",
        "                    if k == 'total_gas':\n",
        "                        stats_table.add_row(k.replace('_', ' ').title(), f\"{v:,} gas units\")\n",
        "                    else:\n",
        "                        stats_table.add_row(k.replace('_', ' ').title(), str(v))\n",
        "\n",
        "                console.print(stats_table)\n",
        "\n",
        "           # 2. Display Contract Interaction Graph\n",
        "            if contract_graph:\n",
        "                console.print(\"\\n\\n[bold cyan3]üìä Contract Interaction Overview[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(contract_graph)\n",
        "                    console.print(\"\\n\\n[info]This graph shows the high-level interactions between contracts in this transaction.\", style=\"info\")\n",
        "                except Exception as viz_err:\n",
        "                    console.print(f\"[warning]Could not render contract interaction graph: {viz_err}\", style=\"warning\")\n",
        "\n",
        "            # 3. Display Call Graph Visualization\n",
        "            console.print(\"\\n\\n[bold cyan3]üìä Detailed Call Graph Visualization[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "            if call_graph:\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(call_graph)\n",
        "                    console.print(\"\\n\\n[info]This visualization shows the detailed call hierarchy in this transaction.\", style=\"info\")\n",
        "                except Exception as viz_err:\n",
        "                    console.print(f\"[warning]Could not render visualization: {viz_err}\", style=\"warning\")\n",
        "            else:\n",
        "                console.print(\"[warning]Call graph generation failed.\", style=\"warning\")\n",
        "\n",
        "            # 4. Display PYUSD Flow Graph if available\n",
        "            if pyusd_flow:\n",
        "                console.print(\"\\n\\n[bold cyan3]üîÑ PYUSD Token Flow Analysis[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "                try:\n",
        "                    # Simply display the visualization\n",
        "                    display(pyusd_flow)\n",
        "                    console.print(\"\\n\\n[info]This graph shows the movement of PYUSD tokens in this transaction.\", style=\"info\")\n",
        "                except Exception as flow_err:\n",
        "                    console.print(f\"[warning]Could not render PYUSD flow: {flow_err}\", style=\"warning\")\n",
        "\n",
        "            # 5. State Changes Analysis\n",
        "            if state_changes_df is not None and not state_changes_df.empty:\n",
        "                console.print(\"\\n\\n[bold cyan3]üîÑ PYUSD State Changes[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "                console.print(\"[info]The following state changes occurred in PYUSD contracts:\", style=\"info\")\n",
        "\n",
        "                # Format amounts in dataframe\n",
        "                state_changes_df['formatted_amount'] = state_changes_df['amount'].apply(format_value_pyusd)\n",
        "\n",
        "                # Display state changes with appropriate columns\n",
        "                display(state_changes_df[['contract', 'function', 'type', 'formatted_amount', 'gas_used']])\n",
        "\n",
        "                # Summary of state impact\n",
        "                if 'type' in state_changes_df.columns:\n",
        "                    changes_by_type = state_changes_df['type'].value_counts()\n",
        "                    console.print(\"\\n[bold]State Change Summary:[/bold]\")\n",
        "                    for change_type, count in changes_by_type.items():\n",
        "                        console.print(f\"- {change_type.title()}: {count} operations\")\n",
        "            else:\n",
        "                console.print(\"\\n\\n[info]No direct PYUSD state changes detected in this transaction.\", style=\"info\")\n",
        "\n",
        "            # 6. Gas Usage Analysis\n",
        "            if gas_category_df is not None and not gas_category_df.empty:\n",
        "                console.print(\"\\n\\n[bold yellow3]‚õΩ Gas Usage Analysis[/bold yellow3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "                # Create simple gas usage table\n",
        "                gas_table = Table(title=\"Gas Usage by Operation Category\", show_header=True, header_style=\"bold yellow3\")\n",
        "                gas_table.add_column(\"Category\", style=\"dim\")\n",
        "                gas_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "                gas_table.add_column(\"Percentage\", justify=\"right\")\n",
        "\n",
        "                total_gas = gas_category_df['gas_used'].sum()\n",
        "\n",
        "                for _, row in gas_category_df.iterrows():\n",
        "                    category = row['category'].replace('_', ' ').title()\n",
        "                    gas_used = row['gas_used']\n",
        "                    percentage = (gas_used / total_gas * 100) if total_gas > 0 else 0\n",
        "                    gas_table.add_row(\n",
        "                        category,\n",
        "                        f\"{gas_used:,}\",\n",
        "                        f\"{percentage:.1f}%\"\n",
        "                    )\n",
        "\n",
        "                console.print(gas_table)\n",
        "\n",
        "                # Gas usage visualization\n",
        "                try:\n",
        "                    # Color by operation category for better visibility\n",
        "                    fig_gas = px.pie(gas_category_df, values='gas_used', names='category',\n",
        "                                     title=f'<b>Gas Usage Distribution ({shorten_address(TARGET_TX_HASH)})</b>')\n",
        "                    fig_gas.update_layout(\n",
        "                        template=\"plotly_white\",\n",
        "                        title={\n",
        "                            'y': 0.95,\n",
        "                            'x': 0.5,\n",
        "                            'xanchor': 'center',\n",
        "                            'yanchor': 'top',\n",
        "                            'font': {'size': 16}\n",
        "                        },\n",
        "                        margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                    )\n",
        "                    fig_gas.show()\n",
        "                except Exception as plot_err:\n",
        "                    console.print(f\"[warning]Could not generate gas usage plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "            # 7. Filtered Call Data Table\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                console.print(\"\\n\\n[bold cyan3]üìã Key Contract Calls[/bold cyan3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "                # Focus on PYUSD calls for a cleaner view\n",
        "                pyusd_calls = call_df[call_df['is_pyusd']]\n",
        "\n",
        "                if not pyusd_calls.empty:\n",
        "                    console.print(f\"[success]Found {len(pyusd_calls)} PYUSD-related calls in this transaction.\", style=\"success\")\n",
        "\n",
        "                    # Style the DataFrame for better visibility\n",
        "                    def highlight_pyusd(val):\n",
        "                        return 'background-color: palegreen' if val else ''\n",
        "\n",
        "                    # Display with conditional formatting - only important columns\n",
        "                    display_cols = ['id', 'type', 'depth', 'contract', 'function_category', 'gasUsed', 'error']\n",
        "                    display(pyusd_calls[display_cols])\n",
        "                else:\n",
        "                    console.print(\"[info]No PYUSD-specific calls found in this transaction.\", style=\"info\")\n",
        "\n",
        "                # Show high gas usage calls with function names\n",
        "                console.print(\"\\n[bold yellow3]Highest Gas Usage Calls:[/bold yellow3]\")\n",
        "                high_gas_calls = call_df.nlargest(5, 'gasUsed')\n",
        "\n",
        "                # Add function description to high gas calls\n",
        "                high_gas_calls['function_name'] = high_gas_calls.apply(\n",
        "                    lambda row: get_function_description(\n",
        "                        row['input_preview'],\n",
        "                        row['is_pyusd'] if 'is_pyusd' in row else False,\n",
        "                        row['contract'] if 'contract' in row else \"Non-PYUSD Contract\"\n",
        "                    ),\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                # Display with function name instead of category if available\n",
        "                display(high_gas_calls[['id', 'type', 'contract', 'function_name', 'gasUsed']])\n",
        "\n",
        "            # 8. PYUSD Event Analysis\n",
        "            if logs_df is not None and not logs_df.empty:\n",
        "                console.print(\"\\n\\n[bold green3]üìù PYUSD Events Analysis[/bold green3]\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "\n",
        "                # Highlight PYUSD logs\n",
        "                pyusd_logs = logs_df[logs_df['is_pyusd']]\n",
        "                if not pyusd_logs.empty:\n",
        "                    console.print(f\"[success]Found {len(pyusd_logs)} PYUSD events in this transaction.\", style=\"success\")\n",
        "\n",
        "                    # Group by event type\n",
        "                    if 'event_name' in pyusd_logs.columns:\n",
        "                        event_counts = pyusd_logs['event_name'].value_counts()\n",
        "\n",
        "                        event_table = Table(title=\"PYUSD Events\", show_header=True, header_style=\"bold green3\")\n",
        "                        event_table.add_column(\"Event Type\", style=\"dim\")\n",
        "                        event_table.add_column(\"Count\", justify=\"right\")\n",
        "\n",
        "                        for event, count in event_counts.items():\n",
        "                            event_table.add_row(event, str(count))\n",
        "\n",
        "                        console.print(event_table)\n",
        "\n",
        "                    # Display detailed event data\n",
        "                    console.print(\"\\n\\n[bold green3]PYUSD Event Details:[/bold green3]\")\n",
        "                    display(pyusd_logs[['contract', 'event_name', 'details']])\n",
        "\n",
        "                    # Transfer value analysis\n",
        "                    if 'amount' in pyusd_logs.columns and 'is_transfer' in pyusd_logs.columns:\n",
        "                        transfer_logs = pyusd_logs[pyusd_logs['is_transfer']]\n",
        "                        if not transfer_logs.empty:\n",
        "                            total_transferred = transfer_logs['amount'].sum()\n",
        "                            console.print(f\"\\n\\n[info][bold cyan3]Total PYUSD transferred:[bold cyan3] {format_value_pyusd(total_transferred)}\", style=\"info\")\n",
        "                else:\n",
        "                    console.print(\"[info]No PYUSD events found in this transaction.\", style=\"info\")\n",
        "            else:\n",
        "                console.print(\"[info]No logs extracted from trace.\", style=\"info\")\n",
        "\n",
        "            # 9. Add Recommendations Section\n",
        "            console.print(\"\\n\\n[bold cyan3]üí° Analysis Observations & Recommendations[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            recommendations = []\n",
        "\n",
        "            # Check for high gas usage patterns\n",
        "            if call_df is not None and not call_df.empty:\n",
        "                high_gas_threshold = call_df['gasUsed'].sum() * 0.25  # 25% of total gas\n",
        "                high_gas_ops = call_df[call_df['gasUsed'] > high_gas_threshold]\n",
        "                if not high_gas_ops.empty:\n",
        "                    recommendations.append(f\"- High gas operations detected: {len(high_gas_ops)} calls used >25% of transaction gas\")\n",
        "\n",
        "            # Check for deep call stack\n",
        "            if call_df is not None and 'depth' in call_df.columns:\n",
        "                max_depth = call_df['depth'].max()\n",
        "                if max_depth > 5:\n",
        "                    recommendations.append(f\"- Deep call stack detected (max depth: {max_depth})\")\n",
        "\n",
        "            # Check token flow patterns\n",
        "            if logs_df is not None and 'is_transfer' in logs_df.columns:\n",
        "                transfer_count = logs_df['is_transfer'].sum()\n",
        "                if transfer_count > 3:\n",
        "                    recommendations.append(f\"- Complex token movement detected ({transfer_count} transfers)\")\n",
        "\n",
        "            # Add general PYUSD observations\n",
        "            if call_df is not None and 'is_pyusd' in call_df.columns:\n",
        "                pyusd_calls = call_df[call_df['is_pyusd']]\n",
        "                if not pyusd_calls.empty:\n",
        "                    recommendations.append(f\"- Transaction involves {len(pyusd_calls)} PYUSD contract interactions\")\n",
        "\n",
        "            # Display recommendations\n",
        "            if recommendations:\n",
        "                for rec in recommendations:\n",
        "                    console.print(rec)\n",
        "            else:\n",
        "                console.print(\"[info]No specific observations to highlight for this transaction.\", style=\"info\")\n",
        "\n",
        "            # 10. Export Options\n",
        "            console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            # Create export output area\n",
        "            export_output = widgets.Output()\n",
        "\n",
        "            # Create export buttons with proper styling\n",
        "            export_buttons = widgets.HBox([\n",
        "                widgets.Button(\n",
        "                    description='Export to CSV',\n",
        "                    button_style='primary',  # Green\n",
        "                    layout=widgets.Layout(width='150px')\n",
        "                ),\n",
        "                widgets.Button(\n",
        "                    description='Export as JSON',\n",
        "                    button_style='warning',  # Orange\n",
        "                    layout=widgets.Layout(width='150px')\n",
        "                ),\n",
        "                widgets.Button(\n",
        "                    description='Export to Google Sheets',\n",
        "                    button_style='info',     # Blue\n",
        "                    layout=widgets.Layout(width='200px')\n",
        "                )\n",
        "            ])\n",
        "\n",
        "            # Define export handlers with simplified loading indicators\n",
        "            def export_csv(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    console.print(\"[cyan3]Exporting to CSV...\", style=\"info\")\n",
        "\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.csv\"\n",
        "\n",
        "                    try:\n",
        "                        # Export to CSV\n",
        "                        result = download_csv_direct(call_df, filename)\n",
        "\n",
        "                        # Clear loading message and show success\n",
        "                        clear_output()\n",
        "                        console.print(\"‚úì Successfully exported to CSV\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"‚ùå Error exporting to CSV: {str(e)}\", style=\"error\")\n",
        "\n",
        "            def export_json(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    console.print(\"[cyan3]Exporting to JSON...\", style=\"info\")\n",
        "\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.json\"\n",
        "\n",
        "                    try:\n",
        "                        # Prepare export data\n",
        "                        export_data = {\n",
        "                            \"transaction_hash\": TARGET_TX_HASH,\n",
        "                            \"analysis_type\": \"callTracer\",\n",
        "                            \"transaction_stats\": tx_stats if 'tx_stats' in locals() else {},\n",
        "                            \"state_changes\": state_changes_df.to_dict('records') if state_changes_df is not None and not state_changes_df.empty else [],\n",
        "                            \"gas_by_category\": gas_category_df.to_dict('records') if gas_category_df is not None and not gas_category_df.empty else [],\n",
        "                            \"pyusd_transfers\": pyusd_transfers if pyusd_transfers is not None else []\n",
        "                        }\n",
        "\n",
        "                        # Export to JSON\n",
        "                        result = download_json_direct(export_data, filename)\n",
        "\n",
        "                        # Clear loading message and show success\n",
        "                        clear_output()\n",
        "                        console.print(\"‚úì Successfully exported to JSON\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"‚ùå Error exporting to JSON: {str(e)}\", style=\"error\")\n",
        "\n",
        "            def export_to_sheets(b):\n",
        "                with export_output:\n",
        "                    clear_output()\n",
        "                    try:\n",
        "                        # Collect all data for the sheet\n",
        "                        export_data = {\n",
        "                            \"transaction_hash\": TARGET_TX_HASH,\n",
        "                            \"transaction_stats\": tx_stats if 'tx_stats' in locals() else {},\n",
        "                            \"gas_distribution\": gas_category_df.to_dict('records') if gas_category_df is not None else [],\n",
        "                            \"pyusd_transfers\": pyusd_transfers if pyusd_transfers is not None else [],\n",
        "                            \"state_changes\": state_changes_df.to_dict('records') if state_changes_df is not None and not state_changes_df.empty else [],\n",
        "                            \"logs_df\": logs_df if logs_df is not None and not logs_df.empty else None\n",
        "                        }\n",
        "\n",
        "                        # Call the export function\n",
        "                        spreadsheet_url, sheet_title = export_to_google_sheets(call_df, export_data, TARGET_TX_HASH)\n",
        "\n",
        "                        # Open the spreadsheet and display link\n",
        "                        display(Javascript(f'window.open(\"{spreadsheet_url}\", \"_blank\");'))\n",
        "\n",
        "                        # 2. Display *only* the link and success message as static HTML output\n",
        "                        clear_output(wait=True)\n",
        "                        console.print(\"‚úì Successfully exported to Google Sheets\", style=\"spring_green3\")\n",
        "                        display(HTML(f'''\n",
        "                        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "                        '''))\n",
        "\n",
        "                    except Exception as e:\n",
        "                        clear_output()\n",
        "                        console.print(f\"‚ùå Error exporting to Google Sheets: {str(e)}\", style=\"error\")\n",
        "                        html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                        display(HTML(html))\n",
        "\n",
        "                        # Fallback to CSV\n",
        "                        console.print(\"[cyan3]Falling back to CSV download...\", style=\"info\")\n",
        "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                        filename = f\"calltrace_{TARGET_TX_HASH[:10]}_{timestamp}.csv\"\n",
        "                        result = download_csv_direct(call_df, filename)\n",
        "\n",
        "                        clear_output()\n",
        "                        console.print(\"‚úì CSV fallback ready\", style=\"spring_green3\")\n",
        "                        display(result)\n",
        "                        display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "            # Connect handlers to buttons\n",
        "            export_buttons.children[0].on_click(export_csv)\n",
        "            export_buttons.children[1].on_click(export_json)\n",
        "            export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "            # Display button container and output area\n",
        "            display(export_buttons)\n",
        "            display(export_output)\n",
        "\n",
        "        except Exception as parse_err:\n",
        "            console.print(f\"[error]Failed during parsing or visualization: {parse_err}\", style=\"error\")\n",
        "            import traceback\n",
        "            console.print(traceback.format_exc())\n",
        "    else:\n",
        "        console.print(\"[error]Failed to retrieve trace data from RPC node.\", style=\"error\")\n",
        "else:\n",
        "    console.print(\"[warning]No valid transaction hash found. Please set TARGET_TX_HASH to a valid transaction hash.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "jlWAKP7_Qdo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Using `structLog` Tracer: Opcode-Level Execution Analysis (Use Cautiously)\n",
        "\n",
        "The `structLog` tracer dives deep into the Ethereum Virtual Machine (EVM), providing a step-by-step log of each opcode executed during the transaction. For each step, it details the program counter (PC), opcode, remaining gas, gas cost, stack contents, memory state, and storage changes (if enabled).\n",
        "\n",
        "> **‚ö†Ô∏è Extreme Granularity & Resource Intensity**\n",
        ">\n",
        "> *   **Method:** `debug_traceTransaction` with `tracer: \"structLog\"`\n",
        "> *   **Multiplier:** `50x` (Same base multiplier as `callTracer`, but output size is *significantly* larger)\n",
        "> *   **Output Size:** Can generate **very large** outputs (potentially hundreds of thousands of steps/lines, consuming significant memory/browser resources) for even moderately complex transactions.\n",
        "> *   **Use Case:** Best suited for highly specific debugging tasks, deep gas optimization analysis at the opcode level, or verifying precise execution paths, rather than general transaction overview. **Use with caution.**\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **GCP Advantage:** While the base multiplier is `50x`, the sheer volume of data returned by `structLog` makes it extremely demanding on RPC node resources. GCP's infrastructure and generous quotas make it feasible to retrieve these detailed traces where other providers might time out, restrict output size, or charge heavily.\n",
        "> *   **PYUSD Insight:** `structLog` can be used for:\n",
        ">     *   **Fine-grained Gas Profiling:** Identifying exactly which opcodes consume the most gas during PYUSD function execution (e.g., `SSTORE` during transfers/approvals).\n",
        ">     *   **Debugging Reverts:** Pinpointing the exact opcode and state (stack/memory) where a PYUSD transaction failed.\n",
        ">     *   **Security Analysis:** Examining low-level execution for potential vulnerabilities or unexpected behavior within PYUSD or interacting contracts.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Conditional Execution:** The code includes a flag (`RUN_STRUCTLOG_TRACE`) which defaults to `False`. Set this to `True` only if you specifically need this level of detail.\n",
        "2.  **Fetch Trace:** Calls `debug_traceTransaction` using `TARGET_TX_HASH` and the `structLog` configuration.\n",
        "3.  **Parse Steps:** The `parse_struct_log` function processes the potentially massive list of execution steps.\n",
        "4.  **Summarize & Visualize:**\n",
        "    *   **Overview:** Displays total steps, gas cost, call depth, and highlights PYUSD execution percentage.\n",
        "    *   **Gas Analysis:** Generates plots showing gas cost distribution by opcode *category* and by individual *opcode*.\n",
        "    *   **Execution Timeline:** Plots gas remaining over execution steps, highlighting sections executed within PYUSD contracts.\n",
        "    *   **PYUSD Focus:** Analyzes opcode frequency and gas usage specifically within PYUSD contract execution steps.\n",
        "    *   **Data Sample:** Displays the first few steps of the detailed execution trace DataFrame.\n",
        "    *   **Export Options:** Allows downloading the full (potentially large) execution step data.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Gas Plots:** Identify which opcode categories (e.g., `STORAGE`, `MEMORY`, `CALL`) and specific opcodes (e.g., `SSTORE`, `CALL`, `KECCAK256`) dominate gas consumption. Compare this within PYUSD vs. non-PYUSD sections.\n",
        "*   **Execution Timeline:** Observe gas depletion patterns. Look for sharp drops corresponding to expensive operations. Note the percentage of time spent executing PYUSD code.\n",
        "*   **Data Sample:** Understand the structure of the per-opcode data (PC, gas, stack, memory).\n",
        "*   **(If Debugging):** Search the full trace data (if exported) for `REVERT` opcodes or unexpected stack/memory states near the point of failure."
      ],
      "metadata": {
        "id": "fHt4Hc9Z_gbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üî¨ Trace Transaction using debug_traceTransaction (structLog Tracer Opcode-Level Detail)\n",
        "# =============================================================================================\n",
        "# This cell performs detailed opcode-level transaction analysis using the debug_traceTransaction method with the structLog tracer.\n",
        "# It prepares the data and presents insights by:\n",
        "# - Conditionally executing the trace based on the RUN_STRUCTLOG_TRACE flag.\n",
        "# - Parsing the raw structLog output, calculating step-by-step gas costs, categorizing opcodes, and tracking contract execution context (including PYUSD).\n",
        "# - Generating interactive Plotly visualizations for overall gas usage (by category, by opcode), execution timeline (highlighting PYUSD), and PYUSD-specific gas analysis.\n",
        "# - Displaying summary statistics (Panel, Rich tables) and a sample of the processed trace data.\n",
        "# - Providing interactive buttons for exporting the detailed trace data to CSV, JSON, or Google Sheets using helper functions.\n",
        "\n",
        "import base64\n",
        "import json\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, tx_hash):\n",
        "    \"\"\"Export StructLog analysis data to Google Sheets with rich formatting.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[cyan3]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD StructLog Analysis {tx_hash[:10]} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Execution Steps\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD StructLog Analysis\"],\n",
        "            [f\"Transaction: {tx_hash}\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # Add transaction stats summary\n",
        "        if \"summary\" in data_dict:\n",
        "            stats = data_dict[\"summary\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Summary\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "\n",
        "                # Try to format numerical values with commas\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        formatted_value = f\"{value:,}\"\n",
        "                    else:\n",
        "                        formatted_value = str(value)\n",
        "                except:\n",
        "                    formatted_value = str(value)\n",
        "\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 2  # Add extra space after table\n",
        "\n",
        "        # Add opcode distribution reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Opcode Distribution Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 0.7, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Opcode distribution visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add gas usage reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Gas usage visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add main DataFrame data\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Execution Steps Data\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # For StructLog data, select most important columns for readability\n",
        "            # if dataframe has too many columns\n",
        "            if len(df.columns) > 10:\n",
        "                key_cols = [\"pc\", \"op\", \"gas\", \"gasCost\", \"depth\", \"stack\", \"memory\", \"storage\"]\n",
        "                display_cols = [col for col in key_cols if col in df.columns]\n",
        "\n",
        "                # Add any custom columns that might contain analysis results\n",
        "                other_important_cols = []\n",
        "                for col in df.columns:\n",
        "                    if col not in display_cols and any(x in col.lower() for x in [\"pyusd\", \"token\", \"contract\", \"note\", \"category\"]):\n",
        "                        other_important_cols.append(col)\n",
        "\n",
        "                display_cols.extend(other_important_cols)\n",
        "                display_df = df[display_cols]\n",
        "            else:\n",
        "                display_df = df\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [display_df.columns.tolist()] + display_df.values.tolist()\n",
        "\n",
        "            # Format values for better readability\n",
        "            for i in range(1, len(df_values)):\n",
        "                for j, col in enumerate(display_df.columns):\n",
        "                    val = df_values[i][j]\n",
        "\n",
        "                    # Format different column types appropriately\n",
        "                    if pd.isnull(val):\n",
        "                        df_values[i][j] = \"\"\n",
        "                    elif col in [\"gas\", \"gasCost\"] and isinstance(val, (int, float)):\n",
        "                        df_values[i][j] = f\"{val:,}\"\n",
        "                    elif col in [\"stack\", \"memory\", \"storage\"] and isinstance(val, (list, dict)):\n",
        "                        # Truncate long data structures to prevent huge cells\n",
        "                        df_values[i][j] = str(val)[:100] + \"...\" if len(str(val)) > 100 else str(val)\n",
        "                    else:\n",
        "                        df_values[i][j] = str(val)\n",
        "\n",
        "            worksheet.update(f\"A{current_row}\", df_values)\n",
        "\n",
        "            # Format the DataFrame header\n",
        "            worksheet.format(f\"A{current_row}:{chr(65+len(display_df.columns)-1)}{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            # Add alternating row colors for readability\n",
        "            data_rows = len(df_values)\n",
        "            for i in range(2, data_rows + 1, 2):\n",
        "                row_num = current_row + i - 1\n",
        "                worksheet.format(f\"A{row_num}:{chr(65+len(display_df.columns)-1)}{row_num}\", {\n",
        "                    \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Attempt to resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Clear loading message and show success message\n",
        "        clear_output()\n",
        "        console.print(\"‚úì Successfully exported to Google Sheets\", style=\"spring_green3\")\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clear loading message and show error\n",
        "        clear_output()\n",
        "        console.print(f\"‚ùå Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "def parse_struct_log(struct_logs_list, tx_hash):\n",
        "    \"\"\"Parses structLog output for analysis and visualization.\"\"\"\n",
        "    if not struct_logs_list or not isinstance(struct_logs_list, list):\n",
        "        console.print(\"[warning]No structLog data provided or invalid format.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    # --- Initialize tracking variables ---\n",
        "    log_data = []\n",
        "    total_gas_cost = 0\n",
        "    last_gas = 0\n",
        "    current_contracts = {}  # Map depth -> contract address\n",
        "    pyusd_execution_steps = 0\n",
        "\n",
        "    # --- Define OPCODE categories for better analysis ---\n",
        "    OPCODE_CATEGORIES = {\n",
        "        \"arithmetic\": [\"ADD\", \"MUL\", \"SUB\", \"DIV\", \"SDIV\", \"MOD\", \"SMOD\", \"ADDMOD\", \"MULMOD\", \"EXP\", \"SIGNEXTEND\"],\n",
        "        \"comparison\": [\"LT\", \"GT\", \"SLT\", \"SGT\", \"EQ\", \"ISZERO\"],\n",
        "        \"bitwise\": [\"AND\", \"OR\", \"XOR\", \"NOT\", \"BYTE\", \"SHL\", \"SHR\", \"SAR\"],\n",
        "        \"memory\": [\"MLOAD\", \"MSTORE\", \"MSTORE8\", \"MSIZE\", \"MCOPY\"],\n",
        "        \"storage\": [\"SLOAD\", \"SSTORE\"],\n",
        "        \"flow\": [\"JUMP\", \"JUMPI\", \"JUMPDEST\", \"PC\", \"STOP\", \"RETURN\", \"REVERT\"],\n",
        "        \"stack\": [\"POP\", \"PUSH1\", \"PUSH2\", \"PUSH3\", \"PUSH4\", \"PUSH5\", \"PUSH6\", \"PUSH7\", \"PUSH8\",\n",
        "                 \"PUSH9\", \"PUSH10\", \"PUSH11\", \"PUSH12\", \"PUSH13\", \"PUSH14\", \"PUSH15\", \"PUSH16\",\n",
        "                 \"PUSH17\", \"PUSH18\", \"PUSH19\", \"PUSH20\", \"PUSH21\", \"PUSH22\", \"PUSH23\", \"PUSH24\",\n",
        "                 \"PUSH25\", \"PUSH26\", \"PUSH27\", \"PUSH28\", \"PUSH29\", \"PUSH30\", \"PUSH31\", \"PUSH32\",\n",
        "                 \"DUP1\", \"DUP2\", \"DUP3\", \"DUP4\", \"DUP5\", \"DUP6\", \"DUP7\", \"DUP8\",\n",
        "                 \"DUP9\", \"DUP10\", \"DUP11\", \"DUP12\", \"DUP13\", \"DUP14\", \"DUP15\", \"DUP16\",\n",
        "                 \"SWAP1\", \"SWAP2\", \"SWAP3\", \"SWAP4\", \"SWAP5\", \"SWAP6\", \"SWAP7\", \"SWAP8\",\n",
        "                 \"SWAP9\", \"SWAP10\", \"SWAP11\", \"SWAP12\", \"SWAP13\", \"SWAP14\", \"SWAP15\", \"SWAP16\"],\n",
        "        \"environment\": [\"ADDRESS\", \"BALANCE\", \"ORIGIN\", \"CALLER\", \"CALLVALUE\", \"CALLDATALOAD\",\n",
        "                        \"CALLDATASIZE\", \"CALLDATACOPY\", \"CODESIZE\", \"CODECOPY\", \"GASPRICE\",\n",
        "                        \"EXTCODESIZE\", \"EXTCODECOPY\", \"RETURNDATASIZE\", \"RETURNDATACOPY\",\n",
        "                        \"EXTCODEHASH\", \"BLOCKHASH\", \"COINBASE\", \"TIMESTAMP\", \"NUMBER\",\n",
        "                        \"DIFFICULTY\", \"GASLIMIT\", \"CHAINID\", \"SELFBALANCE\", \"BASEFEE\"],\n",
        "        \"contract\": [\"CREATE\", \"CREATE2\", \"CALL\", \"CALLCODE\", \"DELEGATECALL\", \"STATICCALL\", \"SELFDESTRUCT\"],\n",
        "        \"logging\": [\"LOG0\", \"LOG1\", \"LOG2\", \"LOG3\", \"LOG4\"],\n",
        "        \"gas\": [\"GAS\"],\n",
        "        \"other\": []\n",
        "    }\n",
        "\n",
        "    def get_opcode_category(opcode):\n",
        "        \"\"\"Determine the category of an opcode based on predefined categories.\"\"\"\n",
        "        for category, opcodes in OPCODE_CATEGORIES.items():\n",
        "            if opcode in opcodes:\n",
        "                return category\n",
        "        return \"other\"\n",
        "\n",
        "    console.print(f\"[info]Parsing {len(struct_logs_list):,} structLog steps for {shorten_address(tx_hash)}\\n\\n\", style=\"info\")\n",
        "\n",
        "    # Get initial gas from the first step if available\n",
        "    if struct_logs_list and isinstance(struct_logs_list[0], dict) and 'gas' in struct_logs_list[0]:\n",
        "        last_gas = struct_logs_list[0].get('gas', 0)\n",
        "\n",
        "    # --- Process each execution step in the struct logs ---\n",
        "    for i, step in enumerate(struct_logs_list):\n",
        "        # Ensure step is a dictionary\n",
        "        if not isinstance(step, dict):\n",
        "            continue\n",
        "\n",
        "        # Calculate gas cost for this step\n",
        "        current_gas = step.get('gas', last_gas)\n",
        "        gas_cost = last_gas - current_gas\n",
        "        total_gas_cost += gas_cost if gas_cost > 0 else 0\n",
        "\n",
        "        # Get basic step information\n",
        "        depth = step.get('depth', 0)\n",
        "        op = step.get('op', 'N/A')\n",
        "\n",
        "        # Track contract context changes on CALL instructions\n",
        "        is_pyusd_related = False\n",
        "        if op in ['CALL', 'STATICCALL', 'DELEGATECALL']:\n",
        "            try:\n",
        "                stack = step.get('stack', [])\n",
        "                if len(stack) >= 2:  # Need at least 2 stack items for call address\n",
        "                    # Address is the second stack item for CALL, STATICCALL\n",
        "                    address_raw = stack[1]\n",
        "                    if address_raw.startswith('0x'):\n",
        "                        address = '0x' + address_raw[-40:]\n",
        "                    else:\n",
        "                        # Handle numeric representation\n",
        "                        try:\n",
        "                            address = '0x' + hex(int(address_raw, 16))[-40:].zfill(40)\n",
        "                        except ValueError:\n",
        "                            address = None\n",
        "\n",
        "                    if address:\n",
        "                        current_contracts[depth+1] = address.lower()\n",
        "                        is_pyusd_related = is_pyusd_contract(address)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Check if we're currently in a PYUSD contract\n",
        "        current_contract = current_contracts.get(depth, None)\n",
        "        is_in_pyusd = is_pyusd_contract(current_contract) if current_contract else False\n",
        "\n",
        "        if is_in_pyusd:\n",
        "            pyusd_execution_steps += 1\n",
        "\n",
        "        # Categorize the opcode\n",
        "        opcode_category = get_opcode_category(op)\n",
        "\n",
        "        # Build the execution data record\n",
        "        log_data.append({\n",
        "            'step': i,\n",
        "            'pc': step.get('pc', 0),\n",
        "            'op': op,\n",
        "            'opcode_category': opcode_category,\n",
        "            'gas': current_gas,\n",
        "            'gasCost': gas_cost if gas_cost >= 0 else 0,  # Ensure non-negative cost\n",
        "            'depth': depth,\n",
        "            'stack_depth': len(step.get('stack', [])),\n",
        "            'mem_size_bytes': len(step.get('memory', [])) * 32,  # Memory size in bytes\n",
        "            'current_contract': current_contract,\n",
        "            'is_pyusd_contract': is_in_pyusd,\n",
        "            'is_pyusd_related': is_pyusd_related or is_in_pyusd\n",
        "        })\n",
        "        last_gas = current_gas\n",
        "\n",
        "    if not log_data:\n",
        "        console.print(\"[warning]No valid steps found in structLog data after parsing.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    # --- Convert to DataFrame for analysis ---\n",
        "    df = pd.DataFrame(log_data)\n",
        "\n",
        "    # --- Display Summary ---\n",
        "    pyusd_percentage = (pyusd_execution_steps / len(df) * 100) if len(df) > 0 else 0\n",
        "\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold]structLog Trace Summary for {shorten_address(tx_hash)}[/bold]\n",
        "Total Steps Parsed: {len(df):,}\n",
        "Total Gas Cost (calc): {total_gas_cost:,}\n",
        "Max Depth: {df['depth'].max() if not df.empty else 'N/A'}\n",
        "Max Stack Depth: {df['stack_depth'].max() if not df.empty else 'N/A'}\n",
        "Max Memory (bytes): {df['mem_size_bytes'].max() if not df.empty else 'N/A'}\n",
        "Steps in PYUSD Contracts: {pyusd_execution_steps:,} ({pyusd_percentage:.1f}% of execution)\"\"\",\n",
        "        title=\"structLog Overview\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # --- Generate Visualizations ---\n",
        "    if not df.empty:\n",
        "        # --- Plot Gas Cost by Opcode Category ---\n",
        "        try:\n",
        "            # Visualization Header\n",
        "            console.print(\"\\n\\n[bold yellow3]‚õΩ Gas Cost by Opcode Category[/bold yellow3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "            # Calculate opcode category gas costs\n",
        "            category_gas = df.groupby('opcode_category')['gasCost'].sum().reset_index()\n",
        "            if not category_gas.empty:\n",
        "                # Sort categories by gas usage for better visualization\n",
        "                category_gas = category_gas.sort_values(by='gasCost', ascending=False)\n",
        "\n",
        "                # Add percentage to the name\n",
        "                total_gas = category_gas['gasCost'].sum()\n",
        "                category_gas['name_with_pct'] = category_gas.apply(\n",
        "                    lambda x: f\"{x['opcode_category']} ({x['gasCost']/total_gas*100:.1f}%)\",\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                fig_cat_gas = px.pie(\n",
        "                    category_gas,\n",
        "                    values='gasCost',\n",
        "                    names='name_with_pct',  # Use the new column with percentages\n",
        "                    title=' '  # Empty title, we'll add it in layout\n",
        "                )\n",
        "\n",
        "                # Custom settings for better visualization\n",
        "                fig_cat_gas.update_traces(\n",
        "                    textposition='inside',\n",
        "                    textinfo='percent',\n",
        "                    insidetextorientation='radial'\n",
        "                )\n",
        "\n",
        "                # Position the title with extra space and make it bold\n",
        "                fig_cat_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>Gas Cost by Opcode Category ({shorten_address(tx_hash)})</b>',  # Bold title\n",
        "                        'y': 0.95,  # Position higher for more space\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50),  # Increased top margin for title\n",
        "                )\n",
        "                fig_cat_gas.show()\n",
        "        except Exception as plot_err:\n",
        "            console.print(f\"[warning]Could not generate opcode category gas plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- Plot Gas Cost per Opcode ---\n",
        "        try:\n",
        "            # Visulization Header\n",
        "            console.print(\"\\n\\n[bold yellow3]‚õΩ Top 30 Opcodes by Gas Cost[/bold yellow3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "            # Calculate opcode gas costs\n",
        "            opcode_gas = df.groupby('op')['gasCost'].sum().sort_values(ascending=False).reset_index()\n",
        "            # Only show opcodes with non-zero gas cost (as requested)\n",
        "            opcode_gas = opcode_gas[opcode_gas['gasCost'] > 0]\n",
        "\n",
        "            if not opcode_gas.empty:\n",
        "                # Show all significant opcodes, not just top 30\n",
        "                significant_opcodes = len(opcode_gas) if len(opcode_gas) <= 30 else 30\n",
        "\n",
        "                fig_op_gas = px.bar(\n",
        "                    opcode_gas.head(significant_opcodes),\n",
        "                    x='op',\n",
        "                    y='gasCost',\n",
        "                    labels={'op': '<b>Opcode</b>', 'gasCost': '<b>Total Gas Cost</b>'}  # Bold axis labels\n",
        "                )\n",
        "\n",
        "                # Bold title\n",
        "                fig_op_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>Top {significant_opcodes} Opcodes by Gas Cost ({shorten_address(tx_hash)})</b>',\n",
        "                        'y': 0.95,\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                )\n",
        "                fig_op_gas.show()\n",
        "            else:\n",
        "                 console.print(\"[info]No significant gas costs found per opcode.\", style=\"info\")\n",
        "        except Exception as plot_err:\n",
        "             console.print(f\"[warning]Could not generate opcode gas plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- Plot Gas Remaining Over Steps with PYUSD Highlighting ---\n",
        "        try:\n",
        "            # Downsample if too many steps to prevent browser freezing\n",
        "            # ‚ö†Ô∏è WARNING: if there are too many steps it will consume lots of computes browser could crash or freeze.\n",
        "            max_points_plot = 5000\n",
        "            if len(df) > max_points_plot:\n",
        "                # Ensure consistent sampling, e.g., take every Nth point\n",
        "                indices = np.round(np.linspace(0, len(df) - 1, max_points_plot)).astype(int)\n",
        "                plot_df = df.iloc[indices]\n",
        "                plot_title = f'<b>Gas Remaining Over Execution Steps (Sampled) ({shorten_address(tx_hash)})</b>'\n",
        "                xaxis_title = '<b>Execution Step (Sampled)</b>'\n",
        "                console.print(\n",
        "                    f\"\\n\\n[bold yellow3]‚õΩ Plotting downsampled gas remaining[/bold yellow3] [info]({len(plot_df)} points out of {len(df)}).[/info]\\n\"\n",
        "                    f\"[yellow3]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[/yellow3]\"\n",
        "                )\n",
        "            else:\n",
        "                plot_df = df\n",
        "                plot_title = f'<b>Gas Remaining Over Execution Steps ({shorten_address(tx_hash)})</b>'\n",
        "                xaxis_title = '<b>Execution Step</b>'\n",
        "\n",
        "            # Create a more informative plot with PYUSD sections highlighted\n",
        "            fig_gas_steps = go.Figure()\n",
        "\n",
        "            # Add base gas trace\n",
        "            fig_gas_steps.add_trace(go.Scatter(\n",
        "                x=plot_df['step'],\n",
        "                y=plot_df['gas'],\n",
        "                mode='lines',\n",
        "                name='Gas Remaining',\n",
        "                line=dict(color='blue')\n",
        "            ))\n",
        "\n",
        "            # Highlight PYUSD contract execution sections\n",
        "            if 'is_pyusd_contract' in plot_df.columns:\n",
        "                pyusd_sections = []\n",
        "                current_section = None\n",
        "\n",
        "                for i, row in plot_df.iterrows():\n",
        "                    if row['is_pyusd_contract'] and current_section is None:\n",
        "                        # Start a new PYUSD section\n",
        "                        current_section = {'start': row['step']}\n",
        "                    elif not row['is_pyusd_contract'] and current_section is not None:\n",
        "                        # End the current PYUSD section\n",
        "                        current_section['end'] = plot_df.iloc[i-1]['step'] if i > 0 else row['step']\n",
        "                        pyusd_sections.append(current_section)\n",
        "                        current_section = None\n",
        "\n",
        "                # Handle case where the last section is a PYUSD section\n",
        "                if current_section is not None:\n",
        "                    current_section['end'] = plot_df.iloc[-1]['step']\n",
        "                    pyusd_sections.append(current_section)\n",
        "\n",
        "                # Add highlighted areas for PYUSD execution\n",
        "                for section in pyusd_sections:\n",
        "                    fig_gas_steps.add_shape(\n",
        "                        type=\"rect\",\n",
        "                        x0=section['start'], x1=section['end'],\n",
        "                        y0=0, y1=plot_df['gas'].max(),\n",
        "                        fillcolor=\"rgba(0,255,0,0.1)\",\n",
        "                        line=dict(width=0),\n",
        "                        layer=\"below\"\n",
        "                    )\n",
        "\n",
        "            fig_gas_steps.update_layout(\n",
        "                title={\n",
        "                    'text': plot_title,\n",
        "                    'y': 0.95,\n",
        "                    'x': 0.5,\n",
        "                    'xanchor': 'center',\n",
        "                    'yanchor': 'top',\n",
        "                    'font': {'size': 16}\n",
        "                },\n",
        "                xaxis_title=xaxis_title,\n",
        "                yaxis_title='<b>Gas</b>',  # Bold y-axis label\n",
        "                showlegend=True,\n",
        "                margin=dict(t=100, b=60, l=60, r=60)  # Increased top margin\n",
        "            )\n",
        "\n",
        "            # Add annotation for PYUSD sections - MOVED TO BOTTOM LEFT\n",
        "            if pyusd_percentage > 0:\n",
        "                fig_gas_steps.add_annotation(\n",
        "                    x=0.02, y=0.02,  # Bottom left\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    text=f\"Green sections: PYUSD contract execution ({pyusd_percentage:.1f}%)\",\n",
        "                    showarrow=False,\n",
        "                    font=dict(color=\"green\"),\n",
        "                    bgcolor=\"white\",\n",
        "                    bordercolor=\"green\",\n",
        "                    borderwidth=1,\n",
        "                    align=\"left\"\n",
        "                )\n",
        "\n",
        "            fig_gas_steps.show()\n",
        "        except Exception as plot_err:\n",
        "             console.print(f\"[warning]Could not generate gas remaining plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # --- PYUSD-Specific Analysis ---\n",
        "        if 'is_pyusd_contract' in df.columns and df['is_pyusd_contract'].any():\n",
        "            console.print(\"\\n[bold green3]üß© PYUSD Contract Execution Analysis[/bold green3]\")\n",
        "\n",
        "            # Filter for PYUSD execution steps\n",
        "            pyusd_df = df[df['is_pyusd_contract']]\n",
        "\n",
        "            # Analyze PYUSD opcodes\n",
        "            pyusd_opcodes = pyusd_df.groupby('op').size().sort_values(ascending=False)\n",
        "\n",
        "            pyusd_table = Table(title=\"Top PYUSD Contract Operations\", show_header=True, header_style=\"bold green3\")\n",
        "            pyusd_table.add_column(\"Opcode\", style=\"dim\")\n",
        "            pyusd_table.add_column(\"Count\", justify=\"right\")\n",
        "            pyusd_table.add_column(\"% of PYUSD Ops\", justify=\"right\")\n",
        "\n",
        "            for op, count in pyusd_opcodes.head(10).items():\n",
        "                percentage = (count / len(pyusd_df) * 100)\n",
        "                pyusd_table.add_row(op, str(count), f\"{percentage:.1f}%\")\n",
        "\n",
        "            console.print(pyusd_table)\n",
        "\n",
        "            # Analyze PYUSD gas usage by category\n",
        "            pyusd_gas_by_cat = pyusd_df.groupby('opcode_category')['gasCost'].sum().sort_values(ascending=False)\n",
        "\n",
        "            try:\n",
        "                # Create a pie chart for PYUSD gas usage by category\n",
        "                gas_cat_df = pd.DataFrame({'category': pyusd_gas_by_cat.index, 'gas_used': pyusd_gas_by_cat.values})\n",
        "\n",
        "                # Add percentage to the name\n",
        "                total_gas = gas_cat_df['gas_used'].sum()\n",
        "                gas_cat_df['name_with_pct'] = gas_cat_df.apply(\n",
        "                    lambda x: f\"{x['category']} ({x['gas_used']/total_gas*100:.1f}%)\",\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "                fig_pyusd_gas = px.pie(\n",
        "                    gas_cat_df,\n",
        "                    values='gas_used',\n",
        "                    names='name_with_pct',\n",
        "                    title=' '  # Empty title, we'll add it in layout\n",
        "                )\n",
        "\n",
        "                # Custom settings for better visualization\n",
        "                fig_pyusd_gas.update_traces(\n",
        "                    textposition='inside',\n",
        "                    textinfo='percent',\n",
        "                    insidetextorientation='radial'\n",
        "                )\n",
        "\n",
        "                # Bold title\n",
        "                fig_pyusd_gas.update_layout(\n",
        "                    title={\n",
        "                        'text': f'<b>PYUSD Contract Gas Usage by Category ({shorten_address(tx_hash)})</b>',\n",
        "                        'y': 0.95,\n",
        "                        'x': 0.5,\n",
        "                        'xanchor': 'center',\n",
        "                        'yanchor': 'top',\n",
        "                        'font': {'size': 16}\n",
        "                    },\n",
        "                    margin=dict(t=100, b=50, l=50, r=50)  # Increased top margin\n",
        "                )\n",
        "\n",
        "                fig_pyusd_gas.show()\n",
        "            except Exception as plot_err:\n",
        "                console.print(f\"[warning]Could not generate PYUSD gas category plot: {plot_err}\", style=\"warning\")\n",
        "\n",
        "        # Display DataFrame sample first\n",
        "        console.print(\"\\n\\n[bold cyan3]üìä structLog Data Sample (First 10 steps)[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        # Get a more informative view by focusing on key columns\n",
        "        display_cols = ['step', 'op', 'opcode_category', 'gas', 'gasCost', 'depth', 'is_pyusd_contract']\n",
        "        display(df[display_cols].head(10))\n",
        "\n",
        "        console.print(f\"[info]Full structLog DataFrame has {len(df)} rows. Displaying only head.\", style=\"info\")\n",
        "\n",
        "        # PYUSD-specific summary\n",
        "        pyusd_steps = df['is_pyusd_contract'].sum()\n",
        "        if pyusd_steps > 0:\n",
        "            pyusd_pct = (pyusd_steps / len(df)) * 100\n",
        "            console.print(f\"[success]PYUSD-specific execution: {pyusd_steps:,} steps ({pyusd_pct:.1f}% of total)\", style=\"success\")\n",
        "\n",
        "            # Top Gas-Consuming PYUSD Operations\n",
        "            if 'is_pyusd_contract' in df.columns:\n",
        "                pyusd_ops_gas = df[df['is_pyusd_contract']].groupby('op')['gasCost'].sum().sort_values(ascending=False)\n",
        "\n",
        "                if not pyusd_ops_gas.empty:\n",
        "                    gas_table = Table(title=\"Top Gas-Consuming PYUSD Operations\", show_header=True, header_style=\"bold green\")\n",
        "                    gas_table.add_column(\"Operation\", style=\"dim\")\n",
        "                    gas_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "                    gas_table.add_column(\"% of PYUSD Gas\", justify=\"right\")\n",
        "\n",
        "                    total_pyusd_gas = pyusd_ops_gas.sum()\n",
        "                    for op, gas in pyusd_ops_gas.head(10).items():\n",
        "                        percentage = (gas / total_pyusd_gas * 100)\n",
        "                        gas_table.add_row(op, f\"{gas:,}\", f\"{percentage:.1f}%\")\n",
        "\n",
        "                    console.print(gas_table)\n",
        "\n",
        "        # Export options\n",
        "        console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        # Create export output area\n",
        "        export_output = widgets.Output()\n",
        "\n",
        "        # Create export buttons with proper styling\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Export to CSV',\n",
        "                button_style='primary',  # Green\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export as JSON',\n",
        "                button_style='warning',  # Orange\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export to Google Sheets',\n",
        "                button_style='info',     # Blue\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # Define export handlers\n",
        "        def export_csv(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.csv\"\n",
        "                display(download_csv_direct(df, filename))\n",
        "\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.json\"\n",
        "                # Prepare export data with basic DataFrame stats to avoid reference issues\n",
        "                export_data = {\n",
        "                    \"transaction_hash\": tx_hash,\n",
        "                    \"analysis_type\": \"structLog\",\n",
        "                    \"summary\": {\n",
        "                        \"total_steps\": len(df),\n",
        "                        \"total_gas_cost\": total_gas_cost,\n",
        "                        \"max_depth\": df['depth'].max() if not df.empty else None,\n",
        "                        \"max_stack_depth\": df['stack_depth'].max() if not df.empty else None,\n",
        "                        \"max_memory_bytes\": df['mem_size_bytes'].max() if not df.empty else None,\n",
        "                        \"pyusd_steps\": pyusd_execution_steps,\n",
        "                        \"pyusd_percentage\": pyusd_percentage\n",
        "                    },\n",
        "                    \"opcode_categories\": category_gas.to_dict('records') if 'category_gas' in locals() and not category_gas.empty else []\n",
        "                }\n",
        "                display(download_json_direct(export_data, filename))\n",
        "\n",
        "        def export_to_sheets(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                try:\n",
        "                    # Only use variables that are in scope and defined\n",
        "                    export_data = {\n",
        "                        \"transaction_hash\": tx_hash,\n",
        "                        \"summary\": {\n",
        "                            \"total_steps\": len(df),\n",
        "                            \"total_gas_cost\": total_gas_cost,\n",
        "                            \"max_depth\": df['depth'].max() if not df.empty else None,\n",
        "                            \"max_stack_depth\": df['stack_depth'].max() if not df.empty else None,\n",
        "                            \"max_memory_bytes\": df['mem_size_bytes'].max() if not df.empty else None,\n",
        "                            \"pyusd_steps\": pyusd_execution_steps,\n",
        "                            \"pyusd_percentage\": pyusd_percentage\n",
        "                        }\n",
        "                    }\n",
        "\n",
        "                    # Add opcode categories if available\n",
        "                    if 'category_gas' in locals() and not category_gas.empty:\n",
        "                        export_data[\"opcode_categories\"] = category_gas.to_dict('records')\n",
        "\n",
        "                    display(export_to_google_sheets(df, export_data, tx_hash))\n",
        "                except Exception as e:\n",
        "                    html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                    display(HTML(html))\n",
        "\n",
        "                    # Fallback to CSV\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    filename = f\"structlog_trace_{tx_hash[:10]}_{timestamp}.csv\"\n",
        "                    display(download_csv_direct(df, filename))\n",
        "                    display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "        # Connect handlers to buttons\n",
        "        export_buttons.children[0].on_click(export_csv)\n",
        "        export_buttons.children[1].on_click(export_json)\n",
        "        export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "        # Display button container and output area\n",
        "        display(export_buttons)\n",
        "        display(export_output)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- Execute Tracing ---\n",
        "# WARNING: structLog can be VERY large and slow. Default to False.\n",
        "RUN_STRUCTLOG_TRACE = True  # <<< SET TO TRUE TO RUN THIS EXPENSIVE TRACE\n",
        "\n",
        "if not validate_tx_hash:  # Check validation flag from setup cell\n",
        "    console.print(\"[warning]TARGET_TX_HASH not set or invalid. Cannot run structLog analysis.\", style=\"warning\")\n",
        "elif RUN_STRUCTLOG_TRACE:\n",
        "    console.print(\"\\n\\n[bold]üéØ Using structLog on Mainnet[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    console.print(f\"Target Transaction : {TARGET_TX_HASH}\")\n",
        "\n",
        "    # Use the default tracer configuration (the one that worked)\n",
        "    tracer_config = {\"tracerConfig\": TRACE_CONFIGS[\"structLog\"]}\n",
        "\n",
        "    # Request trace on Mainnet\n",
        "    trace_result_struct = make_rpc_request(\"debug_traceTransaction\", [TARGET_TX_HASH, tracer_config], network='mainnet')\n",
        "\n",
        "    # Process result if we got one\n",
        "    if trace_result_struct:\n",
        "        # Check where structLogs might be in the response\n",
        "        struct_logs = None\n",
        "        if 'structLogs' in trace_result_struct:\n",
        "            struct_logs = trace_result_struct['structLogs']\n",
        "        elif 'result' in trace_result_struct and isinstance(trace_result_struct['result'], dict) and 'structLogs' in trace_result_struct['result']:\n",
        "            struct_logs = trace_result_struct['result']['structLogs']\n",
        "\n",
        "        if struct_logs and isinstance(struct_logs, list):\n",
        "            struct_log_df = parse_struct_log(struct_logs, TARGET_TX_HASH)\n",
        "        else:\n",
        "            console.print(\"[warning]Got response, but structLogs format was not as expected.\", style=\"warning\")\n",
        "    else:\n",
        "        console.print(f\"[warning]Failed to get trace data for {TARGET_TX_HASH}.\", style=\"warning\")\n",
        "\n",
        "elif not RUN_STRUCTLOG_TRACE:\n",
        "     console.print(\"\\n[info]Skipping trace analysis as RUN_STRUCTLOG_TRACE is False.\", style=\"info\")\n"
      ],
      "metadata": {
        "id": "axyGCZbU_k45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 üìú `eth_getLogs`: Efficiently Fetching PYUSD Events\n",
        "---\n",
        "\n",
        "This section focuses on retrieving specific **event logs** emitted by the PYUSD smart contract. Events are a crucial mechanism for contracts to signal occurrences (like transfers or approvals) to the outside world. `eth_getLogs` provides a highly efficient way to query these events directly from the blockchain's indexed log data, avoiding the need to process non-relevant transactions or blocks.\n",
        "\n",
        "Here, we specifically target the standard ERC-20 `Transfer(address,address,uint256)` event emitted by the PYUSD contract to track token movements.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Blockchain Node Engine**\n",
        ">\n",
        "> *   **Method:** `eth_getLogs`\n",
        "> *   **Quota Multiplier:** `50x` (Indicates this method consumes 50x the request quota compared to a basic call like `eth_getBlockByNumber` under GCP's Blockchain Node Engine pricing model).\n",
        "> *   **GCP Integration & Limits:** While `eth_getLogs` is standard, node performance and limitations vary. Public or lower-tier nodes often impose strict limits on the query block range (e.g., 10,000 blocks) or total logs returned (e.g., 10,000 logs). Furthermore, specific endpoints, like the Google Blockchain Node Engine endpoint potentially used here (`blockchain.googleapis.com`), may enforce even tighter constraints (like the **5-block range limit** handled explicitly in the code). GCP's advantage often lies in providing reliable performance, consistent availability, and potentially higher throughput or more permissive limits on its paid tiers compared to shared public endpoints.\n",
        "> *   **PYUSD Insight:** `eth_getLogs` enables us to:\n",
        ">     *   Quickly find **all PYUSD `Transfer` events** within a specific block or a (potentially limited) range of blocks.\n",
        ">     *   Efficiently track PYUSD **velocity and volume** over time by fetching logs incrementally.\n",
        ">     *   Identify **top senders and receivers** of PYUSD within a given period.\n",
        ">     *   Monitor other PYUSD events (like `Approval`, `Paused`, `Unpaused`) by changing the queried `topic`.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Define Filter:** The code configures a filter targeting the main PYUSD contract address (`PYUSD_CONFIG['ethereum']['address']`) and the specific topic hash for the `Transfer` event. It also specifies the target block(s) (e.g., `TARGET_BLOCK_IDENTIFIER`, 'latest', or a range).\n",
        "2.  **Fetch Logs:** Calls `eth_getLogs` via the `web3.py` client. If a Google API endpoint is detected, it uses direct JSON-RPC requests to handle potential specific constraints (like the 5-block limit).\n",
        "3.  **Parse & Decode:** The returned raw log data is parsed, extracting the `from` address, `to` address, and `value` (amount) for each `Transfer` event. PYUSD amounts are formatted using the correct 6 decimals (`PYUSD_CONFIG['ethereum']['decimals']`). Timestamps are fetched for context.\n",
        "4.  **Analyze & Visualize:**\n",
        "    *   **Data Table:** Displays a sample of the fetched transfer events (showing full addresses).\n",
        "    *   **Statistics:** Calculates and shows key metrics (total transfers, volume, unique addresses) in a summary table.\n",
        "    *   **Top Movers:** Identifies and tables the top senders and receivers by volume (showing full addresses).\n",
        "    *   **Visualizations:** Generates plots showing transfer size distribution, volume over time (if timestamps available), and a network graph (Sankey diagram) of top transfer flows.\n",
        "    *   **Export Options:** Provides buttons to download the parsed transfer data (CSV, JSON) or export to Google Sheets.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Transfer Volume & Count:** Assess the PYUSD activity level within the queried block(s)/range.\n",
        "*   **Top Senders/Receivers:** Identify major players interacting with PYUSD. Are they exchanges, bridges, protocols, or individual wallets?\n",
        "*   **Network Graph:** Visualize the primary flow of PYUSD between addresses for the top flows.\n",
        "*   **Timestamp Data (if available):** Observe any time-based patterns in transfer activity."
      ],
      "metadata": {
        "id": "3q7lkAOwW94n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üìú PYUSD Transfer Logs using eth_getLogs\n",
        "# =============================================================================================\n",
        "# This cell retrieves and analyzes PYUSD token transfer events using the eth_getLogs RPC method.\n",
        "#  Functionality includes:\n",
        "# - Fetching PYUSD ERC-20 Transfer events respecting the 5-block maximum range limit.\n",
        "# - Calculating key statistical metrics (total volume, average transfer size, unique participants).\n",
        "# - Generating detailed visualizations: transfer size distribution, volume timeline, and token flow networks.\n",
        "# - Network visualization using a Sankey diagram showing the top 50 transfer flows between addresses.\n",
        "# - Displaying ranked tables of top senders and receivers with volume and transaction counts.\n",
        "# - Providing interactive exports to CSV, JSON, or Google Sheets with complete analysis data.\n",
        "# - Handling both individual block analysis and small block ranges for detailed examination.\n",
        "\n",
        "import base64\n",
        "import json\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, title_prefix):\n",
        "    \"\"\"Export analysis data to Google Sheets using the existing gspread client.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with main data\n",
        "        data_dict: Dictionary with additional structured data\n",
        "        title_prefix: Prefix for sheet title\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD Transfer Analysis {title_prefix} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Transfer Data\")\n",
        "\n",
        "        # Set up a header with analysis info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transfer Analysis\"],\n",
        "            [f\"Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header\n",
        "        worksheet.format(\"A1:A1\", {\"textFormat\": {\"bold\": True, \"fontSize\": 14}})\n",
        "\n",
        "        # Add summary stats if available\n",
        "        if \"statistics\" in data_dict:\n",
        "            stats = data_dict[\"statistics\"]\n",
        "            stats_rows = [[\"Analysis Summary\"], [\"\"]]\n",
        "            for key, value in stats.items():\n",
        "                stats_rows.append([key.replace(\"_\", \" \").title(), str(value)])\n",
        "\n",
        "            # Add stats after the header (row 4)\n",
        "            worksheet.update(\"A4\", stats_rows)\n",
        "            stats_end_row = 4 + len(stats_rows)\n",
        "        else:\n",
        "            stats_end_row = 4\n",
        "\n",
        "        # Add main DataFrame data below the stats\n",
        "        if not df.empty:\n",
        "            start_row = stats_end_row + 2  # Leave a gap\n",
        "\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{start_row}\", [[\"Transfer Data\"]])\n",
        "            worksheet.format(f\"A{start_row}:A{start_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [df.columns.tolist()] + df.values.tolist()\n",
        "            worksheet.update(f\"A{start_row+1}\", df_values)\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "def fetch_pyusd_transfer_logs(from_block='latest', to_block='latest', network='mainnet'):\n",
        "    \"\"\"Fetches PYUSD Transfer events using eth_getLogs on the specified network.\n",
        "\n",
        "    Handles both direct Web3.py calls and JSON-RPC requests for compatibility with Google Blockchain API,\n",
        "    which has a 5-block maximum range limitation.\n",
        "    \"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    pyusd_checksum_address = Web3.to_checksum_address(PYUSD_CONFIG['ethereum']['address'])\n",
        "    transfer_topic = PYUSD_CONFIG['ethereum']['transfer_event_topic']\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]Fetching PYUSD Transfer logs...[/bold cyan3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Network[/bold]  : [yellow3]{network.capitalize()}[/yellow3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Contract[/bold] : [bold magenta3]{pyusd_checksum_address}[/bold magenta3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Blocks[/bold]   : [bold green3]{from_block} ‚Üí {to_block}[/bold green3]\", style=\"info\")\n",
        "    console.print(f\"[bold]Topic[/bold]    : [dim]{transfer_topic}[/dim]\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Detect if we're using Google Blockchain API\n",
        "        is_google_api = False\n",
        "        if hasattr(w3_client, 'provider') and hasattr(w3_client.provider, 'endpoint_uri'):\n",
        "            endpoint_uri = str(w3_client.provider.endpoint_uri)\n",
        "            is_google_api = \"blockchain.googleapis.com\" in endpoint_uri\n",
        "\n",
        "        if is_google_api:\n",
        "            import requests\n",
        "\n",
        "            # Format block parameters for JSON-RPC\n",
        "            def format_block_param_json(block_id):\n",
        "                if block_id == 'latest' or block_id == 'pending' or block_id == 'earliest':\n",
        "                    return block_id\n",
        "                elif isinstance(block_id, int):\n",
        "                    return hex(block_id)\n",
        "                elif isinstance(block_id, str):\n",
        "                    if block_id.startswith(\"0x\"):\n",
        "                        return block_id\n",
        "                    else:\n",
        "                        try:\n",
        "                            return hex(int(block_id))\n",
        "                        except ValueError:\n",
        "                            raise ValueError(f\"Invalid block identifier: {block_id}\")\n",
        "                else:\n",
        "                    raise ValueError(f\"Invalid block identifier type: {type(block_id)}\")\n",
        "\n",
        "            # Prepare the JSON-RPC payload\n",
        "            payload = {\n",
        "                \"jsonrpc\": \"2.0\",\n",
        "                \"method\": \"eth_getLogs\",\n",
        "                \"params\": [{\n",
        "                    \"fromBlock\": format_block_param_json(from_block),\n",
        "                    \"toBlock\": format_block_param_json(to_block),\n",
        "                    \"address\": pyusd_checksum_address,\n",
        "                    \"topics\": [transfer_topic]\n",
        "                }],\n",
        "                \"id\": 1\n",
        "            }\n",
        "\n",
        "            headers = {\n",
        "                \"Content-Type\": \"application/json\",\n",
        "                \"Accept\": \"application/json\"\n",
        "            }\n",
        "\n",
        "            # Extract API key from the endpoint URI if present\n",
        "            api_key = None\n",
        "            if \"?key=\" in endpoint_uri:\n",
        "                api_key = endpoint_uri.split(\"?key=\")[1]\n",
        "                # Remove the key from the URI for the request\n",
        "                endpoint_uri = endpoint_uri.split(\"?key=\")[0]\n",
        "\n",
        "            # Make direct request to the API\n",
        "            response = requests.post(\n",
        "                endpoint_uri,\n",
        "                json=payload,\n",
        "                headers=headers,\n",
        "                params={\"key\": api_key} if api_key else None\n",
        "            )\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                console.print(f\"[error]API request failed with status {response.status_code}: {response.text}\", style=\"error\")\n",
        "                return None\n",
        "\n",
        "            result = response.json()\n",
        "\n",
        "            if \"error\" in result:\n",
        "                console.print(f\"[error]JSON-RPC error: {result['error']}\", style=\"error\")\n",
        "                return None\n",
        "\n",
        "            # Parse the logs from the response\n",
        "            logs = result.get(\"result\", [])\n",
        "\n",
        "            if not logs:\n",
        "                console.print(f\"[info]No PYUSD Transfer logs found in the specified range ({from_block} - {to_block}) on {network.capitalize()}.\", style=\"info\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            console.print(f\"[success]Found {len(logs)} PYUSD Transfer logs on {network.capitalize()}.\", style=\"success\")\n",
        "        else:\n",
        "            # Use standard web3.py method for non-Google providers\n",
        "            # eth_getLogs expects block numbers as hex strings or integer/tags\n",
        "            def format_block_param(block_id):\n",
        "                \"\"\"Formats block identifier for eth_getLogs.\"\"\"\n",
        "                if isinstance(block_id, int):\n",
        "                    return hex(block_id) # Prefer hex for consistency with RPC spec\n",
        "                elif isinstance(block_id, str):\n",
        "                     # Check if it's already hex or a known tag\n",
        "                    if block_id.startswith(\"0x\") or block_id in [\"latest\", \"pending\", \"earliest\"]:\n",
        "                        return block_id\n",
        "                    else: # Try converting potential numeric strings\n",
        "                        try:\n",
        "                            return hex(int(str(block_id)))\n",
        "                        except ValueError:\n",
        "                            console.print(f\"[error]Invalid block identifier format for eth_getLogs: {block_id}. Use int, hex string, or tag.\", style=\"error\")\n",
        "                            raise ValueError(f\"Invalid block identifier: {block_id}\")\n",
        "                else: # Handle None or other types\n",
        "                     raise ValueError(f\"Invalid block identifier type: {type(block_id)}\")\n",
        "\n",
        "            log_filter = {\n",
        "                \"fromBlock\": format_block_param(from_block),\n",
        "                \"toBlock\": format_block_param(to_block),\n",
        "                \"address\": pyusd_checksum_address,\n",
        "                \"topics\": [transfer_topic] # Topic0 is the event signature\n",
        "            }\n",
        "\n",
        "            # Make the eth_getLogs request using standard web3.py method on the correct client\n",
        "            logs = w3_client.eth.get_logs(log_filter)\n",
        "\n",
        "            if not logs:\n",
        "                console.print(f\"[info]No PYUSD Transfer logs found in the specified range ({from_block} - {to_block}) on {network.capitalize()}.\", style=\"info\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            console.print(f\"[success]Found {len(logs)} PYUSD Transfer logs on {network.capitalize()}.\", style=\"success\")\n",
        "\n",
        "        # Parse the logs (common for both methods)\n",
        "        parsed_logs = []\n",
        "        timestamps = {}  # Cache for block timestamps\n",
        "\n",
        "        for log in logs:\n",
        "            # Ensure log is a dictionary-like object\n",
        "            if isinstance(log, dict):\n",
        "                # For JSON-RPC response, convert hex strings to int where needed\n",
        "                log_dict = log\n",
        "                topics = log_dict.get('topics', [])\n",
        "                data = log_dict.get('data', '')\n",
        "                block_number = int(log_dict.get('blockNumber', '0x0'), 16)\n",
        "                tx_hash = log_dict.get('transactionHash', '')\n",
        "                log_index = int(log_dict.get('logIndex', '0x0'), 16)\n",
        "            else:\n",
        "                # For web3.py response\n",
        "                if not hasattr(log, 'topics') or not hasattr(log, 'data'): continue\n",
        "                topics = log['topics']\n",
        "                data = log['data']\n",
        "                block_number = log['blockNumber']\n",
        "                tx_hash = log['transactionHash']\n",
        "                log_index = log['logIndex']\n",
        "                # Convert bytes to hex strings for consistency\n",
        "                if isinstance(topics[0], bytes):\n",
        "                    topics = [t.hex() if isinstance(t, bytes) else t for t in topics]\n",
        "                if isinstance(data, bytes):\n",
        "                    data = data.hex()\n",
        "                if isinstance(tx_hash, bytes):\n",
        "                    tx_hash = tx_hash.hex()\n",
        "\n",
        "            try:\n",
        "                # Check for standard ERC20 Transfer signature (3 topics)\n",
        "                if len(topics) == 3:\n",
        "                    # Extract addresses from topics (remove 0x if present and take last 40 chars)\n",
        "                    topic1 = topics[1].replace('0x', '') if isinstance(topics[1], str) else topics[1].hex()\n",
        "                    topic2 = topics[2].replace('0x', '') if isinstance(topics[2], str) else topics[2].hex()\n",
        "\n",
        "                    from_addr = Web3.to_checksum_address('0x' + topic1[-40:])\n",
        "                    to_addr = Web3.to_checksum_address('0x' + topic2[-40:])\n",
        "\n",
        "                    # Extract value from data\n",
        "                    data_hex = data if isinstance(data, str) else data.hex()\n",
        "                    data_hex = data_hex.replace('0x', '')\n",
        "                    value_raw = int(data_hex, 16)\n",
        "                    value_pyusd = value_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                    # Get block timestamp (cache to avoid redundant queries)\n",
        "                    if block_number not in timestamps:\n",
        "                        try:\n",
        "                            block = w3_client.eth.get_block(block_number)\n",
        "                            timestamps[block_number] = block.timestamp\n",
        "                        except Exception:\n",
        "                            timestamps[block_number] = None\n",
        "\n",
        "                    # Ensure transaction hash has 0x prefix\n",
        "                    tx_hash_hex = tx_hash if isinstance(tx_hash, str) else tx_hash.hex()\n",
        "                    if not tx_hash_hex.startswith('0x'):\n",
        "                        tx_hash_hex = '0x' + tx_hash_hex\n",
        "\n",
        "                    parsed_logs.append({\n",
        "                        \"blockNumber\": block_number,\n",
        "                        \"transactionHash\": tx_hash_hex,\n",
        "                        \"logIndex\": log_index,\n",
        "                        \"from\": from_addr,\n",
        "                        \"from_short\": shorten_address(from_addr),\n",
        "                        \"to\": to_addr,\n",
        "                        \"to_short\": shorten_address(to_addr),\n",
        "                        \"value_pyusd\": value_pyusd,\n",
        "                        \"value_raw\": value_raw,\n",
        "                        \"timestamp\": timestamps.get(block_number)\n",
        "                    })\n",
        "                else:\n",
        "                    # Log unexpected topic count for debugging\n",
        "                    tx_hash_str = tx_hash if isinstance(tx_hash, str) else tx_hash.hex()\n",
        "                    console.print(f\"[warning]Log index {log_index} tx {shorten_address(tx_hash_str)} has {len(topics)} topics (expected 3 for Transfer). Skipping.\", style=\"warning\")\n",
        "            except Exception as e:\n",
        "                # Handle parsing errors\n",
        "                tx_hash_str = tx_hash if isinstance(tx_hash, str) else tx_hash.hex()\n",
        "                console.print(f\"[warning]Could not parse log index {log_index} tx {shorten_address(tx_hash_str)}: {e}\", style=\"warning\")\n",
        "\n",
        "        return pd.DataFrame(parsed_logs)\n",
        "\n",
        "    except ValueError as ve: # Catch specific invalid block identifier error\n",
        "        console.print(f\"[error]Invalid block parameter for eth_getLogs: {ve}\", style=\"error\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error fetching logs with eth_getLogs on {network.capitalize()}: {e}\", style=\"error\")\n",
        "        # Add hints for common errors\n",
        "        if \"filter not found\" in str(e):\n",
        "            console.print(\"[info]Hint: This might happen with very large block ranges on some nodes.\", style=\"info\")\n",
        "        elif \"exceeds block range limit\" in str(e) or \"block range is too large\" in str(e):\n",
        "            console.print(\"[info]Hint: Reduce the block range (e.g., fetch logs for smaller chunks of blocks).\", style=\"info\")\n",
        "        elif \"invalid topic\" in str(e).lower():\n",
        "             console.print(f\"[error]Hint: Check if transfer_topic '{transfer_topic}' is correct.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "def analyze_pyusd_transfers(df):\n",
        "    \"\"\"Generates enhanced analytics for PYUSD transfer data\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        console.print(\"[warning]No transfer data to analyze.\", style=\"warning\")\n",
        "        return\n",
        "\n",
        "    # Basic statistics\n",
        "    stats = {\n",
        "        \"total_transfers\": len(df),\n",
        "        \"total_volume\": df['value_pyusd'].sum(),\n",
        "        \"avg_transfer\": df['value_pyusd'].mean(),\n",
        "        \"median_transfer\": df['value_pyusd'].median(),\n",
        "        \"max_transfer\": df['value_pyusd'].max(),\n",
        "        \"min_transfer\": df['value_pyusd'].min(),\n",
        "        \"unique_senders\": df['from'].nunique(),\n",
        "        \"unique_receivers\": df['to'].nunique()\n",
        "    }\n",
        "\n",
        "    # Create statistics table\n",
        "    console.print(\"\\n\\n[bold cyan3]PYUSD Transfer Metrices[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    stats_table = Table(title=\"\", header_style=\"bold cyan3\")\n",
        "    stats_table.add_column(\"Metric\")\n",
        "    stats_table.add_column(\"Value\", justify=\"right\")\n",
        "\n",
        "    decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "    stats_table.add_row(\"Total Transfers\", f\"{stats['total_transfers']:,}\")\n",
        "    stats_table.add_row(\"Total Volume\", f\"{stats['total_volume']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Average Transfer\", f\"{stats['avg_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Median Transfer\", f\"{stats['median_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Maximum Transfer\", f\"{stats['max_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Minimum Transfer\", f\"{stats['min_transfer']:,.{decimals}f} PYUSD\")\n",
        "    stats_table.add_row(\"Unique Senders\", f\"{stats['unique_senders']:,}\")\n",
        "    stats_table.add_row(\"Unique Receivers\", f\"{stats['unique_receivers']:,}\")\n",
        "\n",
        "    console.print(stats_table)\n",
        "\n",
        "    # Top senders analysis\n",
        "    if len(df) > 0:\n",
        "        console.print(\"\\n\\n[bold cyan3]Top PYUSD Senders[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        top_senders = df.groupby('from').agg({\n",
        "            'value_pyusd': ['sum', 'count'],\n",
        "            'from_short': 'first'\n",
        "        }).reset_index()\n",
        "\n",
        "        top_senders.columns = ['address', 'total_value', 'transactions', 'address_short']\n",
        "        top_senders = top_senders.sort_values('total_value', ascending=False).head(10)\n",
        "\n",
        "        sender_table = Table(show_header=True, header_style=\"bold cyan\")\n",
        "        sender_table.add_column(\"Sender\")\n",
        "        sender_table.add_column(\"Total Sent (PYUSD)\", justify=\"right\")\n",
        "        sender_table.add_column(\"Transactions\", justify=\"right\")\n",
        "        sender_table.add_column(\"% of Volume\", justify=\"right\")\n",
        "\n",
        "        for _, row in top_senders.iterrows():\n",
        "            pct_volume = (row['total_value'] / stats['total_volume'] * 100)\n",
        "            sender_table.add_row(\n",
        "                row['address'],\n",
        "                f\"{row['total_value']:,.{decimals}f}\",\n",
        "                f\"{row['transactions']:,}\",\n",
        "                f\"{pct_volume:.1f}%\"\n",
        "            )\n",
        "\n",
        "        console.print(sender_table)\n",
        "\n",
        "        # Top receivers analysis\n",
        "        console.print(\"\\n\\n[bold cyan3]Top PYUSD Receivers[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        top_receivers = df.groupby('to').agg({\n",
        "            'value_pyusd': ['sum', 'count'],\n",
        "            'to_short': 'first'\n",
        "        }).reset_index()\n",
        "\n",
        "        top_receivers.columns = ['address', 'total_value', 'transactions', 'address_short']\n",
        "        top_receivers = top_receivers.sort_values('total_value', ascending=False).head(10)\n",
        "\n",
        "        receiver_table = Table(show_header=True, header_style=\"bold cyan\")\n",
        "        receiver_table.add_column(\"Receiver\")\n",
        "        receiver_table.add_column(\"Total Received (PYUSD)\", justify=\"right\")\n",
        "        receiver_table.add_column(\"Transactions\", justify=\"right\")\n",
        "        receiver_table.add_column(\"% of Volume\", justify=\"right\")\n",
        "\n",
        "        for _, row in top_receivers.iterrows():\n",
        "            pct_volume = (row['total_value'] / stats['total_volume'] * 100)\n",
        "            receiver_table.add_row(\n",
        "                row['address'],\n",
        "                f\"{row['total_value']:,.{decimals}f}\",\n",
        "                f\"{row['transactions']:,}\",\n",
        "                f\"{pct_volume:.1f}%\"\n",
        "            )\n",
        "\n",
        "        console.print(receiver_table)\n",
        "\n",
        "    # Visualizations\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]PYUSD Transfer Size Distribution[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "        # 1. Transfer Size Distribution visualization\n",
        "\n",
        "        fig_dist = px.histogram(\n",
        "            df, x='value_pyusd',\n",
        "            title='PYUSD Transfer Size Distribution',\n",
        "            labels={'value_pyusd': 'Transfer Size (PYUSD)', 'count': 'Number of Transfers'},\n",
        "            nbins=50,\n",
        "            opacity=0.75,\n",
        "            color_discrete_sequence=['rgba(0, 123, 255, 0.8)']\n",
        "        )\n",
        "\n",
        "        # Configure histogram layout\n",
        "        fig_dist.update_layout(\n",
        "            template=\"plotly_white\",\n",
        "            bargap=0.1,\n",
        "            plot_bgcolor='white',\n",
        "            margin=dict(l=50, r=50, t=80, b=50),\n",
        "            title_font=dict(size=20),\n",
        "            yaxis_title=\"Number of Transfers\",\n",
        "            xaxis_title=\"Transfer Size (PYUSD)\"\n",
        "        )\n",
        "\n",
        "        # Add range slider to better handle outliers in the distribution\n",
        "        q1 = df['value_pyusd'].quantile(0.25)\n",
        "        q3 = df['value_pyusd'].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        upper_bound = q3 + (1.5 * iqr)\n",
        "\n",
        "        if df['value_pyusd'].max() > upper_bound:\n",
        "            fig_dist.update_layout(\n",
        "                xaxis=dict(\n",
        "                    rangeslider=dict(visible=True),\n",
        "                    type='linear'\n",
        "                )\n",
        "            )\n",
        "\n",
        "        fig_dist.show()\n",
        "\n",
        "        # 2. Transfer Volume Over Time visualization\n",
        "        console.print(\"\\n\\n[bold]PYUSD Transfer Volume Over Time[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        if 'timestamp' in df.columns and df['timestamp'].notna().any():\n",
        "            df_with_time = df[df['timestamp'].notna()].copy()\n",
        "            df_with_time['datetime'] = pd.to_datetime(df_with_time['timestamp'], unit='s')\n",
        "\n",
        "            # Aggregate by hour for cleaner visualization\n",
        "            df_with_time['hour'] = df_with_time['datetime'].dt.floor('H')\n",
        "            hourly_volume = df_with_time.groupby('hour')['value_pyusd'].sum().reset_index()\n",
        "\n",
        "            # Ensure data exists before creating visualization\n",
        "            if not hourly_volume.empty:\n",
        "                fig_time = px.line(\n",
        "                    hourly_volume, x='hour', y='value_pyusd',\n",
        "                    title='PYUSD Transfer Volume Over Time',\n",
        "                    labels={'hour': 'Time', 'value_pyusd': 'Volume (PYUSD)'}\n",
        "                )\n",
        "\n",
        "                # Configure time series chart layout\n",
        "                fig_time.update_layout(\n",
        "                    template=\"plotly_white\",\n",
        "                    plot_bgcolor='white',\n",
        "                    margin=dict(l=50, r=50, t=80, b=50),\n",
        "                    title_font=dict(size=20),\n",
        "                    xaxis_title=\"Time\",\n",
        "                    yaxis_title=\"Volume (PYUSD)\",\n",
        "                    hovermode=\"x unified\"\n",
        "                )\n",
        "\n",
        "                # Style the line for better visibility\n",
        "                fig_time.update_traces(\n",
        "                    line=dict(width=3, color='rgb(0, 123, 255)'),\n",
        "                    mode='lines+markers',\n",
        "                    marker=dict(size=8, color='rgb(0, 123, 255)')\n",
        "                )\n",
        "\n",
        "                fig_time.show()\n",
        "            else:\n",
        "                console.print(\"[warning]No time-based data available for visualization.\", style=\"warning\")\n",
        "\n",
        "        # 3. Network graph using Sankey diagram\n",
        "        if len(df) > 0:\n",
        "            console.print(\"\\n\\n[bold magenta3]PYUSD Transfer Flow - Top 50 Transfers[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "            # Aggregate transfers between address pairs\n",
        "            pair_transfers = df.groupby(['from', 'to'])['value_pyusd'].sum().reset_index()\n",
        "            pair_transfers = pair_transfers.sort_values('value_pyusd', ascending=False).head(50)\n",
        "\n",
        "            # Prepare data for Sankey diagram\n",
        "            labels = []\n",
        "            address_to_idx = {}\n",
        "\n",
        "            # Create a unique index for each address\n",
        "            for _, row in pair_transfers.iterrows():\n",
        "                if row['from'] not in address_to_idx:\n",
        "                    address_to_idx[row['from']] = len(labels)\n",
        "                    labels.append(shorten_address(row['from']))\n",
        "                if row['to'] not in address_to_idx:\n",
        "                    address_to_idx[row['to']] = len(labels)\n",
        "                    labels.append(shorten_address(row['to']))\n",
        "\n",
        "            # Create source, target, and value arrays for Sankey\n",
        "            sources = [address_to_idx[row['from']] for _, row in pair_transfers.iterrows()]\n",
        "            targets = [address_to_idx[row['to']] for _, row in pair_transfers.iterrows()]\n",
        "            values = pair_transfers['value_pyusd'].tolist()\n",
        "\n",
        "            # Create Sankey diagram with flow direction\n",
        "            fig_sankey = go.Figure(data=[go.Sankey(\n",
        "                node=dict(\n",
        "                    pad=15,\n",
        "                    thickness=20,\n",
        "                    line=dict(color=\"black\", width=0.5),\n",
        "                    label=labels,\n",
        "                    color=\"blue\"\n",
        "                ),\n",
        "                link=dict(\n",
        "                    source=sources,\n",
        "                    target=targets,\n",
        "                    value=values,\n",
        "                    color=\"rgba(0,100,200,0.3)\"\n",
        "                )\n",
        "            )])\n",
        "\n",
        "            # Configure Sankey layout\n",
        "            fig_sankey.update_layout(\n",
        "                title_text=\"PYUSD Transfer Flow - Top 50 Transfers\",\n",
        "                font=dict(size=12),\n",
        "                width=1000,\n",
        "                height=800\n",
        "            )\n",
        "\n",
        "            fig_sankey.show()\n",
        "\n",
        "    except Exception as viz_error:\n",
        "        console.print(f\"[warning]Visualization error: {viz_error}\", style=\"warning\")\n",
        "\n",
        "    # --- Add Export Options Section ---\n",
        "    console.print(\"\\n\\n[bold cyan3]üì§ Export Options:[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create export output area\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Create export buttons with proper styling\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Define export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_transfers_{timestamp}.csv\"\n",
        "            display(download_csv_direct(df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_transfers_{timestamp}.json\"\n",
        "            # Prepare export data with basic DataFrame stats\n",
        "            export_data = {\n",
        "                \"analysis_type\": \"PYUSD Transfers\",\n",
        "                \"analysis_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"statistics\": stats,\n",
        "                \"top_senders\": top_senders.to_dict('records') if 'top_senders' in locals() else [],\n",
        "                \"top_receivers\": top_receivers.to_dict('records') if 'top_receivers' in locals() else []\n",
        "            }\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                # Prepare export data\n",
        "                export_data = {\n",
        "                    \"statistics\": stats,\n",
        "                    \"top_senders\": top_senders.to_dict('records') if 'top_senders' in locals() else [],\n",
        "                    \"top_receivers\": top_receivers.to_dict('records') if 'top_receivers' in locals() else []\n",
        "                }\n",
        "\n",
        "                display(export_to_google_sheets(df, export_data, \"Transfers\"))\n",
        "            except Exception as e:\n",
        "                html = f\"<div style='color:red'>Error exporting to Google Sheets: {str(e)}</div>\"\n",
        "                display(HTML(html))\n",
        "\n",
        "                # Fallback to CSV\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"pyusd_transfers_{timestamp}.csv\"\n",
        "                display(download_csv_direct(df, filename))\n",
        "                display(HTML(\"<div>Falling back to CSV download due to Google Sheets error.</div>\"))\n",
        "\n",
        "    # Connect handlers to buttons\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    # Display button container and output area\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- Execute Transfer Log Analysis ---\n",
        "# Set parameters for fetching logs\n",
        "FETCH_TRANSFERS = True\n",
        "BLOCKS_TO_FETCH = 1000\n",
        "\n",
        "if FETCH_TRANSFERS:\n",
        "    if BLOCKS_TO_FETCH == 'latest':\n",
        "        # Just fetch latest block\n",
        "        transfers_df = fetch_pyusd_transfer_logs(from_block='latest', to_block='latest')\n",
        "    else:\n",
        "        # Always respect the 5-block limit for Google Blockchain API\n",
        "        try:\n",
        "            latest_block = w3_clients['mainnet'].eth.block_number\n",
        "\n",
        "            # Strictly respect the 5-block maximum range\n",
        "            start_block = latest_block - 4  # This gives exactly 5 blocks including the latest\n",
        "            console.print(\"\\n\\n[bold]üìú Fetching Logs via eth_getLogs[/bold]\", style=\"cyan3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "            console.print(f\"\\n\\n[bold chartreuse1]üì° Querying Recent PYUSD Transfers [Block {start_block:,} to {latest_block:,} (latest)] (Max 5-Block Limit)[/bold chartreuse1]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "            transfers_df = fetch_pyusd_transfer_logs(from_block=start_block, to_block=latest_block)\n",
        "        except Exception as e:\n",
        "            console.print(f\"[warning]Error fetching latest blocks: {e}. Falling back to single block query.\", style=\"warning\")\n",
        "            transfers_df = fetch_pyusd_transfer_logs(from_block='latest', to_block='latest')\n",
        "\n",
        "    if transfers_df is not None and not transfers_df.empty:\n",
        "        # Display a sample of the data\n",
        "        console.print(\"\\n\\n[bold cyan3]Transfer Data Sample (First 5 rows)[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        sample_display_cols = ['blockNumber', 'transactionHash', 'from', 'to', 'value_pyusd', 'timestamp']\n",
        "        display(transfers_df[sample_display_cols].head())\n",
        "\n",
        "        # Run analysis\n",
        "        analyze_pyusd_transfers(transfers_df)\n",
        "    else:\n",
        "        console.print(\"[warning]No PYUSD transfers found or error occurred.\", style=\"warning\")\n",
        "\n",
        "# --- Execute Log Fetching for Target Block on Mainnet ---\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_getlogs = TARGET_BLOCK_IDENTIFIER\n",
        "    console.print(f\"\\n\\n[bold chartreuse1]üì° Querying PYUSD logs for Target Block Identifier: {block_id_getlogs} on Mainnet[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    # Fetch for a single block by setting from_block and to_block to the same identifier\n",
        "    pyusd_logs_df = fetch_pyusd_transfer_logs(from_block=block_id_getlogs, to_block=block_id_getlogs, network='mainnet')\n",
        "\n",
        "    if pyusd_logs_df is not None and not pyusd_logs_df.empty:\n",
        "        console.print(\"\\n\\n[bold cyan3]üìä PYUSD Transfer Logs (Mainnet Block)[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        # Show full addresses instead of shortened ones\n",
        "        display_cols = ['blockNumber', 'from', 'to', 'value_pyusd', 'transactionHash']\n",
        "        display(pyusd_logs_df[display_cols])\n",
        "\n",
        "        # Run analysis on block data\n",
        "        analyze_pyusd_transfers(pyusd_logs_df)\n",
        "\n",
        "    elif pyusd_logs_df is not None:\n",
        "        console.print(f\"[info]No PYUSD transfers found in block {block_id_getlogs} on Mainnet.\", style=\"info\")\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping Mainnet eth_getLogs analysis.\", style=\"warning\")\n",
        "\n",
        "# --- Optional: Query for a Block Range Instead of Single Block ---\n",
        "RUN_BLOCK_RANGE_FETCH = True\n",
        "\n",
        "if RUN_BLOCK_RANGE_FETCH and 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    # Use TARGET_BLOCK_IDENTIFIER as the center of a smaller range\n",
        "    block_center = TARGET_BLOCK_IDENTIFIER if isinstance(TARGET_BLOCK_IDENTIFIER, int) else int(TARGET_BLOCK_IDENTIFIER, 16) if isinstance(TARGET_BLOCK_IDENTIFIER, str) and TARGET_BLOCK_IDENTIFIER.startswith('0x') else None\n",
        "\n",
        "    if block_center:\n",
        "        # Respect the 5-block limit for Google Blockchain API\n",
        "        # Use center block plus 2 on each side (5 blocks total)\n",
        "        range_start = block_center - 2\n",
        "        range_end = block_center + 2\n",
        "        console.print(f\"[info]Fetching PYUSD logs with 5-block range: {range_start}-{range_end}\", style=\"info\")\n",
        "\n",
        "        range_logs_df = fetch_pyusd_transfer_logs(from_block=range_start, to_block=range_end, network='mainnet')\n",
        "\n",
        "        if range_logs_df is not None and not range_logs_df.empty:\n",
        "            console.print(f\"\\n\\n[bold chartreuse1]üì° Querying PYUSD Transfer Logs (Block Range {range_start}-{range_end})[/bold chartreuse1]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "            # Show full addresses in this display too\n",
        "            display_cols = ['blockNumber', 'from', 'to', 'value_pyusd', 'transactionHash']\n",
        "            display(range_logs_df[display_cols])\n",
        "\n",
        "            # Run analysis on range data\n",
        "            analyze_pyusd_transfers(range_logs_df)\n",
        "\n",
        "        elif range_logs_df is not None:\n",
        "            console.print(f\"[info]No PYUSD transfers found in block range {range_start}-{range_end} on Mainnet.\", style=\"info\")\n",
        "    else:\n",
        "        console.print(\"[warning]Could not determine a numeric block center for range query.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "WBTX90A3XBja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 üìÑ `eth_getCode`: Fetching and Analyzing Contract Bytecode\n",
        "---\n",
        "\n",
        "This section uses the `eth_getCode` RPC method to retrieve the **runtime bytecode** associated with a specific Ethereum address at a given block state. This allows us to inspect the actual executable code deployed on the blockchain.\n",
        "\n",
        "Analyzing bytecode is essential for:\n",
        "\n",
        "*   **Verification:** Confirming whether an address belongs to a smart contract or an Externally Owned Account (EOA). EOAs have no code.\n",
        "*   **Proxy Analysis:** Comparing the minimal bytecode of a proxy contract (like `PYUSD_PROXY`) with the extensive logic bytecode of its implementation contract (`PYUSD_IMPLEMENTATION`).\n",
        "*   **Basic Functionality Identification:** Detecting potential function signatures (like standard ERC-20 functions or *potentially* PYUSD-specific ones *if included in the tool's known signature set*) present within the bytecode. *Note that this relies on matching known 4-byte selectors found via bytecode patterns and is a heuristic approach, not a full decompilation.*\n",
        "*   **Pattern Recognition:** Identifying common contract patterns (e.g., Ownable, Pausable, Proxy types) based on embedded function selectors.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Capabilities**\n",
        ">\n",
        "> *   **Method:** `eth_getCode`\n",
        "> *   **Multiplier:** `10x` (More efficient than tracing, but still higher than basic calls)\n",
        "> *   **GCP Advantage:** While a standard call, reliable access via GCP ensures consistent retrieval of bytecode for analysis, even for large contracts or during high network load.\n",
        "> *   **PYUSD Insight:** Allows us to:\n",
        ">     *   Directly compare the lean **PYUSD proxy** contract code with its feature-rich **implementation** code.\n",
        ">     *   Verify the bytecode of the **Supply Controller** contract.\n",
        ">     *   Potentially identify known PYUSD function signatures *if available in the analysis tool's predefined signature dictionary* directly from the bytecode of any interacting contract.\n",
        "\n",
        "**Analysis Workflow & Features:**\n",
        "\n",
        "This section provides an interactive bytecode analysis tool with multiple modes accessed via tabs:\n",
        "\n",
        "1.  **PYUSD Analysis Tab:**\n",
        "    *   Automatically fetches and analyzes the bytecode for the official PYUSD Proxy, Implementation, and Supply Controller contracts on Mainnet.\n",
        "    *   Performs individual analysis (`analyze_bytecode`) showing size, detected standards/patterns, and known functions.\n",
        "    *   Compares the Proxy and Implementation contracts (`compare_proxy_implementation`), highlighting differences in size and function signatures.\n",
        "    *   Visualizes the proxy architecture and contract relationships using Graphviz (*Note: Requires Graphviz installation and PATH configuration for diagrams to display*).\n",
        "2.  **From Transaction Tab:**\n",
        "    *   Takes a transaction hash as input.\n",
        "    *   Identifies all contract addresses involved (target, event emitters, created contracts) using `get_contracts_from_tx`.\n",
        "    *   Fetches and analyzes the bytecode for each identified contract.\n",
        "    *   If multiple contracts are found, performs a similarity comparison (`compare_multiple_contracts`) based on known function signatures.\n",
        "3.  **Custom Contracts Tab:**\n",
        "    *   Allows entering up to three arbitrary contract addresses.\n",
        "    *   Fetches and analyzes the bytecode for each provided address.\n",
        "    *   Performs comparisons (Proxy vs. Impl if 2 addresses, Multi-contract if 3 addresses).\n",
        "4.  **Export Options:** Available within each tab to download the analysis results (JSON) or export to Google Sheets (Colab).\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **Bytecode Size:** Note the significant size difference between proxy and implementation contracts.\n",
        "*   **Detected Patterns/Standards:** See if contracts adhere to ERC standards or implement common patterns like Ownable/Pausable.\n",
        "*   **Proxy Analysis:** Understand the implementation address linked to the PYUSD proxy.\n",
        "*   **Function Signatures:** Observe which known functions are detected within the bytecode (*remembering this is based on matching predefined signatures found via bytecode heuristics and is not a complete list of all functions*).\n",
        "*   **Comparisons:** Identify shared vs. unique functions between related contracts."
      ],
      "metadata": {
        "id": "0UP-Z1dFIrES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üìÑ Advanced Contract Bytecode Analysis using eth_getCode\n",
        "# =============================================================================================\n",
        "# This cell provides comprehensive bytecode analysis for Ethereum smart contracts through multiple approaches.\n",
        "# Functionality includes:\n",
        "# - Fetching and analyzing contract bytecode with detection of ERC standards, proxy patterns, and security features\n",
        "# - Comparing proxy contracts with their implementations to visualize delegation patterns\n",
        "# - Analyzing multiple contracts from transactions to understand their relationships\n",
        "# - Comparing different stablecoins (PYUSD, USDC, USDT) or other contract types side-by-side\n",
        "# - Generating interactive visualizations of contract sizes, function distributions, and similarity metrics\n",
        "# - Creating proxy architecture diagrams and contract relationship visualizations\n",
        "# - Exporting complete analysis results to JSON or Google Sheets for further investigation\n",
        "# - Supporting mainnet, sepolia, and holesky networks with flexible contract selection options\n",
        "\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display, clear_output\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from web3 import Web3\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.text import Text\n",
        "from rich.theme import Theme\n",
        "from graphviz import Digraph\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",\n",
        "    \"error\": \"red3\",\n",
        "    \"warning\": \"yellow3\",\n",
        "    \"success\": \"green3\",\n",
        "    \"spring_green3\": \"spring_green3\",\n",
        "    \"dim\": \"grey50\",\n",
        "})\n",
        "\n",
        "# Ensure console is created with the theme\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# --- Globals (Ensure these are defined/initialized in a prior cell) ---\n",
        "\n",
        "# Some known signatures into a single dictionary for efficient lookup\n",
        "ALL_KNOWN_SIGNATURES = {\n",
        "    **(ERC20_SIGNATURES if 'ERC20_SIGNATURES' in globals() else {}),\n",
        "    **(ERC721_SIGNATURES if 'ERC721_SIGNATURES' in globals() else {}),\n",
        "    **(ERC1155_SIGNATURES if 'ERC1155_SIGNATURES' in globals() else {}),\n",
        "    **(PROXY_PATTERNS if 'PROXY_PATTERNS' in globals() else {}),\n",
        "    **(UUPS_PATTERNS if 'UUPS_PATTERNS' in globals() else {}),\n",
        "    **(DIAMOND_PATTERNS if 'DIAMOND_PATTERNS' in globals() else {}),\n",
        "    **(SECURITY_PATTERNS if 'SECURITY_PATTERNS' in globals() else {}),\n",
        "    **(DEFI_PATTERNS if 'DEFI_PATTERNS' in globals() else {}),\n",
        "    **(GAS_PATTERNS if 'GAS_PATTERNS' in globals() else {})\n",
        "}\n",
        "if 'PYUSD_SIGNATURES' in globals():\n",
        "    ALL_KNOWN_SIGNATURES.update(PYUSD_SIGNATURES)\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def shorten_address(address, chars=4):\n",
        "    \"\"\"Displays full blockchain address, adding line breaks if too long.\"\"\"\n",
        "    if not isinstance(address, str) or not address.startswith(\"0x\"):\n",
        "        return str(address)  # Return original if not a valid address string\n",
        "\n",
        "    # uncomment if you want to truncate addresses\n",
        "    # # If address is very long (like more than 25 chars), add a line break\n",
        "    # if len(address) > 25:\n",
        "    #     return f\"{address[:14]}\\n{address[14:]}\"\n",
        "    return address\n",
        "\n",
        "# --- Core Analysis Functions ---\n",
        "\n",
        "def get_contract_code(contract_address, block_identifier=\"latest\", network='mainnet'):\n",
        "    \"\"\"Fetches the runtime bytecode for a contract address using the configured Web3 client.\"\"\"\n",
        "    if 'w3_clients' not in globals() or network not in w3_clients:\n",
        "        print(f\"[error]Web3 client for '{network}' network not configured.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        print(f\"[error]Web3 client for '{network}' is not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        checksum_address = Web3.to_checksum_address(contract_address)\n",
        "    except ValueError:\n",
        "        console.print(f\"[error]Invalid contract address format provided: {contract_address}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"[info]Fetching bytecode for {checksum_address} at block '{block_identifier}' on {network.capitalize()}.\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        code_bytes = w3_client.eth.get_code(checksum_address, block_identifier=block_identifier)\n",
        "        hex_code = code_bytes.hex() # Includes '0x' prefix\n",
        "\n",
        "        if hex_code == \"0x\":\n",
        "            console.print(f\"[warning]No bytecode found at {checksum_address} (Block: {block_identifier}, Network: {network.capitalize()}). It might be an EOA or a destroyed contract.\", style=\"warning\")\n",
        "            return None\n",
        "        else:\n",
        "            bytecode_size = len(code_bytes)\n",
        "            console.print(f\"[success]Successfully retrieved bytecode for {checksum_address}.\", style=\"success\")\n",
        "            # Display summary using Rich Table\n",
        "            console.print(\"\\n\\n[bold]üî¨ Contract Bytecode Information[/bold]\", style=\"magenta3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "            table = Table(show_header=False, box=None, padding=(0,1), title=\"\")\n",
        "            table.add_column(\"Field\")\n",
        "            table.add_column(\"Value\")\n",
        "            table.add_row(\"[bold]Address:[/bold]\", checksum_address)\n",
        "            table.add_row(\"[bold]Network:[/bold]\", network.capitalize())\n",
        "            table.add_row(\"[bold]Block:[/bold]\", str(block_identifier))\n",
        "            table.add_row(\"[bold]Bytecode Size:[/bold]\", f\"{bytecode_size:,} bytes\")\n",
        "            table.add_row(\"[bold]Preview:[/bold]\", f\"{hex_code[:100]}...\")\n",
        "            console.print(table)\n",
        "            return hex_code\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error fetching bytecode for {checksum_address} on {network.capitalize()}: {e}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_contracts_from_tx(tx_hash, network='mainnet'):\n",
        "    \"\"\"Extracts contract addresses involved in a transaction (to, logs, creation) and verifies they have bytecode.\"\"\"\n",
        "    if 'w3_clients' not in globals() or network not in w3_clients:\n",
        "         print(f\"[error]Web3 client for '{network}' network not configured.\", style=\"error\")\n",
        "         return None\n",
        "\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        console.print(f\"[info]Fetching transaction details for {tx_hash} on {network.capitalize()}...\", style=\"info\")\n",
        "        tx = w3_client.eth.get_transaction(tx_hash)\n",
        "        if not tx:\n",
        "             console.print(f\"[error]Transaction {tx_hash} not found on {network}.\", style=\"error\")\n",
        "             return None\n",
        "        receipt = w3_client.eth.get_transaction_receipt(tx_hash)\n",
        "        if not receipt:\n",
        "             # This can happen if the transaction hasn't been mined yet\n",
        "             console.print(f\"[warning]Transaction receipt for {tx_hash} not found on {network}. Transaction might be pending.\", style=\"warning\")\n",
        "             return None\n",
        "\n",
        "        contracts = {} # {address: name}\n",
        "        processed_addresses = set() # Avoid duplicate lookups\n",
        "\n",
        "        # Helper to check address for bytecode and add to contracts dict\n",
        "        def check_and_add_contract(address, name_prefix):\n",
        "            if not address or address in processed_addresses:\n",
        "                return\n",
        "            try:\n",
        "                code = w3_client.eth.get_code(address)\n",
        "                # Check if code exists and is not empty bytecode marker\n",
        "                if code and code != b'\\x00' and code.hex() != '0x':\n",
        "                    contract_name = f\"{name_prefix} ({shorten_address(address)})\"\n",
        "                    contracts[address] = contract_name\n",
        "                processed_addresses.add(address)\n",
        "            except Exception as e:\n",
        "                console.print(f\"[warning]Could not check code for address {address}: {e}\", style=\"warning\")\n",
        "\n",
        "        # Check 'to' address\n",
        "        check_and_add_contract(tx.to, \"Target Contract\")\n",
        "\n",
        "        # Check addresses from event logs\n",
        "        for log in receipt.logs:\n",
        "            check_and_add_contract(log.address, \"Event Emitter\")\n",
        "\n",
        "        # Check contract creation address\n",
        "        check_and_add_contract(receipt.contractAddress, \"Created Contract\")\n",
        "\n",
        "        if contracts:\n",
        "            console.print(f\"[success]Found {len(contracts)} address(es) with bytecode involved in transaction {tx_hash}.\", style=\"success\")\n",
        "        else:\n",
        "            console.print(f\"[warning]Found 0 addresses with bytecode involved in transaction {tx_hash}. Transaction might not interact with contracts or contracts might be destroyed.\", style=\"warning\")\n",
        "        return contracts\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error processing transaction {tx_hash}: {str(e)}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def analyze_bytecode(bytecode, contract_name=\"Contract\"):\n",
        "    \"\"\"Analyzes contract bytecode for size, standards, known functions, and common patterns.\"\"\"\n",
        "    if not bytecode or bytecode == \"0x\":\n",
        "        console.print(f\"[warning]No bytecode provided for analysis of '{contract_name}'.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    code = bytecode[2:] if bytecode.startswith('0x') else bytecode\n",
        "    if not code:\n",
        "        console.print(f\"[warning]Empty bytecode provided for analysis of '{contract_name}'.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    results = {\n",
        "        \"contract_name\": contract_name,\n",
        "        \"address\": contract_name.split(\"(\")[-1].strip(\")\") if \"(\" in contract_name and \"...\" in contract_name else \"N/A\",\n",
        "        \"size_bytes\": len(code) // 2,\n",
        "        \"standards\": [],\n",
        "        \"erc20_functionality\": {\"compatible\": False, \"functions\": []},\n",
        "        \"erc721_functionality\": {\"compatible\": False, \"functions\": []},\n",
        "        \"erc1155_functionality\": {\"compatible\": False, \"functions\": []},\n",
        "        \"proxy_functionality\": {\"is_proxy\": False, \"proxy_type\": None, \"functions\": []},\n",
        "        \"security_functionality\": {\"has_security_controls\": False, \"functions\": []},\n",
        "        \"defi_functionality\": {\"has_defi_features\": False, \"functions\": []},\n",
        "        \"gas_optimization\": {\"optimized\": False, \"features\": []},\n",
        "        \"detected_patterns\": [],\n",
        "        \"all_detected_functions\": [], # Stores tuples (signature, name, category) for known functions\n",
        "        \"bytecode_metrics\": {\n",
        "            \"size\": len(code) // 2,\n",
        "            \"complexity_estimate\": max(1, len(code) // 200), # Avoid 0, estimate based on size\n",
        "            \"method_count_estimate\": 0, # Based on known methods found\n",
        "            \"has_loops_or_recursion\": \"Unknown\" # Requires deeper analysis\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Find potential 4-byte signatures using PUSH4 opcode heuristic\n",
        "    potential_sigs_hex = set(re.findall(r'63([0-9a-f]{8})', code))\n",
        "    potential_sigs = set(f\"0x{s}\" for s in potential_sigs_hex) # Add '0x' prefix\n",
        "\n",
        "    found_known_sigs = set() # Track signatures already categorized\n",
        "\n",
        "    # Check against known signature categories\n",
        "    categories_config = {\n",
        "        \"ERC20\": {\"signatures\": ERC20_SIGNATURES if 'ERC20_SIGNATURES' in globals() else {}, \"threshold\": 5, \"result_key\": \"erc20_functionality\"},\n",
        "        \"ERC721\": {\"signatures\": ERC721_SIGNATURES if 'ERC721_SIGNATURES' in globals() else {}, \"threshold\": 4, \"result_key\": \"erc721_functionality\"},\n",
        "        \"ERC1155\": {\"signatures\": ERC1155_SIGNATURES if 'ERC1155_SIGNATURES' in globals() else {}, \"threshold\": 4, \"result_key\": \"erc1155_functionality\"},\n",
        "        \"Proxy\": {\"signatures\": {**(PROXY_PATTERNS if 'PROXY_PATTERNS' in globals() else {}), **(UUPS_PATTERNS if 'UUPS_PATTERNS' in globals() else {}), **(DIAMOND_PATTERNS if 'DIAMOND_PATTERNS' in globals() else {})}, \"threshold\": 1, \"result_key\": \"proxy_functionality\"},\n",
        "        \"Security\": {\"signatures\": SECURITY_PATTERNS if 'SECURITY_PATTERNS' in globals() else {}, \"threshold\": 1, \"result_key\": \"security_functionality\"},\n",
        "        \"DeFi\": {\"signatures\": DEFI_PATTERNS if 'DEFI_PATTERNS' in globals() else {}, \"threshold\": 1, \"result_key\": \"defi_functionality\"},\n",
        "        \"Gas Opt\": {\"signatures\": GAS_PATTERNS if 'GAS_PATTERNS' in globals() else {}, \"threshold\": 1, \"result_key\": \"gas_optimization\"}\n",
        "    }\n",
        "\n",
        "    for category_name, config in categories_config.items():\n",
        "        count = 0\n",
        "        signatures_dict = config[\"signatures\"]\n",
        "        result_key = config[\"result_key\"]\n",
        "        functions_list = []\n",
        "\n",
        "        for signature, func_name in signatures_dict.items():\n",
        "            if signature in potential_sigs:\n",
        "                count += 1\n",
        "                functions_list.append(func_name)\n",
        "                # Add to the overall list if not already seen\n",
        "                if signature not in found_known_sigs:\n",
        "                    results[\"all_detected_functions\"].append((signature, func_name, category_name))\n",
        "                    found_known_sigs.add(signature)\n",
        "\n",
        "        # Store identified functions for this category\n",
        "        if \"functions\" in results[result_key]:\n",
        "            results[result_key][\"functions\"] = sorted(list(set(functions_list))) # Unique sorted list\n",
        "\n",
        "        # Determine compatibility/presence based on threshold\n",
        "        if count >= config[\"threshold\"]:\n",
        "            if \"compatible\" in results[result_key]: results[result_key][\"compatible\"] = True\n",
        "            elif \"is_proxy\" in results[result_key]: results[result_key][\"is_proxy\"] = True\n",
        "            elif \"has_security_controls\" in results[result_key]: results[result_key][\"has_security_controls\"] = True\n",
        "            elif \"has_defi_features\" in results[result_key]: results[result_key][\"has_defi_features\"] = True\n",
        "            elif \"optimized\" in results[result_key]: results[result_key][\"optimized\"] = True\n",
        "\n",
        "    # Update total known method count estimate\n",
        "    results[\"all_detected_functions\"].sort(key=lambda x: (x[2], x[1])) # Sort by category, then name\n",
        "    results[\"bytecode_metrics\"][\"method_count_estimate\"] = len(results[\"all_detected_functions\"])\n",
        "\n",
        "    # Identify standards\n",
        "    if results[\"erc20_functionality\"][\"compatible\"]: results[\"standards\"].append(\"ERC20\")\n",
        "    if results[\"erc721_functionality\"][\"compatible\"]: results[\"standards\"].append(\"ERC721\")\n",
        "    if results[\"erc1155_functionality\"][\"compatible\"]: results[\"standards\"].append(\"ERC1155\")\n",
        "\n",
        "    # Refine proxy type identification\n",
        "    if results[\"proxy_functionality\"][\"is_proxy\"]:\n",
        "        proxy_funcs_found = {f[0] for f in results[\"all_detected_functions\"] if f[2] == 'Proxy'}\n",
        "        # Check based on signature sets defined globally\n",
        "        is_eip1967 = any(s in proxy_funcs_found for s in (PROXY_PATTERNS if 'PROXY_PATTERNS' in globals() else {}))\n",
        "        is_uups = any(s in proxy_funcs_found for s in (UUPS_PATTERNS if 'UUPS_PATTERNS' in globals() else {}))\n",
        "        is_diamond = any(s in proxy_funcs_found for s in (DIAMOND_PATTERNS if 'DIAMOND_PATTERNS' in globals() else {}))\n",
        "\n",
        "        proxy_type = \"Basic/Unknown Proxy\" # Default\n",
        "        pattern_desc = \"Proxy Pattern: Basic/Unknown\"\n",
        "        if is_diamond:\n",
        "            proxy_type = \"Diamond Proxy (EIP-2535)\"\n",
        "            pattern_desc = \"Proxy Pattern: Diamond\"\n",
        "        elif is_uups: # UUPS often uses EIP-1967 storage, so check first\n",
        "            proxy_type = \"UUPS Proxy (EIP-1822 / EIP-1967)\"\n",
        "            pattern_desc = \"Proxy Pattern: UUPS\"\n",
        "        elif is_eip1967:\n",
        "            proxy_type = \"Transparent Proxy (EIP-1967)\"\n",
        "            pattern_desc = \"Proxy Pattern: Transparent\"\n",
        "\n",
        "        results[\"proxy_functionality\"][\"proxy_type\"] = proxy_type\n",
        "        results[\"detected_patterns\"].append(pattern_desc)\n",
        "\n",
        "    # Check for common library patterns based on security functions found\n",
        "    sec_funcs = set(results[\"security_functionality\"][\"functions\"])\n",
        "    if \"pause()\" in sec_funcs and \"unpause()\" in sec_funcs: results[\"detected_patterns\"].append(\"Pattern: Pausable\")\n",
        "    if \"owner()\" in sec_funcs and \"transferOwnership(address)\" in sec_funcs: results[\"detected_patterns\"].append(\"Pattern: Ownable\")\n",
        "\n",
        "    # Check for other bytecode string patterns\n",
        "    # Note: Simple string checks are prone to false positives but can be indicative\n",
        "    if re.search(r'e3010170.{68}0033', code): results[\"detected_patterns\"].append(\"Metadata: IPFS Hash (CBOR)\")\n",
        "    if \"create2\" in code: results[\"detected_patterns\"].append(\"Opcode Hint: CREATE2\")\n",
        "    if \"selfdestruct\" in code: results[\"detected_patterns\"].append(\"Opcode Hint: SELFDESTRUCT\")\n",
        "\n",
        "    # --- Output Results ---\n",
        "    console.print(f\"\\n\\n[bold yellow3]üìä Bytecode Analysis Results: {contract_name}[/bold yellow3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "\n",
        "    # Summary Table using Rich\n",
        "    analysis_table = Table(show_header=False, box=None, padding=(0,1))\n",
        "    analysis_table.add_column(\"Property\")\n",
        "    analysis_table.add_column(\"Value\")\n",
        "    analysis_table.add_row(\"Size:\", f\"{results['size_bytes']:,} bytes\")\n",
        "    if results[\"standards\"]: analysis_table.add_row(\"Standards:\", \", \".join(results[\"standards\"]))\n",
        "    if results[\"proxy_functionality\"][\"is_proxy\"]:\n",
        "        analysis_table.add_row(\"Proxy Contract:\", \"‚úÖ Yes\")\n",
        "        if results[\"proxy_functionality\"][\"proxy_type\"]: analysis_table.add_row(\"Proxy Type:\", results[\"proxy_functionality\"][\"proxy_type\"])\n",
        "    if results[\"security_functionality\"][\"has_security_controls\"]: analysis_table.add_row(\"Security Controls:\", \"‚úÖ Yes\")\n",
        "    if results[\"defi_functionality\"][\"has_defi_features\"]: analysis_table.add_row(\"DeFi Features:\", \"‚úÖ Yes\")\n",
        "    if results[\"detected_patterns\"]: analysis_table.add_row(\"Other Patterns/Hints:\", Text(\", \".join(results[\"detected_patterns\"]), overflow=\"fold\"))\n",
        "    complexity_val = results[\"bytecode_metrics\"][\"complexity_estimate\"]\n",
        "    complexity_label = \"Low\" if complexity_val < 10 else \"Medium\" if complexity_val < 50 else \"High\"\n",
        "    analysis_table.add_row(\"[bold]Complexity Estimate:[/bold]\", complexity_label)\n",
        "    analysis_table.add_row(\"[bold]Known Methods Found:[/bold]\", str(results[\"bytecode_metrics\"][\"method_count_estimate\"]))\n",
        "    console.print(analysis_table)\n",
        "\n",
        "    # Overview DataFrame using Pandas\n",
        "    result_df_data = [\n",
        "        {\"Property\": \"Size\", \"Value\": f\"{results['size_bytes']:,} bytes\"},\n",
        "        {\"Property\": \"Standards\", \"Value\": \", \".join(results[\"standards\"]) if results[\"standards\"] else \"None detected\"},\n",
        "        {\"Property\": \"Is Proxy\", \"Value\": \"Yes\" if results[\"proxy_functionality\"][\"is_proxy\"] else \"No\"},\n",
        "        {\"Property\": \"Proxy Type\", \"Value\": results[\"proxy_functionality\"][\"proxy_type\"] if results[\"proxy_functionality\"][\"is_proxy\"] else \"N/A\"},\n",
        "        {\"Property\": \"Security Controls\", \"Value\": \"Yes\" if results[\"security_functionality\"][\"has_security_controls\"] else \"No\"},\n",
        "        {\"Property\": \"Complexity\", \"Value\": complexity_label},\n",
        "        {\"Property\": \"Known Method Count\", \"Value\": results[\"bytecode_metrics\"][\"method_count_estimate\"]}\n",
        "    ]\n",
        "    result_df = pd.DataFrame(result_df_data)\n",
        "    display(HTML(\"<h4>Contract Overview</h4>\"))\n",
        "    display(result_df)\n",
        "\n",
        "    # Detected Known Functions DataFrame using Pandas\n",
        "    if results[\"all_detected_functions\"]:\n",
        "        func_df_data = [{\"Category\": cat, \"Signature\": sig, \"Function Name\": name}\n",
        "                        for sig, name, cat in results[\"all_detected_functions\"]]\n",
        "        func_df = pd.DataFrame(func_df_data)\n",
        "        display(HTML(f\"<h4>Detected Known Functions ({len(func_df)} entries)</h4>\"))\n",
        "        with pd.option_context('display.max_rows', 100): # Limit display length in notebook\n",
        "             display(func_df)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def compare_proxy_implementation(proxy_code, impl_code, proxy_name=\"Proxy\", impl_name=\"Implementation\"):\n",
        "    \"\"\"Compares proxy and implementation contracts focusing on size and known function signatures.\"\"\"\n",
        "    if not proxy_code or proxy_code == '0x' or not impl_code or impl_code == '0x':\n",
        "        console.print(\"[warning]Missing or empty bytecode provided for proxy-implementation comparison.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    proxy_size = len(proxy_code[2:]) // 2 if proxy_code.startswith('0x') else len(proxy_code) // 2\n",
        "    impl_size = len(impl_code[2:]) // 2 if impl_code.startswith('0x') else len(impl_code) // 2\n",
        "\n",
        "    console.print(\"\\n\\n[bold]üîÑ Proxy vs. Implementation Comparison:[/bold]\", style=\"chartreuse1\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "    console.print(f\"\\n\\n{proxy_name} & {impl_name}\", style=\"chartreuse1\")\n",
        "\n",
        "    # --- Size Comparison ---\n",
        "    display(HTML(\"<h4>Size Comparison</h4>\"))\n",
        "    sizes_df = pd.DataFrame({\n",
        "        'Contract': [proxy_name, impl_name],\n",
        "        'Size (bytes)': [proxy_size, impl_size],\n",
        "        'Notes': [\"Delegates calls, minimal logic\", \"Contains main business logic\"]\n",
        "    })\n",
        "    display(sizes_df)\n",
        "\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Contract Size Comparison (Bytes)[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create size comparison chart using matplotlib\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        bars = plt.bar(sizes_df['Contract'], sizes_df['Size (bytes)'], color=['skyblue', 'lightcoral'])\n",
        "\n",
        "        # Add data labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                    f'{int(height):,}', ha='center', va='bottom')\n",
        "\n",
        "        plt.title('Contract Size Comparison (Bytes)')\n",
        "        plt.ylabel('Size (bytes)')\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        display(plt.gcf())\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not generate size comparison chart: {e}\", style=\"warning\")\n",
        "\n",
        "    comparison_results = {\n",
        "        \"proxy_name\": proxy_name, \"implementation_name\": impl_name,\n",
        "        \"proxy_size\": proxy_size, \"implementation_size\": impl_size,\n",
        "        \"size_ratio\": impl_size / proxy_size if proxy_size > 0 else float('inf')\n",
        "    }\n",
        "\n",
        "    # Add spacing between visualizations\n",
        "    display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "    # --- Function Signature Analysis (Known Signatures Only) ---\n",
        "    console.print(\"\\n[bold]Function Signature Analysis (Known Signatures)[/bold]\", style=\"magenta3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "    # Helper to extract known signatures from bytecode\n",
        "    def get_known_signatures(bytecode):\n",
        "        code_str = bytecode[2:] if bytecode.startswith('0x') else bytecode\n",
        "        sigs_hex = set(re.findall(r'63([0-9a-f]{8})', code_str)) # PUSH4 heuristic\n",
        "        return set(f\"0x{s}\" for s in sigs_hex if f\"0x{s}\" in ALL_KNOWN_SIGNATURES)\n",
        "\n",
        "    proxy_known_sigs = get_known_signatures(proxy_code)\n",
        "    impl_known_sigs = get_known_signatures(impl_code)\n",
        "\n",
        "    shared_sigs = proxy_known_sigs.intersection(impl_known_sigs)\n",
        "    proxy_unique = proxy_known_sigs - shared_sigs\n",
        "    impl_unique = impl_known_sigs - shared_sigs\n",
        "\n",
        "    console.print(f\"Analysis based on signatures found in the known dictionary:\")\n",
        "    console.print(f\"[bold]Shared Known Signatures:[/bold] {len(shared_sigs)}\")\n",
        "    console.print(f\"[bold]Proxy-Only Known Signatures:[/bold] {len(proxy_unique)}\")\n",
        "    console.print(f\"[bold]Implementation-Only Known Signatures:[/bold] {len(impl_unique)}\")\n",
        "\n",
        "        # --- Generate Function Distribution Chart (Excluding 0% Categories) ---\n",
        "    try:\n",
        "        # Define original categories, their corresponding values, and consistent colors\n",
        "        all_categories = ['Shared Known', 'Proxy Only Known', 'Implementation Only Known']\n",
        "        all_values = [len(shared_sigs), len(proxy_unique), len(impl_unique)]\n",
        "        # Use a map to ensure colors stay consistent with categories after filtering\n",
        "        color_map = {\n",
        "            'Shared Known': 'mediumseagreen',\n",
        "            'Proxy Only Known': 'skyblue',\n",
        "            'Implementation Only Known': 'salmon'\n",
        "        }\n",
        "\n",
        "        # Filter out categories with zero signatures to avoid cluttering the chart\n",
        "        filtered_categories = []\n",
        "        filtered_values = []\n",
        "        filtered_colors = []\n",
        "        for category, value in zip(all_categories, all_values):\n",
        "            if value > 0:\n",
        "                filtered_categories.append(category)\n",
        "                filtered_values.append(value)\n",
        "                filtered_colors.append(color_map[category])\n",
        "\n",
        "        # Proceed only if there are non-zero categories to display\n",
        "        if filtered_values:\n",
        "            try:\n",
        "                # Display header for the chart section\n",
        "                console.print(\"\\n\\n[bold]Distribution of Known Function Signatures (Non-Zero)[/bold]\", style=\"magenta3\")\n",
        "                console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                # Create the pie chart using the filtered data\n",
        "                plt.figure(figsize=(8, 4)) # Use smaller dimensions to reduce rendering size\n",
        "                plt.pie(\n",
        "                    filtered_values,\n",
        "                    labels=filtered_categories,\n",
        "                    autopct='%1.1f%%',\n",
        "                    colors=filtered_colors,\n",
        "                    startangle=90,\n",
        "                    pctdistance=0.85, # Place percentage labels slightly inside slices (helps with overlap)\n",
        "                )\n",
        "                plt.axis('equal') # Ensure the pie chart is drawn as a circle\n",
        "\n",
        "                # Add a legend showing counts for each displayed category\n",
        "                plt.legend(\n",
        "                    [f\"{cat} ({val})\" for cat, val in zip(filtered_categories, filtered_values)],\n",
        "                    loc=\"best\" # Position legend automatically\n",
        "                )\n",
        "\n",
        "                plt.tight_layout() # Adjust plot to prevent labels from clipping\n",
        "                display(plt.gcf()) # Display the plot in the notebook\n",
        "                plt.close() # Close the plot object to release memory\n",
        "\n",
        "                # --- Display Filtered Data in a Table ---\n",
        "                # Calculate percentages based on the filtered data sum\n",
        "                func_dist_df_data = []\n",
        "                total_sum = sum(filtered_values)\n",
        "                for cat, val in zip(filtered_categories, filtered_values):\n",
        "                     func_dist_df_data.append({\n",
        "                         'Category': cat,\n",
        "                         'Count': val,\n",
        "                         'Percentage': f\"{val/total_sum*100:.1f}%\" if total_sum > 0 else \"0.0%\"\n",
        "                     })\n",
        "                func_dist_df = pd.DataFrame(func_dist_df_data)\n",
        "\n",
        "                # Display the DataFrame with a clear title\n",
        "                display(HTML(\"<h5>Known Signature Distribution (Non-Zero)</h5>\"))\n",
        "                display(func_dist_df)\n",
        "\n",
        "            except Exception as e:\n",
        "                console.print(f\"[error]Error creating pie chart: {e}\", style=\"error\")\n",
        "                # Fallback: Display the DataFrame even if the chart fails, if data exists\n",
        "                if 'func_dist_df' in locals() and not func_dist_df.empty:\n",
        "                    display(HTML(\"<h5>Known Signature Distribution (Chart Generation Failed)</h5>\"))\n",
        "                    display(func_dist_df)\n",
        "\n",
        "        else:\n",
        "            # If all categories filtered out, display a notification message\n",
        "             display(HTML(\"\"\"\n",
        "            <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "                <strong>Note:</strong> No known function signatures were found in either contract for comparison.\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any unexpected errors during the analysis process\n",
        "        console.print(f\"[error]Error in signature distribution analysis: {e}\", style=\"error\")\n",
        "\n",
        "    # Add spacing between visualizations\n",
        "    display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "    # Prepare DataFrame with identified functions for display\n",
        "    try:\n",
        "        # Convert signatures to function names for better readability\n",
        "        shared_funcs = [ALL_KNOWN_SIGNATURES.get(sig, sig) for sig in shared_sigs]\n",
        "        proxy_funcs = [ALL_KNOWN_SIGNATURES.get(sig, sig) for sig in proxy_unique]\n",
        "        impl_funcs = [ALL_KNOWN_SIGNATURES.get(sig, sig) for sig in impl_unique]\n",
        "\n",
        "        # Create DataFrames for each category\n",
        "        shared_df = pd.DataFrame({'Signature': list(shared_sigs), 'Function': shared_funcs, 'Category': 'Shared'}) if shared_sigs else None\n",
        "        proxy_only_df = pd.DataFrame({'Signature': list(proxy_unique), 'Function': proxy_funcs, 'Category': 'Proxy Only'}) if proxy_unique else None\n",
        "        impl_only_df = pd.DataFrame({'Signature': list(impl_unique), 'Function': impl_funcs, 'Category': 'Implementation Only'}) if impl_unique else None\n",
        "\n",
        "        # Display each DataFrame if it exists\n",
        "        if shared_df is not None and not shared_df.empty:\n",
        "            display(HTML(\"<h5>Shared Known Functions</h5>\"))\n",
        "            display(shared_df)\n",
        "        if proxy_only_df is not None and not proxy_only_df.empty:\n",
        "            display(HTML(\"<h5>Proxy-Only Known Functions</h5>\"))\n",
        "            display(proxy_only_df)\n",
        "        if impl_only_df is not None and not impl_only_df.empty:\n",
        "            display(HTML(\"<h5>Implementation-Only Known Functions</h5>\"))\n",
        "            display(impl_only_df)\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Error displaying function details: {e}\", style=\"error\")\n",
        "\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "    <strong>Note on Function Identification:</strong> This analysis focuses on function signatures present in our predefined dictionaries (ERC20, Proxy, Security, etc.), identified using bytecode patterns. Bytecode contains many 4-byte sequences; those not matching known signatures or patterns are not listed here. Full identification requires comprehensive databases (e.g., <a href=\"https://www.4byte.directory/\" target=\"_blank\">4byte.directory</a>) or decompilation tools.\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    # Add signature data to comparison results (as list of dicts for easier JSON export)\n",
        "    comparison_results[\"shared_functions\"] = shared_df.to_dict('records') if shared_df is not None else []\n",
        "    comparison_results[\"proxy_only_functions\"] = proxy_only_df.to_dict('records') if proxy_only_df is not None else []\n",
        "    comparison_results[\"implementation_only_functions\"] = impl_only_df.to_dict('records') if impl_only_df is not None else []\n",
        "\n",
        "    return comparison_results\n",
        "\n",
        "\n",
        "def compare_multiple_contracts(contract_codes, contract_names):\n",
        "    \"\"\"Compares multiple contracts based on size and similarity of known function signatures.\"\"\"\n",
        "    if len(contract_codes) < 2:\n",
        "        console.print(\"[warning]Need at least two contracts with valid bytecode for comparison.\", style=\"warning\")\n",
        "        return None\n",
        "    if len(contract_codes) != len(contract_names):\n",
        "        console.print(\"[error]Internal error: Number of contract codes and names provided for comparison do not match.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]üìä Multi-Contract Comparison ({len(contract_names)} Contracts)[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # --- Size Comparison ---\n",
        "    display(HTML(\"<h4>Size Comparison</h4>\"))\n",
        "    sizes = [len(code[2:]) // 2 if code.startswith('0x') else len(code) // 2 for code in contract_codes]\n",
        "    sizes_df = pd.DataFrame({'Contract': contract_names, 'Size (bytes)': sizes})\n",
        "    display(sizes_df.sort_values('Size (bytes)', ascending=False))\n",
        "\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Contract Size Comparison (Bytes)[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create size comparison chart using matplotlib\n",
        "        plt.figure(figsize=(12, max(6, 0.5 * len(contract_names))))\n",
        "\n",
        "        # Sort data for better visualization\n",
        "        sorted_sizes_df = sizes_df.sort_values('Size (bytes)', ascending=True)\n",
        "\n",
        "        # Create horizontal bar chart for better fit with many contracts\n",
        "        bars = plt.barh(sorted_sizes_df['Contract'], sorted_sizes_df['Size (bytes)'],\n",
        "                      color=plt.cm.Paired(np.linspace(0, 1, len(sorted_sizes_df))))\n",
        "\n",
        "        # Add text labels next to bars\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(width + 0.1, bar.get_y() + bar.get_height()/2, f\"{int(width):,}\",\n",
        "                    ha='left', va='center')\n",
        "\n",
        "        plt.title('Contract Size Comparison (Bytes)')\n",
        "        plt.xlabel('Size (bytes)')\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        display(plt.gcf())\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Could not generate multi-contract size chart: {e}\", style=\"warning\")\n",
        "\n",
        "    # Add spacing between visualizations\n",
        "    display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "    # --- Function Signature Similarity (Known Signatures Only) ---\n",
        "    display(HTML(\"<h4>Function Signature Similarity (Based on Known Signatures)</h4>\"))\n",
        "    console.print(\"[dim]Comparing contracts based on the Jaccard similarity of their known function signatures.\", style=\"dim\")\n",
        "\n",
        "    # Helper to extract known signatures\n",
        "    def get_known_signatures(bytecode):\n",
        "        code_str = bytecode[2:] if bytecode.startswith('0x') else bytecode\n",
        "        sigs_hex = set(re.findall(r'63([0-9a-f]{8})', code_str))\n",
        "        return set(f\"0x{s}\" for s in sigs_hex if f\"0x{s}\" in ALL_KNOWN_SIGNATURES)\n",
        "\n",
        "    all_signatures_known = {name: get_known_signatures(code) for name, code in zip(contract_names, contract_codes)}\n",
        "\n",
        "    similarity_data = []\n",
        "    for i in range(len(contract_names)):\n",
        "        for j in range(i + 1, len(contract_names)):\n",
        "            name_i, name_j = contract_names[i], contract_names[j]\n",
        "            sigs_i, sigs_j = all_signatures_known[name_i], all_signatures_known[name_j]\n",
        "\n",
        "            intersection_size = len(sigs_i.intersection(sigs_j))\n",
        "            union_size = len(sigs_i.union(sigs_j))\n",
        "            similarity = (intersection_size / union_size * 100) if union_size > 0 else 0\n",
        "\n",
        "            similarity_data.append({\n",
        "                'Contract Pair': f\"{name_i} & {name_j}\",\n",
        "                'Shared Known Signatures': intersection_size,\n",
        "                'Total Unique Known Signatures': union_size,\n",
        "                'Similarity (%)': similarity\n",
        "            })\n",
        "\n",
        "    if not similarity_data:\n",
        "        console.print(\"[info]No contract pairs to compare or no known signatures found in multiple contracts.\", style=\"info\")\n",
        "        # Return basic info even if comparison fails\n",
        "        return {\"contract_names\": contract_names, \"sizes\": dict(zip(contract_names, sizes)), \"similarity_data\": []}\n",
        "\n",
        "    similarity_df = pd.DataFrame(similarity_data).sort_values('Similarity (%)', ascending=False)\n",
        "    similarity_df['Similarity (%)'] = similarity_df['Similarity (%)'].round(2)\n",
        "\n",
        "    display(HTML(\"<h5>Pairwise Similarity (Jaccard Index of Known Signatures)</h5>\"))\n",
        "    display(similarity_df)\n",
        "\n",
        "    # Similarity Bar Chart\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]Contract Similarity (% Shared Known Signatures)[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "        console.print(\"[italic]Enlarge small visualization previews by clicking.[/italic]\", style=\"cyan\")\n",
        "\n",
        "        # Create similarity bar chart using matplotlib\n",
        "        plt.figure(figsize=(10, max(6, 0.6 * len(similarity_df))))\n",
        "\n",
        "        # Sort data by similarity for better visualization\n",
        "        sorted_df = similarity_df.sort_values('Similarity (%)')\n",
        "\n",
        "        # Create horizontal bar chart with color gradient\n",
        "        cmap = plt.cm.viridis\n",
        "        norm = plt.Normalize(min(sorted_df['Similarity (%)']), max(sorted_df['Similarity (%)']))\n",
        "        colors = cmap(norm(sorted_df['Similarity (%)']))\n",
        "\n",
        "        bars = plt.barh(sorted_df['Contract Pair'], sorted_df['Similarity (%)'], color=colors)\n",
        "\n",
        "        # Add percentage labels\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(width + 1, bar.get_y() + bar.get_height()/2, f\"{width:.1f}%\",\n",
        "                    ha='left', va='center')\n",
        "\n",
        "        plt.title('Contract Similarity (% Shared Known Signatures)')\n",
        "        plt.xlabel('Similarity (%)')\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        display(plt.gcf())\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Could not generate similarity chart: {str(e)}\", style=\"error\")\n",
        "        # Try to display the data in a simpler format as fallback\n",
        "        display(HTML(f\"<h5>Contract Similarity Data (Chart Generation Failed)</h5>\"))\n",
        "        display(similarity_df)\n",
        "\n",
        "    # Use light-theme friendly version for the note\n",
        "    display(HTML(\"\"\"\n",
        "    <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "    <strong>Note:</strong> Similarity calculation uses only function signatures found in the predefined dictionaries. Higher similarity indicates more shared known functionality.\n",
        "    </div>\n",
        "    \"\"\"))\n",
        "\n",
        "    return {\n",
        "        \"contract_names\": contract_names,\n",
        "        \"sizes\": dict(zip(contract_names, sizes)),\n",
        "        \"signature_count_known\": {name: len(sigs) for name, sigs in all_signatures_known.items()},\n",
        "        \"similarity_data\": similarity_df.to_dict('records')\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Export Functions ---\n",
        "\n",
        "def export_to_google_sheets(analysis_results, comparison_results=None, multi_contract_comparison=None):\n",
        "    \"\"\"Exports the analysis data to a new Google Sheet.\"\"\"\n",
        "    if 'gc_sheets' not in globals() or gc_sheets is None:\n",
        "         console.print(\"[error]Google Sheets client (gc_sheets) is not initialized. Cannot export.\", style=\"error\")\n",
        "         return HTML(\"<div style='color:red'>Error: Google Sheets client not initialized.</div>\")\n",
        "\n",
        "    try:\n",
        "        console.print(\"[cyan3]Exporting analysis results to Google Sheets...\", style=\"info\")\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"Smart Contract Bytecode Analysis {timestamp}\"\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Bytecode Analysis Report\")\n",
        "\n",
        "        # --- Populate Sheet (Adapt based on required detail level) ---\n",
        "        current_row = 1\n",
        "        header_values = [\n",
        "            [f\"Smart Contract Bytecode Analysis Report\"],\n",
        "            [f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"], [\"\"]\n",
        "        ]\n",
        "        worksheet.update(f\"A{current_row}\", header_values)\n",
        "        worksheet.format(f\"A1:A1\", {\"textFormat\": {\"bold\": True, \"fontSize\": 14}})\n",
        "        current_row += len(header_values)\n",
        "\n",
        "        # Individual Contract Analysis Sections\n",
        "        for contract_name, results in analysis_results.items():\n",
        "            worksheet.update(f\"A{current_row}\", [[f\"Analysis: {contract_name}\"]])\n",
        "            worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True, \"fontSize\": 12}, \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}})\n",
        "            current_row += 1\n",
        "\n",
        "            info_table = [[\"Property\", \"Value\"]]\n",
        "            info_table.append([\"Size\", f\"{results.get('size_bytes', 0):,} bytes\"])\n",
        "            if results.get(\"standards\"): info_table.append([\"Standards\", \", \".join(results[\"standards\"])])\n",
        "            if results.get(\"proxy_functionality\", {}).get(\"is_proxy\"):\n",
        "                info_table.append([\"Is Proxy\", \"Yes\"])\n",
        "                info_table.append([\"Proxy Type\", results[\"proxy_functionality\"].get(\"proxy_type\", \"N/A\")])\n",
        "            # Add more fields as needed...\n",
        "            worksheet.update(f\"A{current_row}\", info_table)\n",
        "            worksheet.format(f\"A{current_row}:B{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "            current_row += len(info_table) + 1 # Add spacing\n",
        "\n",
        "            # Detected Functions Table\n",
        "            if results.get(\"all_detected_functions\"):\n",
        "                 func_table = [[\"Category\", \"Signature\", \"Function Name\"]]\n",
        "                 for sig, name, cat in results[\"all_detected_functions\"][:30]: # Limit rows in export\n",
        "                     func_table.append([cat, sig, name])\n",
        "                 if len(results[\"all_detected_functions\"]) > 30:\n",
        "                      func_table.append([\"...\", \"...\", f\"(and {len(results['all_detected_functions']) - 30} more)\"])\n",
        "\n",
        "                 worksheet.update(f\"A{current_row}\", [[\"Detected Known Functions\"]])\n",
        "                 worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "                 current_row +=1\n",
        "                 worksheet.update(f\"A{current_row}\", func_table)\n",
        "                 worksheet.format(f\"A{current_row}:C{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "                 current_row += len(func_table) + 1\n",
        "\n",
        "\n",
        "        # Proxy-Implementation Comparison Section\n",
        "        if comparison_results:\n",
        "             worksheet.update(f\"A{current_row}\", [[\"Proxy vs. Implementation Comparison\"]])\n",
        "             worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True, \"fontSize\": 12}, \"backgroundColor\": {\"red\": 0.9, \"green\": 1.0, \"blue\": 0.9}})\n",
        "             current_row += 1\n",
        "             comp_table = [[\"Contract\", \"Size (bytes)\"],\n",
        "                           [comparison_results.get(\"proxy_name\", \"Proxy\"), f\"{comparison_results.get('proxy_size', 0):,}\"],\n",
        "                           [comparison_results.get(\"implementation_name\", \"Impl\"), f\"{comparison_results.get('implementation_size', 0):,}\"]]\n",
        "             worksheet.update(f\"A{current_row}\", comp_table)\n",
        "             worksheet.format(f\"A{current_row}:B{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "             current_row += len(comp_table) + 1\n",
        "             # Add function comparison tables if needed...\n",
        "\n",
        "        # Multi-Contract Comparison Section\n",
        "        if multi_contract_comparison:\n",
        "             worksheet.update(f\"A{current_row}\", [[\"Multi-Contract Comparison\"]])\n",
        "             worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True, \"fontSize\": 12}, \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.9}})\n",
        "             current_row += 1\n",
        "             # Add size table...\n",
        "             # Add similarity table...\n",
        "             sim_table = [[\"Contract Pair\", \"Similarity (%)\", \"Shared Known Sigs\"]]\n",
        "             for item in multi_contract_comparison.get(\"similarity_data\", [])[:30]: # Limit rows\n",
        "                 sim_table.append([item.get(\"Contract Pair\"), f\"{item.get('Similarity (%)', 0):.1f}%\", item.get(\"Shared Known Signatures\")])\n",
        "             if len(multi_contract_comparison.get(\"similarity_data\", [])) > 30:\n",
        "                 sim_table.append([\"...\", \"...\", \"...\"])\n",
        "\n",
        "             worksheet.update(f\"A{current_row}\", [[\"Similarity (Known Signatures)\"]])\n",
        "             worksheet.format(f\"A{current_row}\", {\"textFormat\": {\"bold\": True}})\n",
        "             current_row += 1\n",
        "             worksheet.update(f\"A{current_row}\", sim_table)\n",
        "             worksheet.format(f\"A{current_row}:C{current_row}\", {\"textFormat\": {\"bold\": True}}) # Header bold\n",
        "             current_row += len(sim_table) + 1\n",
        "\n",
        "        # Auto-resize columns for readability (optional, might fail on complex sheets)\n",
        "        try: worksheet.columns_auto_resize(0, 5)\n",
        "        except: pass\n",
        "\n",
        "        # --- Finalize and Return Link ---\n",
        "        clear_output()\n",
        "        console.print(\"‚úì Successfully exported analysis to Google Sheets!\", style=\"spring_green3\")\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script> window.open(\"{spreadsheet_url}\", \"_blank\"); </script>\n",
        "        <div>Spreadsheet created: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a> (Opened in new tab)</div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        clear_output()\n",
        "        console.print(f\"‚ùå Error exporting to Google Sheets: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red; font-weight:bold;'>Error exporting to Google Sheets: {str(e)}</div>\")\n",
        "\n",
        "\n",
        "def download_analysis_json(analysis_results, comparison_results=None, multi_contract_comparison=None, filename=None):\n",
        "    \"\"\"Creates a JSON file containing the analysis results for download.\"\"\"\n",
        "    console.print(\"[cyan3]Preparing JSON export...\", style=\"info\")\n",
        "\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"bytecode_analysis_{timestamp}.json\"\n",
        "\n",
        "    export_data = {\n",
        "        \"analysis_metadata\": {\n",
        "             \"export_time\": datetime.now().isoformat(),\n",
        "             \"tool_version\": \"1.0\" # Example version\n",
        "        },\n",
        "        \"contract_analysis\": analysis_results,\n",
        "    }\n",
        "    if comparison_results: export_data[\"proxy_implementation_comparison\"] = comparison_results\n",
        "    if multi_contract_comparison: export_data[\"multi_contract_comparison\"] = multi_contract_comparison\n",
        "\n",
        "    try:\n",
        "        json_str = json.dumps(export_data, default=str, indent=2)\n",
        "        b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "        clear_output() # Clear the \"preparing\" message\n",
        "        console.print(f\"‚úì Successfully prepared JSON file: {filename}\", style=\"spring_green3\")\n",
        "\n",
        "        # Create HTML for direct download link/trigger\n",
        "        html = f'''\n",
        "        <a download=\"{filename}\" href=\"data:application/json;base64,{b64}\" style=\"text-decoration:none;\">\n",
        "            <button style=\"padding: 8px 12px; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer;\">\n",
        "                Download {filename}\n",
        "            </button>\n",
        "        </a>\n",
        "        <script>\n",
        "        // Optional: uncomment to auto-trigger download immediately\n",
        "        /*\n",
        "        (function() {{\n",
        "            const link = document.createElement('a');\n",
        "            link.href = \"data:application/json;base64,{b64}\";\n",
        "            link.download = \"{filename}\";\n",
        "            document.body.appendChild(link);\n",
        "            link.click();\n",
        "            document.body.removeChild(link);\n",
        "        }})();\n",
        "        */\n",
        "        </script>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "    except Exception as e:\n",
        "         clear_output()\n",
        "         console.print(f\"‚ùå Error creating JSON export: {str(e)}\", style=\"error\")\n",
        "         return HTML(f\"<div style='color:red; font-weight:bold;'>Error creating JSON: {str(e)}</div>\")\n",
        "\n",
        "\n",
        "# --- UI Setup and Tab Definitions ---\n",
        "\n",
        "# Global containers for results (cleared by analysis functions)\n",
        "analysis_results = {}\n",
        "comparison_data = None\n",
        "multi_comparison_data = None\n",
        "\n",
        "# Main Tab Interface\n",
        "analysis_tabs = widgets.Tab()\n",
        "\n",
        "# Apply Custom CSS for better UI (ensure this matches your notebook theme)\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        ".jupyter-widgets-output-area .jupyter-widgets .widget-tab > .p-TabBar-tabLabel {\n",
        "    font-weight: bold;\n",
        "}\n",
        ".jupyter-widgets-output-area .jupyter-widgets .widget-tab-contents {\n",
        "    border: 1px solid #ccc;\n",
        "    padding: 15px;\n",
        "}\n",
        ".jupyter-widgets-output-area .jupyter-widgets .jupyter-button {\n",
        "    color: white;\n",
        "}\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "def show_export_options(parent_output=None):\n",
        "    \"\"\"Displays export buttons (JSON, Google Sheets) using global result variables.\"\"\"\n",
        "    global analysis_results, comparison_data, multi_comparison_data\n",
        "\n",
        "    # Check if there are any results to export\n",
        "    has_analysis = isinstance(analysis_results, dict) and analysis_results\n",
        "    has_comparison = isinstance(comparison_data, dict) and comparison_data\n",
        "    has_multi = isinstance(multi_comparison_data, dict) and multi_comparison_data\n",
        "\n",
        "    if not has_analysis:\n",
        "        # Display message within the provided output widget or directly\n",
        "        message = \"[warning]No analysis results currently available to export.[/warning]\"\n",
        "        if parent_output:\n",
        "             with parent_output: console.print(message, style=\"warning\")\n",
        "        else: console.print(message, style=\"warning\")\n",
        "        return\n",
        "\n",
        "    # Create buttons and output area for export actions\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(description='Export as JSON', button_style='warning', icon='download', layout=widgets.Layout(width='auto')),\n",
        "        widgets.Button(description='Export to Google Sheets', button_style='info', icon='table', layout=widgets.Layout(width='auto'))\n",
        "    ])\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Define button click handlers\n",
        "    def export_json_handler(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            result_html = download_analysis_json(\n",
        "                analysis_results if has_analysis else {},\n",
        "                comparison_data if has_comparison else None,\n",
        "                multi_comparison_data if has_multi else None\n",
        "            )\n",
        "            display(result_html)\n",
        "\n",
        "    def export_sheets_handler(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            result_html = export_to_google_sheets(\n",
        "                analysis_results if has_analysis else {},\n",
        "                comparison_data if has_comparison else None,\n",
        "                multi_comparison_data if has_multi else None\n",
        "            )\n",
        "            display(result_html)\n",
        "\n",
        "    # Assign handlers\n",
        "    export_buttons.children[0].on_click(export_json_handler)\n",
        "    export_buttons.children[1].on_click(export_sheets_handler)\n",
        "\n",
        "    header_output = widgets.Output()\n",
        "    with header_output: # Capture prints into this widget\n",
        "      console.print(\"\\n\\n[bold]Export Analysis Results:[/bold]\", style=\"magenta3\")\n",
        "      console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "    # Combine into a VBox for display\n",
        "    export_widget = widgets.VBox([\n",
        "        header_output,\n",
        "        export_buttons,\n",
        "        export_output\n",
        "    ])\n",
        "\n",
        "    # Display within the parent output widget or directly\n",
        "    if parent_output:\n",
        "        with parent_output: display(export_widget)\n",
        "    else: display(export_widget)\n",
        "\n",
        "\n",
        "# --- Tab Content Generation Functions ---\n",
        "\n",
        "def analyze_pyusd_tab():\n",
        "    \"\"\"Creates the UI and logic for the PYUSD analysis tab.\"\"\"\n",
        "    pyusd_tab = widgets.VBox()\n",
        "    pyusd_output = widgets.Output()\n",
        "    analyze_button = widgets.Button(description='Re-Analyze PYUSD Contracts', button_style='primary', icon='refresh', layout=widgets.Layout(width='auto'))\n",
        "\n",
        "    def analyze_pyusd_action(b):\n",
        "        # Access and reset global result containers\n",
        "        global analysis_results, comparison_data, multi_comparison_data\n",
        "        analysis_results = {}\n",
        "        comparison_data = None\n",
        "        multi_comparison_data = None\n",
        "\n",
        "        with pyusd_output:\n",
        "            clear_output()\n",
        "            display(HTML(\"<h4 style='color: #00d7af;'>Analyzing Official PYUSD Contracts on Mainnet</h4>\"))\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            # Define contracts to analyze (ensure these globals exist)\n",
        "            contracts_to_analyze = {}\n",
        "            if 'PYUSD_PROXY' in globals(): contracts_to_analyze[\"PYUSD Proxy\"] = PYUSD_PROXY\n",
        "            if 'PYUSD_IMPLEMENTATION' in globals(): contracts_to_analyze[\"PYUSD Implementation\"] = PYUSD_IMPLEMENTATION\n",
        "            if 'SUPPLY_CONTROL_PROXY' in globals(): contracts_to_analyze[\"Supply Controller Proxy\"] = SUPPLY_CONTROL_PROXY\n",
        "            # Add Supply Controller Impl if needed for specific comparisons\n",
        "\n",
        "            codes = {}\n",
        "            analyses = {}\n",
        "\n",
        "            # Fetch and analyze each contract\n",
        "            for name, address in contracts_to_analyze.items():\n",
        "                if not address:\n",
        "                    console.print(f\"[warning]Skipping {name}: Address not defined.\", style=\"warning\")\n",
        "                    continue\n",
        "                code = get_contract_code(address, network='mainnet')\n",
        "                if code:\n",
        "                    codes[name] = code\n",
        "                    contract_display_name = f\"{name} ({shorten_address(address)})\"\n",
        "                    analysis = analyze_bytecode(code, contract_display_name)\n",
        "                    if analysis:\n",
        "                        analyses[name] = analysis\n",
        "                        analysis_results[contract_display_name] = analysis # Use display name as key\n",
        "\n",
        "            # Perform Proxy-Implementation comparison if both analyzed\n",
        "            proxy_name = \"PYUSD Proxy\"\n",
        "            impl_name = \"PYUSD Implementation\"\n",
        "            if proxy_name in analyses and impl_name in analyses:\n",
        "                comparison_data = compare_proxy_implementation(\n",
        "                    codes[proxy_name], codes[impl_name],\n",
        "                    analyses[proxy_name][\"contract_name\"], analyses[impl_name][\"contract_name\"]\n",
        "                )\n",
        "\n",
        "            # Generate architecture/relationship diagrams (using Graphviz)\n",
        "            # Ensure Graphviz is installed and on the system PATH\n",
        "            try:\n",
        "                # Proxy Architecture Diagram\n",
        "                if proxy_name in analyses and impl_name in analyses and analyses[proxy_name][\"proxy_functionality\"][\"is_proxy\"]:\n",
        "                    display(HTML(\"<h4>PYUSD Proxy Architecture Diagram</h4>\"))\n",
        "                    arch_graph = Digraph(comment=\"PYUSD Proxy Architecture\", format='png')\n",
        "                    arch_graph.attr(rankdir='LR', bgcolor='transparent', node_sep='0.5', rank_sep='1')\n",
        "                    arch_graph.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "                    arch_graph.node('user', 'User / DApp', fillcolor='lightblue')\n",
        "                    arch_graph.node('proxy', analyses[proxy_name][\"contract_name\"], fillcolor='palegreen')\n",
        "                    arch_graph.node('impl', analyses[impl_name][\"contract_name\"], fillcolor='lightcoral')\n",
        "                    # Optionally add Admin Proxy node if known\n",
        "                    # arch_graph.node('admin', 'Proxy Admin\\n(Upgrade Control)', fillcolor='lightyellow')\n",
        "                    arch_graph.edge('user', 'proxy', label='Calls')\n",
        "                    arch_graph.edge('proxy', 'impl', label='delegatecall')\n",
        "                    # arch_graph.edge('admin', 'proxy', label='Upgrades')\n",
        "                    display(arch_graph)\n",
        "\n",
        "                # Add spacing between diagrams\n",
        "                display(HTML(\"<div style='height: 20px;'></div>\"))\n",
        "\n",
        "                # Contract Relationship Diagram (PYUSD + Supply Controller)\n",
        "                supply_proxy_name = \"Supply Controller Proxy\"\n",
        "                if proxy_name in analyses and supply_proxy_name in analyses:\n",
        "\n",
        "                     console.print(\"\\n\\n[bold]PYUSD Contract Relationships Diagram[/bold]\", style=\"magenta3\")\n",
        "                     console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "                     rel_graph = Digraph(comment=\"PYUSD Contract Relationships\", format='png')\n",
        "                     rel_graph.attr(bgcolor='transparent', node_sep='0.5', rank_sep='0.7')\n",
        "                     rel_graph.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "                     pyusd_node_name = analyses[proxy_name][\"contract_name\"]\n",
        "                     supply_node_name = analyses[supply_proxy_name][\"contract_name\"]\n",
        "                     rel_graph.node('pyusd', pyusd_node_name, fillcolor='palegreen')\n",
        "                     if impl_name in analyses:\n",
        "                         rel_graph.node('pyusd_impl', analyses[impl_name][\"contract_name\"], fillcolor='lightcyan')\n",
        "                         rel_graph.edge('pyusd', 'pyusd_impl', label='delegates to')\n",
        "                     rel_graph.node('supply', supply_node_name, fillcolor='lightsalmon')\n",
        "                     # Add Supply Impl if analyzed\n",
        "                     # rel_graph.node('supply_impl', 'Supply Impl\\n(...)', fillcolor='lightpink')\n",
        "                     # rel_graph.edge('supply', 'supply_impl', label='delegates to')\n",
        "                     rel_graph.edge('supply', 'pyusd', label='controls supply (mint/burn)')\n",
        "                     display(rel_graph)\n",
        "\n",
        "            except Exception as viz_err:\n",
        "                 console.print(f\"[warning]Could not render architecture/relationship diagram. Ensure Graphviz is installed and in PATH. Error: {viz_err}\", style=\"warning\")\n",
        "\n",
        "            # Show export options if analysis produced results\n",
        "            if analysis_results:\n",
        "                show_export_options(pyusd_output)\n",
        "            else:\n",
        "                console.print(\"\\n[error]No analysis results were generated for PYUSD contracts. Check network connection and contract addresses.\", style=\"error\")\n",
        "\n",
        "    analyze_button.on_click(analyze_pyusd_action)\n",
        "\n",
        "    # Layout for the tab\n",
        "    pyusd_tab.children = [\n",
        "        widgets.HTML(\"<h3>Analyze Official PYUSD Contracts</h3>\"),\n",
        "        widgets.HTML(\"<p>Analyzes the main PYUSD token proxy, implementation, and supply controller contracts on Ethereum Mainnet. Fetches bytecode, performs analysis, and visualizes relationships.</p>\"),\n",
        "        analyze_button,\n",
        "        pyusd_output\n",
        "    ]\n",
        "\n",
        "    # Automatically run the analysis when the tab is first created\n",
        "    analyze_pyusd_action(None)\n",
        "\n",
        "    return pyusd_tab\n",
        "\n",
        "\n",
        "def analyze_tx_tab():\n",
        "    \"\"\"Creates the UI and logic for the Transaction-based analysis tab.\"\"\"\n",
        "    tx_tab = widgets.VBox()\n",
        "    tx_input = widgets.Text(placeholder='Enter transaction hash (e.g., 0xabc...)', description='Tx Hash:', layout=widgets.Layout(width='90%'))\n",
        "    network_selector = widgets.Dropdown(options=['mainnet', 'sepolia', 'holesky'], value='mainnet', description='Network:', layout=widgets.Layout(width='auto'))\n",
        "    analyze_button = widgets.Button(description='Analyze Contracts in Tx', button_style='primary', icon='search', layout=widgets.Layout(width='auto'))\n",
        "    tx_output = widgets.Output()\n",
        "\n",
        "    def analyze_tx_action(b, tx_hash_override=None): # Allow passing hash for auto-run\n",
        "        # Access and reset global result containers\n",
        "        global analysis_results, multi_comparison_data, comparison_data\n",
        "        analysis_results = {}\n",
        "        multi_comparison_data = None\n",
        "        comparison_data = None # Reset single comparison too\n",
        "\n",
        "        with tx_output:\n",
        "            clear_output()\n",
        "            console.print(\"\\n\\n[bold]Analyzing Transaction for Contracts[/bold]\", style=\"cyan3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "\n",
        "            # Determine transaction hash to use\n",
        "            current_tx_hash = tx_hash_override if tx_hash_override else tx_input.value.strip()\n",
        "\n",
        "            # Validate Tx Hash format\n",
        "            if not current_tx_hash or not re.match(r'^0x[0-9a-fA-F]{64}$', current_tx_hash):\n",
        "                console.print(\"[error]Invalid input: Please enter a valid 64-character transaction hash starting with 0x.\", style=\"error\")\n",
        "                return\n",
        "\n",
        "            # Update input field if hash was passed programmatically\n",
        "            if tx_hash_override: tx_input.value = tx_hash_override\n",
        "\n",
        "            selected_network = network_selector.value\n",
        "            # Fetch contracts involved in the transaction\n",
        "            contracts_in_tx = get_contracts_from_tx(current_tx_hash, selected_network)\n",
        "\n",
        "            if not contracts_in_tx:\n",
        "                console.print(f\"[warning]No contracts with bytecode found in transaction {shorten_address(current_tx_hash)} on {selected_network}, or an error occurred during lookup.\", style=\"warning\")\n",
        "                return # Exit if no contracts to analyze\n",
        "\n",
        "            # Prepare lists for analysis and comparison\n",
        "            contract_codes_list = []\n",
        "            contract_names_list = []\n",
        "            analyzed_contract_count = 0\n",
        "\n",
        "            console.print(f\"\\n\\n[bold cyan3]Analyzing {len(contracts_in_tx)} Contract(s) Found in Transaction[/bold cyan3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "            # Analyze each contract found\n",
        "            for address, name in contracts_in_tx.items():\n",
        "                code = get_contract_code(address, network=selected_network)\n",
        "                if code:\n",
        "                    analysis = analyze_bytecode(code, name) # Name includes address\n",
        "                    if analysis:\n",
        "                        analysis_results[analysis[\"contract_name\"]] = analysis\n",
        "                        contract_codes_list.append(code)\n",
        "                        contract_names_list.append(analysis[\"contract_name\"])\n",
        "                        analyzed_contract_count += 1\n",
        "\n",
        "            # Perform comparison if multiple contracts were successfully analyzed\n",
        "            if analyzed_contract_count > 1:\n",
        "                 multi_comparison_data = compare_multiple_contracts(contract_codes_list, contract_names_list)\n",
        "            elif analyzed_contract_count == 1:\n",
        "                 console.print(\"[info]Only one contract was successfully analyzed from the transaction. Skipping comparison.\", style=\"info\")\n",
        "            else:\n",
        "                 console.print(\"[warning]Could not successfully analyze bytecode for any contracts found in the transaction.\", style=\"warning\")\n",
        "\n",
        "            # Display export options if results were generated\n",
        "            if analysis_results:\n",
        "                show_export_options(tx_output)\n",
        "\n",
        "    analyze_button.on_click(analyze_tx_action)\n",
        "\n",
        "    # Layout for the tab\n",
        "    tx_tab.children = [\n",
        "        widgets.HTML(\"<h3>Analyze Contracts from Transaction</h3>\"),\n",
        "        widgets.HTML(\"<p>Extracts contract addresses involved in a transaction (target, event emitters, created contracts), fetches their bytecode, analyzes them individually, and performs a multi-contract comparison if applicable.</p>\"),\n",
        "        widgets.HBox([tx_input, network_selector, analyze_button]),\n",
        "        tx_output\n",
        "    ]\n",
        "\n",
        "    console.print(\"\\n\\n[bold]üìÑ Advanced Bytecode Analysis via eth_getCode[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Automatically analyze TARGET_TX_HASH if defined globally and valid\n",
        "    if 'TARGET_TX_HASH' in globals() and TARGET_TX_HASH and re.match(r'^0x[0-9a-fA-F]{64}$', TARGET_TX_HASH):\n",
        "        console.print(f\"\\n\\n[info]‚û°Ô∏èAuto-analyzing Target transaction hash: {TARGET_TX_HASH}\", style=\"info\")\n",
        "        analyze_tx_action(None, TARGET_TX_HASH)\n",
        "\n",
        "    return tx_tab\n",
        "\n",
        "\n",
        "def analyze_custom_tab():\n",
        "    \"\"\"Creates the UI and logic for the Custom Contract analysis tab.\"\"\"\n",
        "    custom_tab = widgets.VBox()\n",
        "\n",
        "    # Example stablecoin addresses for comparison\n",
        "    example_addresses = [\n",
        "        \"0x6c3ea9036406852006290770BEdFcAbA0e23A0e8\",  # PYUSD Proxy\n",
        "        \"0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48\",  # USDC Proxy\n",
        "        \"0xdac17f958d2ee523a2206206994597c13d831ec7\"   # USDT\n",
        "    ]\n",
        "    example_names = [\"PYUSD\", \"USDC\", \"USDT\"]\n",
        "\n",
        "    # Input fields for addresses and names\n",
        "    address_inputs = [widgets.Text(placeholder=f'e.g., {example_addresses[i]}',\n",
        "                                  description=f'Addr {i+1}:',\n",
        "                                  layout=widgets.Layout(width='60%')) for i in range(3)]\n",
        "    name_inputs = [widgets.Text(description=f'Name {i+1}:',\n",
        "                               layout=widgets.Layout(width='30%')) for i in range(3)]\n",
        "\n",
        "    # Set default names\n",
        "    for i in range(3):\n",
        "        name_inputs[i].value = f\"Contract {chr(65+i)}\"\n",
        "\n",
        "    # Network selector and buttons\n",
        "    network_selector = widgets.Dropdown(options=['mainnet', 'sepolia', 'holesky'], value='mainnet', description='Network:', layout=widgets.Layout(width='auto'))\n",
        "    analyze_button = widgets.Button(description='Analyze Custom Contracts', button_style='primary', icon='cogs', layout=widgets.Layout(width='auto'))\n",
        "    example_button = widgets.Button(description='Load Stablecoin Examples', button_style='info', icon='info', layout=widgets.Layout(width='auto'))\n",
        "\n",
        "    custom_output = widgets.Output()\n",
        "\n",
        "    def load_examples(b):\n",
        "        \"\"\"Loads example stablecoin addresses into the input fields.\"\"\"\n",
        "        for i in range(3):\n",
        "            address_inputs[i].value = example_addresses[i]\n",
        "            name_inputs[i].value = example_names[i]\n",
        "\n",
        "    example_button.on_click(load_examples)\n",
        "\n",
        "    def analyze_custom_action(b):\n",
        "        # Access and reset global result containers\n",
        "        global analysis_results, comparison_data, multi_comparison_data\n",
        "        analysis_results = {}\n",
        "        comparison_data = None\n",
        "        multi_comparison_data = None\n",
        "\n",
        "        with custom_output:\n",
        "            clear_output()\n",
        "            console.print(\"\\n\\n[bold]‚öôÔ∏è Analyzing Custom Contracts[/bold]\", style=\"cyan3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "            # Collect valid addresses and corresponding names\n",
        "            addresses_to_analyze = []\n",
        "            names_to_analyze = []\n",
        "            for i in range(len(address_inputs)):\n",
        "                addr = address_inputs[i].value.strip()\n",
        "                if addr: # Only process if address field is not empty\n",
        "                    if re.match(r'^0x[0-9a-fA-F]{40}$', addr):\n",
        "                        addresses_to_analyze.append(addr)\n",
        "                        # Use provided name or default\n",
        "                        names_to_analyze.append(name_inputs[i].value.strip() or f\"Contract {chr(65+i)}\")\n",
        "                    else:\n",
        "                        console.print(f\"[warning]Skipping invalid address format entered for Contract {i+1}: '{addr}'\", style=\"warning\")\n",
        "\n",
        "            if not addresses_to_analyze:\n",
        "                console.print(\"[error]No valid contract addresses entered. Please enter at least one valid Ethereum address.\", style=\"error\")\n",
        "                return\n",
        "\n",
        "            selected_network = network_selector.value\n",
        "            contract_codes_list = []\n",
        "            contract_names_list = []\n",
        "            analyzed_contract_count = 0\n",
        "\n",
        "            # Analyze each valid contract\n",
        "            for i, address in enumerate(addresses_to_analyze):\n",
        "                contract_display_name = f\"{names_to_analyze[i]} ({shorten_address(address)})\"\n",
        "                code = get_contract_code(address, network=selected_network)\n",
        "                if code:\n",
        "                    analysis = analyze_bytecode(code, contract_display_name)\n",
        "                    if analysis:\n",
        "                        analysis_results[analysis[\"contract_name\"]] = analysis\n",
        "                        contract_codes_list.append(code)\n",
        "                        contract_names_list.append(analysis[\"contract_name\"])\n",
        "                        analyzed_contract_count += 1\n",
        "\n",
        "            # Perform comparisons based on the number of successfully analyzed contracts\n",
        "            if analyzed_contract_count == 2:\n",
        "                 # Assume the two might be a proxy/implementation pair\n",
        "                 comparison_data = compare_proxy_implementation(\n",
        "                     contract_codes_list[0], contract_codes_list[1],\n",
        "                     contract_names_list[0], contract_names_list[1]\n",
        "                 )\n",
        "            elif analyzed_contract_count > 2:\n",
        "                 # Perform multi-contract comparison\n",
        "                 multi_comparison_data = compare_multiple_contracts(contract_codes_list, contract_names_list)\n",
        "            elif analyzed_contract_count == 1:\n",
        "                 console.print(\"[info]Only one contract was analyzed successfully. Skipping comparison.\", style=\"info\")\n",
        "            else: # analyzed_contract_count == 0\n",
        "                 console.print(\"[warning]Could not successfully analyze bytecode for any of the provided contracts.\", style=\"warning\")\n",
        "\n",
        "            # Show export options if any results were generated\n",
        "            if analysis_results:\n",
        "                show_export_options(custom_output)\n",
        "\n",
        "    analyze_button.on_click(analyze_custom_action)\n",
        "\n",
        "    # Warning about addresses\n",
        "    address_note = widgets.HTML(\"\"\"\n",
        "    <div style=\"margin-top: 15px; padding: 10px; border: 1px solid #ddd; background-color: #00005f; font-size: 0.9em; color:white;\">\n",
        "        <strong>Important:</strong> Enter only smart contract addresses, not user wallet addresses (EOAs).\n",
        "        User wallet addresses will show \"No bytecode found\" error. Try the example stablecoin addresses for a demonstration.\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    # Layout for the tab using HBox for alignment\n",
        "    input_rows = [widgets.HBox([address_inputs[i], name_inputs[i]]) for i in range(3)]\n",
        "    custom_tab.children = [\n",
        "        widgets.HTML(\"<h3>Analyze Custom Contracts by Address</h3>\"),\n",
        "        widgets.HTML(\"<p>Enter up to three contract addresses and optional custom names. The tool will fetch bytecode, analyze each contract, and perform comparisons (Proxy vs. Impl for two, Multi-Contract for three).</p>\"),\n",
        "        address_note,\n",
        "        widgets.HBox([example_button], layout=widgets.Layout(margin='10px 0')),\n",
        "        *input_rows, # Unpack the list of HBox widgets\n",
        "        widgets.HBox([network_selector, analyze_button]),\n",
        "        custom_output\n",
        "    ]\n",
        "\n",
        "    return custom_tab\n",
        "\n",
        "\n",
        "# --- Main Execution: Assemble and Display Tabs ---\n",
        "\n",
        "# Create the tab instances\n",
        "tab1 = analyze_pyusd_tab()\n",
        "tab2 = analyze_tx_tab()\n",
        "tab3 = analyze_custom_tab()\n",
        "\n",
        "# Assign tabs to the Tab widget\n",
        "analysis_tabs.children = [tab1, tab2, tab3]\n",
        "\n",
        "# Set descriptive titles for each tab\n",
        "analysis_tabs.set_title(0, 'PYUSD Analysis')\n",
        "analysis_tabs.set_title(1, 'From Transaction')\n",
        "analysis_tabs.set_title(2, 'Custom Contracts')\n",
        "\n",
        "# Display the main title and the tab interface\n",
        "console.print(\"\\n\\nSelect an analysis mode below to fetch and examine contract bytecode:\\n\\n\")\n",
        "display(analysis_tabs)"
      ],
      "metadata": {
        "id": "IikOrrEzIvKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 üß± `trace_block`: Analyzing All Transactions in a Block\n",
        "---\n",
        "\n",
        "This section utilizes the `trace_block` RPC method to retrieve summary traces for **all transactions** executed within a single target block (`TARGET_BLOCK_IDENTIFIER`). This provides a high-level overview of the block's activity, allowing us to understand the context surrounding specific PYUSD transactions and identify broader patterns.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Method:** `trace_block`\n",
        "> *   **Multiplier:** `50x` (Available on Mainnet via GCP)\n",
        "> *   **GCP Advantage:** Tracing an entire block is computationally demanding. GCP provides this capability on Mainnet, often restricted or unavailable elsewhere, allowing for comprehensive block-level analysis without needing to trace each transaction individually first.\n",
        "> *   **PYUSD Insight:** `trace_block` helps us:\n",
        ">     *   Quickly identify **all transactions interacting with PYUSD** within a specific block.\n",
        ">     *   Analyze the **gas consumption patterns** across different transaction types (PYUSD transfers, DeFi interactions, contract creations) within the block.\n",
        ">     *   Understand the immediate **on-chain environment** surrounding significant PYUSD events.\n",
        ">     *   Detect **potential indicators** of MEV activity or unusual transaction sequences involving PYUSD by examining the full block context (transaction order, gas usage, specific calls).\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Block Trace:** Calls `trace_block` using the target block identifier.\n",
        "2.  **Process Traces:** Iterates through the list of transaction traces returned for the block.\n",
        "3.  **Categorize & Analyze (within `analyze_block_trace`):**\n",
        "    *   Each transaction trace is categorized (e.g., ETH Transfer, Contract Call, PYUSD Transfer, PYUSD Approval) using `categorize_transaction`.\n",
        "    *   PYUSD-specific details (function calls, parameters, events) are extracted using `extract_pyusd_details`.\n",
        "    *   Gas usage is aggregated by transaction type (`analyze_gas_distribution`).\n",
        "    *   PYUSD token flow within the block is analyzed (`analyze_pyusd_flow`).\n",
        "4.  **Visualize & Summarize:**\n",
        "    *   **Block Summary Panel:** Displays key statistics (total transactions, gas, errors, PYUSD interactions) using `rich`.\n",
        "    *   **Gas Analysis:** Shows tables (`rich`) and plots (`plotly`) of gas usage distribution by transaction type.\n",
        "    *   **PYUSD Activity:** Tables (`rich`) detailing PYUSD interactions, function calls, and token flow graphs (`graphviz`).\n",
        "    *   **Transaction Table:** An interactive table (`pandas`, `ipywidgets`) summarizing all transactions in the block, with options to filter for PYUSD interactions.\n",
        "    *   **Export Options:** Download block transaction summaries.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   **PYUSD Transaction Density:** How many transactions in the block interact with PYUSD?\n",
        "*   **Gas Usage Patterns:** Which types of transactions consume the most gas in this block? Are PYUSD interactions relatively efficient or expensive compared to others?\n",
        "*   **PYUSD Flow:** Observe the primary PYUSD movements within the block using the flow diagram.\n",
        "*   **Context:** Examine the transactions immediately before and after significant PYUSD events **using the full transaction table**."
      ],
      "metadata": {
        "id": "-LNSmB5aUaoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üß± Block Tracing and Analysis using trace_block (Google Cost-Efficient API)\n",
        "# =============================================================================================\n",
        "# This cell utilizes the trace_block RPC method to analyze all transactions within a specific block.\n",
        "# Functionality includes:\n",
        "# - Fetching summary traces for every transaction in the target block via trace_block.\n",
        "# - Categorizing each transaction (e.g., ETH Transfer, Contract Call, PYUSD Transfer, PYUSD Approval).\n",
        "# - Extracting detailed information for PYUSD-related transactions (function calls, parameters, amounts, events).\n",
        "# - Analyzing and visualizing gas consumption patterns across different transaction types within the block.\n",
        "# - Analyzing and visualizing the flow of PYUSD tokens (transfers, approvals) within the block context using Graphviz.\n",
        "# - Displaying comprehensive summary statistics and detailed tables using rich console formatting.\n",
        "# - Providing an interactive table of all block transactions with filtering for PYUSD interactions.\n",
        "# - Offering direct export options for the analysis results to CSV, JSON, and Google Sheets.\n",
        "# - Leveraging GCP's premium RPC capabilities for the compute-intensive trace_block method on Mainnet.\n",
        "\n",
        "def categorize_transaction(trace_item):\n",
        "    \"\"\"Categorizes a transaction trace based on its characteristics.\"\"\"\n",
        "    action = trace_item.get('action', {})\n",
        "    to_addr = action.get('to', action.get('address', ''))\n",
        "    input_data = action.get('input', '0x')\n",
        "\n",
        "    # Initialize category data\n",
        "    category = {\n",
        "        'type': 'other',\n",
        "        'subtype': 'unknown',\n",
        "        'description': 'Other transaction',\n",
        "        'is_pyusd': False,\n",
        "        'function_name': None,\n",
        "        'function_category': None\n",
        "    }\n",
        "\n",
        "    # Check contract creation\n",
        "    if action.get('init') and not action.get('to'):\n",
        "        category.update({\n",
        "            'type': 'contract_creation',\n",
        "            'subtype': 'deployment',\n",
        "            'description': 'Contract Deployment'\n",
        "        })\n",
        "        return category\n",
        "\n",
        "    # Check if address is any of the PYUSD contracts\n",
        "    is_pyusd_contract = False\n",
        "    if to_addr:\n",
        "        to_addr_lower = to_addr.lower()\n",
        "        for contract_addr in PYUSD_CONTRACTS:\n",
        "            if to_addr_lower == contract_addr:\n",
        "                is_pyusd_contract = True\n",
        "                category.update({\n",
        "                    'type': 'token',\n",
        "                    'subtype': 'pyusd',\n",
        "                    'description': f'PYUSD: {PYUSD_CONTRACTS[contract_addr]}',\n",
        "                    'is_pyusd': True,\n",
        "                    'contract_name': PYUSD_CONTRACTS[contract_addr]\n",
        "                })\n",
        "                break\n",
        "\n",
        "    # If it's a PYUSD contract, try to decode function\n",
        "    if is_pyusd_contract and input_data and len(input_data) >= 10:\n",
        "        function_name = decode_pyusd_function(input_data)\n",
        "        function_category = get_function_category(input_data)\n",
        "        category.update({\n",
        "            'function_name': function_name,\n",
        "            'function_category': function_category,\n",
        "            'description': f'PYUSD: {function_name}'\n",
        "        })\n",
        "\n",
        "        # Further refine subtype based on function category\n",
        "        if function_category == 'token_movement':\n",
        "            category['subtype'] = 'transfer'\n",
        "        elif function_category == 'allowance':\n",
        "            category['subtype'] = 'approval'\n",
        "        elif function_category == 'supply_change':\n",
        "            category['subtype'] = 'supply_change'\n",
        "        elif function_category == 'control':\n",
        "            category['subtype'] = 'control'\n",
        "\n",
        "    # Check for ETH transfers (no input data)\n",
        "    elif input_data == '0x' or len(input_data) <= 2:\n",
        "        value = int(action.get('value', '0x0'), 16)\n",
        "        if value > 0:\n",
        "            category.update({\n",
        "                'type': 'eth_transfer',\n",
        "                'subtype': 'transfer',\n",
        "                'description': 'ETH Transfer'\n",
        "            })\n",
        "\n",
        "    # Other contract interactions\n",
        "    elif to_addr and len(input_data) >= 10:\n",
        "        # This is a contract interaction, but not with PYUSD\n",
        "        category.update({\n",
        "            'type': 'contract_interaction',\n",
        "            'subtype': 'call',\n",
        "            'description': 'Contract Interaction',\n",
        "            'function_selector': input_data[:10]\n",
        "        })\n",
        "\n",
        "    return category\n",
        "\n",
        "def extract_pyusd_details(trace_item):\n",
        "    \"\"\"Extracts PYUSD-specific details from a trace item if present.\"\"\"\n",
        "    action = trace_item.get('action', {})\n",
        "    result = trace_item.get('result', {})\n",
        "    input_data = action.get('input', '0x')\n",
        "    to_addr = action.get('to', '')\n",
        "\n",
        "    details = {\n",
        "        'is_pyusd_tx': False,\n",
        "        'function': None,\n",
        "        'function_category': None,\n",
        "        'params': {},\n",
        "        'events': [],\n",
        "        'amount': None,\n",
        "        'from_addr': None,\n",
        "        'to_addr': None,\n",
        "        'decoded': {}\n",
        "    }\n",
        "\n",
        "    # Check if this is a PYUSD contract\n",
        "    is_pyusd_contract = False\n",
        "    if to_addr:\n",
        "        to_addr_lower = to_addr.lower()\n",
        "        for contract_addr in PYUSD_CONTRACTS:\n",
        "            if to_addr_lower == contract_addr:\n",
        "                is_pyusd_contract = True\n",
        "                details['contract_name'] = PYUSD_CONTRACTS[contract_addr]\n",
        "                break\n",
        "\n",
        "    if not is_pyusd_contract:\n",
        "        return details\n",
        "\n",
        "    # It's a PYUSD transaction\n",
        "    details['is_pyusd_tx'] = True\n",
        "\n",
        "    # Try to decode function call\n",
        "    if len(input_data) >= 10:\n",
        "        method_sig = input_data[:10]\n",
        "        details['function'] = decode_pyusd_function(input_data)\n",
        "        details['function_category'] = get_function_category(input_data)\n",
        "\n",
        "        # Attempt basic parameter decoding for common functions\n",
        "        if method_sig == '0xa9059cbb':  # transfer(address,uint256)\n",
        "            try:\n",
        "                to_address_hex = '0x' + input_data[10:74].lstrip('0')\n",
        "                amount_hex = '0x' + input_data[74:138].lstrip('0')\n",
        "                details['params']['to'] = Web3.to_checksum_address(to_address_hex)\n",
        "                amount_raw = int(amount_hex, 16)\n",
        "                details['amount'] = amount_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                details['to_addr'] = details['params']['to']\n",
        "                details['from_addr'] = action.get('from')\n",
        "\n",
        "                details['decoded'] = {\n",
        "                    'operation': 'transfer',\n",
        "                    'from': action.get('from'),\n",
        "                    'to': details['params']['to'],\n",
        "                    'amount': f\"{details['amount']} PYUSD\"\n",
        "                }\n",
        "            except Exception as e:\n",
        "                details['decode_error'] = str(e)\n",
        "\n",
        "        elif method_sig == '0x095ea7b3':  # approve(address,uint256)\n",
        "            try:\n",
        "                spender_hex = '0x' + input_data[10:74].lstrip('0')\n",
        "                amount_hex = '0x' + input_data[74:138].lstrip('0')\n",
        "                details['params']['spender'] = Web3.to_checksum_address(spender_hex)\n",
        "                amount_raw = int(amount_hex, 16)\n",
        "                details['amount'] = amount_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                details['decoded'] = {\n",
        "                    'operation': 'approve',\n",
        "                    'owner': action.get('from'),\n",
        "                    'spender': details['params']['spender'],\n",
        "                    'amount': f\"{details['amount']} PYUSD\"\n",
        "                }\n",
        "            except Exception as e:\n",
        "                details['decode_error'] = str(e)\n",
        "\n",
        "    # Extract any logs (events) from the result\n",
        "    if 'logs' in result and isinstance(result['logs'], list):\n",
        "        for log in result['logs']:\n",
        "            if log.get('address', '').lower() == PYUSD_ADDRESS_LOWER_ETH and log.get('topics'):\n",
        "                topic0 = log['topics'][0]\n",
        "\n",
        "                if topic0 in PYUSD_EVENTS:\n",
        "                    event_data = log.get('data', '0x')\n",
        "                    decoded_event = decode_pyusd_event(topic0, log['topics'], event_data)\n",
        "                    details['events'].append(decoded_event)\n",
        "\n",
        "                    # For Transfer events, extract additional information\n",
        "                    if topic0 == TRANSFER_EVENT_TOPIC and 'decoded' in decoded_event:\n",
        "                        event_from = decoded_event['decoded'].get('from')\n",
        "                        event_to = decoded_event['decoded'].get('to')\n",
        "                        event_value = decoded_event['decoded'].get('value')\n",
        "\n",
        "                        if not details['amount'] and event_value is not None:\n",
        "                            details['amount'] = event_value / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "                        if not details['from_addr'] and event_from:\n",
        "                            details['from_addr'] = event_from\n",
        "                        if not details['to_addr'] and event_to:\n",
        "                            details['to_addr'] = event_to\n",
        "\n",
        "    return details\n",
        "\n",
        "def analyze_gas_distribution(traces_with_categories):\n",
        "    \"\"\"Analyzes gas distribution across different transaction types.\"\"\"\n",
        "    gas_by_category = {}\n",
        "    gas_by_function = {}\n",
        "    pyusd_vs_other = {\n",
        "        'pyusd': {'count': 0, 'gas': 0},\n",
        "        'other': {'count': 0, 'gas': 0}\n",
        "    }\n",
        "\n",
        "    for trace in traces_with_categories:\n",
        "        category = trace.get('category', {})\n",
        "        gas_used = trace.get('gas_used', 0)\n",
        "\n",
        "        # By main category\n",
        "        cat_type = category.get('type', 'other')\n",
        "        if cat_type not in gas_by_category:\n",
        "            gas_by_category[cat_type] = {'count': 0, 'gas': 0}\n",
        "        gas_by_category[cat_type]['count'] += 1\n",
        "        gas_by_category[cat_type]['gas'] += gas_used\n",
        "\n",
        "        # PYUSD vs other\n",
        "        if category.get('is_pyusd', False):\n",
        "            pyusd_vs_other['pyusd']['count'] += 1\n",
        "            pyusd_vs_other['pyusd']['gas'] += gas_used\n",
        "\n",
        "            # By PYUSD function\n",
        "            function_name = category.get('function_name', 'unknown')\n",
        "            if function_name not in gas_by_function:\n",
        "                gas_by_function[function_name] = {'count': 0, 'gas': 0}\n",
        "            gas_by_function[function_name]['count'] += 1\n",
        "            gas_by_function[function_name]['gas'] += gas_used\n",
        "        else:\n",
        "            pyusd_vs_other['other']['count'] += 1\n",
        "            pyusd_vs_other['other']['gas'] += gas_used\n",
        "\n",
        "    return {\n",
        "        'by_category': gas_by_category,\n",
        "        'by_function': gas_by_function,\n",
        "        'pyusd_vs_other': pyusd_vs_other\n",
        "    }\n",
        "\n",
        "def visualize_gas_distribution(gas_analysis, title=\"Gas Usage Distribution in Block\"):\n",
        "    \"\"\"Creates visualization for gas distribution across transaction types.\"\"\"\n",
        "    # Prepare data for visualization\n",
        "    categories = []\n",
        "    gas_values = []\n",
        "    counts = []\n",
        "\n",
        "    for category, data in gas_analysis['by_category'].items():\n",
        "        if data['gas'] > 0:  # Only include categories with gas usage\n",
        "            categories.append(category)\n",
        "            gas_values.append(data['gas'])\n",
        "            counts.append(data['count'])\n",
        "\n",
        "    # Create figure with subplots in a container div\n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        subplot_titles=(\"\", \"\"),  # Empty subplot titles, we'll add custom ones\n",
        "        specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}]],\n",
        "        horizontal_spacing=0.05  # Reduce spacing between charts\n",
        "    )\n",
        "\n",
        "    # Add gas usage pie chart\n",
        "    fig.add_trace(\n",
        "        go.Pie(\n",
        "            labels=categories,\n",
        "            values=gas_values,\n",
        "            textinfo='percent+label',\n",
        "            hole=.3,\n",
        "            marker_colors=px.colors.qualitative.Pastel\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Add transaction count pie chart\n",
        "    fig.add_trace(\n",
        "        go.Pie(\n",
        "            labels=categories,\n",
        "            values=counts,\n",
        "            textinfo='percent+label',\n",
        "            hole=.3,\n",
        "            marker_colors=px.colors.qualitative.Pastel\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # Create a container-like layout with proper spacing\n",
        "    fig.update_layout(\n",
        "        # Main title with padding\n",
        "        title={\n",
        "            'text': f\"<b>{title}</b>\",  # Bold with HTML\n",
        "            'y': 0.98,                  # Position higher\n",
        "            'x': 0.5,                   # Center align\n",
        "            'xanchor': 'center',\n",
        "            'yanchor': 'top',\n",
        "            'font': {\n",
        "                'size': 24,             # Larger font\n",
        "                'family': 'Arial, sans-serif'\n",
        "            },\n",
        "            'pad': {'b': 30}            # Add bottom padding to title\n",
        "        },\n",
        "\n",
        "        # Chart container with padding\n",
        "        margin=dict(t=120, b=120, l=40, r=40),  # Extra top and bottom margin\n",
        "        height=650,  # Increased height for better spacing\n",
        "\n",
        "        # Add chart subtitles directly under each chart\n",
        "        annotations=[\n",
        "            dict(\n",
        "                text=\"<b>Gas Usage by Transaction Type</b>\",\n",
        "                x=0.1,\n",
        "                y=-0.10,        # Position directly under first chart\n",
        "                xref=\"paper\",\n",
        "                yref=\"paper\",\n",
        "                showarrow=False,\n",
        "                font=dict(size=14)\n",
        "            ),\n",
        "            dict(\n",
        "                text=\"<b>Transaction Count by Type</b>\",\n",
        "                x=0.9,\n",
        "                y=-0.10,        # Position directly under second chart\n",
        "                xref=\"paper\",\n",
        "                yref=\"paper\",\n",
        "                showarrow=False,\n",
        "                font=dict(size=14)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def analyze_pyusd_flow(traces_with_details, block_number):\n",
        "    \"\"\"Analyzes PYUSD token flow within the block.\"\"\"\n",
        "    # Initialize flow data\n",
        "    flow_data = {\n",
        "        'total_transferred': 0,\n",
        "        'unique_senders': set(),\n",
        "        'unique_receivers': set(),\n",
        "        'transfers': [],\n",
        "        'approvals': [],\n",
        "        'other_operations': []\n",
        "    }\n",
        "\n",
        "    for trace in traces_with_details:\n",
        "        # Get PYUSD details safely\n",
        "        pyusd_details = trace.get('pyusd_details')\n",
        "\n",
        "        # Skip if no PYUSD details or not a PYUSD transaction\n",
        "        if not pyusd_details or not pyusd_details.get('is_pyusd_tx'):\n",
        "            continue\n",
        "\n",
        "        function = pyusd_details.get('function', '')\n",
        "\n",
        "        if function and 'transfer' in function.lower() and pyusd_details.get('amount') and pyusd_details.get('from_addr') and pyusd_details.get('to_addr'):\n",
        "            # This is a transfer\n",
        "            flow_data['total_transferred'] += pyusd_details['amount']\n",
        "            flow_data['unique_senders'].add(pyusd_details['from_addr'])\n",
        "            flow_data['unique_receivers'].add(pyusd_details['to_addr'])\n",
        "\n",
        "            flow_data['transfers'].append({\n",
        "                'tx_hash': trace.get('tx_hash'),\n",
        "                'from': pyusd_details['from_addr'],\n",
        "                'to': pyusd_details['to_addr'],\n",
        "                'amount': pyusd_details['amount'],\n",
        "                'failed': trace.get('failed', False)\n",
        "            })\n",
        "\n",
        "        elif function and 'approve' in function.lower() and pyusd_details.get('amount'):\n",
        "            # This is an approval\n",
        "            flow_data['approvals'].append({\n",
        "                'tx_hash': trace.get('tx_hash'),\n",
        "                'owner': pyusd_details.get('from_addr') or trace.get('from'),\n",
        "                'spender': pyusd_details.get('params', {}).get('spender'),\n",
        "                'amount': pyusd_details['amount'],\n",
        "                'failed': trace.get('failed', False)\n",
        "            })\n",
        "\n",
        "        else:\n",
        "            # Other PYUSD operations\n",
        "            flow_data['other_operations'].append({\n",
        "                'tx_hash': trace.get('tx_hash'),\n",
        "                'function': function,\n",
        "                'from': trace.get('from'),\n",
        "                'failed': trace.get('failed', False)\n",
        "            })\n",
        "\n",
        "    # Calculate statistics\n",
        "    flow_data['unique_senders_count'] = len(flow_data['unique_senders'])\n",
        "    flow_data['unique_receivers_count'] = len(flow_data['unique_receivers'])\n",
        "    flow_data['transfer_count'] = len(flow_data['transfers'])\n",
        "    flow_data['approval_count'] = len(flow_data['approvals'])\n",
        "    flow_data['other_count'] = len(flow_data['other_operations'])\n",
        "\n",
        "    return flow_data\n",
        "\n",
        "def create_pyusd_flow_diagram(flow_data, max_flows=10):\n",
        "    \"\"\"Creates a visualization of PYUSD token flows.\"\"\"\n",
        "    if not flow_data['transfers']:\n",
        "        return None\n",
        "\n",
        "    # Sort transfers by amount\n",
        "    sorted_transfers = sorted(flow_data['transfers'], key=lambda x: x['amount'], reverse=True)\n",
        "\n",
        "    # Take top flows based on amount\n",
        "    top_flows = sorted_transfers[:max_flows]\n",
        "\n",
        "    # Create flow diagram\n",
        "    dot = Digraph(comment='PYUSD Token Flow', format='png')\n",
        "    dot.attr(rankdir='LR', overlap='false')\n",
        "    dot.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "\n",
        "    # Add nodes and edges\n",
        "    added_nodes = set()\n",
        "\n",
        "    for transfer in top_flows:\n",
        "        from_addr = transfer['from']\n",
        "        from_addr_short = from_addr[:6] + '...' + from_addr[-4:]\n",
        "        to_addr = transfer['to']\n",
        "        to_addr_short = to_addr[:6] + '...' + to_addr[-4:]\n",
        "        amount = f\"{transfer['amount']:.2f} PYUSD\"\n",
        "\n",
        "        # Add sender node if not already added\n",
        "        node_id_from = from_addr\n",
        "        if node_id_from not in added_nodes:\n",
        "            dot.node(node_id_from, from_addr_short, fillcolor='lightblue', tooltip=from_addr)\n",
        "            added_nodes.add(node_id_from)\n",
        "\n",
        "        # Add receiver node if not already added\n",
        "        node_id_to = to_addr\n",
        "        if node_id_to not in added_nodes:\n",
        "            dot.node(node_id_to, to_addr_short, fillcolor='palegreen', tooltip=to_addr)\n",
        "            added_nodes.add(node_id_to)\n",
        "\n",
        "        # Add edge for the transfer\n",
        "        edge_style = 'dashed' if transfer.get('failed') else 'solid'\n",
        "        dot.edge(node_id_from, node_id_to, label=amount, style=edge_style)\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Dedicated Export Functions\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets_direct(df, sheet_name=None):\n",
        "    \"\"\"Exports DataFrame directly to Google Sheets using authenticated session.\"\"\"\n",
        "    if sheet_name is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_name = f\"PYUSD Analysis {timestamp}\"\n",
        "\n",
        "    # Use Google Colab integration for direct export\n",
        "    html = f'''\n",
        "    <script src=\"https://apis.google.com/js/platform.js\" async defer></script>\n",
        "    <script>\n",
        "    function createSheet() {{\n",
        "        const csv = `{df.to_csv(index=False).replace('\"', '\"\"')}`;\n",
        "\n",
        "        // Create sheet using Google Colab API\n",
        "        google.colab.kernel.invokeFunction('notebook.createSheet', [csv, '{sheet_name}'], {{}});\n",
        "    }}\n",
        "\n",
        "    // Execute immediately\n",
        "    setTimeout(createSheet, 100);\n",
        "    </script>\n",
        "    <div>Creating Google Sheet \"{sheet_name}\"...</div>\n",
        "    '''\n",
        "\n",
        "    # Register the Python callback that the JavaScript will call\n",
        "    from google.colab import output\n",
        "\n",
        "    @output.register_callback('notebook.createSheet')\n",
        "    def create_sheet_callback(csv_data, name):\n",
        "        try:\n",
        "            from google.colab import auth\n",
        "            from googleapiclient.discovery import build\n",
        "            from googleapiclient.http import MediaInMemoryUpload\n",
        "            import io\n",
        "\n",
        "            # Ensure authentication\n",
        "            auth.authenticate_user()\n",
        "\n",
        "            # Create Drive API client\n",
        "            drive_service = build('drive', 'v3')\n",
        "\n",
        "            # File metadata\n",
        "            file_metadata = {\n",
        "                'name': name,\n",
        "                'mimeType': 'application/vnd.google-apps.spreadsheet'\n",
        "            }\n",
        "\n",
        "            # Create CSV upload\n",
        "            media = MediaInMemoryUpload(\n",
        "                io.BytesIO(csv_data.encode('utf-8')),\n",
        "                mimetype='text/csv',\n",
        "                resumable=True\n",
        "            )\n",
        "\n",
        "            # Create the Sheet\n",
        "            file = drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id,webViewLink'\n",
        "            ).execute()\n",
        "\n",
        "            # Return success with link\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'file_id': file.get('id'),\n",
        "                'link': file.get('webViewLink')\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': str(e)\n",
        "            }\n",
        "\n",
        "    return HTML(html)\n",
        "\n",
        "def analyze_block_trace(block_trace_results_list, block_identifier):\n",
        "    \"\"\"Analyzes the output list from trace_block with PYUSD-focused analysis.\"\"\"\n",
        "    if not isinstance(block_trace_results_list, list): # trace_block should return a list\n",
        "        console.print(f\"[error]Expected a list from trace_block for block {block_identifier}, got {type(block_trace_results_list)}.\", style=\"error\")\n",
        "        display_json(block_trace_results_list, \"Unexpected Result Structure\")\n",
        "        return None\n",
        "    if not block_trace_results_list:\n",
        "        console.print(f\"[warning]No block trace results (empty list) provided for block {block_identifier}.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]üß± Analysis of {len(block_trace_results_list)} Traces for Block {block_identifier}[/bold cyan3]\")\n",
        "    console.print(\"[info]Extracting and categorizing transaction data...\", style=\"info\")\n",
        "\n",
        "    # Initialize counters and trackers\n",
        "    pyusd_interactions_count = 0\n",
        "    total_gas_used_in_traces = 0\n",
        "    failed_traces_count = 0\n",
        "    pyusd_transfer_volume = 0\n",
        "    traces_with_categories = []  # Store traces with their categories\n",
        "\n",
        "    # Process each trace\n",
        "    for i, trace in enumerate(block_trace_results_list):\n",
        "        # Default values\n",
        "        tx_hash = 'N/A'\n",
        "        from_addr = 'N/A'\n",
        "        to_addr = 'N/A'\n",
        "        value_eth = 0\n",
        "        value_eth_str = '0 ETH'\n",
        "        input_data = '0x'\n",
        "        gas_used = 0\n",
        "        error = None\n",
        "        tx_pos = i # Fallback index\n",
        "\n",
        "        try:\n",
        "            # Extract basic trace info\n",
        "            action = trace.get('action', {})\n",
        "            result = trace.get('result', {})\n",
        "            tx_hash = trace.get('transactionHash', action.get('transactionHash', f'trace_{i}'))\n",
        "            tx_pos = trace.get('transactionPosition', tx_pos)\n",
        "\n",
        "            from_addr = action.get('from', 'N/A')\n",
        "            # Handle contract creation ('address') vs. call ('to')\n",
        "            to_addr = action.get('to', action.get('address', 'N/A'))\n",
        "            value_wei_hex = action.get('value', '0x0')\n",
        "            input_data = action.get('input', '0x')\n",
        "\n",
        "            # Check both top-level and result for gasUsed and error\n",
        "            gas_used_hex = result.get('gasUsed', trace.get('gasUsed', '0x0'))\n",
        "            error = trace.get('error', result.get('error', None))\n",
        "\n",
        "            gas_used = int(gas_used_hex, 16) if gas_used_hex and isinstance(gas_used_hex, str) else gas_used_hex or 0\n",
        "\n",
        "            # Convert value from Wei to ETH\n",
        "            if isinstance(value_wei_hex, str) and value_wei_hex.startswith('0x'):\n",
        "                value_eth = int(value_wei_hex, 16) / 1e18\n",
        "            else:\n",
        "                value_eth = (value_wei_hex or 0) / 1e18\n",
        "\n",
        "            value_eth_str = format_value_eth(value_wei_hex)\n",
        "\n",
        "            # Categorize the transaction\n",
        "            category = categorize_transaction(trace)\n",
        "\n",
        "            # Extract PYUSD-specific details if relevant\n",
        "            pyusd_details = extract_pyusd_details(trace) if category.get('is_pyusd') else None\n",
        "\n",
        "            # Update PYUSD transfer volume if this is a PYUSD transfer\n",
        "            if pyusd_details and pyusd_details.get('amount') and 'transfer' in (pyusd_details.get('function') or '').lower():\n",
        "                pyusd_transfer_volume += pyusd_details['amount']\n",
        "\n",
        "        except Exception as parse_err:\n",
        "            console.print(f\"[warning]Could not fully parse trace item {i} in block {block_identifier}: {parse_err}\", style=\"warning\")\n",
        "            error = f\"Parse Error: {parse_err}\" # Mark as failed due to parsing\n",
        "            category = {'type': 'unknown', 'description': 'Parse Error', 'is_pyusd': False}\n",
        "            pyusd_details = None\n",
        "\n",
        "        # Update counters\n",
        "        if category.get('is_pyusd'):\n",
        "            pyusd_interactions_count += 1\n",
        "        if error:\n",
        "            failed_traces_count += 1\n",
        "        total_gas_used_in_traces += gas_used\n",
        "\n",
        "        # Store trace with category and details\n",
        "        trace_summary = {\n",
        "            'tx_index': tx_pos,\n",
        "            'tx_hash': tx_hash,\n",
        "            'from': from_addr,\n",
        "            'to': to_addr,\n",
        "            'value_eth': value_eth,\n",
        "            'value_eth_str': value_eth_str,\n",
        "            'gas_used': gas_used,\n",
        "            'failed': error is not None,\n",
        "            'error': error,\n",
        "            'category': category,\n",
        "            'pyusd_details': pyusd_details,\n",
        "            'input_preview': input_data[:10] + ('...' if len(input_data)>10 else ''),\n",
        "        }\n",
        "\n",
        "        traces_with_categories.append(trace_summary)\n",
        "\n",
        "    # Sort traces by transaction index\n",
        "    traces_with_categories.sort(key=lambda x: x['tx_index'] if isinstance(x['tx_index'], int) else float('inf'))\n",
        "\n",
        "    # Create DataFrame for display - include full addresses for proper data analysis\n",
        "    # Use only one index (not creating an extra 'index' column)\n",
        "    summary_df = pd.DataFrame([{\n",
        "        'tx_index': t['tx_index'],\n",
        "        'tx_hash': t['tx_hash'],\n",
        "        'from': t['from'],  # Full address\n",
        "        'to': t['to'],      # Full address\n",
        "        'value': t['value_eth_str'],\n",
        "        'gas_used': t['gas_used'],\n",
        "        'type': t['category']['description'],\n",
        "        'failed': t['failed'],\n",
        "        'pyusd': t['category'].get('is_pyusd', False)\n",
        "    } for t in traces_with_categories])\n",
        "\n",
        "    # Display Block Summary Panel\n",
        "    block_num = block_identifier\n",
        "    if isinstance(block_identifier, str) and block_identifier.startswith('0x'):\n",
        "        try:\n",
        "            block_num = int(block_identifier, 16)\n",
        "        except:\n",
        "            block_num = block_identifier\n",
        "\n",
        "    # Add more spacing before summary panel\n",
        "    console.print(\"\\n\")\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold]Block Trace Analysis (Block {block_num})[/bold]\n",
        "Transactions Traced: {len(block_trace_results_list)}\n",
        "Total Gas Used (Sum): {total_gas_used_in_traces:,}\n",
        "Traces with Errors: {failed_traces_count}\n",
        "PYUSD Interactions: {pyusd_interactions_count}\n",
        "PYUSD Transfer Volume: {pyusd_transfer_volume:.2f} PYUSD\"\"\",\n",
        "        title=\"üß± trace_block Analysis\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # Analyze gas distribution\n",
        "    console.print(\"\\n\\n[bold chartreuse1]ANALYZING GAS USAGE PATTERNS ACROSS TRANSACTION TYPES[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "    gas_analysis = analyze_gas_distribution(traces_with_categories)\n",
        "\n",
        "    # Add spacing before gas analysis\n",
        "    console.print(\"\\n\\n[bold chartreuse1]üìä Gas Usage Analysis by Transaction Type[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    # Create and display gas usage tables\n",
        "    gas_table = Table(title=\"\", title_style=\"bold chartreuse1\")\n",
        "    gas_table.add_column(\"Transaction Type\", style=\"chartreuse1\")\n",
        "    gas_table.add_column(\"Count\", justify=\"right\")\n",
        "    gas_table.add_column(\"Total Gas\", justify=\"right\")\n",
        "    gas_table.add_column(\"Avg Gas/Tx\", justify=\"right\")\n",
        "    gas_table.add_column(\"% of Total\", justify=\"right\")\n",
        "\n",
        "    for category, data in sorted(gas_analysis['by_category'].items(), key=lambda x: x[1]['gas'], reverse=True):\n",
        "        if data['gas'] > 0:  # Only include categories with gas usage\n",
        "            avg_gas = data['gas'] // data['count'] if data['count'] > 0 else 0\n",
        "            pct_total = (data['gas'] / total_gas_used_in_traces * 100) if total_gas_used_in_traces > 0 else 0\n",
        "            gas_table.add_row(\n",
        "                category.replace('_', ' ').title(),\n",
        "                f\"{data['count']:,}\",\n",
        "                f\"{data['gas']:,}\",\n",
        "                f\"{avg_gas:,}\",\n",
        "                f\"{pct_total:.1f}%\"\n",
        "            )\n",
        "\n",
        "    console.print(gas_table)\n",
        "\n",
        "    # PYUSD specific analysis - only if there are PYUSD interactions\n",
        "    if pyusd_interactions_count > 0:\n",
        "        console.print(\"\\n\\n[bold chartreuse1]ü™ô PYUSD Transactions Analysis in Block[/bold chartreuse1]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "        # Create PYUSD-specific table\n",
        "        pyusd_table = Table(title=\"\", title_style=\"bold chartreuse1\")\n",
        "        pyusd_table.add_column(\"Tx Hash\", style=\"dim\")\n",
        "        pyusd_table.add_column(\"Function\")\n",
        "        pyusd_table.add_column(\"From\")\n",
        "        pyusd_table.add_column(\"To\")\n",
        "        pyusd_table.add_column(\"Amount\")\n",
        "        pyusd_table.add_column(\"Gas Used\")\n",
        "        pyusd_table.add_column(\"Status\")\n",
        "\n",
        "        # Get all PYUSD transactions\n",
        "        pyusd_txs = [t for t in traces_with_categories if t['category'].get('is_pyusd')]\n",
        "\n",
        "        # Sort by gas used (descending)\n",
        "        pyusd_txs.sort(key=lambda x: x['gas_used'], reverse=True)\n",
        "\n",
        "        # Add rows for PYUSD transactions (limit to first 15 to avoid huge output)\n",
        "        for tx in pyusd_txs[:15]:\n",
        "            details = tx['pyusd_details'] or {}\n",
        "            function = tx['category'].get('function_name', 'Unknown')\n",
        "\n",
        "            # Format from/to addresses - showing full addresses on hover\n",
        "            from_full = details.get('from_addr') or tx['from']\n",
        "            from_addr = f\"{from_full[:6]}...{from_full[-4:]}\" if from_full and len(from_full) > 10 else from_full\n",
        "\n",
        "            to_full = None\n",
        "            if details.get('to_addr'):\n",
        "                to_full = details['to_addr']\n",
        "            elif 'approve' in function.lower() and details.get('params', {}).get('spender'):\n",
        "                to_full = details['params']['spender']\n",
        "\n",
        "            to_addr = f\"{to_full[:6]}...{to_full[-4:]}\" if to_full and len(to_full) > 10 else \"N/A\"\n",
        "\n",
        "            # Format amount\n",
        "            amount = \"N/A\"\n",
        "            if details.get('amount') is not None:\n",
        "                amount = f\"{details['amount']:.2f} PYUSD\"\n",
        "\n",
        "            # Format status\n",
        "            status_color = \"red\" if tx['failed'] else \"green\"\n",
        "            status_text = \"Failed\" if tx['failed'] else \"Success\"\n",
        "\n",
        "            # Format transaction hash\n",
        "            tx_hash = tx['tx_hash']\n",
        "            tx_hash_display = f\"{tx_hash[:10]}...\" if len(tx_hash) > 12 else tx_hash\n",
        "\n",
        "            # Add row with full data in title attributes\n",
        "            pyusd_table.add_row(\n",
        "                tx_hash_display,\n",
        "                function,\n",
        "                from_addr,\n",
        "                to_addr,\n",
        "                amount,\n",
        "                f\"{tx['gas_used']:,}\",\n",
        "                f\"[{status_color}]{status_text}[/{status_color}]\"\n",
        "            )\n",
        "\n",
        "        if len(pyusd_txs) > 15:\n",
        "            pyusd_table.add_row(\n",
        "                \"...\",\n",
        "                f\"+ {len(pyusd_txs) - 15} more\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\",\n",
        "                \"\"\n",
        "            )\n",
        "\n",
        "        console.print(pyusd_table)\n",
        "\n",
        "        # Analyze PYUSD token flow\n",
        "        console.print(\"\\n\\n[bold yellow3]ANALYZING PYUSD TOKEN FLOW WITHIN THE BLOCK[/bold yellow3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"yellow3\")\n",
        "        flow_analysis = analyze_pyusd_flow(traces_with_categories, block_num)\n",
        "\n",
        "        # Display flow summary\n",
        "        flow_panel = Panel(f\"\"\"\n",
        "[bold]PYUSD Token Flow in Block {block_num}[/bold]\n",
        "Total PYUSD Transferred: {flow_analysis['total_transferred']:.2f} PYUSD\n",
        "Transfer Transactions: {flow_analysis['transfer_count']}\n",
        "Approval Transactions: {flow_analysis['approval_count']}\n",
        "Other PYUSD Transactions: {flow_analysis['other_count']}\n",
        "Unique Senders: {flow_analysis['unique_senders_count']}\n",
        "Unique Receivers: {flow_analysis['unique_receivers_count']}\"\"\",\n",
        "            title=\"üîÑ PYUSD Flow Analysis\", border_style=\"yellow3\", expand=False)\n",
        "\n",
        "        console.print(flow_panel)\n",
        "\n",
        "        # Create and display flow diagram if there are transfers\n",
        "        if flow_analysis['transfers']:\n",
        "            console.print(\"\\n\\n[bold magenta3]PYUSD Token Flow Fiagram (Top Transfers)[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "            try:\n",
        "                flow_diagram = create_pyusd_flow_diagram(flow_analysis)\n",
        "                if flow_diagram:\n",
        "                    display(flow_diagram)\n",
        "            except Exception as viz_err:\n",
        "                console.print(f\"[warning]Could not create flow visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Visualize gas distribution with better spacing\n",
        "    console.print(\"\\n\\n[bold magenta3]Gas Usage Distribution in Block[/bold magenta3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "    try:\n",
        "        gas_viz = visualize_gas_distribution(gas_analysis)\n",
        "        display(gas_viz)\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create gas visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Show filter options first\n",
        "    console.print(\"\\n\\n[bold cyan3]üìã Block Transaction Summary[/bold cyan3]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create filter controls and PYUSD-focused display\n",
        "    if not summary_df.empty:\n",
        "        # Create PYUSD-only and All transactions dataframes\n",
        "        pyusd_df = summary_df[summary_df['pyusd'] == True].copy()\n",
        "\n",
        "        # Filter options above the table\n",
        "        display(widgets.HTML(\"<h4>Filter Options:</h4>\"))\n",
        "\n",
        "        # Keep both buttons - arranged in an HBox for better layout\n",
        "        filter_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Show PYUSD Only',\n",
        "                button_style='success',\n",
        "                layout=widgets.Layout(width='180px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Show All Transactions',\n",
        "                button_style='info',\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        display(filter_buttons)\n",
        "\n",
        "        # Output area for transactions\n",
        "        transaction_output = widgets.Output()\n",
        "\n",
        "        # Export buttons below the table with better styling\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Export to CSV',\n",
        "                button_style='primary',  # Green\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export as JSON',\n",
        "                button_style='warning',  # Orange\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export to Google Sheets',\n",
        "                button_style='info',     # Blue\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        export_output = widgets.Output()\n",
        "\n",
        "        def show_all_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                display(summary_df)\n",
        "\n",
        "        def show_pyusd_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                display(pyusd_df)\n",
        "\n",
        "        # Export handlers\n",
        "        def export_csv(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame\n",
        "                current_df = summary_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) > len(str(pyusd_df)) else pyusd_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_num}_transactions_{timestamp}.csv\"\n",
        "                display(download_csv_direct(current_df, filename))\n",
        "\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame\n",
        "                current_df = summary_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) > len(str(pyusd_df)) else pyusd_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_num}_transactions_{timestamp}.json\"\n",
        "                records = current_df.to_dict('records')\n",
        "                display(download_json_direct(records, filename))\n",
        "\n",
        "        def export_to_sheets(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame\n",
        "                current_df = summary_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) > len(str(pyusd_df)) else pyusd_df\n",
        "                sheet_name = f\"Block {block_num} Transactions {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "                display(export_to_google_sheets_direct(current_df, sheet_name))\n",
        "\n",
        "        # Connect callbacks\n",
        "        filter_buttons.children[0].on_click(show_pyusd_txs)   # PYUSD Only button\n",
        "        filter_buttons.children[1].on_click(show_all_txs)     # Show All button\n",
        "        export_buttons.children[0].on_click(export_csv)\n",
        "        export_buttons.children[1].on_click(export_json)\n",
        "        export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "        # Display transaction table area\n",
        "        display(transaction_output)\n",
        "\n",
        "        # Show PYUSD transactions by default\n",
        "        show_pyusd_txs(None)\n",
        "\n",
        "        # Export section below the table\n",
        "        console.print(\"\\n\\n[bold]Export Options:[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        display(export_buttons)\n",
        "        display(export_output)\n",
        "\n",
        "    # Return both the basic DataFrame and the enhanced data\n",
        "    return {\n",
        "        'summary_df': summary_df,\n",
        "        'traces_with_categories': traces_with_categories,\n",
        "        'gas_analysis': gas_analysis,\n",
        "        'pyusd_interactions': pyusd_interactions_count,\n",
        "        'total_gas_used': total_gas_used_in_traces,\n",
        "        'pyusd_transfer_volume': pyusd_transfer_volume\n",
        "    }\n",
        "\n",
        "# --- Execute Block Tracing ---\n",
        "# WARNING: Tracing a full block can be slow. Default to False.\n",
        "RUN_TRACE_BLOCK = True # <<< SET TO TRUE TO RUN THIS EXPENSIVE TRACE\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_trace_block = TARGET_BLOCK_IDENTIFIER\n",
        "    block_id_for_rpc = None\n",
        "\n",
        "    # Format block identifier for trace_block (requires hex string or tag)\n",
        "    if isinstance(block_id_trace_block, int):\n",
        "        block_id_for_rpc = hex(block_id_trace_block)\n",
        "    elif isinstance(block_id_trace_block, str):\n",
        "        if block_id_trace_block.startswith(\"0x\"):\n",
        "            block_id_for_rpc = block_id_trace_block # Hash or Hex Number\n",
        "        elif block_id_trace_block in [\"latest\", \"pending\", \"earliest\"]:\n",
        "            block_id_for_rpc = block_id_trace_block\n",
        "        else: # Try converting string int\n",
        "             try:\n",
        "                 block_id_for_rpc = hex(int(block_id_trace_block))\n",
        "             except ValueError:\n",
        "                 console.print(f\"[error]Invalid TARGET_BLOCK_IDENTIFIER '{block_id_trace_block}' for trace_block. Needs hex string, int, or tag.\", style=\"error\")\n",
        "\n",
        "    if RUN_TRACE_BLOCK and block_id_for_rpc:\n",
        "        console.print(\"\\n\\n[bold]üß± Tracing & Analyis via trace_block[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        console.print(f\"\\n\\n[warning]Attempting 'trace_block' for {block_id_for_rpc} on Mainnet (Can be SLOW!)...[/warning]\", style=\"warning\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        block_trace_results = make_rpc_request(\"trace_block\", [block_id_for_rpc], network='mainnet')\n",
        "        end_time = time.time()\n",
        "\n",
        "        trace_time = end_time - start_time\n",
        "        console.print(f\"[info]trace_block API call completed in {trace_time:.2f} seconds\", style=\"info\")\n",
        "\n",
        "        if block_trace_results is not None: # Check for None explicitly, as empty list is valid\n",
        "            console.print(\"[success]Successfully retrieved block trace data.\", style=\"success\")\n",
        "            analysis_results = analyze_block_trace(block_trace_results, block_id_for_rpc)\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to get block trace for {block_id_for_rpc} using 'trace_block'. RPC call failed, timed out, or returned null.\", style=\"error\")\n",
        "\n",
        "    elif not RUN_TRACE_BLOCK:\n",
        "        console.print(f\"\\n[info]Skipping 'trace_block' as RUN_TRACE_BLOCK is False.\", style=\"info\")\n",
        "        console.print(f\"[info]Set RUN_TRACE_BLOCK = True to execute this cell with the target block {block_id_trace_block}.\", style=\"info\")\n",
        "    elif not block_id_for_rpc:\n",
        "         pass # Error already printed\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping trace_block analysis.\", style=\"warning\")\n",
        "    console.print(\"[info]Set TARGET_BLOCK_IDENTIFIER to a block number or hash to use this cell.\", style=\"info\")"
      ],
      "metadata": {
        "id": "Lt34TjimUeF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 üß± `debug_traceBlockByNumber` and `debug_traceBlockByHash`: Detailed Block Tracing\n",
        "---\n",
        "\n",
        "This section explores tracing all transactions within a block using methods from the `debug` namespace: `debug_traceBlockByNumber` (which takes a block number) **and** `debug_traceBlockByHash` (which takes a block hash).\n",
        "\n",
        "Unlike `trace_block` (from the `trace` namespace), these `debug_` methods often provide **more detailed trace outputs for *each* transaction** within the block, typically defaulting to a format similar to `debug_traceTransaction`'s `callTracer` on GCP. This allows for a deeper analysis of the internal execution flow of every transaction in the target block.\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Methods:** `debug_traceBlockByNumber`, `debug_traceBlockByHash`\n",
        "> *   **Multiplier:** `50x` (Each method call)\n",
        "> *   **GCP Advantage:** Tracing full blocks with this level of detail per transaction is highly resource-intensive. GCP's infrastructure and free quotas make it feasible to retrieve and process these potentially very large and numerous trace results efficiently.\n",
        "> *   **PYUSD Insight:** These methods enable:\n",
        ">     *   Detailed analysis of **internal calls** for *all* transactions interacting with PYUSD in a block, not just a single target transaction.\n",
        ">     *   Identifying **indirect PYUSD interactions** where a contract called by the main transaction subsequently interacts with PYUSD.\n",
        ">     *   Comparing gas efficiency and execution paths of multiple PYUSD transactions within the same block context.\n",
        ">     *   Analyzing block-level **MEV patterns** (like sandwich attacks) by examining the detailed traces of surrounding transactions.\n",
        "\n",
        "**Analysis Workflow:**\n",
        "\n",
        "1.  **Fetch Detailed Block Trace:**\n",
        "    *   The first part calls `debug_traceBlockByNumber` using the target block identifier (converted to a hex number or tag) and a tracer configuration (typically `callTracer`).\n",
        "    *   The second part retrieves the corresponding block hash and then calls `debug_traceBlockByHash` with the hash and the tracer configuration.\n",
        "2.  **Process Individual Traces:** The `analyze_debug_block_trace` function is reused for the output list from *both* methods. It iterates through the list, where each item usually contains the detailed trace result for one transaction.\n",
        "3.  **Categorize & Analyze:**\n",
        "    *   Extracts details (gas, status, function calls) for each transaction's trace.\n",
        "    *   Specifically identifies PYUSD function calls and categories.\n",
        "    *   Detects internal transactions involving PYUSD (`detect_pyusd_internal_transactions`).\n",
        "4.  **Visualize & Summarize:** (Outputs are generated for results from both methods if run)\n",
        "    *   **Enhanced Block Summary:** Includes counts for PYUSD transfers, mints, burns, and total volume within the block.\n",
        "    *   **PYUSD Function Analysis:** Shows distribution and visualization of PYUSD functions called across the block.\n",
        "    *   **Internal Call Table:** Lists detected internal calls to PYUSD contracts.\n",
        "    *   **Gas & Transfer Visualizations:** Plots gas distribution and PYUSD transfer networks for the block.\n",
        "    *   **Transaction Table:** Interactive summary table for all transactions.\n",
        "    *   **Export Options:** Download block summary data.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "*   Compare the outputs/analyses from `debug_traceBlockByNumber` and `debug_traceBlockByHash` for consistency (they should generally be the same if targeting the same block).\n",
        "*   **PYUSD Function Distribution:** Which PYUSD functions were most commonly called in this block?\n",
        "*   **Internal PYUSD Calls:** Did contracts *other than* the main target interact with PYUSD?\n",
        "*   **Gas Comparison:** Compare the gas usage of similar PYUSD operations within the same block.\n",
        "*   **Correlated Activity:** Examine traces of transactions near PYUSD interactions for related DeFi or MEV activity."
      ],
      "metadata": {
        "id": "2VAJLLSVVxC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üß± Trace Block using debug_traceBlockByNumber / debug_traceBlockByHash\n",
        "# =============================================================================================\n",
        "# Note: Output format can be complex and node-dependent. Often returns a list of objects,\n",
        "# each containing a 'result' which holds the trace (e.g., callTracer format).\n",
        "# This cell performs detailed tracing and analysis of all transactions within a specific block\n",
        "# using the `debug_traceBlockByNumber` and `debug_traceBlockByHash` RPC methods, providing\n",
        "# deep insights into block activity with a focus on PYUSD interactions.\n",
        "#\n",
        "# Functionality includes:\n",
        "# - Fetching detailed execution traces (e.g., callTracer output) for every transaction\n",
        "#   in the target block via both debug methods.\n",
        "# - Processing each transaction's trace to extract key information (from, to, gas, status, calls).\n",
        "# - Analyzing PYUSD-specific interactions: function decoding, volume calculation, internal call detection.\n",
        "# - Generating comprehensive analysis outputs: summary panel, function category table/pie chart,\n",
        "#   direct PYUSD interactions table, internal calls table.\n",
        "# - Visualizing block-level data: PYUSD transfer network graph (Graphviz), gas usage distribution histogram (Plotly).\n",
        "# - Providing an interactive table (ipywidgets/pandas) for all block transactions with PYUSD filtering.\n",
        "# - Offering direct export options for the analysis results to CSV, JSON, and Google Sheets.\n",
        "# - Leveraging GCP's premium RPC capabilities for these resource-intensive debug methods on Mainnet.\n",
        "\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, clear_output\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Dedicated Export Functions\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_data_{timestamp}.json\"\n",
        "\n",
        "    # Convert to JSON string (handling non-serializable objects)\n",
        "    json_str = json.dumps(data, default=str, indent=2)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets_direct(df, sheet_name=None):\n",
        "    \"\"\"Exports DataFrame directly to Google Sheets using authenticated session.\"\"\"\n",
        "    if sheet_name is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_name = f\"PYUSD Analysis {timestamp}\"\n",
        "\n",
        "    # Use Google Colab integration for direct export\n",
        "    html = f'''\n",
        "    <script src=\"https://apis.google.com/js/platform.js\" async defer></script>\n",
        "    <script>\n",
        "    function createSheet() {{\n",
        "        const csv = `{df.to_csv(index=False).replace('\"', '\"\"')}`;\n",
        "\n",
        "        // Create sheet using Google Colab API\n",
        "        google.colab.kernel.invokeFunction('notebook.createSheet', [csv, '{sheet_name}'], {{}});\n",
        "    }}\n",
        "\n",
        "    // Execute immediately\n",
        "    setTimeout(createSheet, 100);\n",
        "    </script>\n",
        "    <div>Creating Google Sheet \"{sheet_name}\"...</div>\n",
        "    '''\n",
        "\n",
        "    # Register the Python callback that the JavaScript will call\n",
        "    from google.colab import output\n",
        "\n",
        "    @output.register_callback('notebook.createSheet')\n",
        "    def create_sheet_callback(csv_data, name):\n",
        "        try:\n",
        "            from google.colab import auth\n",
        "            from googleapiclient.discovery import build\n",
        "            from googleapiclient.http import MediaInMemoryUpload\n",
        "            import io\n",
        "\n",
        "            # Ensure authentication\n",
        "            auth.authenticate_user()\n",
        "\n",
        "            # Create Drive API client\n",
        "            drive_service = build('drive', 'v3')\n",
        "\n",
        "            # File metadata\n",
        "            file_metadata = {\n",
        "                'name': name,\n",
        "                'mimeType': 'application/vnd.google-apps.spreadsheet'\n",
        "            }\n",
        "\n",
        "            # Create CSV upload\n",
        "            media = MediaInMemoryUpload(\n",
        "                io.BytesIO(csv_data.encode('utf-8')),\n",
        "                mimetype='text/csv',\n",
        "                resumable=True\n",
        "            )\n",
        "\n",
        "            # Create the Sheet\n",
        "            file = drive_service.files().create(\n",
        "                body=file_metadata,\n",
        "                media_body=media,\n",
        "                fields='id,webViewLink'\n",
        "            ).execute()\n",
        "\n",
        "            # Return success with link\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'file_id': file.get('id'),\n",
        "                'link': file.get('webViewLink')\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'status': 'error',\n",
        "                'message': str(e)\n",
        "            }\n",
        "\n",
        "    return HTML(html)\n",
        "\n",
        "def detect_pyusd_internal_transactions(debug_trace_list):\n",
        "    \"\"\"Analyze traces for PYUSD internal transactions (contracts calling PYUSD).\"\"\"\n",
        "    internal_txs = []\n",
        "\n",
        "    for i, trace_item in enumerate(debug_trace_list):\n",
        "        tx_hash = trace_item.get('txHash', f'tx_{i}')\n",
        "        trace_result = trace_item.get('result', {})\n",
        "\n",
        "        # Skip if there are no calls\n",
        "        if not isinstance(trace_result.get('calls'), list):\n",
        "            continue\n",
        "\n",
        "        # Function to recursively process calls\n",
        "        def process_calls(calls, depth=0, parent_from=None, parent_to=None):\n",
        "            for call in calls:\n",
        "                call_to = call.get('to', '')\n",
        "                call_from = call.get('from', parent_from if parent_from else '')\n",
        "                call_type = call.get('type', 'CALL')\n",
        "                call_input = call.get('input', '0x')\n",
        "                call_gas_used = call.get('gasUsed', '0x0')\n",
        "\n",
        "                # Check if this call is to a PYUSD contract\n",
        "                if call_to and call_to.lower() in PYUSD_CONTRACTS:\n",
        "                    # Try to decode the function\n",
        "                    function_name = \"Unknown\"\n",
        "                    if call_input and len(call_input) >= 10:\n",
        "                        method_sig = call_input[:10]\n",
        "                        if method_sig in PYUSD_SIGNATURES:\n",
        "                            function_name = PYUSD_SIGNATURES[method_sig][\"name\"]\n",
        "\n",
        "                    # Record this internal transaction\n",
        "                    internal_txs.append({\n",
        "                        'tx_hash': tx_hash,\n",
        "                        'from': call_from,\n",
        "                        'to': call_to,\n",
        "                        'to_contract': get_contract_name(call_to),\n",
        "                        'function': function_name,\n",
        "                        'call_type': call_type,\n",
        "                        'gas_used': int(call_gas_used, 16) if isinstance(call_gas_used, str) else call_gas_used,\n",
        "                        'depth': depth\n",
        "                    })\n",
        "\n",
        "                # Process nested calls recursively\n",
        "                if isinstance(call.get('calls'), list):\n",
        "                    process_calls(call['calls'], depth + 1, call_from, call_to)\n",
        "\n",
        "        # Start processing from the top level calls\n",
        "        if isinstance(trace_result.get('calls'), list):\n",
        "            process_calls(trace_result['calls'])\n",
        "\n",
        "    return internal_txs\n",
        "\n",
        "def analyze_debug_block_trace(debug_trace_list, block_identifier):\n",
        "    \"\"\"Analyzes the output list from debug_traceBlockByNumber/Hash with PYUSD focus.\"\"\"\n",
        "    if not isinstance(debug_trace_list, list):\n",
        "        console.print(f\"[error]Expected a list from debug_traceBlock for {block_identifier}, got {type(debug_trace_list)}.\", style=\"error\")\n",
        "        display_json(debug_trace_list, \"Unexpected Result Structure\")\n",
        "        return None\n",
        "    if not debug_trace_list:\n",
        "        console.print(f\"[warning]No trace results (empty list) from debug_traceBlock for {block_identifier}.\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "    console.print(f\"\\n\\n[bold cyan3]Analyzing {len(debug_trace_list)} Traces from debug_traceBlock for {block_identifier}[/bold cyan3]\")\n",
        "\n",
        "    # Counters and aggregators\n",
        "    pyusd_interactions_count = 0\n",
        "    pyusd_transfer_count = 0\n",
        "    pyusd_mint_count = 0\n",
        "    pyusd_burn_count = 0\n",
        "    total_gas_used = 0\n",
        "    failed_traces_count = 0\n",
        "\n",
        "    # Track PYUSD transfers within block\n",
        "    pyusd_transfers = []\n",
        "    pyusd_volume = 0\n",
        "\n",
        "    # Track function categories\n",
        "    function_categories = {\n",
        "        \"token_movement\": 0,\n",
        "        \"supply_change\": 0,\n",
        "        \"allowance\": 0,\n",
        "        \"control\": 0,\n",
        "        \"admin\": 0,\n",
        "        \"view\": 0,\n",
        "        \"other\": 0\n",
        "    }\n",
        "\n",
        "    trace_summary_list = []\n",
        "\n",
        "    for i, trace_item in enumerate(debug_trace_list):\n",
        "        # Default values\n",
        "        tx_hash = 'N/A'\n",
        "        from_addr = 'N/A'\n",
        "        to_addr = 'N/A'\n",
        "        value_eth_str = '0 ETH'\n",
        "        gas_used = 0\n",
        "        error = None\n",
        "        interacted_with_pyusd = False\n",
        "        tx_pos = i  # Fallback index\n",
        "        pyusd_function = None\n",
        "        pyusd_function_category = \"other\"\n",
        "        is_pyusd_transfer = False\n",
        "        is_pyusd_mint = False\n",
        "        is_pyusd_burn = False\n",
        "        transfer_value = 0\n",
        "\n",
        "        try:\n",
        "            # debug_traceBlock* often nests the main trace info under 'result'\n",
        "            trace_result = trace_item.get('result', {})  # Get the nested trace\n",
        "            tx_hash = trace_item.get('txHash', f'tx_{i}')  # Hash might be at top level\n",
        "\n",
        "            # Parse fields from the nested 'result' if it exists\n",
        "            if trace_result:\n",
        "                from_addr = trace_result.get('from', 'N/A')\n",
        "                to_addr = trace_result.get('to', 'N/A')\n",
        "                value_wei_hex = trace_result.get('value', '0x0')\n",
        "                gas_used_hex = trace_result.get('gasUsed', '0x0')\n",
        "                error = trace_result.get('error')  # Error within the execution\n",
        "                input_data = trace_result.get('input', '0x')\n",
        "\n",
        "                gas_used = int(gas_used_hex, 16) if gas_used_hex else 0\n",
        "                value_eth_str = format_value_eth(value_wei_hex)\n",
        "\n",
        "                # Check for PYUSD contract interactions\n",
        "                interacted_with_pyusd = to_addr and to_addr.lower() in PYUSD_CONTRACTS\n",
        "\n",
        "                # If this is a PYUSD interaction, analyze the function being called\n",
        "                if interacted_with_pyusd and input_data and input_data != '0x':\n",
        "                    method_sig = input_data[:10]\n",
        "\n",
        "                    if method_sig in PYUSD_SIGNATURES:\n",
        "                        sig_info = PYUSD_SIGNATURES[method_sig]\n",
        "                        pyusd_function = sig_info[\"name\"]\n",
        "                        pyusd_function_category = sig_info[\"category\"]\n",
        "\n",
        "                        # Track function category\n",
        "                        function_categories[pyusd_function_category] += 1\n",
        "\n",
        "                        # Check for specific functions\n",
        "                        if method_sig == '0xa9059cbb':  # transfer\n",
        "                            is_pyusd_transfer = True\n",
        "                            pyusd_transfer_count += 1\n",
        "\n",
        "                            # Try to decode transfer parameters\n",
        "                            try:\n",
        "                                to_offset = 10\n",
        "                                to_param = \"0x\" + input_data[to_offset+24:to_offset+64]\n",
        "                                amount_offset = 74\n",
        "                                amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                                transfer_value = amount\n",
        "                                pyusd_volume += amount\n",
        "\n",
        "                                # Track transfer for visualization\n",
        "                                pyusd_transfers.append({\n",
        "                                    'from': from_addr,\n",
        "                                    'to': to_param,\n",
        "                                    'value': amount,\n",
        "                                    'tx_hash': tx_hash\n",
        "                                })\n",
        "                            except Exception:\n",
        "                                pass\n",
        "\n",
        "                        elif method_sig == '0x40c10f19':  # mint\n",
        "                            is_pyusd_mint = True\n",
        "                            pyusd_mint_count += 1\n",
        "\n",
        "                            # Try to decode mint amount\n",
        "                            try:\n",
        "                                amount_offset = 74\n",
        "                                amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                                transfer_value = amount\n",
        "                                pyusd_volume += amount\n",
        "                            except Exception:\n",
        "                                pass\n",
        "\n",
        "                        elif method_sig == '0x42966c68':  # burn\n",
        "                            is_pyusd_burn = True\n",
        "                            pyusd_burn_count += 1\n",
        "\n",
        "                            # Try to decode burn amount\n",
        "                            try:\n",
        "                                amount_offset = 10\n",
        "                                amount = int(input_data[amount_offset:amount_offset+64], 16)\n",
        "                                transfer_value = amount\n",
        "                                pyusd_volume += amount\n",
        "                            except Exception:\n",
        "                                pass\n",
        "\n",
        "                # Check for sub-calls that might interact with PYUSD\n",
        "                if 'calls' in trace_result and isinstance(trace_result['calls'], list):\n",
        "                    for call in trace_result['calls']:\n",
        "                        if call.get('to', '').lower() in PYUSD_CONTRACTS:\n",
        "                            interacted_with_pyusd = True\n",
        "                            break\n",
        "            else:\n",
        "                # Handle cases where 'result' is missing - trace might have failed earlier\n",
        "                error = trace_item.get('error', 'Missing trace result')  # Check top level error\n",
        "\n",
        "        except Exception as parse_err:\n",
        "            console.print(f\"[warning]Could not fully parse trace item {i} in debug block trace {block_identifier}: {parse_err}\", style=\"warning\")\n",
        "            error = f\"Parse Error: {parse_err}\"\n",
        "\n",
        "        if error:\n",
        "            failed_traces_count += 1\n",
        "        if interacted_with_pyusd:\n",
        "            pyusd_interactions_count += 1\n",
        "        total_gas_used += gas_used\n",
        "\n",
        "        trace_summary_list.append({\n",
        "            'tx_index': tx_pos,  # Using list index as fallback for tx position\n",
        "            'tx_hash': tx_hash,\n",
        "            'from': from_addr,\n",
        "            'to': to_addr,\n",
        "            'value_eth': value_eth_str,\n",
        "            'gas_used': gas_used,\n",
        "            'failed': error is not None,\n",
        "            'pyusd_interaction': interacted_with_pyusd,\n",
        "            'pyusd_function': pyusd_function,\n",
        "            'pyusd_function_category': pyusd_function_category,\n",
        "            'is_pyusd_transfer': is_pyusd_transfer,\n",
        "            'is_pyusd_mint': is_pyusd_mint,\n",
        "            'is_pyusd_burn': is_pyusd_burn,\n",
        "            'transfer_value': transfer_value\n",
        "        })\n",
        "\n",
        "    summary_df = pd.DataFrame(trace_summary_list)\n",
        "\n",
        "    # Calculate key metrics\n",
        "    pyusd_volume_formatted = format_value_pyusd(pyusd_volume) if pyusd_volume > 0 else \"0 PYUSD\"\n",
        "    pyusd_pct = (pyusd_interactions_count / len(debug_trace_list) * 100) if debug_trace_list else 0\n",
        "\n",
        "    # Display Enhanced Summary Stats\n",
        "    console.print(Panel(f\"\"\"\n",
        "[bold cyan3]Enhanced debug_traceBlock Summary ({block_identifier})[/bold cyan3]\n",
        "[bold cyan3]Transactions Traced:[/bold cyan3] {len(debug_trace_list)}\n",
        "[bold cyan3]Total Gas Used:[/bold cyan3] {total_gas_used:,}\n",
        "[bold cyan3]Traces with Errors:[/bold cyan3] {failed_traces_count}\n",
        "\n",
        "[bold green3]PYUSD Activity[/bold green3]\n",
        "[bold green3]PYUSD Interactions:[/bold green3] {pyusd_interactions_count} ({pyusd_pct:.1f}% of transactions)\n",
        "[bold green3]PYUSD Transfers:[/bold green3] {pyusd_transfer_count}\n",
        "[bold green3]PYUSD Mints:[/bold green3] {pyusd_mint_count}\n",
        "[bold green3]PYUSD Burns:[/bold green3] {pyusd_burn_count}\n",
        "[bold green3]PYUSD Volume:[/bold green3] {pyusd_volume_formatted}\"\"\",\n",
        "        title=\"debug_traceBlock Analysis\", border_style=\"cyan3\", expand=False))\n",
        "\n",
        "    # Display function category breakdown if any PYUSD activity\n",
        "    console.print(\"\\n\\n[bold]PYUSD Function Categories[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    if pyusd_interactions_count > 0:\n",
        "        category_table = Table(title=\"\", show_header=True, header_style=\"bold green3\")\n",
        "        category_table.add_column(\"Category\")\n",
        "        category_table.add_column(\"Count\", justify=\"right\")\n",
        "        category_table.add_column(\"Percentage\", justify=\"right\")\n",
        "\n",
        "        for category, count in function_categories.items():\n",
        "            if count > 0:\n",
        "                percentage = (count / pyusd_interactions_count * 100)\n",
        "                category_table.add_row(\n",
        "                    category.replace('_', ' ').title(),\n",
        "                    str(count),\n",
        "                    f\"{percentage:.1f}%\"\n",
        "                )\n",
        "\n",
        "        console.print(category_table)\n",
        "\n",
        "        # Create visualization of function categories\n",
        "        try:\n",
        "            console.print(f\"\\n\\n[bold]PYUSD Function Categories in Block Visualization: [cyan3]{block_identifier}[/cyan3][/bold]\", style=\"magenta3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            category_data = pd.DataFrame([\n",
        "                {\"category\": cat.replace('_', ' ').title(), \"count\": count}\n",
        "                for cat, count in function_categories.items() if count > 0\n",
        "            ])\n",
        "\n",
        "            if not category_data.empty:\n",
        "                fig_categories = px.pie(\n",
        "                    category_data, values='count', names='category',\n",
        "                    title=f'PYUSD Function Categories in Block {block_identifier}'\n",
        "                )\n",
        "                fig_categories.update_layout(template=\"plotly_white\")\n",
        "                fig_categories.show()\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create function category visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Display PYUSD-specific transactions\n",
        "    if pyusd_interactions_count > 0 and not summary_df.empty:\n",
        "        console.print(\"\\n\\n[bold green3]üìä PYUSD Interactions in Block[/bold green3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "\n",
        "        pyusd_txs = summary_df[summary_df['pyusd_interaction']].copy()\n",
        "\n",
        "        if not pyusd_txs.empty:\n",
        "            # Add readable addresses\n",
        "            pyusd_txs['from_short'] = pyusd_txs['from'].apply(shorten_address)\n",
        "            pyusd_txs['to_short'] = pyusd_txs['to'].apply(shorten_address)\n",
        "\n",
        "            # Add transfer value formatting\n",
        "            if 'transfer_value' in pyusd_txs.columns:\n",
        "                pyusd_txs['value_pyusd'] = pyusd_txs['transfer_value'].apply(\n",
        "                    lambda x: format_value_pyusd(x) if x > 0 else \"\"\n",
        "                )\n",
        "\n",
        "            # Display streamlined view\n",
        "            display_cols = [\n",
        "                'tx_index', 'from', 'to', 'pyusd_function',\n",
        "                'value_pyusd', 'gas_used', 'failed'\n",
        "            ]\n",
        "\n",
        "            # Filter columns that exist\n",
        "            display_cols = [col for col in display_cols if col in pyusd_txs.columns]\n",
        "\n",
        "            # Create a table to display this data\n",
        "            console.print(\"\\n\\n[bold]PYUSD Transactions in Block[/bold]\", style=\"cyan3\")\n",
        "            pyusd_table = Table(title=\"\", title_style=\"\")\n",
        "            pyusd_table.add_column(\"Tx Index\")\n",
        "            pyusd_table.add_column(\"From\")\n",
        "            pyusd_table.add_column(\"To\")\n",
        "            pyusd_table.add_column(\"Function\")\n",
        "            pyusd_table.add_column(\"Amount\")\n",
        "            pyusd_table.add_column(\"Gas Used\")\n",
        "            pyusd_table.add_column(\"Status\")\n",
        "\n",
        "            # Add rows (limit to first 15 to avoid huge output)\n",
        "            for idx, row in pyusd_txs.head(15).iterrows():\n",
        "                status_color = \"red\" if row['failed'] else \"green\"\n",
        "                status_text = \"Failed\" if row['failed'] else \"Success\"\n",
        "\n",
        "                pyusd_table.add_row(\n",
        "                    str(row['tx_index']),\n",
        "                    row['from'],\n",
        "                    row['to'],\n",
        "                    str(row['pyusd_function'] or \"\"),\n",
        "                    row.get('value_pyusd', \"\"),\n",
        "                    f\"{row['gas_used']:,}\",\n",
        "                    f\"[{status_color}]{status_text}[/{status_color}]\"\n",
        "                )\n",
        "\n",
        "            if len(pyusd_txs) > 15:\n",
        "                pyusd_table.add_row(\n",
        "                    \"...\",\n",
        "                    f\"+ {len(pyusd_txs) - 15} more\",\n",
        "                    \"\", \"\", \"\", \"\", \"\"\n",
        "                )\n",
        "\n",
        "            console.print(pyusd_table)\n",
        "        else:\n",
        "            console.print(\"[info]No direct PYUSD interactions found.\", style=\"info\")\n",
        "\n",
        "    # Visualize PYUSD transfer network if transfers exist\n",
        "    if pyusd_transfers:\n",
        "        console.print(\"\\n\\n[bold magenta3]üîÑ PYUSD Transfer Network in Block[/bold magenta3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        try:\n",
        "            # Create transfer network visualization\n",
        "            flow_graph = Digraph(comment=f\"PYUSD Transfers in Block {block_identifier}\", format='png')\n",
        "            flow_graph.attr(rankdir='TB', bgcolor='transparent')\n",
        "            flow_graph.attr('node', shape='box', style='filled', fontname='helvetica',\n",
        "                           fontcolor='black', fillcolor='palegreen')\n",
        "\n",
        "            # Track nodes we've added\n",
        "            added_nodes = set()\n",
        "\n",
        "            # Aggregate transfers between same addresses\n",
        "            transfer_map = {}\n",
        "\n",
        "            for transfer in pyusd_transfers:\n",
        "                from_addr = transfer['from']\n",
        "                to_addr = transfer['to']\n",
        "                value = transfer['value']\n",
        "\n",
        "                key = (from_addr, to_addr)\n",
        "                if key in transfer_map:\n",
        "                    transfer_map[key] += value\n",
        "                else:\n",
        "                    transfer_map[key] = value\n",
        "\n",
        "            # Add nodes and edges\n",
        "            for (from_addr, to_addr), total_value in transfer_map.items():\n",
        "\n",
        "                if from_addr not in added_nodes:\n",
        "                    flow_graph.node(from_addr, label=from_addr)\n",
        "                    added_nodes.add(from_addr)\n",
        "\n",
        "                if to_addr not in added_nodes:\n",
        "                    flow_graph.node(to_addr, label=to_addr)\n",
        "                    added_nodes.add(to_addr)\n",
        "\n",
        "                value_str = format_value_pyusd(total_value)\n",
        "                flow_graph.edge(from_addr, to_addr, label=value_str)\n",
        "\n",
        "            display(flow_graph)\n",
        "            console.print(\"[info]This graph shows PYUSD transfers within the block.\", style=\"info\")\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create PYUSD transfer network visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "    # Analyze internal transactions\n",
        "    internal_txs = detect_pyusd_internal_transactions(debug_trace_list)\n",
        "    if internal_txs:\n",
        "        console.print(\"\\n\\n[bold green3]üîÑ PYUSD Internal Transactions[/bold green3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"green3\")\n",
        "        console.print(f\"[info]Found {len(internal_txs)} internal transactions involving PYUSD contracts.\", style=\"info\")\n",
        "\n",
        "        # Create a table of internal transactions\n",
        "        console.print(\"\\n\\n[bold cyan3]Internal PYUSD Calls[/bold cyan3]\")\n",
        "\n",
        "        internal_table = Table(title=\"\", title_style=\"bold cyan\")\n",
        "        internal_table.add_column(\"From\", style=\"dim\")\n",
        "        internal_table.add_column(\"To Contract\", style=\"cyan\")\n",
        "        internal_table.add_column(\"Function\")\n",
        "        internal_table.add_column(\"Gas Used\", justify=\"right\")\n",
        "        internal_table.add_column(\"Depth\", justify=\"right\")\n",
        "\n",
        "        # Show a subset if there are many\n",
        "        display_limit = min(10, len(internal_txs))\n",
        "        for i in range(display_limit):\n",
        "            tx = internal_txs[i]\n",
        "            internal_table.add_row(\n",
        "                tx['from'],\n",
        "                tx['to_contract'],\n",
        "                tx['function'],\n",
        "                f\"{tx['gas_used']:,}\",\n",
        "                str(tx['depth'])\n",
        "            )\n",
        "\n",
        "        if len(internal_txs) > display_limit:\n",
        "            internal_table.add_row(\n",
        "                f\"+ {len(internal_txs) - display_limit} more...\",\n",
        "                \"\", \"\", \"\", \"\"\n",
        "            )\n",
        "\n",
        "        console.print(internal_table)\n",
        "\n",
        "    # Display summary table for all transactions with enhanced interactive features\n",
        "    if not summary_df.empty:\n",
        "        console.print(\"\\n[bold chartreuse1]üìã Block Transaction Summary[/bold chartreuse1]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "        # Create filter controls and PYUSD-focused display\n",
        "        # Create PYUSD-only dataframe\n",
        "        pyusd_df = summary_df[summary_df['pyusd_interaction'] == True].copy()\n",
        "\n",
        "        # Filter options above the table\n",
        "        display(widgets.HTML(\"<h4>Filter Options:</h4>\"))\n",
        "\n",
        "        # Keep both buttons - arranged in an HBox for better layout\n",
        "        filter_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Show PYUSD Only',\n",
        "                button_style='success',\n",
        "                layout=widgets.Layout(width='180px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Show All Transactions',\n",
        "                button_style='info',\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        display(filter_buttons)\n",
        "\n",
        "        # Output area for transactions\n",
        "        transaction_output = widgets.Output()\n",
        "\n",
        "        # Export buttons with better styling\n",
        "        export_buttons = widgets.HBox([\n",
        "            widgets.Button(\n",
        "                description='Export to CSV',\n",
        "                button_style='primary',  # Green\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export as JSON',\n",
        "                button_style='warning',  # Orange\n",
        "                layout=widgets.Layout(width='150px')\n",
        "            ),\n",
        "            widgets.Button(\n",
        "                description='Export to Google Sheets',\n",
        "                button_style='info',     # Blue\n",
        "                layout=widgets.Layout(width='200px')\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        export_output = widgets.Output()\n",
        "\n",
        "        # Display columns for better view\n",
        "        display_cols = [\n",
        "            'tx_index', 'from', 'to', 'gas_used',\n",
        "            'pyusd_interaction', 'pyusd_function', 'failed'\n",
        "        ]\n",
        "\n",
        "        # Filter columns that exist\n",
        "        display_cols = [col for col in display_cols if col in summary_df.columns]\n",
        "\n",
        "        def show_all_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                display(summary_df[display_cols])\n",
        "\n",
        "        def show_pyusd_txs(b):\n",
        "            with transaction_output:\n",
        "                clear_output()\n",
        "                if len(pyusd_df) > 0:\n",
        "                    display(pyusd_df[display_cols])\n",
        "                else:\n",
        "                    display(widgets.HTML(\"<p>No PYUSD transactions in this block.</p>\"))\n",
        "\n",
        "        # Export handlers\n",
        "        def export_csv(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame based on which filter is active\n",
        "                current_df = pyusd_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) <= len(str(pyusd_df)) else summary_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_identifier}_transactions_{timestamp}.csv\"\n",
        "                display(download_csv_direct(current_df, filename))\n",
        "\n",
        "        def export_json(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame based on which filter is active\n",
        "                current_df = pyusd_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) <= len(str(pyusd_df)) else summary_df\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"block_{block_identifier}_transactions_{timestamp}.json\"\n",
        "                records = current_df.to_dict('records')\n",
        "                display(download_json_direct(records, filename))\n",
        "\n",
        "        def export_to_sheets(b):\n",
        "            with export_output:\n",
        "                clear_output()\n",
        "                # Use the currently displayed DataFrame based on which filter is active\n",
        "                current_df = pyusd_df if transaction_output.outputs and len(transaction_output.outputs[0]['text/plain']) <= len(str(pyusd_df)) else summary_df\n",
        "                sheet_name = f\"Block {block_identifier} Transactions {datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "                display(export_to_google_sheets_direct(current_df, sheet_name))\n",
        "\n",
        "        # Connect callbacks\n",
        "        filter_buttons.children[0].on_click(show_pyusd_txs)   # PYUSD Only button\n",
        "        filter_buttons.children[1].on_click(show_all_txs)     # Show All button\n",
        "        export_buttons.children[0].on_click(export_csv)\n",
        "        export_buttons.children[1].on_click(export_json)\n",
        "        export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "        # Display transaction table area\n",
        "        display(transaction_output)\n",
        "\n",
        "        # Show PYUSD transactions by default\n",
        "        show_pyusd_txs(None)\n",
        "\n",
        "        # Export section below the table\n",
        "        console.print(\"\\n\\n[bold]Export Options:[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        display(export_buttons)\n",
        "        display(export_output)\n",
        "\n",
        "    # Return the DataFrame for further analysis\n",
        "    return summary_df\n",
        "\n",
        "# --- Execute debug_traceBlockByNumber with enhanced config ---\n",
        "# WARNING: Can be slow. Default to False.\n",
        "RUN_DEBUG_TRACE_BLOCK_NUM = True # <<< SET TO TRUE TO RUN THIS\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_debug_trace_num = TARGET_BLOCK_IDENTIFIER\n",
        "    block_param_num = None\n",
        "\n",
        "    # Format block identifier for debug_traceBlockByNumber (requires hex number string or tag)\n",
        "    if isinstance(block_id_debug_trace_num, int):\n",
        "        block_param_num = hex(block_id_debug_trace_num)\n",
        "    elif isinstance(block_id_debug_trace_num, str):\n",
        "        if block_id_debug_trace_num.startswith(\"0x\") and len(block_id_debug_trace_num) != 66: # Is hex number\n",
        "             block_param_num = block_id_debug_trace_num\n",
        "        elif block_id_debug_trace_num in [\"latest\", \"pending\", \"earliest\"]:\n",
        "            block_param_num = block_id_debug_trace_num\n",
        "        else: # Try converting string int\n",
        "             try:\n",
        "                 block_param_num = hex(int(block_id_debug_trace_num))\n",
        "             except ValueError:\n",
        "                 console.print(f\"[error]Invalid TARGET_BLOCK_IDENTIFIER '{block_id_debug_trace_num}' for debug_traceBlockByNumber. Needs hex number string or tag.\", style=\"error\")\n",
        "\n",
        "    if RUN_DEBUG_TRACE_BLOCK_NUM and block_param_num:\n",
        "        console.print(\"[bold cyan3]üß± Tracing & Analyis via debug_traceBlockByNumber[/bold cyan3]\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        console.print(f\"\\n\\n[warning]Attempting 'debug_traceBlockByNumber' for {block_param_num} on Mainnet (Can be SLOW!)...[/warning]\", style=\"warning\")\n",
        "\n",
        "        # Use the enhanced tracer config for better insights\n",
        "        enhanced_config = {\n",
        "            \"tracer\": \"callTracer\",\n",
        "            \"tracerConfig\": TRACE_CONFIGS[\"callTracer\"]\n",
        "        }\n",
        "\n",
        "        debug_block_num_trace_results = make_rpc_request(\n",
        "            \"debug_traceBlockByNumber\",\n",
        "            [block_param_num, enhanced_config],\n",
        "            network='mainnet'\n",
        "        )\n",
        "\n",
        "        if debug_block_num_trace_results is not None:\n",
        "            block_analysis = analyze_debug_block_trace(debug_block_num_trace_results, block_param_num)\n",
        "\n",
        "            # Add any post-analysis insights here\n",
        "            if block_analysis is not None and 'pyusd_interaction' in block_analysis.columns:\n",
        "                pyusd_txs = block_analysis[block_analysis['pyusd_interaction']]\n",
        "                if not pyusd_txs.empty:\n",
        "                    # Create a histogram of gas usage for PYUSD vs non-PYUSD transactions\n",
        "                    try:\n",
        "                        # Add interaction type column\n",
        "                        block_analysis['interaction_type'] = block_analysis['pyusd_interaction'].apply(\n",
        "                            lambda x: 'PYUSD Transaction' if x else 'Other Transaction'\n",
        "                        )\n",
        "\n",
        "                        console.print(f\"\\n\\n[bold]Gas Usage Distribution in Block: [cyan3]{block_param_num}[/cyan3][/bold]\", style=\"magenta3\")\n",
        "                        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "                        # Create histogram\n",
        "                        fig_gas = px.histogram(\n",
        "                            block_analysis, x='gas_used', color='interaction_type',\n",
        "                            title=f'Gas Usage Distribution in Block {block_param_num}',\n",
        "                            labels={'gas_used': 'Gas Used', 'count': 'Number of Transactions'},\n",
        "                            log_y=True  # Log scale for better visibility of distribution\n",
        "                        )\n",
        "                        fig_gas.update_layout(template=\"plotly_white\")\n",
        "                        fig_gas.show()\n",
        "                    except Exception as viz_err:\n",
        "                        console.print(f\"[warning]Could not create gas usage histogram: {viz_err}\", style=\"warning\")\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to get block trace for {block_param_num} using 'debug_traceBlockByNumber'.\", style=\"error\")\n",
        "\n",
        "    elif not RUN_DEBUG_TRACE_BLOCK_NUM:\n",
        "        console.print(f\"\\n[info]Skipping 'debug_traceBlockByNumber' as RUN_DEBUG_TRACE_BLOCK_NUM is False.\", style=\"info\")\n",
        "    elif not block_param_num:\n",
        "         pass # Error already printed by validation logic\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping debug_traceBlockByNumber analysis.\", style=\"warning\")\n",
        "\n",
        "\n",
        "# --- Execute debug_traceBlockByHash with enhanced config ---\n",
        "# WARNING: Can be slow. Default to False.\n",
        "RUN_DEBUG_TRACE_BLOCK_HASH = True # <<< SET TO TRUE TO RUN THIS\n",
        "\n",
        "if 'TARGET_BLOCK_IDENTIFIER' in locals() and TARGET_BLOCK_IDENTIFIER is not None:\n",
        "    block_id_debug_trace_hash = TARGET_BLOCK_IDENTIFIER\n",
        "    block_hash_param = None\n",
        "\n",
        "    # Need to get the block HASH for this method\n",
        "    try:\n",
        "        console.print(\"\\n\\n[bold]üß± Tracing & Analyis via debug_traceBlockByHash[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "        console.print(f\"\\n\\n[bold cyan3]üì° Querying block info for identifier '{block_id_debug_trace_hash}' to get hash...[bold cyan3]\")\n",
        "        # Use the mainnet client to get block info\n",
        "        if w3_mainnet:\n",
        "            block_info = w3_mainnet.eth.get_block(block_id_debug_trace_hash)\n",
        "            if block_info and 'hash' in block_info:\n",
        "                block_hash_param = block_info['hash'].hex()\n",
        "                console.print(f\"\\n\\n[info]Found block hash: {block_hash_param}\", style=\"info\")\n",
        "            else:\n",
        "                console.print(f\"[error]Could not retrieve block info or hash for identifier '{block_id_debug_trace_hash}'. Block might not exist.\", style=\"error\")\n",
        "        else:\n",
        "             console.print(\"[error]Mainnet client not available to fetch block hash.\", style=\"error\")\n",
        "\n",
        "    except Exception as e:\n",
        "         console.print(f\"[error]Error retrieving block hash for '{block_id_debug_trace_hash}': {e}\", style=\"error\")\n",
        "\n",
        "\n",
        "    if RUN_DEBUG_TRACE_BLOCK_HASH and block_hash_param:\n",
        "        console.print(f\"\\n[warning]Attempting 'debug_traceBlockByHash' for {block_hash_param} on Mainnet (Can be SLOW!)...[/warning]\", style=\"warning\")\n",
        "\n",
        "        # Use the enhanced tracer config\n",
        "        enhanced_config = {\n",
        "            \"tracer\": \"callTracer\",\n",
        "            \"tracerConfig\": TRACE_CONFIGS[\"callTracer\"]\n",
        "        }\n",
        "\n",
        "        debug_block_hash_trace_results = make_rpc_request(\n",
        "            \"debug_traceBlockByHash\",\n",
        "            [block_hash_param, enhanced_config],\n",
        "            network='mainnet'\n",
        "        )\n",
        "\n",
        "        if debug_block_hash_trace_results is not None:\n",
        "            # Analyze with the same function as debug_traceBlockByNumber\n",
        "            block_analysis = analyze_debug_block_trace(debug_block_hash_trace_results, block_hash_param)\n",
        "        else:\n",
        "            console.print(f\"[error]Failed to get block trace for hash {block_hash_param} using 'debug_traceBlockByHash'.\", style=\"error\")\n",
        "\n",
        "    elif not RUN_DEBUG_TRACE_BLOCK_HASH:\n",
        "        console.print(f\"\\n[info]Skipping 'debug_traceBlockByHash' as RUN_DEBUG_TRACE_BLOCK_HASH is False.\", style=\"info\")\n",
        "    elif not block_hash_param:\n",
        "        pass # Error already printed by validation logic\n",
        "\n",
        "else:\n",
        "    console.print(\"[warning]TARGET_BLOCK_IDENTIFIER not set. Skipping debug_traceBlockByHash analysis.\", style=\"warning\")"
      ],
      "metadata": {
        "id": "TYUZoQwtVzrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 üß™ `debug_traceCall`, `eth.call`, `eth.estimate_gas`: Advanced Simulation of PYUSD Transactions\n",
        "---\n",
        "\n",
        "This section utilizes a **multi-stage simulation approach** to analyze potential PYUSD transactions *without* broadcasting them or requiring real gas/ETH. It intelligently combines standard and advanced RPC methods (`eth.call`, `eth.estimate_gas`, and optionally `debug_traceCall`/`trace_call`) to provide comprehensive insights based on a specific block state.\n",
        "\n",
        "This hybrid strategy is incredibly useful for:\n",
        "\n",
        "*   **Pre-flight Validation (`eth.call`):** Quickly checking if a transaction would likely revert due to basic errors (invalid parameters, immediate contract logic failure).\n",
        "*   **Gas Estimation (`eth.estimate_gas`):** Predicting the gas cost *before* sending, allowing for optimization and budget planning. The code uses this as the primary gas source unless a trace provides a more accurate figure.\n",
        "*   **Revert Debugging (`eth.call` Error + Trace):** Understanding *why* a potential transaction might fail by analyzing the initial revert reason or, if tracing is enabled, examining the detailed execution path and internal calls.\n",
        "*   **State Change Analysis (Trace Events):** Observing the potential impact of operations like `transfer` or `approve` by decoding specific events (e.g., `Transfer` event) emitted during the simulated trace.\n",
        "*   **\"What-If\" Analysis & Comparison:** Testing different parameters for PYUSD functions to compare outcomes, gas costs (`eth.estimate_gas`), and execution details (trace).\n",
        "\n",
        "> **üöÄ Leveraging GCP's Premium RPC Capabilities**\n",
        ">\n",
        "> *   **Methods:** `eth.call`, `eth.estimate_gas`, `debug_traceCall` (preferred for tracing), `trace_call` (fallback)\n",
        "> *   **Multiplier for `debug_traceCall`/`trace_call`:** `50x` (Available on Mainnet via GCP)\n",
        "> *   **GCP Advantage:** Simulating complex transactions and obtaining detailed execution traces via `debug_traceCall` (especially those interacting with multiple contracts) is resource-intensive. GCP allows these detailed simulations efficiently on Mainnet.\n",
        "> *   **PYUSD Insight:** This advanced simulation enables:\n",
        ">     *   Robust **pre-flight checks** for PYUSD transfers, approvals, mints, burns.\n",
        ">     *   Comparing the gas cost (`eth.estimate_gas`) of different PYUSD transfer amounts or approval values.\n",
        ">     *   Debugging potential integration issues by simulating calls *from* other contracts *to* the PYUSD contract and analyzing the trace.\n",
        "\n",
        "**Analysis Workflow (as implemented in the code):**\n",
        "\n",
        "1.  **Define Call & Pre-Check:**\n",
        "    *   Constructs the transaction call dictionary (`from`, `to`, `data`, etc.).\n",
        "    *   Performs an optional, preliminary PYUSD balance check (`estimate_pyusd_balance` using `eth.call`) for relevant operations to provide immediate context.\n",
        "2.  **Stage 1: Basic Simulation (`eth.call`):**\n",
        "    *   *Always* executes `eth.call` first to get an immediate success/fail status and potential revert data.\n",
        "3.  **Stage 2: Gas Estimation (`eth.estimate_gas`):**\n",
        "    *   If `eth.call` succeeded OR failed *only* due to insufficient balance (indicating the logic is otherwise sound), it attempts `eth.estimate_gas` to get the predicted gas cost. This value is stored as the primary `gas_used`.\n",
        "4.  **Stage 3: Detailed Tracing (Optional - `debug_traceCall`/`trace_call`):**\n",
        "    *   If `use_trace=True` and the simulation is plausible (success or hypothetical success from Stage 2), it attempts detailed tracing.\n",
        "    *   It prioritizes `debug_traceCall`, using the `make_rpc_request` helper to try multiple parameter formats for maximum compatibility (essential for providers like GCP).\n",
        "    *   If `debug_traceCall` fails across formats, it attempts `trace_call` as a fallback.\n",
        "5.  **Analyze & Assemble Results:**\n",
        "    *   The `simulate_pyusd_transaction` function gathers results into an `analysis` dictionary.\n",
        "    *   It decodes known ERC-20/PYUSD errors from `eth.call` failures.\n",
        "    *   It categorizes gas usage based on the estimated gas and function type.\n",
        "    *   **If a trace was successful:** It parses the `trace_result` to potentially refine `gas_used` (if available in trace), extract internal calls, and identify `state_changes` by decoding specific emitted events (like PYUSD `Transfer` logs) found within the trace.\n",
        "    *   It decodes the return `output` for view functions (like `balanceOf`).\n",
        "6.  **Visualize & Export:**\n",
        "    *   Uses `display_simulation_analysis` to present a structured summary: function details, execution results (status, gas, errors, decoded output), state changes (from trace events), and transaction flow diagrams.\n",
        "    *   Leverages `compare_pyusd_transactions` and `batch_simulate_pyusd_transactions` for multi-run analysis with comparison tables and charts.\n",
        "    *   Provides export options (CSV, JSON, Google Sheets) via helper functions.\n",
        "\n",
        "**üí° What to Look For:**\n",
        "\n",
        "*   **Status:** Did `eth.call` succeed? If not, what was the decoded error? Is it a \"Hypothetical Success\" (meaning `eth.estimate_gas` worked even if the initial balance was too low)?\n",
        "*   **Gas Used:** What is the `eth.estimate_gas` value? Was it refined by a value from the trace? How does it compare across different parameters (in comparison mode)?\n",
        "*   **Gas Profile:** How does the gas usage categorize (Efficient, Medium, High) for this type of operation?\n",
        "*   **Decoded Output:** For view functions (`balanceOf`, `allowance`), what is the simulated return value?\n",
        "*   **State Changes (from Trace):** If tracing was enabled, were any key events (like `Transfer`) detected in the execution trace, indicating simulated state modifications?\n",
        "*   **Internal Calls (from Trace):** Does the trace reveal calls made by the PYUSD contract to other contracts?"
      ],
      "metadata": {
        "id": "MJEWElUzqMwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================================\n",
        "# üß™ Advanced PYUSD Transaction Simulation with Trace Analysis\n",
        "# =============================================================================================\n",
        "# This cell provides comprehensive simulation and analysis for PYUSD transactions on Ethereum.\n",
        "# Features:\n",
        "# - Hybrid simulation approach using eth.call and trace_call for reliability\n",
        "# - Transaction parameter optimization and gas estimation\n",
        "# - Rich visual analysis of transaction effects and gas usage\n",
        "# - Multi-format export capabilities (CSV, JSON, Google Sheets)\n",
        "# - Advanced error decoding and meaningful diagnostics\n",
        "# - Support for multiple transaction types and batched operations\n",
        "\n",
        "from web3 import Web3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "from rich.layout import Layout\n",
        "from rich.console import Group\n",
        "from rich.rule import Rule\n",
        "from rich import box\n",
        "from graphviz import Digraph\n",
        "import matplotlib.pyplot as plt\n",
        "from rich.theme import Theme\n",
        "\n",
        "# Auto-adapting color theme that works well in both light and dark terminals\n",
        "custom_theme = Theme({\n",
        "    \"info\": \"cyan3\",\n",
        "    \"success\": \"spring_green3\",\n",
        "    \"warning\": \"gold3\",\n",
        "    \"error\": \"red3\",\n",
        "    \"highlight\": \"royal_blue1\"\n",
        "})\n",
        "\n",
        "# Initialize Rich console with the theme\n",
        "console = Console(theme=custom_theme)\n",
        "\n",
        "# =============================================================================================\n",
        "# üìä Visualization Functions\n",
        "# =============================================================================================\n",
        "\n",
        "def create_gas_comparison_chart(results, function_name):\n",
        "    \"\"\"Create a matplotlib bar chart comparing gas usage.\n",
        "\n",
        "    Args:\n",
        "        results: List of simulation results\n",
        "        function_name: Name of the function being compared\n",
        "\n",
        "    Returns:\n",
        "        Success status boolean\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Prepare data for visualization\n",
        "        gas_data = []\n",
        "        for result in results:\n",
        "            if result[\"success\"] or result.get(\"hypothetical_success\", False):\n",
        "                gas_data.append({\n",
        "                    \"variant\": result[\"variant\"],\n",
        "                    \"gas_used\": result[\"gas_used\"],\n",
        "                    \"category\": result.get(\"gas_category\", \"Unknown\")\n",
        "                })\n",
        "\n",
        "        if not gas_data:\n",
        "            return False\n",
        "\n",
        "        # Create dataframe\n",
        "        gas_df = pd.DataFrame(gas_data)\n",
        "\n",
        "        # Print header\n",
        "        console.print(\"\\n\\n[bold]‚õΩ Gas Usage Comparison Chart:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create figure and axis\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        # Plot the bars\n",
        "        bars = ax.bar(gas_df['variant'], gas_df['gas_used'], color='steelblue')\n",
        "\n",
        "        # Add value labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{int(height):,}',\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "        # Add chart styling\n",
        "        ax.set_title(f'Gas Usage Comparison - {function_name}()', fontsize=14, pad=20)\n",
        "        ax.set_xlabel('Variant(s)', fontsize=12)\n",
        "        ax.set_ylabel('Gas Used', fontsize=12)\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the chart\n",
        "        plt.show()\n",
        "\n",
        "        # If we have multiple results, also create a relative cost comparison\n",
        "        if len(gas_data) > 1:\n",
        "            # Find minimum gas cost as baseline\n",
        "            min_gas = min(item[\"gas_used\"] for item in gas_data)\n",
        "            rel_data = []\n",
        "            for item in gas_data:\n",
        "                rel_data.append({\n",
        "                    \"variant\": item[\"variant\"],\n",
        "                    \"relative_cost\": item[\"gas_used\"] / min_gas\n",
        "                })\n",
        "\n",
        "            rel_df = pd.DataFrame(rel_data)\n",
        "\n",
        "            # Create a new figure for relative comparison\n",
        "            console.print(\"\\n\\n[bold]‚õΩ Relative Gas Cost Comparison:[/bold]\", style=\"magenta3\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "            # Plot the relative bars\n",
        "            rel_bars = ax2.bar(rel_df['variant'], rel_df['relative_cost'], color='lightcoral')\n",
        "\n",
        "            # Add value labels\n",
        "            for bar in rel_bars:\n",
        "                height = bar.get_height()\n",
        "                ax2.annotate(f'{height:.2f}x',\n",
        "                            xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                            xytext=(0, 3),  # 3 points vertical offset\n",
        "                            textcoords=\"offset points\",\n",
        "                            ha='center', va='bottom')\n",
        "\n",
        "            # Add chart styling\n",
        "            ax2.set_title('Relative Gas Cost Comparison', fontsize=14, pad=20)\n",
        "            ax2.set_xlabel('Variant', fontsize=12)\n",
        "            ax2.set_ylabel('Relative Cost (1.0 = Cheapest)', fontsize=12)\n",
        "            ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "            # Adjust layout\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Display the chart\n",
        "            plt.show()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create gas comparison chart: {viz_err}\", style=\"warning\")\n",
        "        import traceback\n",
        "        console.print(f\"[dim]{traceback.format_exc()}[/dim]\")\n",
        "        return False\n",
        "\n",
        "def create_batch_gas_chart(results, total_gas):\n",
        "    \"\"\"Create a matplotlib bar chart for batch operations gas usage.\n",
        "\n",
        "    Args:\n",
        "        results: List of simulation results\n",
        "        total_gas: Total gas used by the batch\n",
        "\n",
        "    Returns:\n",
        "        Success status boolean\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if len(results) <= 1:\n",
        "            return False\n",
        "\n",
        "        # Prepare data\n",
        "        gas_data = []\n",
        "        for i, result in enumerate(results):\n",
        "            op_name = f\"{i+1}. {result['function']}\"\n",
        "            gas_data.append({\n",
        "                \"operation\": op_name,\n",
        "                \"gas_used\": result['gas_used']\n",
        "            })\n",
        "\n",
        "        # Create dataframe\n",
        "        gas_df = pd.DataFrame(gas_data)\n",
        "\n",
        "        # Print header\n",
        "        console.print(\"\\n\\n[bold]‚õΩ Batch Operations Gas Usage:[/bold]\", style=\"magenta3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "        # Create figure and axis\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "        # Plot the bars\n",
        "        bars = ax.bar(gas_df['operation'], gas_df['gas_used'], color='steelblue')\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.annotate(f'{int(height):,}',\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom')\n",
        "\n",
        "        # Add total gas line\n",
        "        ax.axhline(y=total_gas, color='r', linestyle='--', linewidth=2)\n",
        "\n",
        "        # Add total gas annotation\n",
        "        ax.annotate(f'Total Gas: {total_gas:,}',\n",
        "                    xy=(len(results)/2 - 0.5, total_gas),\n",
        "                    xytext=(0, 10),\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom',\n",
        "                    color='red', fontsize=12,\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"red\", alpha=0.8))\n",
        "\n",
        "        # Add chart styling\n",
        "        ax.set_title('Batch Operations Gas Usage', fontsize=14, pad=20)\n",
        "        ax.set_xlabel('Operation', fontsize=12)\n",
        "        ax.set_ylabel('Gas Used', fontsize=12)\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        # Rotate x-axis labels for better readability\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the chart\n",
        "        plt.show()\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as viz_err:\n",
        "        console.print(f\"[warning]Could not create batch gas chart: {viz_err}\", style=\"warning\")\n",
        "        import traceback\n",
        "        console.print(f\"[dim]{traceback.format_exc()}[/dim]\")\n",
        "        return False\n",
        "\n",
        "# =============================================================================================\n",
        "# üìã Export Functions\n",
        "# =============================================================================================\n",
        "\n",
        "def download_csv_direct(df, filename=None):\n",
        "    \"\"\"Creates a direct download for CSV without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_simulation_{timestamp}.csv\"\n",
        "\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:text/csv;base64,{payload}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def download_json_direct(data, filename=None):\n",
        "    \"\"\"Creates a direct download for JSON without intermediate display.\"\"\"\n",
        "    if filename is None:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"pyusd_simulation_{timestamp}.json\"\n",
        "\n",
        "    # Custom JSON encoder that handles NumPy types\n",
        "    class NumpyEncoder(json.JSONEncoder):\n",
        "        def default(self, obj):\n",
        "            if isinstance(obj, np.ndarray):\n",
        "                return obj.tolist()\n",
        "            if isinstance(obj, np.integer):\n",
        "                return int(obj)\n",
        "            if isinstance(obj, np.floating):\n",
        "                return float(obj)\n",
        "            if isinstance(obj, (np.bool_)):\n",
        "                return bool(obj)\n",
        "            return super().default(obj)\n",
        "\n",
        "    # Convert to JSON string with custom encoder\n",
        "    json_str = json.dumps(data, default=str, indent=2, cls=NumpyEncoder)\n",
        "    b64 = base64.b64encode(json_str.encode()).decode()\n",
        "\n",
        "    # Create direct download HTML\n",
        "    html = f'''\n",
        "    <script>\n",
        "    function download(filename, data) {{\n",
        "        const a = document.createElement('a');\n",
        "        a.href = data;\n",
        "        a.download = filename;\n",
        "        document.body.appendChild(a);\n",
        "        a.click();\n",
        "        document.body.removeChild(a);\n",
        "    }}\n",
        "\n",
        "    download(\"{filename}\", \"data:application/json;base64,{b64}\");\n",
        "    </script>\n",
        "    <div>Downloading {filename}...</div>\n",
        "    '''\n",
        "    return HTML(html)\n",
        "\n",
        "def export_to_google_sheets(df, data_dict, simulation_title):\n",
        "    \"\"\"Export simulation data to Google Sheets with rich formatting.\"\"\"\n",
        "    # Show loading message\n",
        "    console.print(\"[info]Exporting to Google Sheets...\", style=\"info\")\n",
        "\n",
        "    try:\n",
        "        # Create a new Google Sheet with meaningful title\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        sheet_title = f\"PYUSD Simulation {simulation_title} {timestamp}\"\n",
        "\n",
        "        # Use the global gc_sheets client that's already authenticated\n",
        "        spreadsheet = gc_sheets.create(sheet_title)\n",
        "\n",
        "        # Get the default worksheet and rename it\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update_title(\"Simulation Results\")\n",
        "\n",
        "        # Set up a header with transaction info\n",
        "        header_values = [\n",
        "            [\"PYUSD Transaction Simulation Analysis\"],\n",
        "            [f\"Simulation: {simulation_title}\"],\n",
        "            [f\"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"],\n",
        "            [\"\"],  # Empty row for spacing\n",
        "        ]\n",
        "        worksheet.update(\"A1\", header_values)\n",
        "\n",
        "        # Format the header with bold text and colored background\n",
        "        worksheet.format(\"A1:A1\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 14},\n",
        "            \"backgroundColor\": {\"red\": 0.9, \"green\": 0.9, \"blue\": 1.0}\n",
        "        })\n",
        "\n",
        "        worksheet.format(\"A2:A3\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12}\n",
        "        })\n",
        "\n",
        "        current_row = 5  # Start after header\n",
        "\n",
        "        # Add transaction stats summary\n",
        "        if \"summary\" in data_dict:\n",
        "            stats = data_dict[\"summary\"]\n",
        "\n",
        "            # Add section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Analysis Summary\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.9, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # Add stats data\n",
        "            stats_rows = []\n",
        "            stats_rows.append([\"Metric\", \"Value\"])  # Header row\n",
        "            for key, value in stats.items():\n",
        "                # Format keys and values appropriately\n",
        "                formatted_key = key.replace(\"_\", \" \").title()\n",
        "\n",
        "                # Try to format numerical values with commas\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        formatted_value = f\"{value:,}\"\n",
        "                    else:\n",
        "                        formatted_value = str(value)\n",
        "                except:\n",
        "                    formatted_value = str(value)\n",
        "\n",
        "                stats_rows.append([formatted_key, formatted_value])\n",
        "\n",
        "            # Add stats table\n",
        "            stats_start_row = current_row\n",
        "            worksheet.update(f\"A{stats_start_row}\", stats_rows)\n",
        "\n",
        "            # Format stats table header\n",
        "            worksheet.format(f\"A{stats_start_row}:B{stats_start_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            current_row += len(stats_rows) + 2  # Add extra space after table\n",
        "\n",
        "        # Add gas analysis reference\n",
        "        worksheet.update(f\"A{current_row}\", [[\"Gas Usage Analysis\"]])\n",
        "        worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "            \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "            \"backgroundColor\": {\"red\": 1.0, \"green\": 0.9, \"blue\": 0.7}\n",
        "        })\n",
        "        current_row += 1\n",
        "\n",
        "        worksheet.update(f\"A{current_row}\", [[\"üìä Gas usage visualizations are available in the notebook\"]])\n",
        "        current_row += 2\n",
        "\n",
        "        # Add main DataFrame data\n",
        "        if not df.empty:\n",
        "            # Add a section title\n",
        "            worksheet.update(f\"A{current_row}\", [[\"Simulation Data\"]])\n",
        "            worksheet.format(f\"A{current_row}:A{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True, \"fontSize\": 12},\n",
        "                \"backgroundColor\": {\"red\": 0.8, \"green\": 0.8, \"blue\": 1.0}\n",
        "            })\n",
        "            current_row += 1\n",
        "\n",
        "            # For simulation data, select most important columns for readability\n",
        "            if len(df.columns) > 10:\n",
        "                key_cols = [\"variant\", \"function\", \"from\", \"to\", \"amount\", \"gas_used\", \"status\", \"error\"]\n",
        "                display_cols = [col for col in key_cols if col in df.columns]\n",
        "\n",
        "                # Add any custom columns that might contain analysis results\n",
        "                other_important_cols = []\n",
        "                for col in df.columns:\n",
        "                    if col not in display_cols and any(x in col.lower() for x in [\"pyusd\", \"token\", \"note\", \"category\"]):\n",
        "                        other_important_cols.append(col)\n",
        "\n",
        "                display_cols.extend(other_important_cols)\n",
        "                display_df = df[display_cols]\n",
        "            else:\n",
        "                display_df = df\n",
        "\n",
        "            # Convert DataFrame to list of lists for the worksheet\n",
        "            df_values = [display_df.columns.tolist()] + display_df.values.tolist()\n",
        "\n",
        "            # Format values for better readability\n",
        "            for i in range(1, len(df_values)):\n",
        "                for j, col in enumerate(display_df.columns):\n",
        "                    val = df_values[i][j]\n",
        "\n",
        "                    # Format different column types appropriately\n",
        "                    if pd.isnull(val):\n",
        "                        df_values[i][j] = \"\"\n",
        "                    elif col in [\"gas_used\", \"amount\"] and isinstance(val, (int, float)):\n",
        "                        df_values[i][j] = f\"{val:,}\"\n",
        "                    else:\n",
        "                        df_values[i][j] = str(val)\n",
        "\n",
        "            worksheet.update(f\"A{current_row}\", df_values)\n",
        "\n",
        "            # Format the DataFrame header\n",
        "            worksheet.format(f\"A{current_row}:{chr(65+len(display_df.columns)-1)}{current_row}\", {\n",
        "                \"textFormat\": {\"bold\": True},\n",
        "                \"backgroundColor\": {\"red\": 0.95, \"green\": 0.95, \"blue\": 0.95}\n",
        "            })\n",
        "\n",
        "            # Add alternating row colors for readability\n",
        "            data_rows = len(df_values)\n",
        "            for i in range(2, data_rows + 1, 2):\n",
        "                row_num = current_row + i - 1\n",
        "                worksheet.format(f\"A{row_num}:{chr(65+len(display_df.columns)-1)}{row_num}\", {\n",
        "                    \"backgroundColor\": {\"red\": 0.97, \"green\": 0.97, \"blue\": 1.0}\n",
        "                })\n",
        "\n",
        "        # Try to auto-resize columns for better readability\n",
        "        try:\n",
        "            worksheet.columns_auto_resize(0, 10)  # Resize first 10 columns\n",
        "        except:\n",
        "            pass  # Ignore if not supported\n",
        "\n",
        "        # Clear loading message and show success message\n",
        "        clear_output()\n",
        "        console.print(\"‚úì Successfully exported to Google Sheets\", style=\"success\")\n",
        "\n",
        "        # Open the spreadsheet in a new tab\n",
        "        spreadsheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "        html = f'''\n",
        "        <script>\n",
        "        window.open(\"{spreadsheet_url}\", \"_blank\");\n",
        "        </script>\n",
        "        <div>Spreadsheet created and opened: <a href=\"{spreadsheet_url}\" target=\"_blank\">{sheet_title}</a></div>\n",
        "        '''\n",
        "        return HTML(html)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clear loading message and show error\n",
        "        clear_output()\n",
        "        console.print(f\"‚ùå Error creating Google Sheet: {str(e)}\", style=\"error\")\n",
        "        return HTML(f\"<div style='color:red'>Error creating Google Sheet: {str(e)}</div>\")\n",
        "\n",
        "def create_comparison_export(results, function_name, from_addr):\n",
        "    \"\"\"Creates export options for comparison results.\"\"\"\n",
        "    # Create a DataFrame from results\n",
        "    comp_df = pd.DataFrame(results)\n",
        "\n",
        "    # Format params for better readability\n",
        "    comp_df['formatted_params'] = comp_df['params'].apply(lambda x: ', '.join([str(p) for p in x]))\n",
        "\n",
        "    # Create export output area\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Create export buttons with styling\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Define export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_comparison_{function_name}_{timestamp}.csv\"\n",
        "            # Create a clean export DataFrame\n",
        "            export_cols = ['variant', 'formatted_params', 'success', 'hypothetical_success', 'gas_used', 'gas_category', 'error']\n",
        "            export_df = comp_df[export_cols]\n",
        "            # Rename columns for clarity\n",
        "            export_df.columns = ['Variant', 'Parameters', 'Success', 'Hypothetical Success', 'Gas Used', 'Gas Profile', 'Error']\n",
        "            display(download_csv_direct(export_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_comparison_{function_name}_{timestamp}.json\"\n",
        "\n",
        "            # Create a clean export data structure\n",
        "            export_data = {\n",
        "                \"comparison_type\": \"PYUSD Transaction Comparison\",\n",
        "                \"function\": function_name,\n",
        "                \"from_address\": from_addr,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"variants\": []\n",
        "            }\n",
        "\n",
        "            # Format each variant result\n",
        "            for result in results:\n",
        "                variant_data = {\n",
        "                    \"variant\": result[\"variant\"],\n",
        "                    \"parameters\": [str(p) for p in result[\"params\"]],\n",
        "                    \"success\": result[\"success\"],\n",
        "                    \"hypothetical_success\": result.get(\"hypothetical_success\", False),\n",
        "                    \"gas_used\": result[\"gas_used\"],\n",
        "                    \"gas_category\": result.get(\"gas_category\", \"Unknown\")\n",
        "                }\n",
        "\n",
        "                if result[\"error\"]:\n",
        "                    variant_data[\"error\"] = result[\"error\"]\n",
        "\n",
        "                export_data[\"variants\"].append(variant_data)\n",
        "\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                # Create a clean export DataFrame\n",
        "                export_cols = ['variant', 'formatted_params', 'success', 'hypothetical_success', 'gas_used', 'gas_category', 'error']\n",
        "                export_df = comp_df[export_cols]\n",
        "                # Rename columns for clarity\n",
        "                export_df.columns = ['Variant', 'Parameters', 'Success', 'Hypothetical Success', 'Gas Used', 'Gas Profile', 'Error']\n",
        "\n",
        "                # Create summary data\n",
        "                summary_data = {\n",
        "                    \"summary\": {\n",
        "                        \"function\": function_name,\n",
        "                        \"from_address\": from_addr,\n",
        "                        \"timestamp\": datetime.now().isoformat(),\n",
        "                        \"variants_compared\": len(results),\n",
        "                        \"successful_variants\": sum(1 for r in results if r[\"success\"] or r.get(\"hypothetical_success\", False))\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                display(export_to_google_sheets(export_df, summary_data, f\"Comparison {function_name}()\"))\n",
        "            except Exception as e:\n",
        "                console.print(f\"[error]Error exporting to Google Sheets: {e}\", style=\"error\")\n",
        "                # Fallback to CSV export\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"pyusd_comparison_{function_name}_{timestamp}.csv\"\n",
        "                export_cols = ['variant', 'formatted_params', 'success', 'hypothetical_success', 'gas_used', 'gas_category', 'error']\n",
        "                export_df = comp_df[export_cols]\n",
        "                export_df.columns = ['Variant', 'Parameters', 'Success', 'Hypothetical Success', 'Gas Used', 'Gas Profile', 'Error']\n",
        "                display(download_csv_direct(export_df, filename))\n",
        "                display(HTML(f\"<div style='color:orange'>Falling back to CSV download due to Google Sheets error: {str(e)}</div>\"))\n",
        "\n",
        "    # Connect handlers to buttons\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    # Display export section\n",
        "    console.print(\"\\n\\n[bold]üì§ Export Options:[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "def create_batch_export(results, from_addr):\n",
        "    \"\"\"Creates export options for batch simulation results.\"\"\"\n",
        "    # Create a DataFrame from results\n",
        "    batch_data = []\n",
        "\n",
        "    for i, result in enumerate(results):\n",
        "        # Create a row for each operation\n",
        "        batch_data.append({\n",
        "            \"operation\": i+1,\n",
        "            \"function\": result['function'],\n",
        "            \"params\": str(result['params']),\n",
        "            \"status\": \"Success\" if result['success'] else \"Hypothetical\" if result.get('hypothetical_success', False) else \"Failed\",\n",
        "            \"gas_used\": result['gas_used'],\n",
        "            \"gas_category\": result.get('gas_category', 'Unknown'),\n",
        "            \"error\": result['error'] if result['error'] else \"None\"\n",
        "        })\n",
        "\n",
        "    batch_df = pd.DataFrame(batch_data)\n",
        "\n",
        "    # Create export output area\n",
        "    export_output = widgets.Output()\n",
        "\n",
        "    # Create export buttons with styling\n",
        "    export_buttons = widgets.HBox([\n",
        "        widgets.Button(\n",
        "            description='Export Batch to CSV',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export Batch as JSON',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='180px')\n",
        "        ),\n",
        "        widgets.Button(\n",
        "            description='Export to Google Sheets',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='190px')\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    # Define export handlers\n",
        "    def export_csv(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_batch_simulation_{timestamp}.csv\"\n",
        "            display(download_csv_direct(batch_df, filename))\n",
        "\n",
        "    def export_json(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = f\"pyusd_batch_simulation_{timestamp}.json\"\n",
        "\n",
        "            # Calculate batch statistics\n",
        "            batch_size = len(results)\n",
        "            successful_ops = sum(1 for r in results if r['success'] or r.get('hypothetical_success', False))\n",
        "            total_gas = sum(r['gas_used'] for r in results)\n",
        "\n",
        "            # Create a clean export data structure\n",
        "            export_data = {\n",
        "                \"simulation_type\": \"PYUSD Batch Transaction\",\n",
        "                \"from_address\": from_addr,\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"summary\": {\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"successful_operations\": successful_ops,\n",
        "                    \"success_rate\": f\"{(successful_ops/batch_size)*100:.1f}%\",\n",
        "                    \"total_gas\": total_gas\n",
        "                },\n",
        "                \"operations\": []\n",
        "            }\n",
        "\n",
        "            # Format each operation result\n",
        "            for i, result in enumerate(results):\n",
        "                op_data = {\n",
        "                    \"index\": i+1,\n",
        "                    \"function\": result[\"function\"],\n",
        "                    \"parameters\": [str(p) for p in result[\"params\"]],\n",
        "                    \"success\": result[\"success\"],\n",
        "                    \"hypothetical_success\": result.get(\"hypothetical_success\", False),\n",
        "                    \"gas_used\": result[\"gas_used\"],\n",
        "                    \"gas_category\": result.get(\"gas_category\", \"Unknown\")\n",
        "                }\n",
        "\n",
        "                if result[\"error\"]:\n",
        "                    op_data[\"error\"] = result[\"error\"]\n",
        "\n",
        "                export_data[\"operations\"].append(op_data)\n",
        "\n",
        "            display(download_json_direct(export_data, filename))\n",
        "\n",
        "    def export_to_sheets(b):\n",
        "        with export_output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                # Calculate batch statistics\n",
        "                batch_size = len(results)\n",
        "                successful_ops = sum(1 for r in results if r['success'] or r.get('hypothetical_success', False))\n",
        "                total_gas = sum(r['gas_used'] for r in results)\n",
        "\n",
        "                # Prepare export data\n",
        "                simulation_title = f\"Batch {batch_size} operations\"\n",
        "\n",
        "                # Create summary data\n",
        "                summary_data = {\n",
        "                    \"summary\": {\n",
        "                        \"from_address\": from_addr,\n",
        "                        \"timestamp\": datetime.now().isoformat(),\n",
        "                        \"batch_size\": batch_size,\n",
        "                        \"successful_operations\": successful_ops,\n",
        "                        \"success_rate\": f\"{(successful_ops/batch_size)*100:.1f}%\",\n",
        "                        \"total_gas\": total_gas\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                display(export_to_google_sheets(batch_df, summary_data, simulation_title))\n",
        "            except Exception as e:\n",
        "                console.print(f\"[error]Error exporting to Google Sheets: {e}\", style=\"error\")\n",
        "                # Fallback to CSV export\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                filename = f\"pyusd_batch_simulation_{timestamp}.csv\"\n",
        "                display(download_csv_direct(batch_df, filename))\n",
        "                display(HTML(f\"<div style='color:orange'>Falling back to CSV download due to Google Sheets error: {str(e)}</div>\"))\n",
        "\n",
        "    # Connect handlers to buttons\n",
        "    export_buttons.children[0].on_click(export_csv)\n",
        "    export_buttons.children[1].on_click(export_json)\n",
        "    export_buttons.children[2].on_click(export_to_sheets)\n",
        "\n",
        "    # Display export section\n",
        "    console.print(\"\\n\\n[bold]üì§ Batch Export Options:[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "    display(export_buttons)\n",
        "    display(export_output)\n",
        "\n",
        "# =============================================================================================\n",
        "# üìã Simulation Helpers\n",
        "# =============================================================================================\n",
        "\n",
        "def decode_erc20_error(error_code):\n",
        "    \"\"\"Decodes common ERC-20 error codes into human-readable messages.\"\"\"\n",
        "    known_errors = {\n",
        "        # Common ERC-20 error selectors\n",
        "        \"0x08c379a0\": \"Error string\",\n",
        "        \"0x356680b7\": \"ERC20: transfer amount exceeds balance\",\n",
        "        \"0x4e487b71\": \"Panic/Arithmetic error\",\n",
        "        \"0x01336cea\": \"ERC20: transfer from the zero address\",\n",
        "        \"0xbbc67f8f\": \"ERC20: transfer to the zero address\",\n",
        "        \"0x7939f424\": \"ERC20: approve from the zero address\",\n",
        "        \"0xd505accf\": \"ERC20: permit expired\",\n",
        "        \"0xdab70cb7\": \"ERC20: insufficient allowance\",\n",
        "        \"0xd1bebf0c\": \"ERC20: transfer to the zero address\",\n",
        "        \"0x8baa579f\": \"ERC20: invalid signature\",\n",
        "        \"0x0827a183\": \"ERC20Permit: expired deadline\",\n",
        "        \"0x8f4eb604\": \"ERC20Permit: invalid signature\",\n",
        "        \"0x3b8da488\": \"AccessControl: account is missing role\",\n",
        "        \"0x219f5d17\": \"Token operation is paused\",\n",
        "        \"0xf0019fe6\": \"Address is blacklisted\",\n",
        "        \"0x1bb2a6b6\": \"ERC20: cannot approve from the zero address\",\n",
        "        \"0x710086b0\": \"ERC20: cannot approve to the zero address\"\n",
        "    }\n",
        "\n",
        "    if error_code in known_errors:\n",
        "        return known_errors[error_code]\n",
        "    return f\"Unknown error code: {error_code}\"\n",
        "\n",
        "def categorize_gas_usage(function_name, gas_used):\n",
        "    \"\"\"Categorizes gas usage based on function type for better analysis.\"\"\"\n",
        "    # Define gas usage categories\n",
        "    gas_categories = {\n",
        "        \"Basic Transfer\": [\"transfer\"],\n",
        "        \"Authorization\": [\"approve\", \"increaseAllowance\", \"decreaseAllowance\", \"permit\", \"transferWithAuthorization\"],\n",
        "        \"Advanced Transfer\": [\"transferFrom\"],\n",
        "        \"Supply Management\": [\"mint\", \"burn\"],\n",
        "        \"Administrative\": [\"pause\", \"unpause\", \"transferOwnership\", \"renounceOwnership\"],\n",
        "        \"Query\": [\"balanceOf\", \"allowance\", \"totalSupply\", \"decimals\", \"name\", \"symbol\", \"paused\", \"owner\"]\n",
        "    }\n",
        "\n",
        "    for category, functions in gas_categories.items():\n",
        "        if function_name in functions:\n",
        "            # Add context based on gas amount\n",
        "            if gas_used > 80000:\n",
        "                return f\"{category} (High Gas)\"\n",
        "            elif gas_used > 40000:\n",
        "                return f\"{category} (Medium Gas)\"\n",
        "            else:\n",
        "                return f\"{category} (Efficient)\"\n",
        "\n",
        "    return \"Other Operation\"\n",
        "\n",
        "def make_rpc_request(method, params, network='mainnet'):\n",
        "    \"\"\"Helper function to make raw RPC requests via the specified network's provider.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "    try:\n",
        "        response = w3_client.provider.make_request(method, params)\n",
        "        if 'error' in response:\n",
        "            console.print(f\"[error]RPC Error ({method} on {network}): {response['error']['message']} (Code: {response['error']['code']})\", style=\"error\")\n",
        "            # console.print(response['error']) # Uncomment for full error details\n",
        "            return None\n",
        "        return response.get('result') # Return None if 'result' key is missing\n",
        "    except Exception as e:\n",
        "        console.print(f\"[error]Exception during RPC call ({method} on {network}): {str(e)}\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================================\n",
        "# üîÑ Core Simulation Functions\n",
        "# =============================================================================================\n",
        "\n",
        "def create_pyusd_call_data(function_name, *params):\n",
        "    \"\"\"Creates encoded call data for PYUSD contract functions.\"\"\"\n",
        "    # Use PYUSD_SIGNATURES from the configuration cell\n",
        "    signatures = {}\n",
        "    for selector, sig_info in PYUSD_SIGNATURES.items():\n",
        "        name = sig_info[\"name\"].split(\"(\")[0]  # Extract function name\n",
        "        param_types = []\n",
        "        param_section = sig_info[\"name\"].split(\"(\")[1].rstrip(\")\")\n",
        "        if param_section:\n",
        "            param_types = param_section.split(\",\")\n",
        "        signatures[name] = {\n",
        "            'selector': selector[2:] if selector.startswith(\"0x\") else selector,\n",
        "            'params': param_types\n",
        "        }\n",
        "\n",
        "    if function_name not in signatures:\n",
        "        raise ValueError(f\"Unsupported function: {function_name}\")\n",
        "\n",
        "    sig = signatures[function_name]\n",
        "    if len(params) != len(sig['params']):\n",
        "        raise ValueError(f\"Expected {len(sig['params'])} parameters for {function_name}, got {len(params)}\")\n",
        "\n",
        "    # Start with function selector\n",
        "    call_data = sig['selector']\n",
        "\n",
        "    # Add encoded parameters\n",
        "    for i, param_type in enumerate(sig['params']):\n",
        "        param_value = params[i]\n",
        "\n",
        "        if param_type == 'address':\n",
        "            # Ensure it's a valid address\n",
        "            addr = Web3.to_checksum_address(param_value)\n",
        "            # Remove 0x prefix and pad to 32 bytes\n",
        "            encoded_param = addr[2:].lower().zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "        elif param_type == 'uint256':\n",
        "            # Convert to raw integer value\n",
        "            if isinstance(param_value, float) and function_name in ['transfer', 'approve', 'transferFrom', 'mint', 'burn']:\n",
        "                # For amounts, convert from PYUSD to raw value\n",
        "                decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "                raw_value = int(param_value * (10**decimals))\n",
        "            else:\n",
        "                raw_value = int(param_value)\n",
        "\n",
        "            # Convert to hex without 0x prefix and pad to 32 bytes\n",
        "            encoded_param = hex(raw_value)[2:].zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "        elif param_type == 'bool':\n",
        "            # Encode boolean as 0 or 1 padded to 32 bytes\n",
        "            encoded_param = (1 if param_value else 0)\n",
        "            encoded_param = hex(encoded_param)[2:].zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "        elif param_type == 'bytes32':\n",
        "            # Ensure bytes32 is properly formatted\n",
        "            if isinstance(param_value, str):\n",
        "                if param_value.startswith('0x'):\n",
        "                    param_value = param_value[2:]\n",
        "                encoded_param = param_value.zfill(64)\n",
        "            else:\n",
        "                encoded_param = hex(param_value)[2:].zfill(64)\n",
        "            call_data += encoded_param\n",
        "\n",
        "    return '0x' + call_data\n",
        "\n",
        "def estimate_pyusd_balance(address, block=\"latest\", network='mainnet'):\n",
        "    \"\"\"Estimates PYUSD balance for an address using eth.call.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        address = Web3.to_checksum_address(address)\n",
        "        pyusd_address = PYUSD_CONFIG['ethereum']['address']\n",
        "\n",
        "        # Create call data for balanceOf(address)\n",
        "        call_data = create_pyusd_call_data('balanceOf', address)\n",
        "\n",
        "        # Prepare call parameters\n",
        "        call_params = {\n",
        "            \"to\": pyusd_address,\n",
        "            \"data\": call_data\n",
        "        }\n",
        "\n",
        "        # Execute call\n",
        "        result = w3_client.eth.call(call_params, block_identifier=block)\n",
        "\n",
        "        if result:\n",
        "            # Decode uint256 result\n",
        "            balance_raw = int(result.hex(), 16)\n",
        "            balance_pyusd = balance_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "            return balance_pyusd\n",
        "\n",
        "        return 0\n",
        "    except Exception as e:\n",
        "        console.print(f\"[warning]Error estimating PYUSD balance for {address}: {e}\", style=\"warning\")\n",
        "        return None\n",
        "\n",
        "def simulate_pyusd_transaction(function_name, from_addr, *params, gas_limit=None, gas_price=None, value=0, block=\"latest\", use_trace=True, network='mainnet'):\n",
        "    \"\"\"Simulates PYUSD transactions with an efficient hybrid approach.\"\"\"\n",
        "    w3_client = w3_clients.get(network)\n",
        "    if not w3_client or not w3_client.is_connected():\n",
        "        console.print(f\"[error]Web3 client for '{network}' not available or not connected.\", style=\"error\")\n",
        "        return None, None\n",
        "\n",
        "    # Track operation category for better analysis\n",
        "    operation_category = None\n",
        "    for category, functions in GAS_CATEGORIES.items():\n",
        "        if function_name in functions:\n",
        "            operation_category = category\n",
        "            break\n",
        "\n",
        "    if not operation_category:\n",
        "        operation_category = \"other\"\n",
        "\n",
        "    try:\n",
        "        # Validate addresses and create call data\n",
        "        from_checksum_addr = Web3.to_checksum_address(from_addr)\n",
        "        pyusd_checksum_address = PYUSD_CONFIG['ethereum']['address']\n",
        "        call_data = create_pyusd_call_data(function_name, *params)\n",
        "    except ValueError as e:\n",
        "         console.print(f\"[error]Invalid parameters for simulation: {e}\", style=\"error\")\n",
        "         return None, None\n",
        "\n",
        "    # Create a panel for transaction information\n",
        "    tx_panel_content = f\"[bold cyan3]Function:[/bold cyan3] [white]{function_name}()[/white]\\n\"\n",
        "    tx_panel_content += f\"[bold cyan3]From:[/bold cyan3] [white]{from_checksum_addr}[/white]\\n\"\n",
        "    tx_panel_content += f\"[bold cyan3]To:[/bold cyan3] [white]{pyusd_checksum_address}[/white]\\n\"\n",
        "    tx_panel_content += f\"[bold cyan3]Network:[/bold cyan3] [white]{network.capitalize()}[/white]\"\n",
        "\n",
        "    console.print(Panel(\n",
        "        tx_panel_content,\n",
        "        title=\"[bold]üîÑ Simulating PYUSD Transaction[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    # Check PYUSD balance for relevant operations\n",
        "    if function_name in ['transfer', 'transferFrom', 'burn', 'transferWithAuthorization', 'burnFrom']:\n",
        "        # For transfer and burn, check sender's balance\n",
        "        balance = None\n",
        "        check_address = from_addr\n",
        "\n",
        "        # For transferFrom and burnFrom, check the owner's balance (first param)\n",
        "        if function_name in ['transferFrom', 'burnFrom']:\n",
        "            check_address = params[0]\n",
        "\n",
        "        balance = estimate_pyusd_balance(check_address, block=block, network=network)\n",
        "\n",
        "        if balance is not None:\n",
        "            # Get amount from parameters based on function\n",
        "            amount_index = 1 if function_name in ['transfer', 'approve', 'transferWithAuthorization'] else 2 if function_name == 'transferFrom' else 0\n",
        "            if amount_index < len(params):\n",
        "                amount = params[amount_index]\n",
        "                if isinstance(amount, float):\n",
        "                    if balance < amount:\n",
        "                        console.print(Panel(\n",
        "                            f\"Address [bold]{shorten_address(check_address)}[/bold] has [bold red]insufficient[/bold red] PYUSD balance ([bold]{balance:.6f}[/bold]) for this operation ([bold]{amount:.6f}[/bold]).\",\n",
        "                            border_style=\"yellow\",\n",
        "                            box=box.ROUNDED\n",
        "                        ))\n",
        "                    else:\n",
        "                        console.print(Panel(\n",
        "                            f\"Address [bold]{shorten_address(check_address)}[/bold] has [bold green]sufficient[/bold green] PYUSD balance ([bold]{balance:.6f}[/bold]) for this operation ([bold]{amount:.6f}[/bold]).\",\n",
        "                            border_style=\"green\",\n",
        "                            box=box.ROUNDED\n",
        "                        ))\n",
        "\n",
        "    # Prepare transaction parameters\n",
        "    call_params = {\n",
        "        \"from\": from_checksum_addr,\n",
        "        \"to\": pyusd_checksum_address,\n",
        "        \"data\": call_data,\n",
        "    }\n",
        "\n",
        "    # Add optional parameters if provided\n",
        "    if value > 0:\n",
        "        call_params[\"value\"] = hex(value)\n",
        "    if gas_limit:\n",
        "        call_params[\"gas\"] = hex(gas_limit)\n",
        "    if gas_price:\n",
        "        call_params[\"gasPrice\"] = hex(gas_price)\n",
        "\n",
        "    # STEP 1: Always try eth.call first - guaranteed to work\n",
        "    console.print(\"\\n\\n[info]Running basic transaction simulation...\", style=\"info\")\n",
        "    try:\n",
        "        result = w3_client.eth.call(call_params, block_identifier=block)\n",
        "        success = True\n",
        "        output = result.hex() if result else '0x'\n",
        "    except Exception as e:\n",
        "        success = False\n",
        "        error_msg = str(e)\n",
        "        console.print(f\"[warning]Transaction simulation revealed error: {error_msg}\", style=\"warning\")\n",
        "        output = None\n",
        "\n",
        "    # STEP 2: Try to estimate gas if call succeeded, or even if it failed due to balance\n",
        "    gas_used = 0\n",
        "    hypothetical_success = False\n",
        "\n",
        "    if success or (not success and error_msg == \"0x356680b7\"):  # If successful or just a balance issue\n",
        "        try:\n",
        "            # Try to estimate gas usage\n",
        "            console.print(\"[info]Estimating gas usage...\", style=\"info\")\n",
        "            gas_estimated = w3_client.eth.estimate_gas({\n",
        "                **call_params,\n",
        "                \"value\": 0  # Ensure no ETH is sent\n",
        "            })\n",
        "            gas_used = gas_estimated\n",
        "\n",
        "            if not success and error_msg == \"0x356680b7\":\n",
        "                hypothetical_success = True\n",
        "                console.print(\"[info]Transaction would likely succeed with sufficient balance.\", style=\"info\")\n",
        "        except Exception as gas_err:\n",
        "            # Couldn't estimate gas\n",
        "            console.print(f\"[warning]Could not estimate gas: {gas_err}\", style=\"warning\")\n",
        "\n",
        "    # STEP 3: Advanced trace analysis if requested\n",
        "    trace_result = None\n",
        "    if use_trace and (success or hypothetical_success):\n",
        "        console.print(\"[info]Attempting detailed transaction trace analysis...\", style=\"info\")\n",
        "\n",
        "        # Configure trace parameters based on mode\n",
        "        tracer_config = TRACE_CONFIGS[\"callTracer\"]\n",
        "\n",
        "        # Try multiple trace call parameter formats to maximize compatibility\n",
        "        trace_formats = [\n",
        "            # Format 1: Simple params array\n",
        "            [call_params, block],\n",
        "\n",
        "            # Format 2: With tracer specified\n",
        "            [call_params, block, \"callTracer\"],\n",
        "\n",
        "            # Format 3: Full tracer config\n",
        "            [call_params, block, {\"tracer\": \"callTracer\", \"tracerConfig\": tracer_config}],\n",
        "\n",
        "            # Format 4: Object format for Google RPC\n",
        "            {\n",
        "                \"transaction\": call_params,\n",
        "                \"blockNumber\": block if block != \"latest\" else \"latest\",\n",
        "                \"tracer\": \"callTracer\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        for i, trace_params in enumerate(trace_formats):\n",
        "            try:\n",
        "                console.print(f\"[info]Trying trace format {i+1}...\", style=\"info\")\n",
        "                trace_result = make_rpc_request(\"debug_traceCall\", trace_params, network=network)\n",
        "                if trace_result:\n",
        "                    console.print(\"[success]Successfully obtained transaction trace.\", style=\"success\")\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                console.print(f\"[warning]Trace format {i+1} failed: {e}\", style=\"warning\")\n",
        "\n",
        "        if not trace_result:\n",
        "            # Try alternate RPC method as last resort\n",
        "            try:\n",
        "                console.print(\"[info]Trying alternate tracing method...\", style=\"info\")\n",
        "                trace_result = make_rpc_request(\"trace_call\", trace_formats[0], network=network)\n",
        "                if trace_result:\n",
        "                    console.print(\"[success]Successfully obtained transaction trace using alternate method.\", style=\"success\")\n",
        "            except Exception as e:\n",
        "                console.print(f\"[warning]All trace methods failed: {e}\", style=\"warning\")\n",
        "\n",
        "    # Create analysis from the available data\n",
        "    analysis = {\n",
        "        'function': function_name,\n",
        "        'params': params,\n",
        "        'success': success,\n",
        "        'hypothetical_success': hypothetical_success,\n",
        "        'gas_used': gas_used,\n",
        "        'operation_category': operation_category,\n",
        "        'gas_category': categorize_gas_usage(function_name, gas_used),\n",
        "        'error': None,\n",
        "        'state_changes': [],\n",
        "        'output': output,\n",
        "        'calls': [],\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Handle error decoding\n",
        "    if not success:\n",
        "        # Decode error if it looks like a hex code\n",
        "        if isinstance(error_msg, str) and error_msg.startswith(\"0x\"):\n",
        "            decoded_error = decode_erc20_error(error_msg)\n",
        "            analysis['error'] = decoded_error\n",
        "\n",
        "            # Special handling for balance errors\n",
        "            if error_msg == \"0x356680b7\":\n",
        "                analysis['note'] = \"This transaction would succeed if the address had sufficient PYUSD balance.\"\n",
        "        else:\n",
        "            analysis['error'] = error_msg\n",
        "\n",
        "    # Add trace data if available\n",
        "    if trace_result:\n",
        "        # Extract relevant data from trace if available\n",
        "        if isinstance(trace_result, dict):\n",
        "            # Extract gas usage from trace if available\n",
        "            if 'gasUsed' in trace_result:\n",
        "                gas_used_value = trace_result['gasUsed']\n",
        "                analysis['gas_used'] = int(gas_used_value, 16) if isinstance(gas_used_value, str) and gas_used_value.startswith('0x') else int(gas_used_value)\n",
        "\n",
        "            # Extract internal calls\n",
        "            if 'calls' in trace_result and isinstance(trace_result['calls'], list):\n",
        "                analysis['calls'] = trace_result['calls']\n",
        "\n",
        "                # Extract state changes from internal calls\n",
        "                for call in trace_result['calls']:\n",
        "                    # Look for events, logs, or storage changes\n",
        "                    if 'logs' in call and isinstance(call['logs'], list):\n",
        "                        for log in call['logs']:\n",
        "                            if 'address' in log and log['address'].lower() == PYUSD_CONFIG['ethereum']['address'].lower():\n",
        "                                # This is a PYUSD log\n",
        "                                if 'topics' in log and log['topics']:\n",
        "                                    # Check if it's a Transfer event\n",
        "                                    topic0 = log['topics'][0]\n",
        "                                    if topic0 == PYUSD_CONFIG['ethereum']['transfer_event_topic']:\n",
        "                                        try:\n",
        "                                            from_addr = Web3.to_checksum_address('0x' + log['topics'][1][-40:])\n",
        "                                            to_addr = Web3.to_checksum_address('0x' + log['topics'][2][-40:])\n",
        "                                            value_raw = int(log['data'], 16)\n",
        "                                            value_pyusd = value_raw / (10**PYUSD_CONFIG['ethereum']['decimals'])\n",
        "\n",
        "                                            analysis['state_changes'].append({\n",
        "                                                'type': 'transfer',\n",
        "                                                'from': from_addr,\n",
        "                                                'to': to_addr,\n",
        "                                                'amount': value_pyusd\n",
        "                                            })\n",
        "                                        except Exception as e:\n",
        "                                            console.print(f\"[warning]Could not decode Transfer event: {e}\", style=\"warning\")\n",
        "\n",
        "    # Decode function outputs for view functions\n",
        "    if success and function_name in ['balanceOf', 'allowance', 'totalSupply', 'decimals']:\n",
        "        try:\n",
        "            if output and output != '0x':\n",
        "                output_raw = int(output, 16)\n",
        "                if function_name in ['balanceOf', 'allowance', 'totalSupply']:\n",
        "                    # Convert raw value to PYUSD\n",
        "                    decimals = PYUSD_CONFIG['ethereum']['decimals']\n",
        "                    output_value = output_raw / (10**decimals)\n",
        "                    analysis['decoded_output'] = output_value\n",
        "                else:\n",
        "                    analysis['decoded_output'] = output_raw\n",
        "        except Exception as e:\n",
        "            analysis['output_error'] = str(e)\n",
        "\n",
        "    # Display analysis results\n",
        "    display_simulation_analysis(analysis, function_name, params, from_address=from_checksum_addr)\n",
        "\n",
        "    # Export simulation data if requested\n",
        "    if success or hypothetical_success:\n",
        "        # Create export options with detailed simulation data\n",
        "        create_comparison_export([analysis], function_name, from_checksum_addr)\n",
        "\n",
        "    return output, analysis\n",
        "\n",
        "def display_simulation_analysis(analysis, function_name, params, from_address=None):\n",
        "    \"\"\"Displays the results of the simulation analysis in a user-friendly format.\"\"\"\n",
        "    # Create a visual divider\n",
        "    console.print(\"\\n\\n[bold]üîç PYUSD Transaction Simulation Analysis[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Create function information panel\n",
        "    function_info = []\n",
        "\n",
        "    # Function name with styling\n",
        "    function_info.append(f\"[bold cyan3]Function:[/bold cyan3] [bold white]{function_name}()[/bold white]\")\n",
        "\n",
        "    # Format parameters based on function\n",
        "    if function_name == 'transfer':\n",
        "        to_addr = params[0]\n",
        "        amount = params[1]\n",
        "        function_info.append(f\"[bold cyan3]From:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'approve':\n",
        "        spender = params[0]\n",
        "        amount = params[1]\n",
        "        function_info.append(f\"[bold cyan3]Owner:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{spender}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'transferFrom':\n",
        "        from_addr = params[0]\n",
        "        to_addr = params[1]\n",
        "        amount = params[2]\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]From:[/bold cyan3] [white]{from_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'balanceOf':\n",
        "        address = params[0]\n",
        "        function_info.append(f\"[bold cyan3]Address:[/bold cyan3] [white]{address}[/white]\")\n",
        "    elif function_name == 'allowance':\n",
        "        owner = params[0]\n",
        "        spender = params[1]\n",
        "        function_info.append(f\"[bold cyan3]Owner:[/bold cyan3] [white]{owner}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{spender}[/white]\")\n",
        "    elif function_name == 'mint':\n",
        "        to_addr = params[0]\n",
        "        amount = params[1]\n",
        "        function_info.append(f\"[bold cyan3]Minter:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'burn':\n",
        "        amount = params[0]\n",
        "        function_info.append(f\"[bold cyan3]Burner:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "    elif function_name == 'transferWithAuthorization':\n",
        "        to_addr = params[1]\n",
        "        amount = params[2]\n",
        "        function_info.append(f\"[bold cyan3]Authorized From:[/bold cyan3] [white]{params[0]}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]To:[/bold cyan3] [white]{to_addr}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Executor:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "    elif function_name == 'permit':\n",
        "        owner = params[1]\n",
        "        spender = params[1]\n",
        "        amount = params[2]\n",
        "        function_info.append(f\"[bold cyan3]Owner:[/bold cyan3] [white]{owner}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Spender:[/bold cyan3] [white]{spender}[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Amount:[/bold cyan3] [white]{amount:,.2f} PYUSD[/white]\")\n",
        "        function_info.append(f\"[bold cyan3]Submitter:[/bold cyan3] [white]{from_address}[/white]\")\n",
        "\n",
        "    # Create transaction result information\n",
        "    transaction_info = []\n",
        "\n",
        "    # Status with appropriate coloring\n",
        "    status_color = \"green3\" if analysis['success'] else \"yellow3\" if analysis['hypothetical_success'] else \"red3\"\n",
        "    status_text = \"Success\" if analysis['success'] else \"Hypothetical Success\" if analysis['hypothetical_success'] else \"Failed\"\n",
        "    transaction_info.append(f\"[bold cyan3]Status:[/bold cyan3] [{status_color}]{status_text}[/{status_color}]\")\n",
        "\n",
        "    # Operation category\n",
        "    transaction_info.append(f\"[bold cyan3]Category:[/bold cyan3] [white]{analysis['operation_category'].title()}[/white]\")\n",
        "\n",
        "    # Error message if any\n",
        "    if analysis['error']:\n",
        "        transaction_info.append(f\"[bold cyan3]Error:[/bold cyan3] [red3]{analysis['error']}[/red3]\")\n",
        "\n",
        "    # Additional notes if any\n",
        "    if 'note' in analysis:\n",
        "        transaction_info.append(f\"[bold cyan3]Note:[/bold cyan3] [yellow3]{analysis['note']}[/yellow3]\")\n",
        "\n",
        "    # Gas usage\n",
        "    transaction_info.append(f\"[bold cyan3]Gas Used:[/bold cyan3] [white]{analysis['gas_used']:,}[/white]\")\n",
        "    transaction_info.append(f\"[bold cyan3]Gas Profile:[/bold cyan3] [white]{analysis['gas_category']}[/white]\")\n",
        "\n",
        "    # Output data for view functions\n",
        "    if 'decoded_output' in analysis:\n",
        "        if function_name in ['balanceOf', 'allowance', 'totalSupply']:\n",
        "            transaction_info.append(f\"[bold cyan3]Result:[/bold cyan3] [green3]{analysis['decoded_output']:,.6f} PYUSD[/green3]\")\n",
        "        else:\n",
        "            transaction_info.append(f\"[bold cyan3]Result:[/bold cyan3] [green3]{analysis['decoded_output']}[/green3]\")\n",
        "    elif analysis['output']:\n",
        "        transaction_info.append(f\"[bold cyan3]Raw Output:[/bold cyan3] [dim white]{analysis['output']}[/dim white]\")\n",
        "\n",
        "    # Internal Calls Count if available\n",
        "    if 'calls' in analysis and analysis['calls']:\n",
        "        transaction_info.append(f\"[bold cyan3]Internal Calls:[/bold cyan3] [white]{len(analysis['calls'])}[/white]\")\n",
        "\n",
        "    # Create panels for better visual separation\n",
        "    function_panel = Panel(\n",
        "        \"\\n\".join(function_info),\n",
        "        title=\"[bold]Transaction Details[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    )\n",
        "\n",
        "    result_panel = Panel(\n",
        "        \"\\n\".join(transaction_info),\n",
        "        title=\"[bold]Execution Results[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    )\n",
        "\n",
        "    # Display panels side by side if possible, otherwise stacked\n",
        "    console.print(Group(function_panel, result_panel))\n",
        "\n",
        "    # Display state changes if any\n",
        "    if analysis['state_changes']:\n",
        "        console.print(\"\\n[bold cyan3]State Changes:[/bold cyan3]\")\n",
        "\n",
        "        state_table = Table(show_header=True, header_style=\"bold cyan3\", box=box.ROUNDED)\n",
        "        state_table.add_column(\"Type\", style=\"cyan3\")\n",
        "        state_table.add_column(\"Details\", style=\"white\")\n",
        "\n",
        "        for change in analysis['state_changes']:\n",
        "            if change['type'] == 'transfer':\n",
        "                from_addr = shorten_address(change['from'])\n",
        "                to_addr = shorten_address(change['to'])\n",
        "                amount = change['amount']\n",
        "                details = f\"{amount:,.2f} PYUSD from {from_addr} to {to_addr}\"\n",
        "                state_table.add_row(\"Transfer\", details)\n",
        "            else:\n",
        "                state_table.add_row(change['type'].title(), str(change))\n",
        "\n",
        "        console.print(Panel(state_table, title=\"[bold]State Changes[/bold]\", border_style=\"cyan\", box=box.ROUNDED))\n",
        "\n",
        "    # Create transaction flow diagram for transfers\n",
        "    if from_address and function_name in ['transfer', 'transferFrom', 'mint', 'burn', 'transferWithAuthorization', 'permit'] and (analysis['success'] or analysis['hypothetical_success']):\n",
        "        try:\n",
        "            console.print(\"\\n\\n[bold magenta3]Transaction Flow Visualization:[/bold magenta3]\")\n",
        "            console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"magenta3\")\n",
        "\n",
        "            flow_graph = Digraph(comment=f\"PYUSD {function_name} Flow\", format='png')\n",
        "            flow_graph.attr(rankdir='TB', bgcolor='transparent')\n",
        "            flow_graph.attr('node', shape='box', style='filled', fontname='helvetica', fontsize='10')\n",
        "\n",
        "            if function_name == 'transfer':\n",
        "                sender_addr = from_address\n",
        "                to_addr = params[0]\n",
        "                amount = params[1]\n",
        "\n",
        "                flow_graph.node('sender', f\"Sender\\n{sender_addr}\", fillcolor='lightblue')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{to_addr}\", fillcolor='palegreen')\n",
        "                flow_graph.edge('sender', 'receiver', label=f\"{amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'transferFrom':\n",
        "                owner_addr = params[0]\n",
        "                to_addr = params[1]\n",
        "                amount = params[2]\n",
        "                sender_addr = from_address\n",
        "\n",
        "                flow_graph.node('owner', f\"Owner\\n{owner_addr}\", fillcolor='lightblue')\n",
        "                flow_graph.node('spender', f\"Spender\\n{sender_addr}\", fillcolor='lightyellow')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{to_addr}\", fillcolor='palegreen')\n",
        "\n",
        "                flow_graph.edge('spender', 'owner', label=\"1. Has Allowance\")\n",
        "                flow_graph.edge('owner', 'receiver', label=f\"2. {amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'mint':\n",
        "                to_addr = params[0]\n",
        "                amount = params[1]\n",
        "\n",
        "                flow_graph.node('minter', f\"Minter\\n{shorten_address(from_address)}\", fillcolor='lightcoral')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{shorten_address(to_addr)}\", fillcolor='palegreen')\n",
        "                flow_graph.node('supply', \"PYUSD Supply\", fillcolor='lightcyan')\n",
        "\n",
        "                flow_graph.edge('minter', 'supply', label=f\"1. Increases by {amount:,.2f}\")\n",
        "                flow_graph.edge('supply', 'receiver', label=f\"2. {amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'burn':\n",
        "                amount = params[0]\n",
        "\n",
        "                flow_graph.node('burner', f\"Burner\\n{shorten_address(from_address)}\", fillcolor='lightcoral')\n",
        "                flow_graph.node('supply', \"PYUSD Supply\", fillcolor='lightcyan')\n",
        "\n",
        "                flow_graph.edge('burner', 'supply', label=f\"Burns {amount:,.2f} PYUSD\")\n",
        "                flow_graph.edge('supply', 'null', label=f\"Decreases by {amount:,.2f}\", style='dashed')\n",
        "\n",
        "            elif function_name == 'transferWithAuthorization':\n",
        "                from_addr = params[0]\n",
        "                to_addr = params[1]\n",
        "                amount = params[2]\n",
        "\n",
        "                flow_graph.node('owner', f\"Owner\\n{from_addr}\", fillcolor='lightblue')\n",
        "                flow_graph.node('executor', f\"Executor\\n{from_address}\", fillcolor='lightyellow')\n",
        "                flow_graph.node('receiver', f\"Receiver\\n{to_addr}\", fillcolor='palegreen')\n",
        "\n",
        "                flow_graph.edge('owner', 'executor', label=\"1. Authorization\")\n",
        "                flow_graph.edge('executor', 'receiver', label=f\"2. {amount:,.2f} PYUSD\")\n",
        "\n",
        "            elif function_name == 'permit':\n",
        "                owner = params[0]\n",
        "                spender = params[1]\n",
        "                amount = params[2]\n",
        "\n",
        "                flow_graph.node('owner', f\"Owner\\n{owner}\", fillcolor='lightblue')\n",
        "                flow_graph.node('spender', f\"Spender\\n{spender}\", fillcolor='palegreen')\n",
        "                flow_graph.node('submitter', f\"Submitter\\n{from_address}\", fillcolor='lightyellow')\n",
        "\n",
        "                flow_graph.edge('owner', 'submitter', label=\"1. Signed Permit\")\n",
        "                flow_graph.edge('submitter', 'spender', label=f\"2. Approve {amount:,.2f} PYUSD\")\n",
        "\n",
        "            display(flow_graph)\n",
        "\n",
        "        except Exception as viz_err:\n",
        "            console.print(f\"[warning]Could not create flow visualization: {viz_err}\", style=\"warning\")\n",
        "\n",
        "def compare_pyusd_transactions(function_name, from_addr, param_sets, network='mainnet'):\n",
        "    \"\"\"Compares multiple PYUSD transaction simulations with different parameters.\"\"\"\n",
        "    # Create a visual divider for the comparison section\n",
        "    console.print(\"\\n\\n[bold]üîÑ PYUSD Transaction Comparison[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Display function being compared\n",
        "    console.print(Panel(\n",
        "        f\"[bold white]Function:[/bold white] [cyan3]{function_name}()[/cyan3]\\n\"\n",
        "        f\"[bold white]From:[/bold white] [cyan3]{from_addr}[/cyan3]\\n\"\n",
        "        f\"[bold white]Network:[/bold white] [cyan3]{network.capitalize()}[/cyan3]\\n\"\n",
        "        f\"[bold white]Variants:[/bold white] [cyan3]{len(param_sets)}[/cyan3]\",\n",
        "        title=\"[bold]Comparison Parameters[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, params in enumerate(param_sets):\n",
        "        # Create visual separator between variants\n",
        "        console.print(f\"\\n\\n[bold cyan3]Variant {i+1}[/bold cyan3]: {params}\")\n",
        "        sim_result, analysis = simulate_pyusd_transaction(function_name, from_addr, *params, network=network)\n",
        "\n",
        "        if analysis:\n",
        "            # Store result for comparison\n",
        "            variant_name = f\"Variant {i+1}\"\n",
        "            results.append({\n",
        "                \"variant\": variant_name,\n",
        "                \"params\": params,\n",
        "                \"success\": analysis['success'],\n",
        "                \"hypothetical_success\": analysis.get('hypothetical_success', False),\n",
        "                \"gas_used\": analysis['gas_used'],\n",
        "                \"gas_category\": analysis.get('gas_category', 'Unknown'),\n",
        "                \"error\": analysis['error']\n",
        "            })\n",
        "\n",
        "    # Create comparison table\n",
        "    if results:\n",
        "        # Final comparison header\n",
        "        console.print(\"\\n\\n[bold]üìä Comparison Results[/bold]\", style=\"cyan3\")\n",
        "        console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "        comp_table = Table(show_header=True, header_style=\"bold cyan3\", box=box.ROUNDED)\n",
        "        comp_table.add_column(\"Variant\", style=\"cyan3\")\n",
        "\n",
        "        # Add parameter columns based on function\n",
        "        if function_name == 'transfer' or function_name == 'approve':\n",
        "            comp_table.add_column(\"Recipient/Spender\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'transferFrom':\n",
        "            comp_table.add_column(\"From\", style=\"white\")\n",
        "            comp_table.add_column(\"To\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'mint':\n",
        "            comp_table.add_column(\"To\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'burn':\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'transferWithAuthorization':\n",
        "            comp_table.add_column(\"From\", style=\"white\")\n",
        "            comp_table.add_column(\"To\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "        elif function_name == 'permit':\n",
        "            comp_table.add_column(\"Owner\", style=\"white\")\n",
        "            comp_table.add_column(\"Spender\", style=\"white\")\n",
        "            comp_table.add_column(\"Amount\", style=\"white\")\n",
        "\n",
        "        comp_table.add_column(\"Status\")\n",
        "        comp_table.add_column(\"Gas Used\", style=\"white\")\n",
        "        comp_table.add_column(\"Gas Profile\", style=\"white\")\n",
        "\n",
        "        for result in results:\n",
        "            row = [result[\"variant\"]]\n",
        "\n",
        "            # Add parameter values\n",
        "            params = result[\"params\"]\n",
        "            if function_name == 'transfer' or function_name == 'approve':\n",
        "                row.append(params[0])\n",
        "                row.append(f\"{params[1]:,.2f}\")\n",
        "            elif function_name == 'transferFrom':\n",
        "                row.append(params[0])\n",
        "                row.append(params[1])\n",
        "                row.append(f\"{params[2]:,.2f}\")\n",
        "            elif function_name == 'mint':\n",
        "                row.append(params[0])\n",
        "                row.append(f\"{params[1]:,.2f}\")\n",
        "            elif function_name == 'burn':\n",
        "                row.append(f\"{params[0]:,.2f}\")\n",
        "            elif function_name == 'transferWithAuthorization':\n",
        "                row.append(params[0])\n",
        "                row.append(params[1])\n",
        "                row.append(f\"{params[2]:,.2f}\")\n",
        "            elif function_name == 'permit':\n",
        "                row.append(params[0])\n",
        "                row.append(params[1])\n",
        "                row.append(f\"{params[2]:,.2f}\")\n",
        "\n",
        "            # Add status and gas\n",
        "            status_color = \"green3\" if result[\"success\"] else \"yellow3\" if result[\"hypothetical_success\"] else \"red3\"\n",
        "            status_text = \"Success\" if result[\"success\"] else \"Hypothetical Success\" if result[\"hypothetical_success\"] else \"Failed\"\n",
        "            row.append(f\"[{status_color}]{status_text}[/{status_color}]\")\n",
        "            row.append(f\"{result['gas_used']:,}\")\n",
        "            row.append(result[\"gas_category\"])\n",
        "\n",
        "            comp_table.add_row(*row)\n",
        "\n",
        "        console.print(Panel(comp_table, border_style=\"cyan3\", box=box.ROUNDED))\n",
        "\n",
        "        # Create gas comparison chart\n",
        "        create_gas_comparison_chart(results, function_name)\n",
        "\n",
        "        # Create export options for comparison results\n",
        "        create_comparison_export(results, function_name, from_addr)\n",
        "\n",
        "    return results\n",
        "\n",
        "def batch_simulate_pyusd_transactions(from_addr, batch_operations, network='mainnet'):\n",
        "    \"\"\"Simulates a batch of PYUSD transactions in sequence.\"\"\"\n",
        "    # Create a visual divider for the batch simulation\n",
        "    console.print(\"\\n\\n[bold]üîÑ PYUSD Batch Transaction Simulation[/bold]\", style=\"cyan3\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"cyan3\")\n",
        "\n",
        "    # Display batch information\n",
        "    console.print(Panel(\n",
        "        f\"[bold white]From Address:[/bold white] [cyan3]{from_addr}[/cyan3]\\n\"\n",
        "        f\"[bold white]Network:[/bold white] [cyan3]{network.capitalize()}[/cyan3]\\n\"\n",
        "        f\"[bold white]Batch Size:[/bold white] [cyan3]{len(batch_operations)}[/cyan3]\",\n",
        "        title=\"[bold]Batch Parameters[/bold]\",\n",
        "        border_style=\"cyan3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    results = []\n",
        "    total_gas = 0\n",
        "    batch_success = True\n",
        "\n",
        "    # Run each simulation in the batch\n",
        "    for i, (function_name, params) in enumerate(batch_operations):\n",
        "        console.print(f\"\\n\\n[bold cyan3]Operation {i+1}/{len(batch_operations)}[/bold cyan3]: {function_name}{params}\")\n",
        "\n",
        "        # Convert params to a proper list if it's not already\n",
        "        params_list = list(params) if isinstance(params, (list, tuple)) else [params]\n",
        "\n",
        "        # Simulate this transaction\n",
        "        sim_result, analysis = simulate_pyusd_transaction(function_name, from_addr, *params_list, network=network)\n",
        "\n",
        "        # Store result\n",
        "        results.append(analysis)\n",
        "\n",
        "        # Update batch statistics\n",
        "        if analysis['success'] or analysis.get('hypothetical_success', False):\n",
        "            total_gas += analysis['gas_used']\n",
        "        else:\n",
        "            batch_success = False\n",
        "            # Stop batch if a transaction fails\n",
        "            console.print(Panel(\n",
        "                f\"[bold red]Batch simulation stopped at operation {i+1} due to failure[/bold red]\\n\"\n",
        "                f\"Function: {function_name}\\n\"\n",
        "                f\"Error: {analysis['error']}\",\n",
        "                title=\"[bold]Batch Failure[/bold]\",\n",
        "                border_style=\"red\",\n",
        "                box=box.ROUNDED\n",
        "            ))\n",
        "            break\n",
        "\n",
        "    # Display batch summary\n",
        "    status_color = \"green\" if batch_success else \"red\"\n",
        "    status_text = \"Success\" if batch_success else \"Failed\"\n",
        "\n",
        "    console.print(Panel(\n",
        "        f\"[bold white]Total Operations:[/bold white] [cyan]{len(results)}/{len(batch_operations)}[/cyan]\\n\"\n",
        "        f\"[bold white]Batch Status:[/bold white] [{status_color}]{status_text}[/{status_color}]\\n\"\n",
        "        f\"[bold white]Total Gas:[/bold white] [cyan]{total_gas:,}[/cyan]\",\n",
        "        title=\"[bold]Batch Summary[/bold]\",\n",
        "        border_style=\"cyan\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    # Create visualization for batch gas usage\n",
        "    create_batch_gas_chart(results, total_gas)\n",
        "\n",
        "    # Create export options for batch results\n",
        "    create_batch_export(results, from_addr)\n",
        "\n",
        "    return results\n",
        "\n",
        "# =============================================================================================\n",
        "# üöÄ Interactive Demo Section\n",
        "# =============================================================================================\n",
        "\n",
        "def run_pyusd_simulations():\n",
        "    \"\"\"Run a series of PYUSD transaction simulations with enhanced UI display.\"\"\"\n",
        "    # Addresses with PYUSD balance (publicly available on blockchain)\n",
        "    PYUSD_HOLDER_ADDRESSES = [\n",
        "        \"0xf845a0A05Cbd91Ac15C3E59D126DE5dFbC2aAbb7\",  # Primary simulation address\n",
        "        \"0xad6452a9b8F10b0fE084C83c396ABAe96411C761\",\n",
        "        \"0x51C72848c68a965f66FA7a88855F9f7784502a7F\",\n",
        "        \"0x4bb41165A817628992ee40ea8e92F8800f143FbD\",\n",
        "        \"0x3519eE4d387150F230BaCa90f5C50E9d296164c6\"\n",
        "    ]\n",
        "\n",
        "    # Use first address with balance for simulations\n",
        "    SIM_FROM_ADDR = PYUSD_HOLDER_ADDRESSES[0]\n",
        "    SIM_TO_ADDR = \"0x5754284f345afc66a98fbB0a0Afe71e0F007B949\"  # Example recipient\n",
        "    SIM_AMOUNT = 100.0  # Amount of PYUSD\n",
        "\n",
        "    # Create a visually appealing header\n",
        "    console.print(\"\\n\\n[bold]üß™ Advanced PYUSD Transaction Simulator[/bold]\", style=\"chartreuse1\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"[bold chartreuse1]This Cell simulates PYUSD transactions against the Ethereum blockchain[/bold chartreuse1]\\n\"\n",
        "        \"[white]Test various ERC-20 operations without executing actual transactions[/white]\\n\\n\"\n",
        "        \"[bold yellow3]Features:[/bold yellow3]\\n\"\n",
        "        \"‚Ä¢ Reliable transaction simulation with advanced tracing\\n\"\n",
        "        \"‚Ä¢ Gas usage analysis and optimization recommendations\\n\"\n",
        "        \"‚Ä¢ Detailed state change tracking\\n\"\n",
        "        \"‚Ä¢ Multi-format data export options\\n\"\n",
        "        \"‚Ä¢ Batch transaction simulation\\n\"\n",
        "        \"‚Ä¢ Support for advanced PYUSD operations\",\n",
        "        title=\"[bold]Transaction Simulator Information[/bold]\",\n",
        "        subtitle=\"[dim]Powered by Google Blockchain RPC[/dim]\",\n",
        "        border_style=\"chartreuse1\",\n",
        "        box=box.ROUNDED,\n",
        "        padding=(1, 2)\n",
        "    ))\n",
        "\n",
        "    # Add disclaimer in a panel\n",
        "    console.print(\"\\n\\n[bold]‚ö†Ô∏è Disclaimer[/bold]\", style=\"yellow3\")\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"‚Ä¢ This is a [bold]read-only simulation tool[/bold]. No actual transactions are executed.\\n\"\n",
        "        \"‚Ä¢ The addresses used contain real PYUSD balances found on the public blockchain.\\n\"\n",
        "        \"‚Ä¢ This tool is for [bold]educational and testing purposes only[/bold].\\n\"\n",
        "        \"‚Ä¢ All simulations are performed against blockchain data without modifying any state.\\n\"\n",
        "        \"‚Ä¢ The trace_call API optimizations maximize Google's blockchain RPC capabilities.\",\n",
        "        title=\"[bold yellow3]DISCLAIMER[/bold yellow3]\",\n",
        "        border_style=\"yellow3\",\n",
        "        box=box.ROUNDED\n",
        "    ))\n",
        "\n",
        "    console.print(\"\\n\")  # Add spacing\n",
        "\n",
        "    # 1. Transfer simulation\n",
        "    console.print(\"\\n\\n[bold chartreuse1]1. PYUSD Transfer Simulation[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    sim_result, sim_analysis = simulate_pyusd_transaction(\n",
        "        'transfer', SIM_FROM_ADDR, SIM_TO_ADDR, SIM_AMOUNT, network='mainnet'\n",
        "    )\n",
        "\n",
        "    # 2. PYUSD Balance check simulation\n",
        "    console.print(\"\\n\\n[bold chartreuse1]2. PYUSD Balance Check Simulation[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    sim_result_balance, sim_analysis_balance = simulate_pyusd_transaction(\n",
        "        'balanceOf', SIM_FROM_ADDR, SIM_FROM_ADDR, network='mainnet'\n",
        "    )\n",
        "\n",
        "    # 3. PYUSD Transfer Amount Comparison\n",
        "    console.print(\"\\n\\n[bold chartreuse1]3. PYUSD Transfer Amount Comparison[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    compare_results = compare_pyusd_transactions(\n",
        "        'transfer',\n",
        "        SIM_FROM_ADDR,\n",
        "        [\n",
        "            (SIM_TO_ADDR, 10000.0),\n",
        "            (SIM_TO_ADDR, 3000.0),\n",
        "            (SIM_TO_ADDR, 200.0)\n",
        "        ],\n",
        "        network='mainnet'\n",
        "    )\n",
        "\n",
        "    # 4. Batch Transaction Simulation\n",
        "    console.print(\"\\n\\n[bold chartreuse1]4. PYUSD Batch Transaction Simulation[/bold chartreuse1]\")\n",
        "    console.print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\", style=\"chartreuse1\")\n",
        "\n",
        "    batch_operations = [\n",
        "        ('balanceOf', [SIM_FROM_ADDR]),\n",
        "        ('transfer', [SIM_TO_ADDR, 50.0]),\n",
        "        ('approve', [SIM_TO_ADDR, 200.0]),\n",
        "    ]\n",
        "    batch_results = batch_simulate_pyusd_transactions(\n",
        "        SIM_FROM_ADDR,\n",
        "        batch_operations,\n",
        "        network='mainnet'\n",
        "    )\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"[cyan3]Simulation completed successfully![/cyan3]\\n\\n\"\n",
        "        \"[white]This cell demonstrates advanced PYUSD transaction simulation capabilities:[/white]\\n\"\n",
        "        \"‚Ä¢ [bold]Basic Transfer[/bold]: Simple PYUSD transfer with gas estimation\\n\"\n",
        "        \"‚Ä¢ [bold]Balance Check[/bold]: View operation with result decoding\\n\"\n",
        "        \"‚Ä¢ [bold]Transaction Comparison[/bold]: Gas usage analysis across different amounts\\n\"\n",
        "        \"‚Ä¢ [bold]Batch Operations[/bold]: Multiple operations simulated in sequence\\n\\n\"\n",
        "        \"[white]All results can be exported in CSV, JSON, or Google Sheets formats.[/white]\",\n",
        "        border_style=\"green3\",\n",
        "        box=box.ROUNDED,\n",
        "        title=\"[bold]üéâ Simulation Complete[/bold]\"\n",
        "    ))\n",
        "\n",
        "# Execute the simulations\n",
        "run_pyusd_simulations()"
      ],
      "metadata": {
        "id": "0ZBvghirsuew"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}